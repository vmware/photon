From 725ac7c54935bbff858092e2db302afe88062162 Mon Sep 17 00:00:00 2001
From: Alexey Makhalov <amakhalov@vmware.com>
Date: Tue, 9 May 2017 12:39:18 -0700
Subject: [PATCH] x86/vmware: pv-ops clocksource

---
 arch/x86/kernel/cpu/vmware.c | 21 +++++++++++++++++++++
 1 file changed, 21 insertions(+)

diff --git a/arch/x86/kernel/cpu/vmware.c b/arch/x86/kernel/cpu/vmware.c
index 70b8c4614e22..987ac571d16c 100644
--- a/arch/x86/kernel/cpu/vmware.c
+++ b/arch/x86/kernel/cpu/vmware.c
@@ -155,6 +155,26 @@ static void __init vmware_cyc2ns_setup(void)
 	pr_info("using clock offset of %llu ns\n", d->cyc2ns_offset);
 }
 
+static cycle_t vmware_clock_get_cycles(struct clocksource *cs)
+{
+	return (cycle_t)rdtsc_ordered();
+}
+
+static struct clocksource clocksource_vmware = {
+	.name = "vmware-clock",
+	.read = vmware_clock_get_cycles,
+	.rating = 400,
+	.mask = CLOCKSOURCE_MASK(64),
+	.flags = CLOCK_SOURCE_IS_CONTINUOUS,
+};
+
+/* We want to use clocksource_vmware from the beginning to avoid drifting in
+   monotonic clock */
+struct clocksource * __init clocksource_default_clock(void)
+{
+	return &clocksource_vmware;
+}
+
 static uint64_t vmware_steal_clock(int cpu)
 {
 	struct vmware_steal_time *steal;
@@ -290,6 +310,7 @@ static void __init vmware_paravirt_ops_setup(void)
 		vmware_guest_cpu_init();
 #endif
 	}
+	clocksource_register_khz(&clocksource_vmware, vmware_tsc_khz);
 }
 #else
 #define vmware_paravirt_ops_setup() do {} while (0)
-- 
2.11.0

