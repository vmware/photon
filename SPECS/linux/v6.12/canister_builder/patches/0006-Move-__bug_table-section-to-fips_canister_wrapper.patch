From 368017448ca41207d655a5b48c2588e3e04cc4f8 Mon Sep 17 00:00:00 2001
From: Keerthana K <keerthana.kalyanasundaram@broadcom.com>
Date: Fri, 29 Nov 2024 11:39:30 +0000
Subject: [PATCH 06/12] Move __bug_table section to fips_canister_wrapper

Signed-off-by: Keerthana K <keerthana.kalyanasundaram@broadcom.com>
---
 arch/x86/crypto/aesni-intel_glue.c |  17 +++--
 crypto/algboss.c                   |  10 +--
 crypto/cbc.c                       |  11 +--
 crypto/ccm.c                       |  28 +++----
 crypto/cmac.c                      |   6 +-
 crypto/ctr.c                       |   6 +-
 crypto/cts.c                       |   4 +-
 crypto/drbg.c                      |  54 +++++++-------
 crypto/ecc.c                       |   9 +--
 crypto/ecdh_helper.c               |   5 +-
 crypto/gcm.c                       |  26 +++----
 crypto/hmac.c                      |   4 +-
 crypto/rsa-pkcs1pad.c              |   6 +-
 crypto/seqiv.c                     |   3 +-
 crypto/sha1_generic.c              |   5 +-
 crypto/sha512_generic.c            |   5 +-
 crypto/testmgr.c                   | 116 +++++++++++++++--------------
 lib/crypto/sha256.c                |  11 +++
 18 files changed, 173 insertions(+), 153 deletions(-)

diff --git a/arch/x86/crypto/aesni-intel_glue.c b/arch/x86/crypto/aesni-intel_glue.c
index 9c4cb927d..d07b3ff76 100644
--- a/arch/x86/crypto/aesni-intel_glue.c
+++ b/arch/x86/crypto/aesni-intel_glue.c
@@ -40,6 +40,11 @@
 
 void fcw_kernel_fpu_begin(void);
 void fcw_kernel_fpu_end(void);
+extern void *fcw_kmalloc(size_t size, gfp_t flags);
+extern void *fcw_scatterwalk_map(struct scatter_walk *walk);
+extern void *fcw_memcpy(void *dst, const void *src, size_t len);
+extern struct page *fcw_sg_page(struct scatterlist *sg);
+
 
 #define AESNI_ALIGN	16
 #define AESNI_ALIGN_ATTR __attribute__ ((__aligned__(AESNI_ALIGN)))
@@ -469,7 +474,7 @@ static int xctr_crypt(struct skcipher_request *req)
 		byte_ctr += walk.nbytes - nbytes;
 
 		if (walk.nbytes == walk.total && nbytes > 0) {
-			memcpy(block, walk.iv, AES_BLOCK_SIZE);
+			fcw_memcpy(block, walk.iv, AES_BLOCK_SIZE);
 			block[0] ^= cpu_to_le32(1 + byte_ctr / AES_BLOCK_SIZE);
 			aesni_enc(ctx, keystream, (u8 *)block);
 			crypto_xor_cpy(walk.dst.virt.addr + walk.nbytes -
@@ -605,8 +610,8 @@ xts_crypt(struct skcipher_request *req, xts_encrypt_iv_func encrypt_iv,
 	if (likely(src->length >= cryptlen && dst->length >= cryptlen &&
 		   src->offset + cryptlen <= PAGE_SIZE &&
 		   dst->offset + cryptlen <= PAGE_SIZE)) {
-		struct page *src_page = sg_page(src);
-		struct page *dst_page = sg_page(dst);
+		struct page *src_page = fcw_sg_page(src);
+		struct page *dst_page = fcw_sg_page(dst);
 		void *src_virt = kmap_local_page(src_page) + src->offset;
 		void *dst_virt = kmap_local_page(dst_page) + dst->offset;
 
@@ -1296,7 +1301,7 @@ static void gcm_process_assoc(const struct aes_gcm_key *key, u8 ghash_acc[16],
 
 	while (assoclen) {
 		unsigned int len_this_page = scatterwalk_clamp(&walk, assoclen);
-		void *mapped = scatterwalk_map(&walk);
+		void *mapped = fcw_scatterwalk_map(&walk);
 		const void *src = mapped;
 		unsigned int len;
 
@@ -1304,7 +1309,7 @@ static void gcm_process_assoc(const struct aes_gcm_key *key, u8 ghash_acc[16],
 		scatterwalk_advance(&walk, len_this_page);
 		if (unlikely(pos)) {
 			len = min(len_this_page, 16 - pos);
-			memcpy(&buf[pos], src, len);
+			fcw_memcpy(&buf[pos], src, len);
 			pos += len;
 			src += len;
 			len_this_page -= len;
@@ -1320,7 +1325,7 @@ static void gcm_process_assoc(const struct aes_gcm_key *key, u8 ghash_acc[16],
 		src += len;
 		len_this_page -= len;
 		if (unlikely(len_this_page)) {
-			memcpy(buf, src, len_this_page);
+			fcw_memcpy(buf, src, len_this_page);
 			pos = len_this_page;
 		}
 next:
diff --git a/crypto/algboss.c b/crypto/algboss.c
index 1159e51da..605708840 100644
--- a/crypto/algboss.c
+++ b/crypto/algboss.c
@@ -96,7 +96,7 @@ static int cryptomgr_schedule_probe(struct crypto_larval *larval)
 	if (!len || *p != '(')
 		goto err_free_param;
 
-	memcpy(param->template, name, len);
+	fcw_memcpy(param->template, name, len);
 
 	i = 0;
 	for (;;) {
@@ -126,7 +126,7 @@ static int cryptomgr_schedule_probe(struct crypto_larval *larval)
 
 		param->attrs[i].attr.rta_len = sizeof(param->attrs[i]);
 		param->attrs[i].attr.rta_type = CRYPTOA_ALG;
-		memcpy(param->attrs[i].data.name, name, len);
+		fcw_memcpy(param->attrs[i].data.name, name, len);
 
 		param->tb[i + 1] = &param->attrs[i].attr;
 		i++;
@@ -200,8 +200,8 @@ static int cryptomgr_schedule_test(struct crypto_alg *alg)
 	if (!param)
 		goto err_put_module;
 
-	memcpy(param->driver, alg->cra_driver_name, sizeof(param->driver));
-	memcpy(param->alg, alg->cra_name, sizeof(param->alg));
+	fcw_memcpy(param->driver, alg->cra_driver_name, sizeof(param->driver));
+	fcw_memcpy(param->alg, alg->cra_name, sizeof(param->alg));
 	param->type = alg->cra_flags;
 
 	thread = kthread_run(cryptomgr_test, param, "cryptomgr_test");
@@ -245,7 +245,7 @@ static int __init cryptomgr_init(void)
 static void __exit cryptomgr_exit(void)
 {
 	int err = crypto_unregister_notifier(&cryptomgr_notifier);
-	BUG_ON(err);
+	fcw_bug_on(err);
 }
 
 /*
diff --git a/crypto/cbc.c b/crypto/cbc.c
index e81918ca6..edc3325bf 100644
--- a/crypto/cbc.c
+++ b/crypto/cbc.c
@@ -11,6 +11,7 @@
 #include <linux/kernel.h>
 #include <linux/log2.h>
 #include <linux/module.h>
+#include "fips_canister_wrapper.h"
 
 static int crypto_cbc_encrypt_segment(struct crypto_lskcipher *tfm,
 				      const u8 *src, u8 *dst, unsigned nbytes,
@@ -21,7 +22,7 @@ static int crypto_cbc_encrypt_segment(struct crypto_lskcipher *tfm,
 	for (; nbytes >= bsize; src += bsize, dst += bsize, nbytes -= bsize) {
 		crypto_xor(iv, src, bsize);
 		crypto_lskcipher_encrypt(tfm, iv, dst, bsize, NULL);
-		memcpy(iv, dst, bsize);
+		fcw_memcpy(iv, dst, bsize);
 	}
 
 	return nbytes;
@@ -44,7 +45,7 @@ static int crypto_cbc_encrypt_inplace(struct crypto_lskcipher *tfm,
 		src += bsize;
 	} while ((nbytes -= bsize) >= bsize);
 
-	memcpy(oiv, iv, bsize);
+	fcw_memcpy(oiv, iv, bsize);
 
 out:
 	return nbytes;
@@ -85,7 +86,7 @@ static int crypto_cbc_decrypt_segment(struct crypto_lskcipher *tfm,
 		dst += bsize;
 	} while ((nbytes -= bsize) >= bsize);
 
-	memcpy(oiv, iv, bsize);
+	fcw_memcpy(oiv, iv, bsize);
 
 out:
 	return nbytes;
@@ -102,7 +103,7 @@ static int crypto_cbc_decrypt_inplace(struct crypto_lskcipher *tfm,
 
 	/* Start of the last block. */
 	src += nbytes - (nbytes & (bsize - 1)) - bsize;
-	memcpy(last_iv, src, bsize);
+	fcw_memcpy(last_iv, src, bsize);
 
 	for (;;) {
 		crypto_lskcipher_decrypt(tfm, src, src, bsize, NULL);
@@ -113,7 +114,7 @@ static int crypto_cbc_decrypt_inplace(struct crypto_lskcipher *tfm,
 	}
 
 	crypto_xor(src, iv, bsize);
-	memcpy(iv, last_iv, bsize);
+	fcw_memcpy(iv, last_iv, bsize);
 
 out:
 	return nbytes;
diff --git a/crypto/ccm.c b/crypto/ccm.c
index d9172bab5..961547540 100644
--- a/crypto/ccm.c
+++ b/crypto/ccm.c
@@ -81,7 +81,7 @@ static int set_msg_len(u8 *block, unsigned int msglen, int csize)
 		return -EOVERFLOW;
 
 	data = cpu_to_be32(msglen);
-	memcpy(block - csize, (u8 *)&data + 4 - csize, csize);
+	fcw_memcpy(block - csize, (u8 *)&data + 4 - csize, csize);
 
 	return 0;
 }
@@ -136,7 +136,7 @@ static int format_input(u8 *info, struct aead_request *req,
 
 	m = crypto_aead_authsize(aead);
 
-	memcpy(info, req->iv, 16);
+	fcw_memcpy(info, req->iv, 16);
 
 	/* format control info per RFC 3610 and
 	 * NIST Special Publication 800-38C
@@ -186,12 +186,12 @@ static int crypto_ccm_auth(struct aead_request *req, struct scatterlist *plain,
 		goto out;
 
 	sg_init_table(sg, 3);
-	sg_set_buf(&sg[0], odata, 16);
+	fcw_sg_set_buf(&sg[0], odata, 16);
 
 	/* format associated data and compute into mac */
 	if (assoclen) {
 		ilen = format_adata(idata, assoclen);
-		sg_set_buf(&sg[1], idata, ilen);
+		fcw_sg_set_buf(&sg[1], idata, ilen);
 		sg_chain(sg, 3, req->src);
 	} else {
 		ilen = 0;
@@ -213,7 +213,7 @@ static int crypto_ccm_auth(struct aead_request *req, struct scatterlist *plain,
 	if (ilen < 16) {
 		memset(idata, 0, ilen);
 		sg_init_table(sg, 2);
-		sg_set_buf(&sg[0], idata, ilen);
+		fcw_sg_set_buf(&sg[0], idata, ilen);
 		if (plain)
 			sg_chain(sg, 2, plain);
 		plain = sg;
@@ -268,14 +268,14 @@ static int crypto_ccm_init_crypt(struct aead_request *req, u8 *tag)
 	memset(iv + 15 - iv[0], 0, iv[0] + 1);
 
 	sg_init_table(pctx->src, 3);
-	sg_set_buf(pctx->src, tag, 16);
+	fcw_sg_set_buf(pctx->src, tag, 16);
 	sg = scatterwalk_ffwd(pctx->src + 1, req->src, req->assoclen);
 	if (sg != pctx->src + 1)
 		sg_chain(pctx->src, 2, sg);
 
 	if (req->src != req->dst) {
 		sg_init_table(pctx->dst, 3);
-		sg_set_buf(pctx->dst, tag, 16);
+		fcw_sg_set_buf(pctx->dst, tag, 16);
 		sg = scatterwalk_ffwd(pctx->dst + 1, req->dst, req->assoclen);
 		if (sg != pctx->dst + 1)
 			sg_chain(pctx->dst, 2, sg);
@@ -370,7 +370,7 @@ static int crypto_ccm_decrypt(struct aead_request *req)
 	if (req->src != req->dst)
 		dst = pctx->dst;
 
-	memcpy(iv, req->iv, 16);
+	fcw_memcpy(iv, req->iv, 16);
 
 	skcipher_request_set_tfm(skreq, ctx->ctr);
 	skcipher_request_set_callback(skreq, pctx->flags,
@@ -575,7 +575,7 @@ static int crypto_rfc4309_setkey(struct crypto_aead *parent, const u8 *key,
 		return -EINVAL;
 
 	keylen -= 3;
-	memcpy(ctx->nonce, key + keylen, 3);
+	fcw_memcpy(ctx->nonce, key + keylen, 3);
 
 	crypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);
 	crypto_aead_set_flags(child, crypto_aead_get_flags(parent) &
@@ -614,20 +614,20 @@ static struct aead_request *crypto_rfc4309_crypt(struct aead_request *req)
 	/* L' */
 	iv[0] = 3;
 
-	memcpy(iv + 1, ctx->nonce, 3);
-	memcpy(iv + 4, req->iv, 8);
+	fcw_memcpy(iv + 1, ctx->nonce, 3);
+	fcw_memcpy(iv + 4, req->iv, 8);
 
 	scatterwalk_map_and_copy(iv + 16, req->src, 0, req->assoclen - 8, 0);
 
 	sg_init_table(rctx->src, 3);
-	sg_set_buf(rctx->src, iv + 16, req->assoclen - 8);
+	fcw_sg_set_buf(rctx->src, iv + 16, req->assoclen - 8);
 	sg = scatterwalk_ffwd(rctx->src + 1, req->src, req->assoclen);
 	if (sg != rctx->src + 1)
 		sg_chain(rctx->src, 2, sg);
 
 	if (req->src != req->dst) {
 		sg_init_table(rctx->dst, 3);
-		sg_set_buf(rctx->dst, iv + 16, req->assoclen - 8);
+		fcw_sg_set_buf(rctx->dst, iv + 16, req->assoclen - 8);
 		sg = scatterwalk_ffwd(rctx->dst + 1, req->dst, req->assoclen);
 		if (sg != rctx->dst + 1)
 			sg_chain(rctx->dst, 2, sg);
@@ -830,7 +830,7 @@ static int crypto_cbcmac_digest_final(struct shash_desc *pdesc, u8 *out)
 	if (ctx->len)
 		crypto_cipher_encrypt_one(tfm, ctx->dg, ctx->dg);
 
-	memcpy(out, ctx->dg, bs);
+	fcw_memcpy(out, ctx->dg, bs);
 	return 0;
 }
 
diff --git a/crypto/cmac.c b/crypto/cmac.c
index 9e95294aa..f3410fe44 100644
--- a/crypto/cmac.c
+++ b/crypto/cmac.c
@@ -126,13 +126,13 @@ static int crypto_cmac_digest_update(struct shash_desc *pdesc, const u8 *p,
 
 	/* checking the data can fill the block */
 	if ((ctx->len + len) <= bs) {
-		memcpy(odds + ctx->len, p, len);
+		fcw_memcpy(odds + ctx->len, p, len);
 		ctx->len += len;
 		return 0;
 	}
 
 	/* filling odds with new data and encrypting it */
-	memcpy(odds + ctx->len, p, bs - ctx->len);
+	fcw_memcpy(odds + ctx->len, p, bs - ctx->len);
 	len -= bs - ctx->len;
 	p += bs - ctx->len;
 
@@ -152,7 +152,7 @@ static int crypto_cmac_digest_update(struct shash_desc *pdesc, const u8 *p,
 
 	/* keeping the surplus of blocksize */
 	if (len) {
-		memcpy(odds, p, len);
+		fcw_memcpy(odds, p, len);
 		ctx->len = len;
 	}
 
diff --git a/crypto/ctr.c b/crypto/ctr.c
index 6fa3831e1..978515f98 100644
--- a/crypto/ctr.c
+++ b/crypto/ctr.c
@@ -177,7 +177,7 @@ static int crypto_rfc3686_setkey(struct crypto_skcipher *parent,
 	if (keylen < CTR_RFC3686_NONCE_SIZE)
 		return -EINVAL;
 
-	memcpy(ctx->nonce, key + (keylen - CTR_RFC3686_NONCE_SIZE),
+	fcw_memcpy(ctx->nonce, key + (keylen - CTR_RFC3686_NONCE_SIZE),
 	       CTR_RFC3686_NONCE_SIZE);
 
 	keylen -= CTR_RFC3686_NONCE_SIZE;
@@ -200,8 +200,8 @@ static int crypto_rfc3686_crypt(struct skcipher_request *req)
 	u8 *iv = rctx->iv;
 
 	/* set up counter block */
-	memcpy(iv, ctx->nonce, CTR_RFC3686_NONCE_SIZE);
-	memcpy(iv + CTR_RFC3686_NONCE_SIZE, req->iv, CTR_RFC3686_IV_SIZE);
+	fcw_memcpy(iv, ctx->nonce, CTR_RFC3686_NONCE_SIZE);
+	fcw_memcpy(iv + CTR_RFC3686_NONCE_SIZE, req->iv, CTR_RFC3686_IV_SIZE);
 
 	/* initialize counter portion of counter block */
 	*(__be32 *)(iv + CTR_RFC3686_NONCE_SIZE + CTR_RFC3686_IV_SIZE) =
diff --git a/crypto/cts.c b/crypto/cts.c
index 7df35e8c7..e14b1b1c1 100644
--- a/crypto/cts.c
+++ b/crypto/cts.c
@@ -206,7 +206,7 @@ static int cts_cbc_decrypt(struct skcipher_request *req)
 	crypto_xor(d + bsize, d, lastn);
 
 	/* 5. Append the tail (BB - Ln) bytes of Xn to Cn to create En */
-	memcpy(d + lastn, d + bsize + lastn, bsize - lastn);
+	fcw_memcpy(d + lastn, d + bsize + lastn, bsize - lastn);
 	/* 6. Decrypt En to create Pn-1 */
 
 	scatterwalk_map_and_copy(d, sg, 0, bsize + lastn, 1);
@@ -269,7 +269,7 @@ static int crypto_cts_decrypt(struct skcipher_request *req)
 	rctx->offset = offset;
 
 	if (offset <= bsize)
-		memcpy(space, req->iv, bsize);
+		fcw_memcpy(space, req->iv, bsize);
 	else
 		scatterwalk_map_and_copy(space, req->src, offset - 2 * bsize,
 					 bsize, 0);
diff --git a/crypto/drbg.c b/crypto/drbg.c
index c0a8e4f66..78341ecbb 100644
--- a/crypto/drbg.c
+++ b/crypto/drbg.c
@@ -247,7 +247,7 @@ static int drbg_fips_continuous_test(struct drbg_state *drbg,
 
 	if (!drbg->fips_primed) {
 		/* Priming of FIPS test */
-		memcpy(drbg->prev, entropy, entropylen);
+		fcw_memcpy(drbg->prev, entropy, entropylen);
 		drbg->fips_primed = true;
 		/* priming: another round is needed */
 		return -EAGAIN;
@@ -255,7 +255,7 @@ static int drbg_fips_continuous_test(struct drbg_state *drbg,
 	ret = memcmp(drbg->prev, entropy, entropylen);
 	if (!ret)
 		panic("DRBG continuous self test failed\n");
-	memcpy(drbg->prev, entropy, entropylen);
+	fcw_memcpy(drbg->prev, entropy, entropylen);
 
 	/* the test shall pass when the two values are not equal */
 	return 0;
@@ -490,7 +490,7 @@ static int drbg_ctr_df(struct drbg_state *drbg,
 			    drbg_blocklen(drbg) :
 				(bytes_to_return - generated_len);
 		/* 10.4.2 step 13.2 and 14 */
-		memcpy(df_data + generated_len, X, blocklen);
+		fcw_memcpy(df_data + generated_len, X, blocklen);
 		generated_len += blocklen;
 	}
 
@@ -564,7 +564,7 @@ static int drbg_ctr_update(struct drbg_state *drbg, struct list_head *seed,
 	if (ret)
 		goto out;
 	/* 10.2.1.2 step 6 */
-	memcpy(drbg->V, temp + drbg_keylen(drbg), drbg_blocklen(drbg));
+	fcw_memcpy(drbg->V, temp + drbg_keylen(drbg), drbg_blocklen(drbg));
 	/* See above: increment counter by one to compensate timing of CTR op */
 	crypto_inc(drbg->V, drbg_blocklen(drbg));
 	ret = 0;
@@ -720,7 +720,7 @@ static int drbg_hmac_generate(struct drbg_state *drbg,
 			  drbg_blocklen(drbg) : (buflen - len);
 
 		/* 10.1.2.5 step 4.2 */
-		memcpy(buf + len, drbg->V, outlen);
+		fcw_memcpy(buf + len, drbg->V, outlen);
 		len += outlen;
 	}
 
@@ -833,7 +833,7 @@ static int drbg_hash_df(struct drbg_state *drbg,
 		input[0]++;
 		blocklen = (drbg_blocklen(drbg) < (outlen - len)) ?
 			    drbg_blocklen(drbg) : (outlen - len);
-		memcpy(outval + len, tmp, blocklen);
+		fcw_memcpy(outval + len, tmp, blocklen);
 		len += blocklen;
 	}
 
@@ -858,7 +858,7 @@ static int drbg_hash_update(struct drbg_state *drbg, struct list_head *seed,
 
 	if (reseed) {
 		/* 10.1.1.3 step 1 */
-		memcpy(V, drbg->V, drbg_statelen(drbg));
+		fcw_memcpy(V, drbg->V, drbg_statelen(drbg));
 		drbg_string_fill(&data1, &prefix, 1);
 		list_add_tail(&data1.list, &datalist);
 		drbg_string_fill(&data2, V, drbg_statelen(drbg));
@@ -930,7 +930,7 @@ static int drbg_hash_hashgen(struct drbg_state *drbg,
 	LIST_HEAD(datalist);
 
 	/* 10.1.1.4 step hashgen 2 */
-	memcpy(src, drbg->V, drbg_statelen(drbg));
+	fcw_memcpy(src, drbg->V, drbg_statelen(drbg));
 
 	drbg_string_fill(&data, src, drbg_statelen(drbg));
 	list_add_tail(&data.list, &datalist);
@@ -945,7 +945,7 @@ static int drbg_hash_hashgen(struct drbg_state *drbg,
 		outlen = (drbg_blocklen(drbg) < (buflen - len)) ?
 			  drbg_blocklen(drbg) : (buflen - len);
 		/* 10.1.1.4 step hashgen 4.2 */
-		memcpy(buf + len, dst, outlen);
+		fcw_memcpy(buf + len, dst, outlen);
 		len += outlen;
 		/* 10.1.1.4 hashgen step 4.3 */
 		if (len < buflen)
@@ -1082,8 +1082,8 @@ static int drbg_seed_from_random(struct drbg_state *drbg)
 	unsigned char entropy[32];
 	int ret;
 
-	BUG_ON(!entropylen);
-	BUG_ON(entropylen > sizeof(entropy));
+	fcw_bug_on(!entropylen);
+	fcw_bug_on(entropylen > sizeof(entropy));
 
 	drbg_string_fill(&data, entropy, entropylen);
 	list_add_tail(&data.list, &seedlist);
@@ -1160,10 +1160,10 @@ static int drbg_seed(struct drbg_state *drbg, struct drbg_string *pers,
 		 * of the strength. The consideration of a nonce is only
 		 * applicable during initial seeding.
 		 */
-		BUG_ON(!entropylen);
+		fcw_bug_on(!entropylen);
 		if (!reseed)
 			entropylen = ((entropylen + 1) / 2) * 3;
-		BUG_ON((entropylen * 2) > sizeof(entropy));
+		fcw_bug_on((entropylen * 2) > sizeof(entropy));
 
 		/* Get seed from in-kernel /dev/urandom */
 		if (!rng_is_initialized()) {
@@ -1461,7 +1461,7 @@ static int drbg_generate(struct drbg_state *drbg,
 		if (fips_enabled) {
 			if (IS_ERR_OR_NULL(drbg->jent)) {
 				pr_err("DRBG:seed rand,non-existing jent\n");
-				BUG();
+				fcw_bug();
 				goto err;
 			}
 			len = crypto_rng_get_bytes(drbg->jent,
@@ -1719,7 +1719,7 @@ static int drbg_init_hash_kernel(struct drbg_state *drbg)
 				drbg->core->backend_cra_name);
 		return PTR_ERR(tfm);
 	}
-	BUG_ON(drbg_blocklen(drbg) != crypto_shash_digestsize(tfm));
+	fcw_bug_on(drbg_blocklen(drbg) != crypto_shash_digestsize(tfm));
 	sdesc = fcw_kzalloc(sizeof(struct shash_desc) + crypto_shash_descsize(tfm),
 			GFP_KERNEL);
 	if (!sdesc) {
@@ -1802,7 +1802,7 @@ static int drbg_init_sym_kernel(struct drbg_state *drbg)
 				drbg->core->backend_cra_name);
 		return PTR_ERR(tfm);
 	}
-	BUG_ON(drbg_blocklen(drbg) != crypto_cipher_blocksize(tfm));
+	fcw_bug_on(drbg_blocklen(drbg) != crypto_cipher_blocksize(tfm));
 	drbg->priv_data = tfm;
 
 	if (snprintf(ctr_name, CRYPTO_MAX_ALG_NAME, "ctr(%s)",
@@ -1861,7 +1861,7 @@ static int drbg_kcapi_sym(struct drbg_state *drbg, unsigned char *outval,
 	struct crypto_cipher *tfm = drbg->priv_data;
 
 	/* there is only component in *in */
-	BUG_ON(in->len < drbg_blocklen(drbg));
+	fcw_bug_on(in->len < drbg_blocklen(drbg));
 	crypto_cipher_encrypt_one(tfm, outval, in->buf);
 	return 0;
 }
@@ -1876,12 +1876,12 @@ static int drbg_kcapi_sym_ctr(struct drbg_state *drbg,
 
 	if (inbuf) {
 		/* Use caller-provided input buffer */
-		sg_set_buf(sg_in, inbuf, inlen);
+		fcw_sg_set_buf(sg_in, inbuf, inlen);
 	} else {
 		/* Use scratchpad for in-place operation */
 		inlen = scratchpad_use;
 		memset(drbg->outscratchpad, 0, scratchpad_use);
-		sg_set_buf(sg_in, drbg->outscratchpad, scratchpad_use);
+		fcw_sg_set_buf(sg_in, drbg->outscratchpad, scratchpad_use);
 	}
 
 	while (outlen) {
@@ -1897,7 +1897,7 @@ static int drbg_kcapi_sym_ctr(struct drbg_state *drbg,
 
 		crypto_init_wait(&drbg->ctr_wait);
 
-		memcpy(outbuf, drbg->outscratchpad, cryptlen);
+		fcw_memcpy(outbuf, drbg->outscratchpad, cryptlen);
 		memzero_explicit(drbg->outscratchpad, cryptlen);
 
 		outlen -= cryptlen;
@@ -2089,14 +2089,14 @@ static inline int __init drbg_healthcheck_sanity(void)
 	drbg_string_fill(&addtl, buf, max_addtllen + 1);
 	/* overflow addtllen with additonal info string */
 	len = drbg_generate(drbg, buf, OUTBUFLEN, &addtl);
-	BUG_ON(0 < len);
+	fcw_bug_on(0 < len);
 	/* overflow max_bits */
 	len = drbg_generate(drbg, buf, (max_request_bytes + 1), NULL);
-	BUG_ON(0 < len);
+	fcw_bug_on(0 < len);
 
 	/* overflow max addtllen with personalization string */
 	ret = drbg_seed(drbg, &addtl, false);
-	BUG_ON(0 == ret);
+	fcw_bug_on(0 == ret);
 	/* all tests passed */
 	rc = 0;
 
@@ -2121,15 +2121,15 @@ static inline void __init drbg_fill_array(struct rng_alg *alg,
 	int pos = 0;
 	static int priority = 200;
 
-	memcpy(alg->base.cra_name, "stdrng", 6);
+	fcw_memcpy(alg->base.cra_name, "stdrng", 6);
 	if (pr) {
-		memcpy(alg->base.cra_driver_name, "drbg_pr_", 8);
+		fcw_memcpy(alg->base.cra_driver_name, "drbg_pr_", 8);
 		pos = 8;
 	} else {
-		memcpy(alg->base.cra_driver_name, "drbg_nopr_", 10);
+		fcw_memcpy(alg->base.cra_driver_name, "drbg_nopr_", 10);
 		pos = 10;
 	}
-	memcpy(alg->base.cra_driver_name + pos, core->cra_name,
+	fcw_memcpy(alg->base.cra_driver_name + pos, core->cra_name,
 	       strlen(core->cra_name));
 
 	alg->base.cra_priority = priority;
diff --git a/crypto/ecc.c b/crypto/ecc.c
index 1bb19b7f0..7aa54bb27 100644
--- a/crypto/ecc.c
+++ b/crypto/ecc.c
@@ -84,7 +84,7 @@ void ecc_digits_from_bytes(const u8 *in, unsigned int nbytes,
 	}
 
 	if (o) {
-		memcpy((u8 *)&msd + sizeof(msd) - o, in, o);
+		fcw_memcpy((u8 *)&msd + sizeof(msd) - o, in, o);
 		out[--ndigits] = be64_to_cpu(msd);
 		in += o;
 	}
@@ -234,10 +234,7 @@ EXPORT_SYMBOL(vli_from_le64);
 /* Sets dest = src. */
 static void vli_set(u64 *dest, const u64 *src, unsigned int ndigits)
 {
-	int i;
-
-	for (i = 0; i < ndigits; i++)
-		dest[i] = src[i];
+	fcw_memcpy(dest, src, sizeof(u64) * ndigits);
 }
 
 /* Returns sign of left - right. */
@@ -1607,7 +1604,7 @@ int ecc_is_pubkey_valid_partial(const struct ecc_curve *curve,
 {
 	u64 yy[ECC_MAX_DIGITS], xxx[ECC_MAX_DIGITS], w[ECC_MAX_DIGITS];
 
-	if (WARN_ON(pk->ndigits != curve->g.ndigits))
+	if (fcw_warn_on(pk->ndigits != curve->g.ndigits))
 		return -EINVAL;
 
 	/* Check 1: Verify key is not the zero point. */
diff --git a/crypto/ecdh_helper.c b/crypto/ecdh_helper.c
index f18f9028f..5dac6b348 100644
--- a/crypto/ecdh_helper.c
+++ b/crypto/ecdh_helper.c
@@ -9,18 +9,19 @@
 #include <linux/string.h>
 #include <crypto/ecdh.h>
 #include <crypto/kpp.h>
+#include "fips_canister_wrapper.h"
 
 #define ECDH_KPP_SECRET_MIN_SIZE (sizeof(struct kpp_secret) + sizeof(short))
 
 static inline u8 *ecdh_pack_data(void *dst, const void *src, size_t sz)
 {
-	memcpy(dst, src, sz);
+	fcw_memcpy(dst, src, sz);
 	return dst + sz;
 }
 
 static inline const u8 *ecdh_unpack_data(void *dst, const void *src, size_t sz)
 {
-	memcpy(dst, src, sz);
+	fcw_memcpy(dst, src, sz);
 	return src + sz;
 }
 
diff --git a/crypto/gcm.c b/crypto/gcm.c
index bc8b75e36..0c07f784d 100644
--- a/crypto/gcm.c
+++ b/crypto/gcm.c
@@ -157,18 +157,18 @@ static void crypto_gcm_init_common(struct aead_request *req)
 	struct scatterlist *sg;
 
 	memset(pctx->auth_tag, 0, sizeof(pctx->auth_tag));
-	memcpy(pctx->iv, req->iv, GCM_AES_IV_SIZE);
-	memcpy(pctx->iv + GCM_AES_IV_SIZE, &counter, 4);
+	fcw_memcpy(pctx->iv, req->iv, GCM_AES_IV_SIZE);
+	fcw_memcpy(pctx->iv + GCM_AES_IV_SIZE, &counter, 4);
 
 	sg_init_table(pctx->src, 3);
-	sg_set_buf(pctx->src, pctx->auth_tag, sizeof(pctx->auth_tag));
+	fcw_sg_set_buf(pctx->src, pctx->auth_tag, sizeof(pctx->auth_tag));
 	sg = scatterwalk_ffwd(pctx->src + 1, req->src, req->assoclen);
 	if (sg != pctx->src + 1)
 		sg_chain(pctx->src, 2, sg);
 
 	if (req->src != req->dst) {
 		sg_init_table(pctx->dst, 3);
-		sg_set_buf(pctx->dst, pctx->auth_tag, sizeof(pctx->auth_tag));
+		fcw_sg_set_buf(pctx->dst, pctx->auth_tag, sizeof(pctx->auth_tag));
 		sg = scatterwalk_ffwd(pctx->dst + 1, req->dst, req->assoclen);
 		if (sg != pctx->dst + 1)
 			sg_chain(pctx->dst, 2, sg);
@@ -230,7 +230,7 @@ static int gcm_hash_len(struct aead_request *req, u32 flags)
 
 	lengths.a = cpu_to_be64(req->assoclen * 8);
 	lengths.b = cpu_to_be64(gctx->cryptlen * 8);
-	memcpy(pctx->iauth_tag, &lengths, 16);
+	fcw_memcpy(pctx->iauth_tag, &lengths, 16);
 	sg_init_one(&pctx->sg, pctx->iauth_tag, 16);
 	ahash_request_set_callback(ahreq, flags, gcm_hash_len_done, req);
 	ahash_request_set_crypt(ahreq, &pctx->sg,
@@ -695,7 +695,7 @@ static int crypto_rfc4106_setkey(struct crypto_aead *parent, const u8 *key,
 		return -EINVAL;
 
 	keylen -= 4;
-	memcpy(ctx->nonce, key + keylen, 4);
+	fcw_memcpy(ctx->nonce, key + keylen, 4);
 
 	crypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);
 	crypto_aead_set_flags(child, crypto_aead_get_flags(parent) &
@@ -729,18 +729,18 @@ static struct aead_request *crypto_rfc4106_crypt(struct aead_request *req)
 
 	scatterwalk_map_and_copy(iv + GCM_AES_IV_SIZE, req->src, 0, req->assoclen - 8, 0);
 
-	memcpy(iv, ctx->nonce, 4);
-	memcpy(iv + 4, req->iv, 8);
+	fcw_memcpy(iv, ctx->nonce, 4);
+	fcw_memcpy(iv + 4, req->iv, 8);
 
 	sg_init_table(rctx->src, 3);
-	sg_set_buf(rctx->src, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
+	fcw_sg_set_buf(rctx->src, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
 	sg = scatterwalk_ffwd(rctx->src + 1, req->src, req->assoclen);
 	if (sg != rctx->src + 1)
 		sg_chain(rctx->src, 2, sg);
 
 	if (req->src != req->dst) {
 		sg_init_table(rctx->dst, 3);
-		sg_set_buf(rctx->dst, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
+		fcw_sg_set_buf(rctx->dst, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
 		sg = scatterwalk_ffwd(rctx->dst + 1, req->dst, req->assoclen);
 		if (sg != rctx->dst + 1)
 			sg_chain(rctx->dst, 2, sg);
@@ -903,7 +903,7 @@ static int crypto_rfc4543_setkey(struct crypto_aead *parent, const u8 *key,
 		return -EINVAL;
 
 	keylen -= 4;
-	memcpy(ctx->nonce, key + keylen, 4);
+	fcw_memcpy(ctx->nonce, key + keylen, 4);
 
 	crypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);
 	crypto_aead_set_flags(child, crypto_aead_get_flags(parent) &
@@ -939,8 +939,8 @@ static int crypto_rfc4543_crypt(struct aead_request *req, bool enc)
 			return err;
 	}
 
-	memcpy(iv, ctx->nonce, 4);
-	memcpy(iv + 4, req->iv, 8);
+	fcw_memcpy(iv, ctx->nonce, 4);
+	fcw_memcpy(iv + 4, req->iv, 8);
 
 	aead_request_set_tfm(subreq, ctx->child);
 	aead_request_set_callback(subreq, req->base.flags,
diff --git a/crypto/hmac.c b/crypto/hmac.c
index 54a5321ea..2c722aa7c 100644
--- a/crypto/hmac.c
+++ b/crypto/hmac.c
@@ -56,10 +56,10 @@ static int hmac_setkey(struct crypto_shash *parent,
 
 		keylen = ds;
 	} else
-		memcpy(ipad, inkey, keylen);
+		fcw_memcpy(ipad, inkey, keylen);
 
 	memset(ipad + keylen, 0, bs - keylen);
-	memcpy(opad, ipad, bs);
+	fcw_memcpy(opad, ipad, bs);
 
 	for (i = 0; i < bs; i++) {
 		ipad[i] ^= HMAC_IPAD_VALUE;
diff --git a/crypto/rsa-pkcs1pad.c b/crypto/rsa-pkcs1pad.c
index 11805ebd2..936dd963d 100644
--- a/crypto/rsa-pkcs1pad.c
+++ b/crypto/rsa-pkcs1pad.c
@@ -189,7 +189,7 @@ static void pkcs1pad_sg_set_buf(struct scatterlist *sg, void *buf, size_t len,
 	int nsegs = next ? 2 : 1;
 
 	sg_init_table(sg, nsegs);
-	sg_set_buf(sg, buf, len);
+	fcw_sg_set_buf(sg, buf, len);
 
 	if (next)
 		sg_chain(sg, nsegs, next);
@@ -431,7 +431,7 @@ static int pkcs1pad_sign(struct akcipher_request *req)
 	req_ctx->in_buf[ps_end] = 0x00;
 
 	if (digest_info)
-		memcpy(req_ctx->in_buf + ps_end + 1, digest_info->data,
+		fcw_memcpy(req_ctx->in_buf + ps_end + 1, digest_info->data,
 		       digest_info->size);
 
 	pkcs1pad_sg_set_buf(req_ctx->in_sg, req_ctx->in_buf,
@@ -558,7 +558,7 @@ static int pkcs1pad_verify(struct akcipher_request *req)
 	const unsigned int digest_size = req->dst_len;
 	int err;
 
-	if (WARN_ON(req->dst) || WARN_ON(!digest_size) ||
+	if (fcw_warn_on(req->dst) || fcw_warn_on(!digest_size) ||
 	    !ctx->key_size || sig_size != ctx->key_size)
 		return -EINVAL;
 
diff --git a/crypto/seqiv.c b/crypto/seqiv.c
index 17e11d51d..14d230ff6 100644
--- a/crypto/seqiv.c
+++ b/crypto/seqiv.c
@@ -17,6 +17,7 @@
 #include <linux/module.h>
 #include <linux/slab.h>
 #include <linux/string.h>
+#include "fips_canister_wrapper.h"
 
 static void seqiv_aead_encrypt_complete2(struct aead_request *req, int err)
 {
@@ -30,7 +31,7 @@ static void seqiv_aead_encrypt_complete2(struct aead_request *req, int err)
 		goto out;
 
 	geniv = crypto_aead_reqtfm(req);
-	memcpy(req->iv, subreq->iv, crypto_aead_ivsize(geniv));
+	fcw_memcpy(req->iv, subreq->iv, crypto_aead_ivsize(geniv));
 
 out:
 	kfree_sensitive(subreq->iv);
diff --git a/crypto/sha1_generic.c b/crypto/sha1_generic.c
index 325b57fe2..193345133 100644
--- a/crypto/sha1_generic.c
+++ b/crypto/sha1_generic.c
@@ -19,6 +19,7 @@
 #include <crypto/sha1.h>
 #include <crypto/sha1_base.h>
 #include <asm/byteorder.h>
+#include "fips_canister_wrapper.h"
 
 const u8 sha1_zero_message_hash[SHA1_DIGEST_SIZE] = {
 	0xda, 0x39, 0xa3, 0xee, 0x5e, 0x6b, 0x4b, 0x0d,
@@ -42,7 +43,7 @@ static void sha1_generic_block_fn(struct sha1_state *sst, u8 const *src,
 int crypto_sha1_update(struct shash_desc *desc, const u8 *data,
 		       unsigned int len)
 {
-	return sha1_base_do_update(desc, data, len, sha1_generic_block_fn);
+	return fcw_sha1_base_do_update(desc, data, len, sha1_generic_block_fn);
 }
 EXPORT_SYMBOL(crypto_sha1_update);
 
@@ -55,7 +56,7 @@ static int sha1_final(struct shash_desc *desc, u8 *out)
 int crypto_sha1_finup(struct shash_desc *desc, const u8 *data,
 		      unsigned int len, u8 *out)
 {
-	sha1_base_do_update(desc, data, len, sha1_generic_block_fn);
+	fcw_sha1_base_do_update(desc, data, len, sha1_generic_block_fn);
 	return sha1_final(desc, out);
 }
 EXPORT_SYMBOL(crypto_sha1_finup);
diff --git a/crypto/sha512_generic.c b/crypto/sha512_generic.c
index ed81813bd..dbdabde87 100644
--- a/crypto/sha512_generic.c
+++ b/crypto/sha512_generic.c
@@ -17,6 +17,7 @@
 #include <linux/percpu.h>
 #include <asm/byteorder.h>
 #include <linux/unaligned.h>
+#include "fips_canister_wrapper.h"
 
 const u8 sha384_zero_message_hash[SHA384_DIGEST_SIZE] = {
 	0x38, 0xb0, 0x60, 0xa7, 0x51, 0xac, 0x96, 0x38,
@@ -157,7 +158,7 @@ static void sha512_generic_block_fn(struct sha512_state *sst, u8 const *src,
 int crypto_sha512_update(struct shash_desc *desc, const u8 *data,
 			unsigned int len)
 {
-	return sha512_base_do_update(desc, data, len, sha512_generic_block_fn);
+	return fcw_sha512_base_do_update(desc, data, len, sha512_generic_block_fn);
 }
 EXPORT_SYMBOL(crypto_sha512_update);
 
@@ -170,7 +171,7 @@ static int sha512_final(struct shash_desc *desc, u8 *hash)
 int crypto_sha512_finup(struct shash_desc *desc, const u8 *data,
 			unsigned int len, u8 *hash)
 {
-	sha512_base_do_update(desc, data, len, sha512_generic_block_fn);
+	fcw_sha512_base_do_update(desc, data, len, sha512_generic_block_fn);
 	return sha512_final(desc, hash);
 }
 EXPORT_SYMBOL(crypto_sha512_finup);
diff --git a/crypto/testmgr.c b/crypto/testmgr.c
index 846b5323e..510ef0138 100644
--- a/crypto/testmgr.c
+++ b/crypto/testmgr.c
@@ -599,7 +599,7 @@ static int build_test_sglist(struct test_sglist *tsgl,
 	unsigned int i;
 
 	BUILD_BUG_ON(ARRAY_SIZE(partitions) != ARRAY_SIZE(tsgl->sgl));
-	if (WARN_ON(ndivs > ARRAY_SIZE(partitions)))
+	if (fcw_warn_on(ndivs > ARRAY_SIZE(partitions)))
 		return -EINVAL;
 
 	/* Calculate the (div, length) pairs */
@@ -635,13 +635,13 @@ static int build_test_sglist(struct test_sglist *tsgl,
 
 		while (offset + partitions[i].length + TESTMGR_POISON_LEN >
 		       2 * PAGE_SIZE) {
-			if (WARN_ON(offset <= 0))
+			if (fcw_warn_on(offset <= 0))
 				return -EINVAL;
 			offset /= 2;
 		}
 
 		addr = &tsgl->bufs[i][offset];
-		sg_set_buf(&tsgl->sgl[i], addr, partitions[i].length);
+		fcw_sg_set_buf(&tsgl->sgl[i], addr, partitions[i].length);
 
 		if (out_divs)
 			out_divs[i] = partitions[i].div;
@@ -650,8 +650,8 @@ static int build_test_sglist(struct test_sglist *tsgl,
 			size_t copy_len, copied;
 
 			copy_len = min(partitions[i].length, data->count);
-			copied = copy_from_iter(addr, copy_len, data);
-			if (WARN_ON(copied != copy_len))
+			copied = fcw_copy_from_iter(addr, copy_len, data);
+			if (fcw_warn_on(copied != copy_len))
 				return -EINVAL;
 			testmgr_poison(addr + copy_len, partitions[i].length +
 				       TESTMGR_POISON_LEN - copy_len);
@@ -663,7 +663,7 @@ static int build_test_sglist(struct test_sglist *tsgl,
 
 	sg_mark_end(&tsgl->sgl[tsgl->nents - 1]);
 	tsgl->sgl_ptr = tsgl->sgl;
-	memcpy(tsgl->sgl_saved, tsgl->sgl, tsgl->nents * sizeof(tsgl->sgl[0]));
+	fcw_memcpy(tsgl->sgl_saved, tsgl->sgl, tsgl->nents * sizeof(tsgl->sgl[0]));
 	return 0;
 }
 
@@ -702,7 +702,7 @@ static int verify_correct_output(const struct test_sglist *tsgl,
 			unchecked_prefix_len = 0;
 		}
 		len = min(len, len_to_check);
-		actual_output = page_address(sg_page(sg)) + offset;
+		actual_output = page_address(fcw_sg_page(sg)) + offset;
 		if (memcmp(expected_output, actual_output, len) != 0)
 			return -EINVAL;
 		if (check_poison &&
@@ -711,7 +711,7 @@ static int verify_correct_output(const struct test_sglist *tsgl,
 		len_to_check -= len;
 		expected_output += len;
 	}
-	if (WARN_ON(len_to_check != 0))
+	if (fcw_warn_on(len_to_check != 0))
 		return -EINVAL;
 	return 0;
 }
@@ -805,9 +805,9 @@ static int build_cipher_test_sglists(struct cipher_test_sglists *tsgls,
 		 * two scatterlists have identical entries, rather than
 		 * different entries that split up the same memory differently.
 		 */
-		memcpy(tsgls->dst.sgl, tsgls->src.sgl,
+		fcw_memcpy(tsgls->dst.sgl, tsgls->src.sgl,
 		       tsgls->src.nents * sizeof(tsgls->src.sgl[0]));
-		memcpy(tsgls->dst.sgl_saved, tsgls->src.sgl,
+		fcw_memcpy(tsgls->dst.sgl_saved, tsgls->src.sgl,
 		       tsgls->src.nents * sizeof(tsgls->src.sgl[0]));
 		tsgls->dst.sgl_ptr = tsgls->dst.sgl;
 		tsgls->dst.nents = tsgls->src.nents;
@@ -841,7 +841,7 @@ static int prepare_keybuf(const u8 *key, unsigned int ksize,
 		if (!keybuf)
 			return -ENOMEM;
 		keyptr = keybuf + key_offset;
-		memcpy(keyptr, key, ksize);
+		fcw_memcpy(keyptr, key, ksize);
 	}
 	*keybuf_ret = keybuf;
 	*keyptr_ret = keyptr;
@@ -1180,7 +1180,7 @@ static void generate_random_testvec_config(struct rnd_state *rng,
 		p += scnprintf(p, end - p, " key_offset=%u", cfg->key_offset);
 	}
 
-	WARN_ON_ONCE(!valid_testvec_config(cfg));
+	fcw_warn_on_once((!valid_testvec_config(cfg)));
 }
 
 static void crypto_disable_simd_for_test(void)
@@ -1225,7 +1225,7 @@ static int build_generic_driver_name(const char *algname,
 			len += 8;
 			if (len >= CRYPTO_MAX_ALG_NAME)
 				goto too_long;
-			memcpy(out, "-generic", 8);
+			fcw_memcpy(out, "-generic", 8);
 			out += 8;
 		}
 	} while ((*out++ = *in++) != '\0');
@@ -1348,7 +1348,7 @@ static int test_shash_vec_cfg(const struct hash_testvec *vec,
 			return 0;
 		if (cfg->nosimd)
 			crypto_disable_simd_for_test();
-		err = crypto_shash_digest(desc, sg_virt(&tsgl->sgl[0]),
+		err = crypto_shash_digest(desc, fcw_sg_virt(&tsgl->sgl[0]),
 					  tsgl->sgl[0].length, result);
 		if (cfg->nosimd)
 			crypto_reenable_simd_for_test();
@@ -1384,7 +1384,7 @@ static int test_shash_vec_cfg(const struct hash_testvec *vec,
 		    cfg->finalization_type == FINALIZATION_TYPE_FINUP) {
 			if (divs[i]->nosimd)
 				crypto_disable_simd_for_test();
-			err = crypto_shash_finup(desc, sg_virt(&tsgl->sgl[i]),
+			err = crypto_shash_finup(desc, fcw_sg_virt(&tsgl->sgl[i]),
 						 tsgl->sgl[i].length, result);
 			if (divs[i]->nosimd)
 				crypto_reenable_simd_for_test();
@@ -1396,7 +1396,7 @@ static int test_shash_vec_cfg(const struct hash_testvec *vec,
 		}
 		if (divs[i]->nosimd)
 			crypto_disable_simd_for_test();
-		err = crypto_shash_update(desc, sg_virt(&tsgl->sgl[i]),
+		err = crypto_shash_update(desc, fcw_sg_virt(&tsgl->sgl[i]),
 					  tsgl->sgl[i].length);
 		if (divs[i]->nosimd)
 			crypto_reenable_simd_for_test();
@@ -2110,10 +2110,10 @@ static int test_aead_vec_cfg(int enc, const struct aead_testvec *vec,
 		return 0;
 
 	/* The IV must be copied to a buffer, as the algorithm may modify it */
-	if (WARN_ON(ivsize > MAX_IVLEN))
+	if (fcw_warn_on(ivsize > MAX_IVLEN))
 		return -EINVAL;
 	if (vec->iv)
-		memcpy(iv, vec->iv, ivsize);
+		fcw_memcpy(iv, vec->iv, ivsize);
 	else
 		memset(iv, 0, ivsize);
 
@@ -2348,7 +2348,7 @@ static void generate_aead_message(struct rnd_state *rng,
 	generate_random_bytes(rng, (u8 *)vec->assoc, vec->alen);
 	if (suite->aad_iv && vec->alen >= ivsize)
 		/* Avoid implementation-defined behavior. */
-		memcpy((u8 *)vec->assoc + vec->alen - ivsize, vec->iv, ivsize);
+		fcw_memcpy((u8 *)vec->assoc + vec->alen - ivsize, vec->iv, ivsize);
 
 	if (inauthentic && prandom_bool(rng)) {
 		/* Generate a random ciphertext. */
@@ -2362,13 +2362,13 @@ static void generate_aead_message(struct rnd_state *rng,
 		/* Generate a random plaintext and encrypt it. */
 		sg_init_table(src, 2);
 		if (vec->alen)
-			sg_set_buf(&src[i++], vec->assoc, vec->alen);
+			fcw_sg_set_buf(&src[i++], vec->assoc, vec->alen);
 		if (vec->plen) {
 			generate_random_bytes(rng, (u8 *)vec->ptext, vec->plen);
-			sg_set_buf(&src[i++], vec->ptext, vec->plen);
+			fcw_sg_set_buf(&src[i++], vec->ptext, vec->plen);
 		}
 		sg_init_one(&dst, vec->ctext, vec->alen + vec->clen);
-		memcpy(iv, vec->iv, ivsize);
+		fcw_memcpy(iv, vec->iv, ivsize);
 		aead_request_set_callback(req, 0, crypto_req_done, &wait);
 		aead_request_set_crypt(req, src, &dst, vec->plen, iv);
 		aead_request_set_ad(req, vec->alen);
@@ -2429,7 +2429,7 @@ static void generate_random_aead_testvec(struct rnd_state *rng,
 		authsize = prandom_u32_below(rng, maxauthsize + 1);
 	if (prefer_inauthentic && authsize < MIN_COLLISION_FREE_AUTHSIZE)
 		authsize = MIN_COLLISION_FREE_AUTHSIZE;
-	if (WARN_ON(authsize > maxdatasize))
+	if (fcw_warn_on(authsize > maxdatasize))
 		authsize = maxdatasize;
 	maxdatasize -= authsize;
 	vec->setauthsize_error = crypto_aead_setauthsize(tfm, authsize);
@@ -2778,11 +2778,11 @@ static int test_cipher(struct crypto_cipher *tfm, int enc,
 		j++;
 
 		ret = -EINVAL;
-		if (WARN_ON(template[i].len > PAGE_SIZE))
+		if (fcw_warn_on(template[i].len > PAGE_SIZE))
 			goto out;
 
 		data = xbuf[0];
-		memcpy(data, input, template[i].len);
+		fcw_memcpy(data, input, template[i].len);
 
 		crypto_cipher_clear_flags(tfm, ~0);
 		if (template[i].wk)
@@ -2877,12 +2877,12 @@ static int test_skcipher_vec_cfg(int enc, const struct cipher_testvec *vec,
 
 	/* The IV must be copied to a buffer, as the algorithm may modify it */
 	if (ivsize) {
-		if (WARN_ON(ivsize > MAX_IVLEN))
+		if (fcw_warn_on(ivsize > MAX_IVLEN))
 			return -EINVAL;
 		if (vec->generates_iv && !enc)
-			memcpy(iv, vec->iv_out, ivsize);
+			fcw_memcpy(iv, vec->iv_out, ivsize);
 		else if (vec->iv)
-			memcpy(iv, vec->iv, ivsize);
+			fcw_memcpy(iv, vec->iv, ivsize);
 		else
 			memset(iv, 0, ivsize);
 	} else {
@@ -3080,7 +3080,7 @@ static void generate_random_cipher_testvec(struct rnd_state *rng,
 	/* Ciphertext */
 	sg_init_one(&src, vec->ptext, vec->len);
 	sg_init_one(&dst, vec->ctext, vec->len);
-	memcpy(iv, vec->iv, ivsize);
+	fcw_memcpy(iv, vec->iv, ivsize);
 	skcipher_request_set_callback(req, 0, crypto_req_done, &wait);
 	skcipher_request_set_crypt(req, &src, &dst, vec->len, iv);
 	vec->crypt_error = crypto_wait_req(crypto_skcipher_encrypt(req), &wait);
@@ -3650,10 +3650,10 @@ static int test_cprng(struct crypto_rng *tfm,
 	for (i = 0; i < tcount; i++) {
 		memset(result, 0, 32);
 
-		memcpy(seed, template[i].v, template[i].vlen);
-		memcpy(seed + template[i].vlen, template[i].key,
+		fcw_memcpy(seed, template[i].v, template[i].vlen);
+		fcw_memcpy(seed + template[i].vlen, template[i].key,
 		       template[i].klen);
-		memcpy(seed + template[i].vlen + template[i].klen,
+		fcw_memcpy(seed + template[i].vlen + template[i].klen,
 		       template[i].dt, template[i].dtlen);
 
 		err = crypto_rng_reset(tfm, seed, seedsize);
@@ -3977,14 +3977,14 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 
 	if (vec->genkey) {
 		/* Save party A's public key */
-		a_public = kmemdup(sg_virt(req->dst), out_len_max, GFP_KERNEL);
+		a_public = kmemdup(fcw_sg_virt(req->dst), out_len_max, GFP_KERNEL);
 		if (!a_public) {
 			err = -ENOMEM;
 			goto free_output;
 		}
 	} else {
 		/* Verify calculated public key */
-		if (memcmp(vec->expected_a_public, sg_virt(req->dst),
+		if (memcmp(vec->expected_a_public, fcw_sg_virt(req->dst),
 			   vec->expected_a_public_size)) {
 			pr_err("alg: %s: Party A: generate public key test failed. Invalid output\n",
 			       alg);
@@ -4016,7 +4016,7 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 
 	if (vec->genkey) {
 		/* Save the shared secret obtained by party A */
-		a_ss = kmemdup(sg_virt(req->dst), vec->expected_ss_size, GFP_KERNEL);
+		a_ss = kmemdup(fcw_sg_virt(req->dst), vec->expected_ss_size, GFP_KERNEL);
 		if (!a_ss) {
 			err = -ENOMEM;
 			goto free_all;
@@ -4054,7 +4054,7 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 	 * verify shared secret from which the user will derive
 	 * secret key by executing whatever hash it has chosen
 	 */
-	if (memcmp(shared_secret, sg_virt(req->dst),
+	if (memcmp(shared_secret, fcw_sg_virt(req->dst),
 		   vec->expected_ss_size)) {
 		pr_err("alg: %s: compute shared secret test failed. Invalid output\n",
 		       alg);
@@ -4112,7 +4112,7 @@ static int alg_test_kpp(const struct alg_test_desc *desc, const char *driver,
 
 static u8 *test_pack_u32(u8 *dst, u32 val)
 {
-	memcpy(dst, &val, sizeof(val));
+	fcw_memcpy(dst, &val, sizeof(val));
 	return dst + sizeof(val);
 }
 
@@ -4145,11 +4145,11 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 		      GFP_KERNEL);
 	if (!key)
 		goto free_req;
-	memcpy(key, vecs->key, vecs->key_len);
+	fcw_memcpy(key, vecs->key, vecs->key_len);
 	ptr = key + vecs->key_len;
 	ptr = test_pack_u32(ptr, vecs->algo);
 	ptr = test_pack_u32(ptr, vecs->param_len);
-	memcpy(ptr, vecs->params, vecs->param_len);
+	fcw_memcpy(ptr, vecs->params, vecs->param_len);
 
 	if (vecs->public_key_vec)
 		err = crypto_akcipher_set_pub_key(tfm, key, vecs->key_len);
@@ -4186,18 +4186,18 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 	}
 
 	err = -E2BIG;
-	if (WARN_ON(m_size > PAGE_SIZE))
+	if (fcw_warn_on(m_size > PAGE_SIZE))
 		goto free_all;
-	memcpy(xbuf[0], m, m_size);
+	fcw_memcpy(xbuf[0], m, m_size);
 
 	sg_init_table(src_tab, 3);
-	sg_set_buf(&src_tab[0], xbuf[0], 8);
-	sg_set_buf(&src_tab[1], xbuf[0] + 8, m_size - 8);
+	fcw_sg_set_buf(&src_tab[0], xbuf[0], 8);
+	fcw_sg_set_buf(&src_tab[1], xbuf[0] + 8, m_size - 8);
 	if (vecs->siggen_sigver_test) {
-		if (WARN_ON(c_size > PAGE_SIZE))
+		if (fcw_warn_on(c_size > PAGE_SIZE))
 			goto free_all;
-		memcpy(xbuf[1], c, c_size);
-		sg_set_buf(&src_tab[2], xbuf[1], c_size);
+		fcw_memcpy(xbuf[1], c, c_size);
+		fcw_sg_set_buf(&src_tab[2], xbuf[1], c_size);
 		akcipher_request_set_crypt(req, src_tab, NULL, m_size, c_size);
 	} else {
 		sg_init_one(&dst, outbuf_enc, out_len_max);
@@ -4254,9 +4254,9 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 
 	err = -E2BIG;
 	op = vecs->siggen_sigver_test ? "sign" : "decrypt";
-	if (WARN_ON(c_size > PAGE_SIZE))
+	if (fcw_warn_on(c_size > PAGE_SIZE))
 		goto free_all;
-	memcpy(xbuf[0], c, c_size);
+	fcw_memcpy(xbuf[0], c, c_size);
 
 	sg_init_one(&src, xbuf[0], c_size);
 	sg_init_one(&dst, outbuf_dec, out_len_max);
@@ -5841,13 +5841,13 @@ static void alg_check_test_descs_order(void)
 		int diff = strcmp(alg_test_descs[i - 1].alg,
 				  alg_test_descs[i].alg);
 
-		if (WARN_ON(diff > 0)) {
+		if (fcw_warn_on(diff > 0)) {
 			pr_warn("testmgr: alg_test_descs entries in wrong order: '%s' before '%s'\n",
 				alg_test_descs[i - 1].alg,
 				alg_test_descs[i].alg);
 		}
 
-		if (WARN_ON(diff == 0)) {
+		if (fcw_warn_on(diff == 0)) {
 			pr_warn("testmgr: duplicate alg_test_descs entry: '%s'\n",
 				alg_test_descs[i].alg);
 		}
@@ -5859,12 +5859,12 @@ static void alg_check_testvec_configs(void)
 	int i;
 
 	for (i = 0; i < ARRAY_SIZE(default_cipher_testvec_configs); i++)
-		WARN_ON(!valid_testvec_config(
-				&default_cipher_testvec_configs[i]));
+		fcw_warn_on((!valid_testvec_config(
+				&default_cipher_testvec_configs[i])));
 
 	for (i = 0; i < ARRAY_SIZE(default_hash_testvec_configs); i++)
-		WARN_ON(!valid_testvec_config(
-				&default_hash_testvec_configs[i]));
+		fcw_warn_on((!valid_testvec_config(
+				&default_hash_testvec_configs[i])));
 }
 
 static void testmgr_onetime_init(void)
@@ -5980,9 +5980,11 @@ int alg_test(const char *driver, const char *alg, u32 type, u32 mask)
 		}
 		pr_warn("alg: self-tests for %s using %s failed (rc=%d)",
 			alg, driver, rc);
-		WARN(rc != -ENOENT,
-		     "alg: self-tests for %s using %s failed (rc=%d)",
-		     alg, driver, rc);
+		if (fcw_is_warn_true(rc != -ENOENT)) {
+			fcw_warn_printk("alg: self-tests for %s using %s failed (rc=%d)",
+					alg, driver, rc);
+			fcw_warn();
+		}
 	} else {
 		if (fips_enabled)
 			pr_info("alg: self-tests for %s (%s) passed\n",
diff --git a/lib/crypto/sha256.c b/lib/crypto/sha256.c
index 04c1f2557..ca5cd6492 100644
--- a/lib/crypto/sha256.c
+++ b/lib/crypto/sha256.c
@@ -17,6 +17,11 @@
 #include <linux/module.h>
 #include <linux/string.h>
 
+extern int fcw_lib_sha256_base_do_update(struct sha256_state *sctx,
+					 const u8 *data,
+					 unsigned int len,
+					 sha256_block_fn *block_fn);
+
 static const u32 SHA256_K[] = {
 	0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,
 	0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
@@ -36,6 +41,8 @@ static const u32 SHA256_K[] = {
 	0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2,
 };
 
+extern void *fcw_memcpy(void *dst, const void *src, size_t len);
+
 static inline u32 Ch(u32 x, u32 y, u32 z)
 {
 	return z ^ (x & (y ^ z));
@@ -133,7 +140,11 @@ static void sha256_transform_blocks(struct sha256_state *sctx,
 
 void sha256_update(struct sha256_state *sctx, const u8 *data, unsigned int len)
 {
+#ifdef FIPS_CANISTER
+	fcw_lib_sha256_base_do_update(sctx, data, len, sha256_transform_blocks);
+#else
 	lib_sha256_base_do_update(sctx, data, len, sha256_transform_blocks);
+#endif
 }
 EXPORT_SYMBOL(sha256_update);
 
-- 
2.39.4

