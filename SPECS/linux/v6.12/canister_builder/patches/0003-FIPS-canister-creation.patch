From f2c54f9bf8907f01233d7f28e0e48d50c8b5b396 Mon Sep 17 00:00:00 2001
From: Vamsi Krishna Brahmajosyula <vamsi-krishna.brahmajosyula@broadcom.com>
Date: Fri, 2 May 2025 02:57:23 -0500
Subject: [PATCH 03/12] FIPS canister creation

Canister creation patch.
 - Makefile changes to generate canister binary (fips_canister.o)
 - Move mutex API out of canister to the wrapper as it expands differently
   depending on .config options. The difference is huge in -rt kernel.
 - Use mutex instead of spinlock in canister. There is no difference to the
   code that use it, but improvement for -rt kernel and simplification for
   the wrapper.
 - Move kernel memory alloc functions out of canister as their implementations
   vary depending on .config options.
 - Move cond_resched function to the wrapper.
 - Add internal static functions to eliminate glue helpers calls.
 - Redo DO_ONCE as it is not supported by integrity code.
 - Do not use latent entropy GCC plugin for canister objects
 - Do not check indirect call destination signatures from canister
 - Remove rsa-pkcs1pad encrypt/decrypt functions from canister

Signed-off-by: Alexey Makhalov <amakhalov@vmware.com>
Signed-off-by: Vamsi Krishna Brahmajosyula <vbrahmajosyula@vmware.com>
Signed-off-by: Keerthana K <keerthana.kalyanasundaram@broadcom.com>
Signed-off-by: Shivani Agarwal <shivani.agarwal@broadcom.com>
---
 arch/x86/crypto/aesni-intel_glue.c |  77 ++++++-------
 crypto/Makefile                    |  91 ++++++++++++++++
 crypto/algboss.c                   |   5 +-
 crypto/ccm.c                       |   7 +-
 crypto/cmac.c                      |   3 +-
 crypto/ctr.c                       |   3 +-
 crypto/cts.c                       |   3 +-
 crypto/drbg.c                      |  50 +++++----
 crypto/ecb.c                       |   2 +-
 crypto/ecc.c                       |   5 +-
 crypto/ecdh.c                      |   5 +-
 crypto/ecdsa.c                     |   3 +-
 crypto/gcm.c                       |  11 +-
 crypto/ghash-generic.c             |   5 +-
 crypto/hmac.c                      |   3 +-
 crypto/rsa-pkcs1pad.c              | 168 ++---------------------------
 crypto/sha3_generic.c              |   5 +-
 crypto/testmgr.c                   | 108 ++++++++++---------
 crypto/xts.c                       |   3 +-
 include/crypto/drbg.h              |   3 +-
 20 files changed, 271 insertions(+), 289 deletions(-)

diff --git a/arch/x86/crypto/aesni-intel_glue.c b/arch/x86/crypto/aesni-intel_glue.c
index b0dd83555..55ed01a67 100644
--- a/arch/x86/crypto/aesni-intel_glue.c
+++ b/arch/x86/crypto/aesni-intel_glue.c
@@ -37,7 +37,10 @@
 #include <linux/workqueue.h>
 #include <linux/spinlock.h>
 #include <linux/static_call.h>
+#include <crypto/gf128mul.h>
 
+void fcw_kernel_fpu_begin(void);
+void fcw_kernel_fpu_end(void);
 
 #define AESNI_ALIGN	16
 #define AESNI_ALIGN_ATTR __attribute__ ((__aligned__(AESNI_ALIGN)))
@@ -130,9 +133,9 @@ static int aes_set_key_common(struct crypto_aes_ctx *ctx,
 	if (err)
 		return err;
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 	aesni_set_key(ctx, in_key, key_len);
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 	return 0;
 }
 
@@ -150,9 +153,9 @@ static void aesni_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)
 	if (!crypto_simd_usable()) {
 		aes_encrypt(ctx, dst, src);
 	} else {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_enc(ctx, dst, src);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 	}
 }
 
@@ -163,9 +166,9 @@ static void aesni_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)
 	if (!crypto_simd_usable()) {
 		aes_decrypt(ctx, dst, src);
 	} else {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_dec(ctx, dst, src);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 	}
 }
 
@@ -186,10 +189,10 @@ static int ecb_encrypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes)) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_ecb_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			      nbytes & AES_BLOCK_MASK);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		nbytes &= AES_BLOCK_SIZE - 1;
 		err = skcipher_walk_done(&walk, nbytes);
 	}
@@ -208,10 +211,10 @@ static int ecb_decrypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes)) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_ecb_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			      nbytes & AES_BLOCK_MASK);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		nbytes &= AES_BLOCK_SIZE - 1;
 		err = skcipher_walk_done(&walk, nbytes);
 	}
@@ -230,10 +233,10 @@ static int cbc_encrypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes)) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_cbc_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			      nbytes & AES_BLOCK_MASK, walk.iv);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		nbytes &= AES_BLOCK_SIZE - 1;
 		err = skcipher_walk_done(&walk, nbytes);
 	}
@@ -252,10 +255,10 @@ static int cbc_decrypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes)) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_cbc_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			      nbytes & AES_BLOCK_MASK, walk.iv);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		nbytes &= AES_BLOCK_SIZE - 1;
 		err = skcipher_walk_done(&walk, nbytes);
 	}
@@ -311,10 +314,10 @@ static int cts_cbc_encrypt(struct skcipher_request *req)
 	if (err)
 		return err;
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 	aesni_cts_cbc_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			  walk.nbytes, walk.iv);
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 
 	return skcipher_walk_done(&walk, 0);
 }
@@ -367,10 +370,10 @@ static int cts_cbc_decrypt(struct skcipher_request *req)
 	if (err)
 		return err;
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 	aesni_cts_cbc_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			  walk.nbytes, walk.iv);
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 
 	return skcipher_walk_done(&walk, 0);
 }
@@ -405,7 +408,7 @@ static int ctr_crypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes) > 0) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		if (nbytes & AES_BLOCK_MASK)
 			static_call(aesni_ctr_enc_tfm)(ctx, walk.dst.virt.addr,
 						       walk.src.virt.addr,
@@ -421,7 +424,7 @@ static int ctr_crypt(struct skcipher_request *req)
 			crypto_inc(walk.iv, AES_BLOCK_SIZE);
 			nbytes = 0;
 		}
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		err = skcipher_walk_done(&walk, nbytes);
 	}
 	return err;
@@ -456,7 +459,7 @@ static int xctr_crypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes) > 0) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		if (nbytes & AES_BLOCK_MASK)
 			aesni_xctr_enc_avx_tfm(ctx, walk.dst.virt.addr,
 				walk.src.virt.addr, nbytes & AES_BLOCK_MASK,
@@ -474,7 +477,7 @@ static int xctr_crypt(struct skcipher_request *req)
 			byte_ctr += nbytes;
 			nbytes = 0;
 		}
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		err = skcipher_walk_done(&walk, nbytes);
 	}
 	return err;
@@ -541,11 +544,11 @@ xts_crypt_slowpath(struct skcipher_request *req, xts_crypt_func crypt_func)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while (walk.nbytes) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		(*crypt_func)(&ctx->crypt_ctx,
 			      walk.src.virt.addr, walk.dst.virt.addr,
 			      walk.nbytes & ~(AES_BLOCK_SIZE - 1), req->iv);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		err = skcipher_walk_done(&walk,
 					 walk.nbytes & (AES_BLOCK_SIZE - 1));
 	}
@@ -566,10 +569,10 @@ xts_crypt_slowpath(struct skcipher_request *req, xts_crypt_func crypt_func)
 	if (err)
 		return err;
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 	(*crypt_func)(&ctx->crypt_ctx, walk.src.virt.addr, walk.dst.virt.addr,
 		      walk.nbytes, req->iv);
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 
 	return skcipher_walk_done(&walk, 0);
 }
@@ -588,7 +591,7 @@ xts_crypt(struct skcipher_request *req, xts_encrypt_iv_func encrypt_iv,
 	if (unlikely(cryptlen < AES_BLOCK_SIZE))
 		return -EINVAL;
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 	(*encrypt_iv)(&ctx->tweak_ctx, req->iv);
 
 	/*
@@ -610,10 +613,10 @@ xts_crypt(struct skcipher_request *req, xts_encrypt_iv_func encrypt_iv,
 			      req->iv);
 		kunmap_local(dst_virt);
 		kunmap_local(src_virt);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		return 0;
 	}
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 	return xts_crypt_slowpath(req, crypt_func);
 }
 
@@ -1215,10 +1218,10 @@ static int gcm_setkey(struct crypto_aead *tfm, const u8 *raw_key,
 		err = aes_check_keylen(keylen);
 		if (err)
 			return err;
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_set_key(&key->aes_key, raw_key, keylen);
 		aes_gcm_precompute(key, flags);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 	} else {
 		static const u8 x_to_the_minus1[16] __aligned(__alignof__(be128)) = {
 			[0] = 0xc2, [15] = 1
@@ -1323,8 +1326,8 @@ static void gcm_process_assoc(const struct aes_gcm_key *key, u8 ghash_acc[16],
 		scatterwalk_unmap(mapped);
 		scatterwalk_pagedone(&walk, 0, assoclen);
 		if (need_resched()) {
-			kernel_fpu_end();
-			kernel_fpu_begin();
+			fcw_kernel_fpu_end();
+			fcw_kernel_fpu_begin();
 		}
 	}
 	if (unlikely(pos))
@@ -1377,7 +1380,7 @@ gcm_crypt(struct aead_request *req, int flags)
 	 * section and start a new one if there are multiple data segments or if
 	 * rescheduling is needed while processing the associated data.
 	 */
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 
 	/* Pass the associated data through GHASH. */
 	gcm_process_assoc(key, ghash_acc, req->src, assoclen, flags);
@@ -1395,11 +1398,11 @@ gcm_crypt(struct aead_request *req, int flags)
 		aes_gcm_update(key, le_ctr, ghash_acc, walk.src.virt.addr,
 			       walk.dst.virt.addr, nbytes, flags);
 		le_ctr[0] += nbytes / AES_BLOCK_SIZE;
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		err = skcipher_walk_done(&walk, walk.nbytes - nbytes);
 		if (err)
 			return err;
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 	}
 	/* Last segment: process all remaining data. */
 	aes_gcm_update(key, le_ctr, ghash_acc, walk.src.virt.addr,
@@ -1435,7 +1438,7 @@ gcm_crypt(struct aead_request *req, int flags)
 				       datalen, tag, taglen, flags))
 			err = -EBADMSG;
 	}
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 	if (nbytes)
 		skcipher_walk_done(&walk, 0);
 	return err;
diff --git a/crypto/Makefile b/crypto/Makefile
index 1b301de0b..ea127f8b5 100644
--- a/crypto/Makefile
+++ b/crypto/Makefile
@@ -14,9 +14,11 @@ crypto_algapi-y := algapi.o scatterwalk.o $(crypto_algapi-y)
 obj-$(CONFIG_CRYPTO_ALGAPI2) += crypto_algapi.o
 
 obj-$(CONFIG_CRYPTO_AEAD2) += aead.o
+canister += geniv.o
 
 crypto_skcipher-y += lskcipher.o
 crypto_skcipher-y += skcipher.o
+canister += seqiv.o
 
 obj-$(CONFIG_CRYPTO_SKCIPHER2) += crypto_skcipher.o
 ifeq ($(CONFIG_BPF_SYSCALL),y)
@@ -46,26 +48,35 @@ rsa_generic-y += rsaprivkey.asn1.o
 rsa_generic-y += rsa.o
 rsa_generic-y += rsa_helper.o
 rsa_generic-y += rsa-pkcs1pad.o
+canister += $(rsa_generic-y)
 obj-$(CONFIG_CRYPTO_RSA) += rsa-pkcs1pad_crypt.o
 
 $(obj)/ecdsasignature.asn1.o: $(obj)/ecdsasignature.asn1.c $(obj)/ecdsasignature.asn1.h
 $(obj)/ecdsa.o: $(obj)/ecdsasignature.asn1.h
 ecdsa_generic-y += ecdsa.o
 ecdsa_generic-y += ecdsasignature.asn1.o
+canister += $(ecdsa_generic-y)
 
 crypto_acompress-y := acompress.o
 crypto_acompress-y += scompress.o
 obj-$(CONFIG_CRYPTO_ACOMP2) += crypto_acompress.o
 
 cryptomgr-y := algboss.o testmgr.o
+canister += $(cryptomgr-y)
 
 obj-$(CONFIG_CRYPTO_USER) += crypto_user.o
+canister += hmac.o
+canister += cmac.o
 obj-$(CONFIG_CRYPTO_VMAC) += vmac.o
 obj-$(CONFIG_CRYPTO_XCBC) += xcbc.o
 obj-$(CONFIG_CRYPTO_NULL2) += crypto_null.o
 obj-$(CONFIG_CRYPTO_MD4) += md4.o
 obj-$(CONFIG_CRYPTO_MD5) += md5.o
 obj-$(CONFIG_CRYPTO_RMD160) += rmd160.o
+canister += sha1_generic.o
+canister += sha256_generic.o
+canister += sha512_generic.o
+canister += sha3_generic.o
 obj-$(CONFIG_CRYPTO_SM3) += sm3.o
 obj-$(CONFIG_CRYPTO_SM3_GENERIC) += sm3_generic.o
 obj-$(CONFIG_CRYPTO_STREEBOG) += streebog_generic.o
@@ -73,13 +84,20 @@ obj-$(CONFIG_CRYPTO_WP512) += wp512.o
 CFLAGS_wp512.o := $(call cc-option,-fno-schedule-insns)  # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=79149
 obj-$(CONFIG_CRYPTO_BLAKE2B) += blake2b_generic.o
 CFLAGS_blake2b_generic.o := -Wframe-larger-than=4096 #  https://gcc.gnu.org/bugzilla/show_bug.cgi?id=105930
+canister += ecb.o
+canister += cbc.o
 obj-$(CONFIG_CRYPTO_PCBC) += pcbc.o
+canister += cts.o
 obj-$(CONFIG_CRYPTO_LRW) += lrw.o
+canister += xts.o
+canister += ctr.o
 obj-$(CONFIG_CRYPTO_XCTR) += xctr.o
 obj-$(CONFIG_CRYPTO_HCTR2) += hctr2.o
 obj-$(CONFIG_CRYPTO_KEYWRAP) += keywrap.o
 obj-$(CONFIG_CRYPTO_ADIANTUM) += adiantum.o
 obj-$(CONFIG_CRYPTO_NHPOLY1305) += nhpoly1305.o
+canister += gcm.o
+canister += ccm.o
 obj-$(CONFIG_CRYPTO_CHACHA20POLY1305) += chacha20poly1305.o
 obj-$(CONFIG_CRYPTO_AEGIS128) += aegis128.o
 aegis128-y := aegis128-core.o
@@ -114,6 +132,7 @@ obj-$(CONFIG_CRYPTO_TWOFISH) += twofish_generic.o
 obj-$(CONFIG_CRYPTO_TWOFISH_COMMON) += twofish_common.o
 obj-$(CONFIG_CRYPTO_SERPENT) += serpent_generic.o
 CFLAGS_serpent_generic.o := $(call cc-option,-fsched-pressure)  # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=79149
+canister += aes_generic.o
 CFLAGS_aes_generic.o := $(call cc-option,-fno-code-hoisting) # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=83356
 obj-$(CONFIG_CRYPTO_SM4) += sm4.o
 obj-$(CONFIG_CRYPTO_SM4_GENERIC) += sm4_generic.o
@@ -151,6 +170,7 @@ UBSAN_SANITIZE_jitterentropy.o = n
 jitterentropy_rng-y := jitterentropy.o jitterentropy-kcapi.o
 obj-$(CONFIG_CRYPTO_JITTERENTROPY_TESTINTERFACE) += jitterentropy-testing.o
 obj-$(CONFIG_CRYPTO_TEST) += tcrypt.o
+canister += ghash-generic.o
 obj-$(CONFIG_CRYPTO_POLYVAL) += polyval-generic.o
 obj-$(CONFIG_CRYPTO_USER_API) += af_alg.o
 obj-$(CONFIG_CRYPTO_USER_API_HASH) += algif_hash.o
@@ -158,11 +178,14 @@ obj-$(CONFIG_CRYPTO_USER_API_SKCIPHER) += algif_skcipher.o
 obj-$(CONFIG_CRYPTO_USER_API_RNG) += algif_rng.o
 obj-$(CONFIG_CRYPTO_USER_API_AEAD) += algif_aead.o
 obj-$(CONFIG_CRYPTO_ZSTD) += zstd.o
+canister += ecc.o
 obj-$(CONFIG_CRYPTO_ESSIV) += essiv.o
 obj-$(CONFIG_CRYPTO_CURVE25519) += curve25519-generic.o
+canister += drbg.o
 
 ecdh_generic-y += ecdh.o
 ecdh_generic-y += ecdh_helper.o
+canister += $(ecdh_generic-y)
 
 $(obj)/ecrdsa_params.asn1.o: $(obj)/ecrdsa_params.asn1.c $(obj)/ecrdsa_params.asn1.h
 $(obj)/ecrdsa_pub_key.asn1.o: $(obj)/ecrdsa_pub_key.asn1.c $(obj)/ecrdsa_pub_key.asn1.h
@@ -186,6 +209,74 @@ obj-$(CONFIG_CRYPTO_SIMD) += crypto_simd.o
 # Key derivation function
 #
 obj-$(CONFIG_CRYPTO_KDF800108_CTR) += kdf_sp800108.o
+
+aesni-intel-y := aesni-intel_asm.o aesni-intel_glue.o
+aesni-intel-$(CONFIG_64BIT) += aes_ctrby8_avx-x86_64.o aes-gcm-aesni-x86_64.o aes-xts-avx-x86_64.o
+ifeq ($(CONFIG_AS_VAES)$(CONFIG_AS_VPCLMULQDQ),yy)
+aesni-intel-$(CONFIG_64BIT) += aes-gcm-avx10-x86_64.o
+OBJECT_FILES_NON_STANDARD_x86-aes-gcm-avx10-x86_64.o := y
+endif
+OBJECT_FILES_NON_STANDARD_x86-aes-gcm-aesni-x86_64.o := y
+OBJECT_FILES_NON_STANDARD_x86-aes-xts-avx-x86_64.o := y
+
+crypto/x86-%.o: arch/x86/crypto/%.c $(recordmcount_source) $(objtool_dep) FORCE
+	$(call cmd,force_checksrc)
+	$(call if_changed_rule,cc_o_c)
+
+crypto/x86-%.o: arch/x86/crypto/%.S $(objtool_dep) FORCE
+	$(call if_changed_rule,as_o_S)
+
+lib-crypto-y := aes.o sha256.o sha1.o
+crypto/lib-crypto-%.o: lib/crypto/%.c $(recordmcount_source) $(objtool_dep) FORCE
+	$(call cmd,force_checksrc)
+	$(call if_changed_rule,cc_o_c)
+
+canister += crypto_self_test.o
+
+canister += fips_integrity.o
+
+extra-y += $(canister)
+$(obj)/canister.o: $(addprefix crypto/x86-,$(aesni-intel-y)) $(addprefix crypto/lib-crypto-,$(lib-crypto-y)) $(addprefix $(obj)/,$(canister))
+	$(LD) -z noexecstack -T $(obj)/canister_combine.lds -r $^ -o $@
+define UPDATE_CFLAGS =
+  CFLAGS_$1 += -DFIPS_CANISTER
+  CFLAGS_REMOVE_$1 += -DLATENT_ENTROPY_PLUGIN -fplugin=./scripts/gcc-plugins/latent_entropy_plugin.so -fplugin-arg-rap_plugin-check=call $(RETPOLINE_CFLAGS) $(RETHUNK_CFLAGS)
+endef
+$(foreach obj,$(canister),$(eval $(call UPDATE_CFLAGS,$(obj))))
+
+define UPDATE_CFLAGS_LIB_CRYPTO =
+  CFLAGS_lib-crypto-$1 += -DFIPS_CANISTER
+  CFLAGS_REMOVE_lib-crypto-$1 += -DLATENT_ENTROPY_PLUGIN -fplugin=./scripts/gcc-plugins/latent_entropy_plugin.so -fplugin-arg-rap_plugin-check=call $(RETPOLINE_CFLAGS) $(RETHUNK_CFLAGS)
+endef
+$(foreach obj,$(lib-crypto-y),$(eval $(call UPDATE_CFLAGS_LIB_CRYPTO,$(obj))))
+
+define UPDATE_CFLAGS_X86 =
+  CFLAGS_x86-$1 += -DFIPS_CANISTER
+  CFLAGS_REMOVE_x86-$1 += -DLATENT_ENTROPY_PLUGIN -fplugin=./scripts/gcc-plugins/latent_entropy_plugin.so -fplugin-arg-rap_plugin-check=call $(RETPOLINE_CFLAGS) $(RETHUNK_CFLAGS)
+endef
+$(foreach obj,$(aesni-intel-y),$(eval $(call UPDATE_CFLAGS_X86,$(obj))))
+
+hostprogs := gen_canister_relocs
+HOSTLDLIBS_gen_canister_relocs = -lelf
+HOSTCFLAGS_gen_canister_relocs = -g
+
+quiet_cmd_gencr = GENCR   $@
+cmd_gencr = $(obj)/gen_canister_relocs $< $@ $(obj)/canister_markers.lds $(obj)/fips_canister-kallsyms
+$(src)/canister_relocs.c: $(obj)/canister.o $(obj)/gen_canister_relocs FORCE
+	$(call if_changed,gencr)
+clean-files += canister_relocs.c
+clean-files += fips_canister-kallsyms
+targets += canister_relocs.o
+$(obj)/canister_markers.lds: $(src)/canister_relocs.c
+
+clean-files += canister_markers.lds
+
+quiet_cmd_update_hmac = HMAC    $@
+cmd_update_hmac = $(obj)/update_canister_hmac.sh $@ $(obj)/canister_markers.lds
+$(obj)/fips_canister.o: $(obj)/canister.o $(obj)/canister_relocs.o $(obj)/canister_markers.lds FORCE
+	$(LD) -z noexecstack -T $(obj)/canister_markers.lds -r $(obj)/canister.o $(obj)/canister_relocs.o -o $@
+	$(call if_changed,update_hmac)
+
 obj-$(CONFIG_CRYPTO_FIPS) += fips_canister_wrapper_asm.o fips_canister_wrapper.o fips_canister.o
 obj-$(CONFIG_CRYPTO_FIPS) += fips_canister_wrapper_internal.o
 
diff --git a/crypto/algboss.c b/crypto/algboss.c
index a20926bfd..1159e51da 100644
--- a/crypto/algboss.c
+++ b/crypto/algboss.c
@@ -19,6 +19,7 @@
 #include <linux/string.h>
 
 #include "internal.h"
+#include "fips_canister_wrapper.h"
 
 struct cryptomgr_param {
 	struct rtattr *tb[CRYPTO_MAX_ATTRS + 2];
@@ -84,7 +85,7 @@ static int cryptomgr_schedule_probe(struct crypto_larval *larval)
 	if (!try_module_get(THIS_MODULE))
 		goto err;
 
-	param = kzalloc(sizeof(*param), GFP_KERNEL);
+	param = fcw_kzalloc(sizeof(*param), GFP_KERNEL);
 	if (!param)
 		goto err_put_module;
 
@@ -195,7 +196,7 @@ static int cryptomgr_schedule_test(struct crypto_alg *alg)
 	if (!try_module_get(THIS_MODULE))
 		goto err;
 
-	param = kzalloc(sizeof(*param), GFP_KERNEL);
+	param = fcw_kzalloc(sizeof(*param), GFP_KERNEL);
 	if (!param)
 		goto err_put_module;
 
diff --git a/crypto/ccm.c b/crypto/ccm.c
index 36f0acec3..d9172bab5 100644
--- a/crypto/ccm.c
+++ b/crypto/ccm.c
@@ -15,6 +15,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/slab.h>
+#include "fips_canister_wrapper.h"
 
 struct ccm_instance_ctx {
 	struct crypto_skcipher_spawn ctr;
@@ -459,7 +460,7 @@ static int crypto_ccm_create_common(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ictx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ictx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	ictx = aead_instance_ctx(inst);
@@ -714,7 +715,7 @@ static int crypto_rfc4309_create(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
@@ -867,7 +868,7 @@ static int cbcmac_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	spawn = shash_instance_ctx(inst);
diff --git a/crypto/cmac.c b/crypto/cmac.c
index c7aa3665b..9e95294aa 100644
--- a/crypto/cmac.c
+++ b/crypto/cmac.c
@@ -16,6 +16,7 @@
 #include <linux/err.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
+#include "fips_canister_wrapper.h"
 
 /*
  * +------------------------
@@ -241,7 +242,7 @@ static int cmac_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	spawn = shash_instance_ctx(inst);
diff --git a/crypto/ctr.c b/crypto/ctr.c
index 142049606..6fa3831e1 100644
--- a/crypto/ctr.c
+++ b/crypto/ctr.c
@@ -14,6 +14,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/slab.h>
+#include "fips_canister_wrapper.h"
 
 struct crypto_rfc3686_ctx {
 	struct crypto_skcipher *child;
@@ -267,7 +268,7 @@ static int crypto_rfc3686_create(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
diff --git a/crypto/cts.c b/crypto/cts.c
index f5b42156b..7df35e8c7 100644
--- a/crypto/cts.c
+++ b/crypto/cts.c
@@ -51,6 +51,7 @@
 #include <crypto/scatterwalk.h>
 #include <linux/slab.h>
 #include <linux/compiler.h>
+#include "fips_canister_wrapper.h"
 
 struct crypto_cts_ctx {
 	struct crypto_skcipher *child;
@@ -333,7 +334,7 @@ static int crypto_cts_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
diff --git a/crypto/drbg.c b/crypto/drbg.c
index 1ff3052d4..c0a8e4f66 100644
--- a/crypto/drbg.c
+++ b/crypto/drbg.c
@@ -101,6 +101,7 @@
 #include <crypto/internal/cipher.h>
 #include <linux/kernel.h>
 #include <linux/jiffies.h>
+#include "fips_canister_wrapper.h"
 
 /***************************************************************
  * Backend cipher definitions available to DRBG
@@ -1325,13 +1326,13 @@ static inline int drbg_alloc_state(struct drbg_state *drbg)
 	if (ret < 0)
 		goto err;
 
-	drbg->Vbuf = kmalloc(drbg_statelen(drbg) + ret, GFP_KERNEL);
+	drbg->Vbuf = fcw_kmalloc(drbg_statelen(drbg) + ret, GFP_KERNEL);
 	if (!drbg->Vbuf) {
 		ret = -ENOMEM;
 		goto fini;
 	}
 	drbg->V = PTR_ALIGN(drbg->Vbuf, ret + 1);
-	drbg->Cbuf = kmalloc(drbg_statelen(drbg) + ret, GFP_KERNEL);
+	drbg->Cbuf = fcw_kmalloc(drbg_statelen(drbg) + ret, GFP_KERNEL);
 	if (!drbg->Cbuf) {
 		ret = -ENOMEM;
 		goto fini;
@@ -1350,7 +1351,7 @@ static inline int drbg_alloc_state(struct drbg_state *drbg)
 		sb_size = drbg_statelen(drbg) + drbg_blocklen(drbg);
 
 	if (0 < sb_size) {
-		drbg->scratchpadbuf = kzalloc(sb_size + ret, GFP_KERNEL);
+		drbg->scratchpadbuf = fcw_kzalloc(sb_size + ret, GFP_KERNEL);
 		if (!drbg->scratchpadbuf) {
 			ret = -ENOMEM;
 			goto fini;
@@ -1359,7 +1360,7 @@ static inline int drbg_alloc_state(struct drbg_state *drbg)
 	}
 
 	if (IS_ENABLED(CONFIG_CRYPTO_FIPS)) {
-		drbg->prev = kzalloc(drbg_sec_strength(drbg->core->flags),
+		drbg->prev = fcw_kzalloc(drbg_sec_strength(drbg->core->flags),
 				     GFP_KERNEL);
 		if (!drbg->prev) {
 			ret = -ENOMEM;
@@ -1556,9 +1557,9 @@ static int drbg_generate_long(struct drbg_state *drbg,
 		unsigned int chunk = 0;
 		slice = ((buflen - len) / drbg_max_request_bytes(drbg));
 		chunk = slice ? drbg_max_request_bytes(drbg) : (buflen - len);
-		mutex_lock(&drbg->drbg_mutex);
+		fcw_mutex_lock(drbg->drbg_mutex);
 		err = drbg_generate(drbg, buf + len, chunk, addtl);
-		mutex_unlock(&drbg->drbg_mutex);
+		fcw_mutex_unlock(drbg->drbg_mutex);
 		if (0 > err)
 			return err;
 		len += chunk;
@@ -1610,7 +1611,7 @@ static int drbg_instantiate(struct drbg_state *drbg, struct drbg_string *pers,
 
 	pr_devel("DRBG: Initializing DRBG core %d with prediction resistance "
 		 "%s\n", coreref, pr ? "enabled" : "disabled");
-	mutex_lock(&drbg->drbg_mutex);
+	fcw_mutex_lock(drbg->drbg_mutex);
 
 	/* 9.1 step 1 is implicit with the selected DRBG type */
 
@@ -1645,15 +1646,15 @@ static int drbg_instantiate(struct drbg_state *drbg, struct drbg_string *pers,
 	if (ret && !reseed)
 		goto free_everything;
 
-	mutex_unlock(&drbg->drbg_mutex);
+	fcw_mutex_unlock(drbg->drbg_mutex);
 	return ret;
 
 unlock:
-	mutex_unlock(&drbg->drbg_mutex);
+	fcw_mutex_unlock(drbg->drbg_mutex);
 	return ret;
 
 free_everything:
-	mutex_unlock(&drbg->drbg_mutex);
+	fcw_mutex_unlock(drbg->drbg_mutex);
 	drbg_uninstantiate(drbg);
 	return ret;
 }
@@ -1692,9 +1693,9 @@ static void drbg_kcapi_set_entropy(struct crypto_rng *tfm,
 {
 	struct drbg_state *drbg = crypto_rng_ctx(tfm);
 
-	mutex_lock(&drbg->drbg_mutex);
+	fcw_mutex_lock(drbg->drbg_mutex);
 	drbg_string_fill(&drbg->test_data, data, len);
-	mutex_unlock(&drbg->drbg_mutex);
+	fcw_mutex_unlock(drbg->drbg_mutex);
 }
 
 /***************************************************************
@@ -1719,7 +1720,7 @@ static int drbg_init_hash_kernel(struct drbg_state *drbg)
 		return PTR_ERR(tfm);
 	}
 	BUG_ON(drbg_blocklen(drbg) != crypto_shash_digestsize(tfm));
-	sdesc = kzalloc(sizeof(struct shash_desc) + crypto_shash_descsize(tfm),
+	sdesc = fcw_kzalloc(sizeof(struct shash_desc) + crypto_shash_descsize(tfm),
 			GFP_KERNEL);
 	if (!sdesc) {
 		crypto_free_shash(tfm);
@@ -1819,7 +1820,7 @@ static int drbg_init_sym_kernel(struct drbg_state *drbg)
 	drbg->ctr_handle = sk_tfm;
 	crypto_init_wait(&drbg->ctr_wait);
 
-	req = skcipher_request_alloc(sk_tfm, GFP_KERNEL);
+	req = fcw_skcipher_request_alloc(sk_tfm, GFP_KERNEL);
 	if (!req) {
 		pr_info("DRBG: could not allocate request queue\n");
 		drbg_fini_sym_kernel(drbg);
@@ -1831,7 +1832,7 @@ static int drbg_init_sym_kernel(struct drbg_state *drbg)
 					crypto_req_done, &drbg->ctr_wait);
 
 	alignmask = crypto_skcipher_alignmask(sk_tfm);
-	drbg->outscratchpadbuf = kmalloc(DRBG_OUTSCRATCHLEN + alignmask,
+	drbg->outscratchpadbuf = fcw_kmalloc(DRBG_OUTSCRATCHLEN + alignmask,
 					 GFP_KERNEL);
 	if (!drbg->outscratchpadbuf) {
 		drbg_fini_sym_kernel(drbg);
@@ -1957,14 +1958,19 @@ static int drbg_kcapi_init(struct crypto_tfm *tfm)
 {
 	struct drbg_state *drbg = crypto_tfm_ctx(tfm);
 
-	mutex_init(&drbg->drbg_mutex);
+	drbg->drbg_mutex = fcw_mutex_init();
+	if (!drbg->drbg_mutex)
+		return -ENOMEM;
 
 	return 0;
 }
 
 static void drbg_kcapi_cleanup(struct crypto_tfm *tfm)
 {
-	drbg_uninstantiate(crypto_tfm_ctx(tfm));
+	struct drbg_state *drbg = crypto_tfm_ctx(tfm);
+
+	drbg_uninstantiate(drbg);
+	kfree(drbg->drbg_mutex);
 }
 
 /*
@@ -2057,11 +2063,16 @@ static inline int __init drbg_healthcheck_sanity(void)
 	drbg_convert_tfm_core("drbg_nopr_hmac_sha512", &coreref, &pr);
 #endif
 
-	drbg = kzalloc(sizeof(struct drbg_state), GFP_KERNEL);
+	drbg = fcw_kzalloc(sizeof(struct drbg_state), GFP_KERNEL);
 	if (!drbg)
 		return -ENOMEM;
 
-	mutex_init(&drbg->drbg_mutex);
+	drbg->drbg_mutex = fcw_mutex_init();
+	if (!drbg->drbg_mutex) {
+		kfree(drbg);
+		return -ENOMEM;
+	}
+
 	drbg->core = &drbg_cores[coreref];
 	drbg->reseed_threshold = drbg_max_requests(drbg);
 
@@ -2092,6 +2103,7 @@ static inline int __init drbg_healthcheck_sanity(void)
 	pr_devel("DRBG: Sanity tests for failure code paths successfully "
 		 "completed\n");
 
+	kfree(drbg->drbg_mutex);
 	kfree(drbg);
 	return rc;
 }
diff --git a/crypto/ecb.c b/crypto/ecb.c
index e3a677890..c8047736c 100644
--- a/crypto/ecb.c
+++ b/crypto/ecb.c
@@ -107,7 +107,7 @@ static struct lskcipher_instance *lskcipher_alloc_instance_simple2(
 	if (err)
 		return ERR_PTR(err);
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return ERR_PTR(-ENOMEM);
 	spawn = lskcipher_instance_ctx(inst);
diff --git a/crypto/ecc.c b/crypto/ecc.c
index 234eb2b89..1bb19b7f0 100644
--- a/crypto/ecc.c
+++ b/crypto/ecc.c
@@ -38,6 +38,7 @@
 #include <linux/fips.h>
 
 #include "ecc_curve_defs.h"
+#include "fips_canister_wrapper.h"
 
 typedef struct {
 	u64 m_low;
@@ -98,7 +99,7 @@ static u64 *ecc_alloc_digits_space(unsigned int ndigits)
 	if (!len)
 		return NULL;
 
-	return kmalloc(len, GFP_KERNEL);
+	return fcw_kmalloc(len, GFP_KERNEL);
 }
 
 static void ecc_free_digits_space(u64 *space)
@@ -108,7 +109,7 @@ static void ecc_free_digits_space(u64 *space)
 
 struct ecc_point *ecc_alloc_point(unsigned int ndigits)
 {
-	struct ecc_point *p = kmalloc(sizeof(*p), GFP_KERNEL);
+	struct ecc_point *p = fcw_kmalloc(sizeof(*p), GFP_KERNEL);
 
 	if (!p)
 		return NULL;
diff --git a/crypto/ecdh.c b/crypto/ecdh.c
index 72cfd1590..93996076c 100644
--- a/crypto/ecdh.c
+++ b/crypto/ecdh.c
@@ -11,6 +11,7 @@
 #include <crypto/kpp.h>
 #include <crypto/ecdh.h>
 #include <linux/scatterlist.h>
+#include "fips_canister_wrapper.h"
 
 struct ecdh_ctx {
 	unsigned int curve_id;
@@ -66,12 +67,12 @@ static int ecdh_compute_value(struct kpp_request *req)
 	/* Public part is a point thus it has both coordinates */
 	public_key_sz = 2 * nbytes;
 
-	public_key = kmalloc(public_key_sz, GFP_KERNEL);
+	public_key = fcw_kmalloc(public_key_sz, GFP_KERNEL);
 	if (!public_key)
 		return -ENOMEM;
 
 	if (req->src) {
-		shared_secret = kmalloc(nbytes, GFP_KERNEL);
+		shared_secret = fcw_kmalloc(nbytes, GFP_KERNEL);
 		if (!shared_secret)
 			goto free_pubkey;
 
diff --git a/crypto/ecdsa.c b/crypto/ecdsa.c
index d5a10959e..e097ba178 100644
--- a/crypto/ecdsa.c
+++ b/crypto/ecdsa.c
@@ -12,6 +12,7 @@
 #include <linux/scatterlist.h>
 
 #include "ecdsasignature.asn1.h"
+#include "fips_canister_wrapper.h"
 
 struct ecc_ctx {
 	unsigned int curve_id;
@@ -141,7 +142,7 @@ static int ecdsa_verify(struct akcipher_request *req)
 	if (unlikely(!ctx->pub_key_set))
 		return -EINVAL;
 
-	buffer = kmalloc(req->src_len + req->dst_len, GFP_KERNEL);
+	buffer = fcw_kmalloc(req->src_len + req->dst_len, GFP_KERNEL);
 	if (!buffer)
 		return -ENOMEM;
 
diff --git a/crypto/gcm.c b/crypto/gcm.c
index 84f7c23d1..bc8b75e36 100644
--- a/crypto/gcm.c
+++ b/crypto/gcm.c
@@ -18,6 +18,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/slab.h>
+#include "fips_canister_wrapper.h"
 
 struct gcm_instance_ctx {
 	struct crypto_skcipher_spawn ctr;
@@ -113,7 +114,7 @@ static int crypto_gcm_setkey(struct crypto_aead *aead, const u8 *key,
 	if (err)
 		return err;
 
-	data = kzalloc(sizeof(*data) + crypto_skcipher_reqsize(ctr),
+	data = fcw_kzalloc(sizeof(*data) + crypto_skcipher_reqsize(ctr),
 		       GFP_KERNEL);
 	if (!data)
 		return -ENOMEM;
@@ -587,7 +588,7 @@ static int crypto_gcm_create_common(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	ctx = aead_instance_ctx(inst);
@@ -833,7 +834,7 @@ static int crypto_rfc4106_create(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
@@ -1048,7 +1049,7 @@ static int crypto_rfc4543_create(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
@@ -1131,7 +1132,7 @@ static int __init crypto_gcm_module_init(void)
 {
 	int err;
 
-	gcm_zeroes = kzalloc(sizeof(*gcm_zeroes), GFP_KERNEL);
+	gcm_zeroes = fcw_kzalloc(sizeof(*gcm_zeroes), GFP_KERNEL);
 	if (!gcm_zeroes)
 		return -ENOMEM;
 
diff --git a/crypto/ghash-generic.c b/crypto/ghash-generic.c
index c70d163c1..81ae2cc2c 100644
--- a/crypto/ghash-generic.c
+++ b/crypto/ghash-generic.c
@@ -42,6 +42,7 @@
 #include <linux/init.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
+#include "fips_canister_wrapper.h"
 
 static int ghash_init(struct shash_desc *desc)
 {
@@ -65,7 +66,7 @@ static int ghash_setkey(struct crypto_shash *tfm,
 		gf128mul_free_4k(ctx->gf128);
 
 	BUILD_BUG_ON(sizeof(k) != GHASH_BLOCK_SIZE);
-	memcpy(&k, key, GHASH_BLOCK_SIZE); /* avoid violating alignment rules */
+	fcw_memcpy(&k, key, GHASH_BLOCK_SIZE); /* avoid violating alignment rules */
 	ctx->gf128 = gf128mul_init_4k_lle(&k);
 	memzero_explicit(&k, GHASH_BLOCK_SIZE);
 
@@ -135,7 +136,7 @@ static int ghash_final(struct shash_desc *desc, u8 *dst)
 	u8 *buf = dctx->buffer;
 
 	ghash_flush(ctx, dctx);
-	memcpy(dst, buf, GHASH_BLOCK_SIZE);
+	fcw_memcpy(dst, buf, GHASH_BLOCK_SIZE);
 
 	return 0;
 }
diff --git a/crypto/hmac.c b/crypto/hmac.c
index 7cec25ff9..54a5321ea 100644
--- a/crypto/hmac.c
+++ b/crypto/hmac.c
@@ -21,6 +21,7 @@
 #include <linux/module.h>
 #include <linux/scatterlist.h>
 #include <linux/string.h>
+#include "fips_canister_wrapper.h"
 
 struct hmac_ctx {
 	struct crypto_shash *hash;
@@ -189,7 +190,7 @@ static int hmac_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	spawn = shash_instance_ctx(inst);
diff --git a/crypto/rsa-pkcs1pad.c b/crypto/rsa-pkcs1pad.c
index cd501195f..bfde0f28c 100644
--- a/crypto/rsa-pkcs1pad.c
+++ b/crypto/rsa-pkcs1pad.c
@@ -9,12 +9,14 @@
 #include <crypto/akcipher.h>
 #include <crypto/internal/akcipher.h>
 #include <crypto/internal/rsa.h>
+#include <crypto/internal/rsa_pkcs1pad.h>
 #include <linux/err.h>
 #include <linux/init.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/random.h>
 #include <linux/scatterlist.h>
+#include "fips_canister_wrapper.h"
 
 /*
  * Hash algorithm OIDs plus ASN.1 DER wrappings [RFC4880 sec 5.2.2].
@@ -194,7 +196,7 @@ static void pkcs1pad_sg_set_buf(struct scatterlist *sg, void *buf, size_t len,
 		sg_chain(sg, nsegs, next);
 }
 
-static int pkcs1pad_encrypt_sign_complete(struct akcipher_request *req, int err)
+static int pkcs1pad_sign_complete(struct akcipher_request *req, int err)
 {
 	struct crypto_akcipher *tfm = crypto_akcipher_reqtfm(req);
 	struct pkcs1pad_ctx *ctx = akcipher_tfm_ctx(tfm);
@@ -213,7 +215,7 @@ static int pkcs1pad_encrypt_sign_complete(struct akcipher_request *req, int err)
 	if (likely(!pad_len))
 		goto out;
 
-	out_buf = kzalloc(ctx->key_size, GFP_ATOMIC);
+	out_buf = fcw_kzalloc(ctx->key_size, GFP_ATOMIC);
 	err = -ENOMEM;
 	if (!out_buf)
 		goto out;
@@ -233,167 +235,19 @@ static int pkcs1pad_encrypt_sign_complete(struct akcipher_request *req, int err)
 	return err;
 }
 
-static void pkcs1pad_encrypt_sign_complete_cb(void *data, int err)
+static void pkcs1pad_sign_complete_cb(void *data, int err)
 {
 	struct akcipher_request *req = data;
 
 	if (err == -EINPROGRESS)
 		goto out;
 
-	err = pkcs1pad_encrypt_sign_complete(req, err);
+	err = pkcs1pad_sign_complete(req, err);
 
 out:
 	akcipher_request_complete(req, err);
 }
 
-static int pkcs1pad_encrypt(struct akcipher_request *req)
-{
-	struct crypto_akcipher *tfm = crypto_akcipher_reqtfm(req);
-	struct pkcs1pad_ctx *ctx = akcipher_tfm_ctx(tfm);
-	struct pkcs1pad_request *req_ctx = akcipher_request_ctx(req);
-	int err;
-	unsigned int i, ps_end;
-
-	if (!ctx->key_size)
-		return -EINVAL;
-
-	if (req->src_len > ctx->key_size - 11)
-		return -EOVERFLOW;
-
-	if (req->dst_len < ctx->key_size) {
-		req->dst_len = ctx->key_size;
-		return -EOVERFLOW;
-	}
-
-	req_ctx->in_buf = kmalloc(ctx->key_size - 1 - req->src_len,
-				  GFP_KERNEL);
-	if (!req_ctx->in_buf)
-		return -ENOMEM;
-
-	ps_end = ctx->key_size - req->src_len - 2;
-	req_ctx->in_buf[0] = 0x02;
-	for (i = 1; i < ps_end; i++)
-		req_ctx->in_buf[i] = get_random_u32_inclusive(1, 255);
-	req_ctx->in_buf[ps_end] = 0x00;
-
-	pkcs1pad_sg_set_buf(req_ctx->in_sg, req_ctx->in_buf,
-			ctx->key_size - 1 - req->src_len, req->src);
-
-	akcipher_request_set_tfm(&req_ctx->child_req, ctx->child);
-	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
-			pkcs1pad_encrypt_sign_complete_cb, req);
-
-	/* Reuse output buffer */
-	akcipher_request_set_crypt(&req_ctx->child_req, req_ctx->in_sg,
-				   req->dst, ctx->key_size - 1, req->dst_len);
-
-	err = crypto_akcipher_encrypt(&req_ctx->child_req);
-	if (err != -EINPROGRESS && err != -EBUSY)
-		return pkcs1pad_encrypt_sign_complete(req, err);
-
-	return err;
-}
-
-static int pkcs1pad_decrypt_complete(struct akcipher_request *req, int err)
-{
-	struct crypto_akcipher *tfm = crypto_akcipher_reqtfm(req);
-	struct pkcs1pad_ctx *ctx = akcipher_tfm_ctx(tfm);
-	struct pkcs1pad_request *req_ctx = akcipher_request_ctx(req);
-	unsigned int dst_len;
-	unsigned int pos;
-	u8 *out_buf;
-
-	if (err)
-		goto done;
-
-	err = -EINVAL;
-	dst_len = req_ctx->child_req.dst_len;
-	if (dst_len < ctx->key_size - 1)
-		goto done;
-
-	out_buf = req_ctx->out_buf;
-	if (dst_len == ctx->key_size) {
-		if (out_buf[0] != 0x00)
-			/* Decrypted value had no leading 0 byte */
-			goto done;
-
-		dst_len--;
-		out_buf++;
-	}
-
-	if (out_buf[0] != 0x02)
-		goto done;
-
-	for (pos = 1; pos < dst_len; pos++)
-		if (out_buf[pos] == 0x00)
-			break;
-	if (pos < 9 || pos == dst_len)
-		goto done;
-	pos++;
-
-	err = 0;
-
-	if (req->dst_len < dst_len - pos)
-		err = -EOVERFLOW;
-	req->dst_len = dst_len - pos;
-
-	if (!err)
-		sg_copy_from_buffer(req->dst,
-				sg_nents_for_len(req->dst, req->dst_len),
-				out_buf + pos, req->dst_len);
-
-done:
-	kfree_sensitive(req_ctx->out_buf);
-
-	return err;
-}
-
-static void pkcs1pad_decrypt_complete_cb(void *data, int err)
-{
-	struct akcipher_request *req = data;
-
-	if (err == -EINPROGRESS)
-		goto out;
-
-	err = pkcs1pad_decrypt_complete(req, err);
-
-out:
-	akcipher_request_complete(req, err);
-}
-
-static int pkcs1pad_decrypt(struct akcipher_request *req)
-{
-	struct crypto_akcipher *tfm = crypto_akcipher_reqtfm(req);
-	struct pkcs1pad_ctx *ctx = akcipher_tfm_ctx(tfm);
-	struct pkcs1pad_request *req_ctx = akcipher_request_ctx(req);
-	int err;
-
-	if (!ctx->key_size || req->src_len != ctx->key_size)
-		return -EINVAL;
-
-	req_ctx->out_buf = kmalloc(ctx->key_size, GFP_KERNEL);
-	if (!req_ctx->out_buf)
-		return -ENOMEM;
-
-	pkcs1pad_sg_set_buf(req_ctx->out_sg, req_ctx->out_buf,
-			    ctx->key_size, NULL);
-
-	akcipher_request_set_tfm(&req_ctx->child_req, ctx->child);
-	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
-			pkcs1pad_decrypt_complete_cb, req);
-
-	/* Reuse input buffer, output to a new buffer */
-	akcipher_request_set_crypt(&req_ctx->child_req, req->src,
-				   req_ctx->out_sg, req->src_len,
-				   ctx->key_size);
-
-	err = crypto_akcipher_decrypt(&req_ctx->child_req);
-	if (err != -EINPROGRESS && err != -EBUSY)
-		return pkcs1pad_decrypt_complete(req, err);
-
-	return err;
-}
-
 static int pkcs1pad_sign(struct akcipher_request *req)
 {
 	struct crypto_akcipher *tfm = crypto_akcipher_reqtfm(req);
@@ -419,7 +273,7 @@ static int pkcs1pad_sign(struct akcipher_request *req)
 		return -EOVERFLOW;
 	}
 
-	req_ctx->in_buf = kmalloc(ctx->key_size - 1 - req->src_len,
+	req_ctx->in_buf = fcw_kmalloc(ctx->key_size - 1 - req->src_len,
 				  GFP_KERNEL);
 	if (!req_ctx->in_buf)
 		return -ENOMEM;
@@ -438,7 +292,7 @@ static int pkcs1pad_sign(struct akcipher_request *req)
 
 	akcipher_request_set_tfm(&req_ctx->child_req, ctx->child);
 	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
-			pkcs1pad_encrypt_sign_complete_cb, req);
+			pkcs1pad_sign_complete_cb, req);
 
 	/* Reuse output buffer */
 	akcipher_request_set_crypt(&req_ctx->child_req, req_ctx->in_sg,
@@ -446,7 +300,7 @@ static int pkcs1pad_sign(struct akcipher_request *req)
 
 	err = crypto_akcipher_decrypt(&req_ctx->child_req);
 	if (err != -EINPROGRESS && err != -EBUSY)
-		return pkcs1pad_encrypt_sign_complete(req, err);
+		return pkcs1pad_sign_complete(req, err);
 
 	return err;
 }
@@ -561,7 +415,7 @@ static int pkcs1pad_verify(struct akcipher_request *req)
 	    !ctx->key_size || sig_size != ctx->key_size)
 		return -EINVAL;
 
-	req_ctx->out_buf = kmalloc(ctx->key_size + digest_size, GFP_KERNEL);
+	req_ctx->out_buf = fcw_kmalloc(ctx->key_size + digest_size, GFP_KERNEL);
 	if (!req_ctx->out_buf)
 		return -ENOMEM;
 
@@ -631,7 +485,7 @@ static int pkcs1pad_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
diff --git a/crypto/sha3_generic.c b/crypto/sha3_generic.c
index b103642b5..0e36ce003 100644
--- a/crypto/sha3_generic.c
+++ b/crypto/sha3_generic.c
@@ -14,6 +14,7 @@
 #include <linux/types.h>
 #include <crypto/sha3.h>
 #include <linux/unaligned.h>
+#include "fips_canister_wrapper.h"
 
 /*
  * On some 32-bit architectures (h8300), GCC ends up using
@@ -185,7 +186,7 @@ int crypto_sha3_update(struct shash_desc *desc, const u8 *data,
 	if ((sctx->partial + len) > (sctx->rsiz - 1)) {
 		if (sctx->partial) {
 			done = -sctx->partial;
-			memcpy(sctx->buf + sctx->partial, data,
+			fcw_memcpy(sctx->buf + sctx->partial, data,
 			       done + sctx->rsiz);
 			src = sctx->buf;
 		}
@@ -203,7 +204,7 @@ int crypto_sha3_update(struct shash_desc *desc, const u8 *data,
 
 		sctx->partial = 0;
 	}
-	memcpy(sctx->buf + sctx->partial, src, len - done);
+	fcw_memcpy(sctx->buf + sctx->partial, src, len - done);
 	sctx->partial += (len - done);
 
 	return 0;
diff --git a/crypto/testmgr.c b/crypto/testmgr.c
index f3d7cd846..846b5323e 100644
--- a/crypto/testmgr.c
+++ b/crypto/testmgr.c
@@ -37,6 +37,7 @@
 #include <crypto/internal/simd.h>
 
 #include "internal.h"
+#include "fips_canister_wrapper.h"
 
 MODULE_IMPORT_NS(CRYPTO_INTERNAL);
 
@@ -739,7 +740,7 @@ static struct cipher_test_sglists *alloc_cipher_test_sglists(void)
 {
 	struct cipher_test_sglists *tsgls;
 
-	tsgls = kmalloc(sizeof(*tsgls), GFP_KERNEL);
+	tsgls = fcw_kmalloc(sizeof(*tsgls), GFP_KERNEL);
 	if (!tsgls)
 		return NULL;
 
@@ -836,7 +837,7 @@ static int prepare_keybuf(const u8 *key, unsigned int ksize,
 	if (key_offset != 0) {
 		if (cfg->key_offset_relative_to_alignmask)
 			key_offset += alignmask;
-		keybuf = kmalloc(key_offset + ksize, GFP_KERNEL);
+		keybuf = fcw_kmalloc(key_offset + ksize, GFP_KERNEL);
 		if (!keybuf)
 			return -ENOMEM;
 		keyptr = keybuf + key_offset;
@@ -1699,7 +1700,7 @@ static int test_hash_vec(const struct hash_testvec *vec, unsigned int vec_num,
 						req, desc, tsgl, hashstate);
 			if (err)
 				return err;
-			cond_resched();
+			fcw_cond_resched();
 		}
 	}
 #endif
@@ -1805,13 +1806,13 @@ static int test_hash_vs_generic_impl(const char *generic_driver,
 		return err;
 	}
 
-	cfg = kzalloc(sizeof(*cfg), GFP_KERNEL);
+	cfg = fcw_kzalloc(sizeof(*cfg), GFP_KERNEL);
 	if (!cfg) {
 		err = -ENOMEM;
 		goto out;
 	}
 
-	generic_desc = kzalloc(sizeof(*desc) +
+	generic_desc = fcw_kzalloc(sizeof(*desc) +
 			       crypto_shash_descsize(generic_tfm), GFP_KERNEL);
 	if (!generic_desc) {
 		err = -ENOMEM;
@@ -1841,9 +1842,9 @@ static int test_hash_vs_generic_impl(const char *generic_driver,
 	 * the other implementation against them.
 	 */
 
-	vec.key = kmalloc(maxkeysize, GFP_KERNEL);
-	vec.plaintext = kmalloc(maxdatasize, GFP_KERNEL);
-	vec.digest = kmalloc(digestsize, GFP_KERNEL);
+	vec.key = fcw_kmalloc(maxkeysize, GFP_KERNEL);
+	vec.plaintext = fcw_kmalloc(maxdatasize, GFP_KERNEL);
+	vec.digest = fcw_kmalloc(digestsize, GFP_KERNEL);
 	if (!vec.key || !vec.plaintext || !vec.digest) {
 		err = -ENOMEM;
 		goto out;
@@ -1860,7 +1861,7 @@ static int test_hash_vs_generic_impl(const char *generic_driver,
 					req, desc, tsgl, hashstate);
 		if (err)
 			goto out;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	err = 0;
 out:
@@ -1905,7 +1906,7 @@ static int alloc_shash(const char *driver, u32 type, u32 mask,
 		return PTR_ERR(tfm);
 	}
 
-	desc = kmalloc(sizeof(*desc) + crypto_shash_descsize(tfm), GFP_KERNEL);
+	desc = fcw_kmalloc(sizeof(*desc) + crypto_shash_descsize(tfm), GFP_KERNEL);
 	if (!desc) {
 		crypto_free_shash(tfm);
 		return -ENOMEM;
@@ -1947,7 +1948,7 @@ static int __alg_test_hash(const struct hash_testvec *vecs,
 	}
 	driver = crypto_ahash_driver_name(atfm);
 
-	req = ahash_request_alloc(atfm, GFP_KERNEL);
+	req = fcw_ahash_request_alloc(atfm, GFP_KERNEL);
 	if (!req) {
 		pr_err("alg: hash: failed to allocate request for %s\n",
 		       driver);
@@ -1963,7 +1964,7 @@ static int __alg_test_hash(const struct hash_testvec *vecs,
 	if (err)
 		goto out;
 
-	tsgl = kmalloc(sizeof(*tsgl), GFP_KERNEL);
+	tsgl = fcw_kmalloc(sizeof(*tsgl), GFP_KERNEL);
 	if (!tsgl || init_test_sglist(tsgl) != 0) {
 		pr_err("alg: hash: failed to allocate test buffers for %s\n",
 		       driver);
@@ -1976,7 +1977,7 @@ static int __alg_test_hash(const struct hash_testvec *vecs,
 	statesize = crypto_ahash_statesize(atfm);
 	if (stfm)
 		statesize = max(statesize, crypto_shash_statesize(stfm));
-	hashstate = kmalloc(statesize + TESTMGR_POISON_LEN, GFP_KERNEL);
+	hashstate = fcw_kmalloc(statesize + TESTMGR_POISON_LEN, GFP_KERNEL);
 	if (!hashstate) {
 		pr_err("alg: hash: failed to allocate hash state buffer for %s\n",
 		       driver);
@@ -1991,7 +1992,7 @@ static int __alg_test_hash(const struct hash_testvec *vecs,
 		err = test_hash_vec(&vecs[i], i, req, desc, tsgl, hashstate);
 		if (err)
 			goto out;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	err = test_hash_vs_generic_impl(generic_driver, maxkeysize, req,
 					desc, tsgl, hashstate);
@@ -2271,7 +2272,7 @@ static int test_aead_vec(int enc, const struct aead_testvec *vec,
 						&cfg, req, tsgls);
 			if (err)
 				return err;
-			cond_resched();
+			fcw_cond_resched();
 		}
 	}
 #endif
@@ -2501,7 +2502,7 @@ static int test_aead_inauthentic_inputs(struct aead_extra_tests_ctx *ctx)
 			if (err)
 				return err;
 		}
-		cond_resched();
+		fcw_cond_resched();
 	}
 	return 0;
 }
@@ -2545,7 +2546,7 @@ static int test_aead_vs_generic_impl(struct aead_extra_tests_ctx *ctx)
 		return err;
 	}
 
-	generic_req = aead_request_alloc(generic_tfm, GFP_KERNEL);
+	generic_req = fcw_aead_request_alloc(generic_tfm, GFP_KERNEL);
 	if (!generic_req) {
 		err = -ENOMEM;
 		goto out;
@@ -2605,7 +2606,7 @@ static int test_aead_vs_generic_impl(struct aead_extra_tests_ctx *ctx)
 			if (err)
 				goto out;
 		}
-		cond_resched();
+		fcw_cond_resched();
 	}
 	err = 0;
 out:
@@ -2625,7 +2626,7 @@ static int test_aead_extra(const struct alg_test_desc *test_desc,
 	if (noextratests)
 		return 0;
 
-	ctx = kzalloc(sizeof(*ctx), GFP_KERNEL);
+	ctx = fcw_kzalloc(sizeof(*ctx), GFP_KERNEL);
 	if (!ctx)
 		return -ENOMEM;
 	init_rnd_state(&ctx->rng);
@@ -2639,11 +2640,11 @@ static int test_aead_extra(const struct alg_test_desc *test_desc,
 		ctx->maxkeysize = max_t(unsigned int, ctx->maxkeysize,
 					test_desc->suite.aead.vecs[i].klen);
 
-	ctx->vec.key = kmalloc(ctx->maxkeysize, GFP_KERNEL);
-	ctx->vec.iv = kmalloc(crypto_aead_ivsize(ctx->tfm), GFP_KERNEL);
-	ctx->vec.assoc = kmalloc(ctx->maxdatasize, GFP_KERNEL);
-	ctx->vec.ptext = kmalloc(ctx->maxdatasize, GFP_KERNEL);
-	ctx->vec.ctext = kmalloc(ctx->maxdatasize, GFP_KERNEL);
+	ctx->vec.key = fcw_kmalloc(ctx->maxkeysize, GFP_KERNEL);
+	ctx->vec.iv = fcw_kmalloc(crypto_aead_ivsize(ctx->tfm), GFP_KERNEL);
+	ctx->vec.assoc = fcw_kmalloc(ctx->maxdatasize, GFP_KERNEL);
+	ctx->vec.ptext = fcw_kmalloc(ctx->maxdatasize, GFP_KERNEL);
+	ctx->vec.ctext = fcw_kmalloc(ctx->maxdatasize, GFP_KERNEL);
 	if (!ctx->vec.key || !ctx->vec.iv || !ctx->vec.assoc ||
 	    !ctx->vec.ptext || !ctx->vec.ctext) {
 		err = -ENOMEM;
@@ -2684,7 +2685,7 @@ static int test_aead(int enc, const struct aead_test_suite *suite,
 		err = test_aead_vec(enc, &suite->vecs[i], i, req, tsgls);
 		if (err)
 			return err;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	return 0;
 }
@@ -2713,7 +2714,7 @@ static int alg_test_aead(const struct alg_test_desc *desc, const char *driver,
 	}
 	driver = crypto_aead_driver_name(tfm);
 
-	req = aead_request_alloc(tfm, GFP_KERNEL);
+	req = fcw_aead_request_alloc(tfm, GFP_KERNEL);
 	if (!req) {
 		pr_err("alg: aead: failed to allocate request for %s\n",
 		       driver);
@@ -3033,7 +3034,7 @@ static int test_skcipher_vec(int enc, const struct cipher_testvec *vec,
 						    &cfg, req, tsgls);
 			if (err)
 				return err;
-			cond_resched();
+			fcw_cond_resched();
 		}
 	}
 #endif
@@ -3155,13 +3156,13 @@ static int test_skcipher_vs_generic_impl(const char *generic_driver,
 		return err;
 	}
 
-	cfg = kzalloc(sizeof(*cfg), GFP_KERNEL);
+	cfg = fcw_kzalloc(sizeof(*cfg), GFP_KERNEL);
 	if (!cfg) {
 		err = -ENOMEM;
 		goto out;
 	}
 
-	generic_req = skcipher_request_alloc(generic_tfm, GFP_KERNEL);
+	generic_req = fcw_skcipher_request_alloc(generic_tfm, GFP_KERNEL);
 	if (!generic_req) {
 		err = -ENOMEM;
 		goto out;
@@ -3206,10 +3207,10 @@ static int test_skcipher_vs_generic_impl(const char *generic_driver,
 	 * the other implementation against them.
 	 */
 
-	vec.key = kmalloc(maxkeysize, GFP_KERNEL);
-	vec.iv = kmalloc(ivsize, GFP_KERNEL);
-	vec.ptext = kmalloc(maxdatasize, GFP_KERNEL);
-	vec.ctext = kmalloc(maxdatasize, GFP_KERNEL);
+	vec.key = fcw_kmalloc(maxkeysize, GFP_KERNEL);
+	vec.iv = fcw_kmalloc(ivsize, GFP_KERNEL);
+	vec.ptext = fcw_kmalloc(maxdatasize, GFP_KERNEL);
+	vec.ctext = fcw_kmalloc(maxdatasize, GFP_KERNEL);
 	if (!vec.key || !vec.iv || !vec.ptext || !vec.ctext) {
 		err = -ENOMEM;
 		goto out;
@@ -3230,7 +3231,7 @@ static int test_skcipher_vs_generic_impl(const char *generic_driver,
 					    cfg, req, tsgls);
 		if (err)
 			goto out;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	err = 0;
 out:
@@ -3263,7 +3264,7 @@ static int test_skcipher(int enc, const struct cipher_test_suite *suite,
 		err = test_skcipher_vec(enc, &suite->vecs[i], i, req, tsgls);
 		if (err)
 			return err;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	return 0;
 }
@@ -3292,7 +3293,7 @@ static int alg_test_skcipher(const struct alg_test_desc *desc,
 	}
 	driver = crypto_skcipher_driver_name(tfm);
 
-	req = skcipher_request_alloc(tfm, GFP_KERNEL);
+	req = fcw_skcipher_request_alloc(tfm, GFP_KERNEL);
 	if (!req) {
 		pr_err("alg: skcipher: failed to allocate request for %s\n",
 		       driver);
@@ -3334,11 +3335,11 @@ static int test_comp(struct crypto_comp *tfm,
 	unsigned int i;
 	int ret;
 
-	output = kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
+	output = fcw_kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
 	if (!output)
 		return -ENOMEM;
 
-	decomp_output = kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
+	decomp_output = fcw_kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
 	if (!decomp_output) {
 		kfree(output);
 		return -ENOMEM;
@@ -3443,11 +3444,11 @@ static int test_acomp(struct crypto_acomp *tfm,
 	struct acomp_req *req;
 	struct crypto_wait wait;
 
-	output = kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
+	output = fcw_kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
 	if (!output)
 		return -ENOMEM;
 
-	decomp_out = kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
+	decomp_out = fcw_kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
 	if (!decomp_out) {
 		kfree(output);
 		return -ENOMEM;
@@ -3639,7 +3640,7 @@ static int test_cprng(struct crypto_rng *tfm,
 
 	seedsize = crypto_rng_seedsize(tfm);
 
-	seed = kmalloc(seedsize, GFP_KERNEL);
+	seed = fcw_kmalloc(seedsize, GFP_KERNEL);
 	if (!seed) {
 		printk(KERN_ERR "alg: cprng: Failed to allocate seed space "
 		       "for %s\n", algo);
@@ -3839,7 +3840,7 @@ static int drbg_cavs_test(const struct drbg_testvec *test, int pr,
 	struct crypto_rng *drng;
 	struct drbg_test_data test_data;
 	struct drbg_string addtl, pers, testentropy;
-	unsigned char *buf = kzalloc(test->expectedlen, GFP_KERNEL);
+	unsigned char *buf = fcw_kzalloc(test->expectedlen, GFP_KERNEL);
 
 	if (!buf)
 		return -ENOMEM;
@@ -3941,7 +3942,7 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 	int err = -ENOMEM;
 	struct scatterlist src, dst;
 
-	req = kpp_request_alloc(tfm, GFP_KERNEL);
+	req = fcw_kpp_request_alloc(tfm, GFP_KERNEL);
 	if (!req)
 		return err;
 
@@ -3952,7 +3953,7 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 		goto free_req;
 
 	out_len_max = crypto_kpp_maxsize(tfm);
-	output_buf = kzalloc(out_len_max, GFP_KERNEL);
+	output_buf = fcw_kzalloc(out_len_max, GFP_KERNEL);
 	if (!output_buf) {
 		err = -ENOMEM;
 		goto free_req;
@@ -4134,13 +4135,13 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 	if (testmgr_alloc_buf(xbuf))
 		return err;
 
-	req = akcipher_request_alloc(tfm, GFP_KERNEL);
+	req = fcw_akcipher_request_alloc(tfm, GFP_KERNEL);
 	if (!req)
 		goto free_xbuf;
 
 	crypto_init_wait(&wait);
 
-	key = kmalloc(vecs->key_len + sizeof(u32) * 2 + vecs->param_len,
+	key = fcw_kmalloc(vecs->key_len + sizeof(u32) * 2 + vecs->param_len,
 		      GFP_KERNEL);
 	if (!key)
 		goto free_req;
@@ -4163,7 +4164,7 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 	 */
 	err = -ENOMEM;
 	out_len_max = crypto_akcipher_maxsize(tfm);
-	outbuf_enc = kzalloc(out_len_max, GFP_KERNEL);
+	outbuf_enc = fcw_kzalloc(out_len_max, GFP_KERNEL);
 	if (!outbuf_enc)
 		goto free_key;
 
@@ -4240,7 +4241,7 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 		err = 0;
 		goto free_all;
 	}
-	outbuf_dec = kzalloc(out_len_max, GFP_KERNEL);
+	outbuf_dec = fcw_kzalloc(out_len_max, GFP_KERNEL);
 	if (!outbuf_dec) {
 		err = -ENOMEM;
 		goto free_all;
@@ -5913,13 +5914,22 @@ int alg_test(const char *driver, const char *alg, u32 type, u32 mask)
 	int i;
 	int j;
 	int rc;
+	static bool done = false;
 
 	if (!fips_enabled && notests) {
 		printk_once(KERN_INFO "alg: self-tests disabled\n");
 		return 0;
 	}
 
-	DO_ONCE(testmgr_onetime_init);
+	/* Replace DO_ONCE by this. As DO_ONCE generates jump labels entry
+	 * and its data (__once_key) get changed at early boot time at
+	 * jump_label_init() from setup_arch(). We cannot run
+	 * fips_integrity_init() before that time. So, replace it to
+	 * avoid jump table entry creation. */
+	if (unlikely(!done)) {
+		testmgr_onetime_init();
+		done = true;
+	}
 
 	if ((type & CRYPTO_ALG_TYPE_MASK) == CRYPTO_ALG_TYPE_CIPHER) {
 		char nalg[CRYPTO_MAX_ALG_NAME];
diff --git a/crypto/xts.c b/crypto/xts.c
index 672e1a3f0..54259a7f6 100644
--- a/crypto/xts.c
+++ b/crypto/xts.c
@@ -20,6 +20,7 @@
 #include <crypto/xts.h>
 #include <crypto/b128ops.h>
 #include <crypto/gf128mul.h>
+#include "fips_canister_wrapper.h"
 
 struct xts_tfm_ctx {
 	struct crypto_skcipher *child;
@@ -355,7 +356,7 @@ static int xts_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (IS_ERR(cipher_name))
 		return PTR_ERR(cipher_name);
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
diff --git a/include/crypto/drbg.h b/include/crypto/drbg.h
index af5ad51d3..f3e132d6f 100644
--- a/include/crypto/drbg.h
+++ b/include/crypto/drbg.h
@@ -50,7 +50,6 @@
 #include <crypto/internal/rng.h>
 #include <crypto/rng.h>
 #include <linux/fips.h>
-#include <linux/mutex.h>
 #include <linux/list.h>
 #include <linux/workqueue.h>
 
@@ -112,7 +111,7 @@ enum drbg_seed_state {
 };
 
 struct drbg_state {
-	struct mutex drbg_mutex;	/* lock around DRBG */
+	void *drbg_mutex;	/* lock around DRBG */
 	unsigned char *V;	/* internal state 10.1.1.1 1a) */
 	unsigned char *Vbuf;
 	/* hash: static value 10.1.1.1 1b) hmac / ctr: key */
-- 
2.49.0

