From b4a48fd8f37c45afd3e529a57168af8859b4637e Mon Sep 17 00:00:00 2001
From: Bo Gan <ganb@vmware.com>
Date: Thu, 27 Aug 2020 05:00:45 -0700
Subject: [PATCH] Revert clockevents: Stop unused clockevent devices

Since d25408756accb ("clockevents: Stop unused clockevent devices"),
cyclictest average latency regressed in x86 VMs. With the default
idling behavior (idle=halt), the patch introduced unnecessary shutdown
and re-initialization of local APIC timer in scenarios including
coming out of NOHZ idle and within timer interrupt context. Whenever
the local APIC register is being programmed (written), x86 VM takes VMEXIT
to the hypervisor. As the hypervisor needs to figure out the intent of
local APIC timer programming, each of these VMEXITs can take from
several hundred ns to ~1us on a modern x86 CPU. Thus, average latency
is increased.

In addition to reverting the above mentioned commit, this patch adds a
BUG_ON() for the condition 'expires == KTIME_MAX' (which was not
present in the original code), in order to catch any unexpected bugs.

Signed-off-by: Bo Gan <ganb@vmware.com>
Signed-off-by: Srivatsa S. Bhat (VMware) <srivatsa@csail.mit.edu>
---
 kernel/time/hrtimer.c      |  6 ++++--
 kernel/time/tick-oneshot.c | 17 +----------------
 2 files changed, 5 insertions(+), 18 deletions(-)

diff --git a/kernel/time/hrtimer.c b/kernel/time/hrtimer.c
index cddcd08ea..edabb0b01 100644
--- a/kernel/time/hrtimer.c
+++ b/kernel/time/hrtimer.c
@@ -676,7 +676,8 @@ static void __hrtimer_reprogram(struct hrtimer_cpu_base *cpu_base,
 	if (!hrtimer_hres_active(cpu_base) || cpu_base->hang_detected)
 		return;
 
-	tick_program_event(expires_next, 1);
+	if (expires_next != KTIME_MAX)
+		tick_program_event(expires_next, 1);
 }
 
 /*
@@ -1827,7 +1828,8 @@ void hrtimer_interrupt(struct clock_event_device *dev)
 	raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
 
 	/* Reprogramming necessary ? */
-	if (!tick_program_event(expires_next, 0)) {
+	if (expires_next == KTIME_MAX ||
+	    !tick_program_event(expires_next, 0)) {
 		cpu_base->hang_detected = 0;
 		return;
 	}
diff --git a/kernel/time/tick-oneshot.c b/kernel/time/tick-oneshot.c
index 5e2c2c26b..9c182c7a0 100644
--- a/kernel/time/tick-oneshot.c
+++ b/kernel/time/tick-oneshot.c
@@ -24,22 +24,7 @@ int tick_program_event(ktime_t expires, int force)
 {
 	struct clock_event_device *dev = __this_cpu_read(tick_cpu_device.evtdev);
 
-	if (unlikely(expires == KTIME_MAX)) {
-		/*
-		 * We don't need the clock event device any more, stop it.
-		 */
-		clockevents_switch_state(dev, CLOCK_EVT_STATE_ONESHOT_STOPPED);
-		dev->next_event = KTIME_MAX;
-		return 0;
-	}
-
-	if (unlikely(clockevent_state_oneshot_stopped(dev))) {
-		/*
-		 * We need the clock event again, configure it in ONESHOT mode
-		 * before using it.
-		 */
-		clockevents_switch_state(dev, CLOCK_EVT_STATE_ONESHOT);
-	}
+	BUG_ON(expires == KTIME_MAX);
 
 	return clockevents_program_event(dev, expires, force);
 }
-- 
2.39.4

