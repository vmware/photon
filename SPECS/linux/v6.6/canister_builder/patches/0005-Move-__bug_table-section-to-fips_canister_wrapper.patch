From 434351807cf633fb4ffce37100300ff161b575c8 Mon Sep 17 00:00:00 2001
From: Keerthana K <keerthanak@vmware.com>
Date: Wed, 17 May 2023 16:11:40 +0000
Subject: [PATCH] Move __bug_table section to fips_canister_wrapper

Signed-off-by: Keerthana K <keerthanak@vmware.com>
Signed-off-by: Srish Srinivasan <ssrish@vmware.com>
---
 arch/x86/crypto/aesni-intel_glue.c |  16 ++--
 crypto/algboss.c                   |  10 +--
 crypto/cbc.c                       |  11 +--
 crypto/ccm.c                       |  28 +++----
 crypto/cfb.c                       |   9 ++-
 crypto/cmac.c                      |   6 +-
 crypto/ctr.c                       |   6 +-
 crypto/cts.c                       |   4 +-
 crypto/dh_helper.c                 |   5 +-
 crypto/drbg.c                      |  54 +++++++-------
 crypto/ecc.c                       |   7 +-
 crypto/ecdh.c                      |   2 +-
 crypto/ecdh_helper.c               |   5 +-
 crypto/ecdsa.c                     |   6 +-
 crypto/gcm.c                       |  26 +++----
 crypto/hmac.c                      |   4 +-
 crypto/rsa-pkcs1pad.c              |   6 +-
 crypto/seqiv.c                     |   3 +-
 crypto/sha1_generic.c              |   5 +-
 crypto/sha512_generic.c            |   5 +-
 crypto/testmgr.c                   | 116 +++++++++++++++--------------
 lib/crypto/sha256.c                |   2 +
 22 files changed, 173 insertions(+), 163 deletions(-)

diff --git a/arch/x86/crypto/aesni-intel_glue.c b/arch/x86/crypto/aesni-intel_glue.c
index 2b506fdc7..b5f702124 100644
--- a/arch/x86/crypto/aesni-intel_glue.c
+++ b/arch/x86/crypto/aesni-intel_glue.c
@@ -38,6 +38,10 @@
 
 void fcw_kernel_fpu_begin(void);
 void fcw_kernel_fpu_end(void);
+extern void *fcw_kmalloc(size_t size, gfp_t flags);
+extern void *fcw_scatterwalk_map(struct scatter_walk *walk);
+extern void *fcw_memcpy(void *dst, const void *src, size_t len);
+
 
 #define AESNI_ALIGN	16
 #define AESNI_ALIGN_ATTR __attribute__ ((__aligned__(AESNI_ALIGN)))
@@ -589,7 +593,7 @@ static int xctr_crypt(struct skcipher_request *req)
 		byte_ctr += walk.nbytes - nbytes;
 
 		if (walk.nbytes == walk.total && nbytes > 0) {
-			memcpy(block, walk.iv, AES_BLOCK_SIZE);
+			fcw_memcpy(block, walk.iv, AES_BLOCK_SIZE);
 			block[0] ^= cpu_to_le32(1 + byte_ctr / AES_BLOCK_SIZE);
 			aesni_enc(ctx, keystream, (u8 *)block);
 			crypto_xor_cpy(walk.dst.virt.addr + walk.nbytes -
@@ -635,7 +639,7 @@ static int common_rfc4106_set_key(struct crypto_aead *aead, const u8 *key,
 	/*Account for 4 byte nonce at the end.*/
 	key_len -= 4;
 
-	memcpy(ctx->nonce, key + key_len, sizeof(ctx->nonce));
+	fcw_memcpy(ctx->nonce, key + key_len, sizeof(ctx->nonce));
 
 	return aes_set_key_common(&ctx->aes_key_expanded, key, key_len) ?:
 	       rfc4106_set_hash_subkey(ctx->hash_subkey, key, key_len);
@@ -677,8 +681,6 @@ static int generic_gcmaes_set_authsize(struct crypto_aead *tfm,
 	return 0;
 }
 
-extern void *fcw_kmalloc(size_t size, gfp_t flags);
-
 static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 			      unsigned int assoclen, u8 *hash_subkey,
 			      u8 *iv, void *aes_ctx, u8 *auth_tag,
@@ -703,7 +705,7 @@ static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 	/* Linearize assoc, if not already linear */
 	if (req->src->length >= assoclen && req->src->length) {
 		scatterwalk_start(&assoc_sg_walk, req->src);
-		assoc = scatterwalk_map(&assoc_sg_walk);
+		assoc = fcw_scatterwalk_map(&assoc_sg_walk);
 	} else {
 		gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
 			      GFP_KERNEL : GFP_ATOMIC;
@@ -1173,7 +1175,7 @@ static int generic_gcmaes_encrypt(struct aead_request *req)
 	u8 *iv = PTR_ALIGN(&ivbuf[0], AESNI_ALIGN);
 	__be32 counter = cpu_to_be32(1);
 
-	memcpy(iv, req->iv, 12);
+	fcw_memcpy(iv, req->iv, 12);
 	*((__be32 *)(iv+12)) = counter;
 
 	return gcmaes_encrypt(req, req->assoclen, ctx->hash_subkey, iv,
@@ -1189,7 +1191,7 @@ static int generic_gcmaes_decrypt(struct aead_request *req)
 	u8 ivbuf[16 + (AESNI_ALIGN - 8)] __aligned(8);
 	u8 *iv = PTR_ALIGN(&ivbuf[0], AESNI_ALIGN);
 
-	memcpy(iv, req->iv, 12);
+	fcw_memcpy(iv, req->iv, 12);
 	*((__be32 *)(iv+12)) = counter;
 
 	return gcmaes_decrypt(req, req->assoclen, ctx->hash_subkey, iv,
diff --git a/crypto/algboss.c b/crypto/algboss.c
index 2c64da757..eef91116c 100644
--- a/crypto/algboss.c
+++ b/crypto/algboss.c
@@ -94,7 +94,7 @@ static int cryptomgr_schedule_probe(struct crypto_larval *larval)
 	if (!len || *p != '(')
 		goto err_free_param;
 
-	memcpy(param->template, name, len);
+	fcw_memcpy(param->template, name, len);
 
 	i = 0;
 	for (;;) {
@@ -124,7 +124,7 @@ static int cryptomgr_schedule_probe(struct crypto_larval *larval)
 
 		param->attrs[i].attr.rta_len = sizeof(param->attrs[i]);
 		param->attrs[i].attr.rta_type = CRYPTOA_ALG;
-		memcpy(param->attrs[i].data.name, name, len);
+		fcw_memcpy(param->attrs[i].data.name, name, len);
 
 		param->tb[i + 1] = &param->attrs[i].attr;
 		i++;
@@ -201,8 +201,8 @@ static int cryptomgr_schedule_test(struct crypto_alg *alg)
 	if (!param)
 		goto err_put_module;
 
-	memcpy(param->driver, alg->cra_driver_name, sizeof(param->driver));
-	memcpy(param->alg, alg->cra_name, sizeof(param->alg));
+	fcw_memcpy(param->driver, alg->cra_driver_name, sizeof(param->driver));
+	fcw_memcpy(param->alg, alg->cra_name, sizeof(param->alg));
 	param->type = alg->cra_flags;
 
 	thread = kthread_run(cryptomgr_test, param, "cryptomgr_test");
@@ -246,7 +246,7 @@ static int __init cryptomgr_init(void)
 static void __exit cryptomgr_exit(void)
 {
 	int err = crypto_unregister_notifier(&cryptomgr_notifier);
-	BUG_ON(err);
+	fcw_bug_on(err);
 }
 
 /*
diff --git a/crypto/cbc.c b/crypto/cbc.c
index 6c03e96b9..2f266530e 100644
--- a/crypto/cbc.c
+++ b/crypto/cbc.c
@@ -13,6 +13,7 @@
 #include <linux/kernel.h>
 #include <linux/log2.h>
 #include <linux/module.h>
+#include "fips_canister_wrapper.h"
 
 static int crypto_cbc_encrypt_segment(struct skcipher_walk *walk,
 				      struct crypto_skcipher *skcipher)
@@ -33,7 +34,7 @@ static int crypto_cbc_encrypt_segment(struct skcipher_walk *walk,
 	do {
 		crypto_xor(iv, src, bsize);
 		fn(tfm, dst, iv);
-		memcpy(iv, dst, bsize);
+		fcw_memcpy(iv, dst, bsize);
 
 		src += bsize;
 		dst += bsize;
@@ -65,7 +66,7 @@ static int crypto_cbc_encrypt_inplace(struct skcipher_walk *walk,
 		src += bsize;
 	} while ((nbytes -= bsize) >= bsize);
 
-	memcpy(walk->iv, iv, bsize);
+	fcw_memcpy(walk->iv, iv, bsize);
 
 	return nbytes;
 }
@@ -114,7 +115,7 @@ static int crypto_cbc_decrypt_segment(struct skcipher_walk *walk,
 		dst += bsize;
 	} while ((nbytes -= bsize) >= bsize);
 
-	memcpy(walk->iv, iv, bsize);
+	fcw_memcpy(walk->iv, iv, bsize);
 
 	return nbytes;
 }
@@ -136,7 +137,7 @@ static int crypto_cbc_decrypt_inplace(struct skcipher_walk *walk,
 
 	/* Start of the last block. */
 	src += nbytes - (nbytes & (bsize - 1)) - bsize;
-	memcpy(last_iv, src, bsize);
+	fcw_memcpy(last_iv, src, bsize);
 
 	for (;;) {
 		fn(tfm, src, src);
@@ -147,7 +148,7 @@ static int crypto_cbc_decrypt_inplace(struct skcipher_walk *walk,
 	}
 
 	crypto_xor(src, walk->iv, bsize);
-	memcpy(walk->iv, last_iv, bsize);
+	fcw_memcpy(walk->iv, last_iv, bsize);
 
 	return nbytes;
 }
diff --git a/crypto/ccm.c b/crypto/ccm.c
index 1b77da008..60e2145f4 100644
--- a/crypto/ccm.c
+++ b/crypto/ccm.c
@@ -80,7 +80,7 @@ static int set_msg_len(u8 *block, unsigned int msglen, int csize)
 		return -EOVERFLOW;
 
 	data = cpu_to_be32(msglen);
-	memcpy(block - csize, (u8 *)&data + 4 - csize, csize);
+	fcw_memcpy(block - csize, (u8 *)&data + 4 - csize, csize);
 
 	return 0;
 }
@@ -135,7 +135,7 @@ static int format_input(u8 *info, struct aead_request *req,
 
 	m = crypto_aead_authsize(aead);
 
-	memcpy(info, req->iv, 16);
+	fcw_memcpy(info, req->iv, 16);
 
 	/* format control info per RFC 3610 and
 	 * NIST Special Publication 800-38C
@@ -185,12 +185,12 @@ static int crypto_ccm_auth(struct aead_request *req, struct scatterlist *plain,
 		goto out;
 
 	sg_init_table(sg, 3);
-	sg_set_buf(&sg[0], odata, 16);
+	fcw_sg_set_buf(&sg[0], odata, 16);
 
 	/* format associated data and compute into mac */
 	if (assoclen) {
 		ilen = format_adata(idata, assoclen);
-		sg_set_buf(&sg[1], idata, ilen);
+		fcw_sg_set_buf(&sg[1], idata, ilen);
 		sg_chain(sg, 3, req->src);
 	} else {
 		ilen = 0;
@@ -212,7 +212,7 @@ static int crypto_ccm_auth(struct aead_request *req, struct scatterlist *plain,
 	if (ilen < 16) {
 		memset(idata, 0, ilen);
 		sg_init_table(sg, 2);
-		sg_set_buf(&sg[0], idata, ilen);
+		fcw_sg_set_buf(&sg[0], idata, ilen);
 		if (plain)
 			sg_chain(sg, 2, plain);
 		plain = sg;
@@ -267,14 +267,14 @@ static int crypto_ccm_init_crypt(struct aead_request *req, u8 *tag)
 	memset(iv + 15 - iv[0], 0, iv[0] + 1);
 
 	sg_init_table(pctx->src, 3);
-	sg_set_buf(pctx->src, tag, 16);
+	fcw_sg_set_buf(pctx->src, tag, 16);
 	sg = scatterwalk_ffwd(pctx->src + 1, req->src, req->assoclen);
 	if (sg != pctx->src + 1)
 		sg_chain(pctx->src, 2, sg);
 
 	if (req->src != req->dst) {
 		sg_init_table(pctx->dst, 3);
-		sg_set_buf(pctx->dst, tag, 16);
+		fcw_sg_set_buf(pctx->dst, tag, 16);
 		sg = scatterwalk_ffwd(pctx->dst + 1, req->dst, req->assoclen);
 		if (sg != pctx->dst + 1)
 			sg_chain(pctx->dst, 2, sg);
@@ -369,7 +369,7 @@ static int crypto_ccm_decrypt(struct aead_request *req)
 	if (req->src != req->dst)
 		dst = pctx->dst;
 
-	memcpy(iv, req->iv, 16);
+	fcw_memcpy(iv, req->iv, 16);
 
 	skcipher_request_set_tfm(skreq, ctx->ctr);
 	skcipher_request_set_callback(skreq, pctx->flags,
@@ -576,7 +576,7 @@ static int crypto_rfc4309_setkey(struct crypto_aead *parent, const u8 *key,
 		return -EINVAL;
 
 	keylen -= 3;
-	memcpy(ctx->nonce, key + keylen, 3);
+	fcw_memcpy(ctx->nonce, key + keylen, 3);
 
 	crypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);
 	crypto_aead_set_flags(child, crypto_aead_get_flags(parent) &
@@ -615,20 +615,20 @@ static struct aead_request *crypto_rfc4309_crypt(struct aead_request *req)
 	/* L' */
 	iv[0] = 3;
 
-	memcpy(iv + 1, ctx->nonce, 3);
-	memcpy(iv + 4, req->iv, 8);
+	fcw_memcpy(iv + 1, ctx->nonce, 3);
+	fcw_memcpy(iv + 4, req->iv, 8);
 
 	scatterwalk_map_and_copy(iv + 16, req->src, 0, req->assoclen - 8, 0);
 
 	sg_init_table(rctx->src, 3);
-	sg_set_buf(rctx->src, iv + 16, req->assoclen - 8);
+	fcw_sg_set_buf(rctx->src, iv + 16, req->assoclen - 8);
 	sg = scatterwalk_ffwd(rctx->src + 1, req->src, req->assoclen);
 	if (sg != rctx->src + 1)
 		sg_chain(rctx->src, 2, sg);
 
 	if (req->src != req->dst) {
 		sg_init_table(rctx->dst, 3);
-		sg_set_buf(rctx->dst, iv + 16, req->assoclen - 8);
+		fcw_sg_set_buf(rctx->dst, iv + 16, req->assoclen - 8);
 		sg = scatterwalk_ffwd(rctx->dst + 1, req->dst, req->assoclen);
 		if (sg != rctx->dst + 1)
 			sg_chain(rctx->dst, 2, sg);
@@ -834,7 +834,7 @@ static int crypto_cbcmac_digest_final(struct shash_desc *pdesc, u8 *out)
 	if (ctx->len)
 		crypto_cipher_encrypt_one(tfm, dg, dg);
 
-	memcpy(out, dg, bs);
+	fcw_memcpy(out, dg, bs);
 	return 0;
 }
 
diff --git a/crypto/cfb.c b/crypto/cfb.c
index 5c36b7b65..460b9d2f8 100644
--- a/crypto/cfb.c
+++ b/crypto/cfb.c
@@ -27,6 +27,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/string.h>
+#include "fips_canister_wrapper.h"
 
 static unsigned int crypto_cfb_bsize(struct crypto_skcipher *tfm)
 {
@@ -73,7 +74,7 @@ static int crypto_cfb_encrypt_segment(struct skcipher_walk *walk,
 		dst += bsize;
 	} while ((nbytes -= bsize) >= bsize);
 
-	memcpy(walk->iv, iv, bsize);
+	fcw_memcpy(walk->iv, iv, bsize);
 
 	return nbytes;
 }
@@ -95,7 +96,7 @@ static int crypto_cfb_encrypt_inplace(struct skcipher_walk *walk,
 		src += bsize;
 	} while ((nbytes -= bsize) >= bsize);
 
-	memcpy(walk->iv, iv, bsize);
+	fcw_memcpy(walk->iv, iv, bsize);
 
 	return nbytes;
 }
@@ -143,7 +144,7 @@ static int crypto_cfb_decrypt_segment(struct skcipher_walk *walk,
 		dst += bsize;
 	} while ((nbytes -= bsize) >= bsize);
 
-	memcpy(walk->iv, iv, bsize);
+	fcw_memcpy(walk->iv, iv, bsize);
 
 	return nbytes;
 }
@@ -159,7 +160,7 @@ static int crypto_cfb_decrypt_inplace(struct skcipher_walk *walk,
 
 	do {
 		crypto_cfb_encrypt_one(tfm, iv, tmp);
-		memcpy(iv, src, bsize);
+		fcw_memcpy(iv, src, bsize);
 		crypto_xor(src, tmp, bsize);
 		src += bsize;
 	} while ((nbytes -= bsize) >= bsize);
diff --git a/crypto/cmac.c b/crypto/cmac.c
index e5af76456..b7e58d081 100644
--- a/crypto/cmac.c
+++ b/crypto/cmac.c
@@ -130,13 +130,13 @@ static int crypto_cmac_digest_update(struct shash_desc *pdesc, const u8 *p,
 
 	/* checking the data can fill the block */
 	if ((ctx->len + len) <= bs) {
-		memcpy(odds + ctx->len, p, len);
+		fcw_memcpy(odds + ctx->len, p, len);
 		ctx->len += len;
 		return 0;
 	}
 
 	/* filling odds with new data and encrypting it */
-	memcpy(odds + ctx->len, p, bs - ctx->len);
+	fcw_memcpy(odds + ctx->len, p, bs - ctx->len);
 	len -= bs - ctx->len;
 	p += bs - ctx->len;
 
@@ -156,7 +156,7 @@ static int crypto_cmac_digest_update(struct shash_desc *pdesc, const u8 *p,
 
 	/* keeping the surplus of blocksize */
 	if (len) {
-		memcpy(odds, p, len);
+		fcw_memcpy(odds, p, len);
 		ctx->len = len;
 	}
 
diff --git a/crypto/ctr.c b/crypto/ctr.c
index 1906d0f8c..b4c6ae0ab 100644
--- a/crypto/ctr.c
+++ b/crypto/ctr.c
@@ -177,7 +177,7 @@ static int crypto_rfc3686_setkey(struct crypto_skcipher *parent,
 	if (keylen < CTR_RFC3686_NONCE_SIZE)
 		return -EINVAL;
 
-	memcpy(ctx->nonce, key + (keylen - CTR_RFC3686_NONCE_SIZE),
+	fcw_memcpy(ctx->nonce, key + (keylen - CTR_RFC3686_NONCE_SIZE),
 	       CTR_RFC3686_NONCE_SIZE);
 
 	keylen -= CTR_RFC3686_NONCE_SIZE;
@@ -200,8 +200,8 @@ static int crypto_rfc3686_crypt(struct skcipher_request *req)
 	u8 *iv = rctx->iv;
 
 	/* set up counter block */
-	memcpy(iv, ctx->nonce, CTR_RFC3686_NONCE_SIZE);
-	memcpy(iv + CTR_RFC3686_NONCE_SIZE, req->iv, CTR_RFC3686_IV_SIZE);
+	fcw_memcpy(iv, ctx->nonce, CTR_RFC3686_NONCE_SIZE);
+	fcw_memcpy(iv + CTR_RFC3686_NONCE_SIZE, req->iv, CTR_RFC3686_IV_SIZE);
 
 	/* initialize counter portion of counter block */
 	*(__be32 *)(iv + CTR_RFC3686_NONCE_SIZE + CTR_RFC3686_IV_SIZE) =
diff --git a/crypto/cts.c b/crypto/cts.c
index 06d08cf25..65a64c63d 100644
--- a/crypto/cts.c
+++ b/crypto/cts.c
@@ -206,7 +206,7 @@ static int cts_cbc_decrypt(struct skcipher_request *req)
 	crypto_xor(d + bsize, d, lastn);
 
 	/* 5. Append the tail (BB - Ln) bytes of Xn to Cn to create En */
-	memcpy(d + lastn, d + bsize + lastn, bsize - lastn);
+	fcw_memcpy(d + lastn, d + bsize + lastn, bsize - lastn);
 	/* 6. Decrypt En to create Pn-1 */
 
 	scatterwalk_map_and_copy(d, sg, 0, bsize + lastn, 1);
@@ -269,7 +269,7 @@ static int crypto_cts_decrypt(struct skcipher_request *req)
 	rctx->offset = offset;
 
 	if (offset <= bsize)
-		memcpy(space, req->iv, bsize);
+		fcw_memcpy(space, req->iv, bsize);
 	else
 		scatterwalk_map_and_copy(space, req->src, offset - 2 * bsize,
 					 bsize, 0);
diff --git a/crypto/dh_helper.c b/crypto/dh_helper.c
index 2d4998793..e3ca27455 100644
--- a/crypto/dh_helper.c
+++ b/crypto/dh_helper.c
@@ -9,6 +9,7 @@
 #include <linux/string.h>
 #include <crypto/dh.h>
 #include <crypto/kpp.h>
+#include "fips_canister_wrapper.h"
 
 #define DH_KPP_SECRET_MIN_SIZE (sizeof(struct kpp_secret) + 3 * sizeof(int))
 
@@ -16,13 +17,13 @@ static inline u8 *dh_pack_data(u8 *dst, u8 *end, const void *src, size_t size)
 {
 	if (!dst || size > end - dst)
 		return NULL;
-	memcpy(dst, src, size);
+	fcw_memcpy(dst, src, size);
 	return dst + size;
 }
 
 static inline const u8 *dh_unpack_data(void *dst, const void *src, size_t size)
 {
-	memcpy(dst, src, size);
+	fcw_memcpy(dst, src, size);
 	return src + size;
 }
 
diff --git a/crypto/drbg.c b/crypto/drbg.c
index d51275071..693579b52 100644
--- a/crypto/drbg.c
+++ b/crypto/drbg.c
@@ -259,7 +259,7 @@ static int drbg_fips_continuous_test(struct drbg_state *drbg,
 
 	if (!drbg->fips_primed) {
 		/* Priming of FIPS test */
-		memcpy(drbg->prev, entropy, entropylen);
+		fcw_memcpy(drbg->prev, entropy, entropylen);
 		drbg->fips_primed = true;
 		/* priming: another round is needed */
 		return -EAGAIN;
@@ -267,7 +267,7 @@ static int drbg_fips_continuous_test(struct drbg_state *drbg,
 	ret = memcmp(drbg->prev, entropy, entropylen);
 	if (!ret)
 		panic("DRBG continuous self test failed\n");
-	memcpy(drbg->prev, entropy, entropylen);
+	fcw_memcpy(drbg->prev, entropy, entropylen);
 
 	/* the test shall pass when the two values are not equal */
 	return 0;
@@ -502,7 +502,7 @@ static int drbg_ctr_df(struct drbg_state *drbg,
 			    drbg_blocklen(drbg) :
 				(bytes_to_return - generated_len);
 		/* 10.4.2 step 13.2 and 14 */
-		memcpy(df_data + generated_len, X, blocklen);
+		fcw_memcpy(df_data + generated_len, X, blocklen);
 		generated_len += blocklen;
 	}
 
@@ -576,7 +576,7 @@ static int drbg_ctr_update(struct drbg_state *drbg, struct list_head *seed,
 	if (ret)
 		goto out;
 	/* 10.2.1.2 step 6 */
-	memcpy(drbg->V, temp + drbg_keylen(drbg), drbg_blocklen(drbg));
+	fcw_memcpy(drbg->V, temp + drbg_keylen(drbg), drbg_blocklen(drbg));
 	/* See above: increment counter by one to compensate timing of CTR op */
 	crypto_inc(drbg->V, drbg_blocklen(drbg));
 	ret = 0;
@@ -734,7 +734,7 @@ static int drbg_hmac_generate(struct drbg_state *drbg,
 			  drbg_blocklen(drbg) : (buflen - len);
 
 		/* 10.1.2.5 step 4.2 */
-		memcpy(buf + len, drbg->V, outlen);
+		fcw_memcpy(buf + len, drbg->V, outlen);
 		len += outlen;
 	}
 
@@ -849,7 +849,7 @@ static int drbg_hash_df(struct drbg_state *drbg,
 		input[0]++;
 		blocklen = (drbg_blocklen(drbg) < (outlen - len)) ?
 			    drbg_blocklen(drbg) : (outlen - len);
-		memcpy(outval + len, tmp, blocklen);
+		fcw_memcpy(outval + len, tmp, blocklen);
 		len += blocklen;
 	}
 
@@ -874,7 +874,7 @@ static int drbg_hash_update(struct drbg_state *drbg, struct list_head *seed,
 
 	if (reseed) {
 		/* 10.1.1.3 step 1 */
-		memcpy(V, drbg->V, drbg_statelen(drbg));
+		fcw_memcpy(V, drbg->V, drbg_statelen(drbg));
 		drbg_string_fill(&data1, &prefix, 1);
 		list_add_tail(&data1.list, &datalist);
 		drbg_string_fill(&data2, V, drbg_statelen(drbg));
@@ -946,7 +946,7 @@ static int drbg_hash_hashgen(struct drbg_state *drbg,
 	LIST_HEAD(datalist);
 
 	/* 10.1.1.4 step hashgen 2 */
-	memcpy(src, drbg->V, drbg_statelen(drbg));
+	fcw_memcpy(src, drbg->V, drbg_statelen(drbg));
 
 	drbg_string_fill(&data, src, drbg_statelen(drbg));
 	list_add_tail(&data.list, &datalist);
@@ -961,7 +961,7 @@ static int drbg_hash_hashgen(struct drbg_state *drbg,
 		outlen = (drbg_blocklen(drbg) < (buflen - len)) ?
 			  drbg_blocklen(drbg) : (buflen - len);
 		/* 10.1.1.4 step hashgen 4.2 */
-		memcpy(buf + len, dst, outlen);
+		fcw_memcpy(buf + len, dst, outlen);
 		len += outlen;
 		/* 10.1.1.4 hashgen step 4.3 */
 		if (len < buflen)
@@ -1098,8 +1098,8 @@ static int drbg_seed_from_random(struct drbg_state *drbg)
 	unsigned char entropy[32];
 	int ret;
 
-	BUG_ON(!entropylen);
-	BUG_ON(entropylen > sizeof(entropy));
+	fcw_bug_on(!entropylen);
+	fcw_bug_on(entropylen > sizeof(entropy));
 
 	drbg_string_fill(&data, entropy, entropylen);
 	list_add_tail(&data.list, &seedlist);
@@ -1176,10 +1176,10 @@ static int drbg_seed(struct drbg_state *drbg, struct drbg_string *pers,
 		 * of the strength. The consideration of a nonce is only
 		 * applicable during initial seeding.
 		 */
-		BUG_ON(!entropylen);
+		fcw_bug_on(!entropylen);
 		if (!reseed)
 			entropylen = ((entropylen + 1) / 2) * 3;
-		BUG_ON((entropylen * 2) > sizeof(entropy));
+		fcw_bug_on((entropylen * 2) > sizeof(entropy));
 
 		/* Get seed from in-kernel /dev/urandom */
 		if (!rng_is_initialized()) {
@@ -1477,7 +1477,7 @@ static int drbg_generate(struct drbg_state *drbg,
 		if (fips_enabled) {
 			if (IS_ERR_OR_NULL(drbg->jent)) {
 				pr_err("DRBG:seed rand,non-existing jent\n");
-				BUG();
+				fcw_bug();
 				goto err;
 			}
 			len = crypto_rng_get_bytes(drbg->jent,
@@ -1735,7 +1735,7 @@ static int drbg_init_hash_kernel(struct drbg_state *drbg)
 				drbg->core->backend_cra_name);
 		return PTR_ERR(tfm);
 	}
-	BUG_ON(drbg_blocklen(drbg) != crypto_shash_digestsize(tfm));
+	fcw_bug_on(drbg_blocklen(drbg) != crypto_shash_digestsize(tfm));
 	sdesc = fcw_kzalloc(sizeof(struct shash_desc) + crypto_shash_descsize(tfm),
 			GFP_KERNEL);
 	if (!sdesc) {
@@ -1818,7 +1818,7 @@ static int drbg_init_sym_kernel(struct drbg_state *drbg)
 				drbg->core->backend_cra_name);
 		return PTR_ERR(tfm);
 	}
-	BUG_ON(drbg_blocklen(drbg) != crypto_cipher_blocksize(tfm));
+	fcw_bug_on(drbg_blocklen(drbg) != crypto_cipher_blocksize(tfm));
 	drbg->priv_data = tfm;
 
 	if (snprintf(ctr_name, CRYPTO_MAX_ALG_NAME, "ctr(%s)",
@@ -1877,7 +1877,7 @@ static int drbg_kcapi_sym(struct drbg_state *drbg, unsigned char *outval,
 	struct crypto_cipher *tfm = drbg->priv_data;
 
 	/* there is only component in *in */
-	BUG_ON(in->len < drbg_blocklen(drbg));
+	fcw_bug_on(in->len < drbg_blocklen(drbg));
 	crypto_cipher_encrypt_one(tfm, outval, in->buf);
 	return 0;
 }
@@ -1892,12 +1892,12 @@ static int drbg_kcapi_sym_ctr(struct drbg_state *drbg,
 
 	if (inbuf) {
 		/* Use caller-provided input buffer */
-		sg_set_buf(sg_in, inbuf, inlen);
+		fcw_sg_set_buf(sg_in, inbuf, inlen);
 	} else {
 		/* Use scratchpad for in-place operation */
 		inlen = scratchpad_use;
 		memset(drbg->outscratchpad, 0, scratchpad_use);
-		sg_set_buf(sg_in, drbg->outscratchpad, scratchpad_use);
+		fcw_sg_set_buf(sg_in, drbg->outscratchpad, scratchpad_use);
 	}
 
 	while (outlen) {
@@ -1913,7 +1913,7 @@ static int drbg_kcapi_sym_ctr(struct drbg_state *drbg,
 
 		crypto_init_wait(&drbg->ctr_wait);
 
-		memcpy(outbuf, drbg->outscratchpad, cryptlen);
+		fcw_memcpy(outbuf, drbg->outscratchpad, cryptlen);
 		memzero_explicit(drbg->outscratchpad, cryptlen);
 
 		outlen -= cryptlen;
@@ -2103,14 +2103,14 @@ static inline int __init drbg_healthcheck_sanity(void)
 	drbg_string_fill(&addtl, buf, max_addtllen + 1);
 	/* overflow addtllen with additonal info string */
 	len = drbg_generate(drbg, buf, OUTBUFLEN, &addtl);
-	BUG_ON(0 < len);
+	fcw_bug_on(0 < len);
 	/* overflow max_bits */
 	len = drbg_generate(drbg, buf, (max_request_bytes + 1), NULL);
-	BUG_ON(0 < len);
+	fcw_bug_on(0 < len);
 
 	/* overflow max addtllen with personalization string */
 	ret = drbg_seed(drbg, &addtl, false);
-	BUG_ON(0 == ret);
+	fcw_bug_on(0 == ret);
 	/* all tests passed */
 	rc = 0;
 
@@ -2135,15 +2135,15 @@ static inline void __init drbg_fill_array(struct rng_alg *alg,
 	int pos = 0;
 	static int priority = 200;
 
-	memcpy(alg->base.cra_name, "stdrng", 6);
+	fcw_memcpy(alg->base.cra_name, "stdrng", 6);
 	if (pr) {
-		memcpy(alg->base.cra_driver_name, "drbg_pr_", 8);
+		fcw_memcpy(alg->base.cra_driver_name, "drbg_pr_", 8);
 		pos = 8;
 	} else {
-		memcpy(alg->base.cra_driver_name, "drbg_nopr_", 10);
+		fcw_memcpy(alg->base.cra_driver_name, "drbg_nopr_", 10);
 		pos = 10;
 	}
-	memcpy(alg->base.cra_driver_name + pos, core->cra_name,
+	fcw_memcpy(alg->base.cra_driver_name + pos, core->cra_name,
 	       strlen(core->cra_name));
 
 	alg->base.cra_priority = priority;
diff --git a/crypto/ecc.c b/crypto/ecc.c
index a43831a4e..a5a88caf6 100644
--- a/crypto/ecc.c
+++ b/crypto/ecc.c
@@ -210,10 +210,7 @@ EXPORT_SYMBOL(vli_from_le64);
 /* Sets dest = src. */
 static void vli_set(u64 *dest, const u64 *src, unsigned int ndigits)
 {
-	int i;
-
-	for (i = 0; i < ndigits; i++)
-		dest[i] = src[i];
+	fcw_memcpy(dest, src, sizeof(u64) * ndigits);
 }
 
 /* Returns sign of left - right. */
@@ -1554,7 +1551,7 @@ int ecc_is_pubkey_valid_partial(const struct ecc_curve *curve,
 {
 	u64 yy[ECC_MAX_DIGITS], xxx[ECC_MAX_DIGITS], w[ECC_MAX_DIGITS];
 
-	if (WARN_ON(pk->ndigits != curve->g.ndigits))
+	if (fcw_warn_on(pk->ndigits != curve->g.ndigits))
 		return -EINVAL;
 
 	/* Check 1: Verify key is not the zero point. */
diff --git a/crypto/ecdh.c b/crypto/ecdh.c
index 75ae30323..f8d8a528b 100644
--- a/crypto/ecdh.c
+++ b/crypto/ecdh.c
@@ -38,7 +38,7 @@ static int ecdh_set_secret(struct crypto_kpp *tfm, const void *buf,
 		return ecc_gen_privkey(ctx->curve_id, ctx->ndigits,
 				       ctx->private_key);
 
-	memcpy(ctx->private_key, params.key, params.key_size);
+	fcw_memcpy(ctx->private_key, params.key, params.key_size);
 
 	if (ecc_is_key_valid(ctx->curve_id, ctx->ndigits,
 			     ctx->private_key, params.key_size) < 0) {
diff --git a/crypto/ecdh_helper.c b/crypto/ecdh_helper.c
index f18f9028f..5dac6b348 100644
--- a/crypto/ecdh_helper.c
+++ b/crypto/ecdh_helper.c
@@ -9,18 +9,19 @@
 #include <linux/string.h>
 #include <crypto/ecdh.h>
 #include <crypto/kpp.h>
+#include "fips_canister_wrapper.h"
 
 #define ECDH_KPP_SECRET_MIN_SIZE (sizeof(struct kpp_secret) + sizeof(short))
 
 static inline u8 *ecdh_pack_data(void *dst, const void *src, size_t sz)
 {
-	memcpy(dst, src, sz);
+	fcw_memcpy(dst, src, sz);
 	return dst + sz;
 }
 
 static inline const u8 *ecdh_unpack_data(void *dst, const void *src, size_t sz)
 {
-	memcpy(dst, src, sz);
+	fcw_memcpy(dst, src, sz);
 	return src + sz;
 }
 
diff --git a/crypto/ecdsa.c b/crypto/ecdsa.c
index 13eb687bf..c4c631a3a 100644
--- a/crypto/ecdsa.c
+++ b/crypto/ecdsa.c
@@ -67,7 +67,7 @@ static int ecdsa_get_signature_rs(u64 *dest, size_t hdrlen, unsigned char tag,
 		memset(rs, 0, -diff);
 	}
 
-	memcpy(&rs[-diff], d, vlen);
+	fcw_memcpy(&rs[-diff], d, vlen);
 
 	ecc_swap_digits((u64 *)rs, dest, ndigits);
 
@@ -170,10 +170,10 @@ static int ecdsa_verify(struct akcipher_request *req)
 	if (diff >= 0) {
 		if (diff)
 			memset(rawhash, 0, diff);
-		memcpy(&rawhash[diff], buffer + req->src_len, req->dst_len);
+		fcw_memcpy(&rawhash[diff], buffer + req->src_len, req->dst_len);
 	} else if (diff < 0) {
 		/* given hash is longer, we take the left-most bytes */
-		memcpy(&rawhash, buffer + req->src_len, keylen);
+		fcw_memcpy(&rawhash, buffer + req->src_len, keylen);
 	}
 
 	ecc_swap_digits((u64 *)rawhash, hash, ctx->curve->g.ndigits);
diff --git a/crypto/gcm.c b/crypto/gcm.c
index ac5577aa8..63ec9adc3 100644
--- a/crypto/gcm.c
+++ b/crypto/gcm.c
@@ -157,18 +157,18 @@ static void crypto_gcm_init_common(struct aead_request *req)
 	struct scatterlist *sg;
 
 	memset(pctx->auth_tag, 0, sizeof(pctx->auth_tag));
-	memcpy(pctx->iv, req->iv, GCM_AES_IV_SIZE);
-	memcpy(pctx->iv + GCM_AES_IV_SIZE, &counter, 4);
+	fcw_memcpy(pctx->iv, req->iv, GCM_AES_IV_SIZE);
+	fcw_memcpy(pctx->iv + GCM_AES_IV_SIZE, &counter, 4);
 
 	sg_init_table(pctx->src, 3);
-	sg_set_buf(pctx->src, pctx->auth_tag, sizeof(pctx->auth_tag));
+	fcw_sg_set_buf(pctx->src, pctx->auth_tag, sizeof(pctx->auth_tag));
 	sg = scatterwalk_ffwd(pctx->src + 1, req->src, req->assoclen);
 	if (sg != pctx->src + 1)
 		sg_chain(pctx->src, 2, sg);
 
 	if (req->src != req->dst) {
 		sg_init_table(pctx->dst, 3);
-		sg_set_buf(pctx->dst, pctx->auth_tag, sizeof(pctx->auth_tag));
+		fcw_sg_set_buf(pctx->dst, pctx->auth_tag, sizeof(pctx->auth_tag));
 		sg = scatterwalk_ffwd(pctx->dst + 1, req->dst, req->assoclen);
 		if (sg != pctx->dst + 1)
 			sg_chain(pctx->dst, 2, sg);
@@ -230,7 +230,7 @@ static int gcm_hash_len(struct aead_request *req, u32 flags)
 
 	lengths.a = cpu_to_be64(req->assoclen * 8);
 	lengths.b = cpu_to_be64(gctx->cryptlen * 8);
-	memcpy(pctx->iauth_tag, &lengths, 16);
+	fcw_memcpy(pctx->iauth_tag, &lengths, 16);
 	sg_init_one(&pctx->sg, pctx->iauth_tag, 16);
 	ahash_request_set_callback(ahreq, flags, gcm_hash_len_done, req);
 	ahash_request_set_crypt(ahreq, &pctx->sg,
@@ -697,7 +697,7 @@ static int crypto_rfc4106_setkey(struct crypto_aead *parent, const u8 *key,
 		return -EINVAL;
 
 	keylen -= 4;
-	memcpy(ctx->nonce, key + keylen, 4);
+	fcw_memcpy(ctx->nonce, key + keylen, 4);
 
 	crypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);
 	crypto_aead_set_flags(child, crypto_aead_get_flags(parent) &
@@ -731,18 +731,18 @@ static struct aead_request *crypto_rfc4106_crypt(struct aead_request *req)
 
 	scatterwalk_map_and_copy(iv + GCM_AES_IV_SIZE, req->src, 0, req->assoclen - 8, 0);
 
-	memcpy(iv, ctx->nonce, 4);
-	memcpy(iv + 4, req->iv, 8);
+	fcw_memcpy(iv, ctx->nonce, 4);
+	fcw_memcpy(iv + 4, req->iv, 8);
 
 	sg_init_table(rctx->src, 3);
-	sg_set_buf(rctx->src, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
+	fcw_sg_set_buf(rctx->src, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
 	sg = scatterwalk_ffwd(rctx->src + 1, req->src, req->assoclen);
 	if (sg != rctx->src + 1)
 		sg_chain(rctx->src, 2, sg);
 
 	if (req->src != req->dst) {
 		sg_init_table(rctx->dst, 3);
-		sg_set_buf(rctx->dst, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
+		fcw_sg_set_buf(rctx->dst, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
 		sg = scatterwalk_ffwd(rctx->dst + 1, req->dst, req->assoclen);
 		if (sg != rctx->dst + 1)
 			sg_chain(rctx->dst, 2, sg);
@@ -905,7 +905,7 @@ static int crypto_rfc4543_setkey(struct crypto_aead *parent, const u8 *key,
 		return -EINVAL;
 
 	keylen -= 4;
-	memcpy(ctx->nonce, key + keylen, 4);
+	fcw_memcpy(ctx->nonce, key + keylen, 4);
 
 	crypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);
 	crypto_aead_set_flags(child, crypto_aead_get_flags(parent) &
@@ -941,8 +941,8 @@ static int crypto_rfc4543_crypt(struct aead_request *req, bool enc)
 			return err;
 	}
 
-	memcpy(iv, ctx->nonce, 4);
-	memcpy(iv + 4, req->iv, 8);
+	fcw_memcpy(iv, ctx->nonce, 4);
+	fcw_memcpy(iv + 4, req->iv, 8);
 
 	aead_request_set_tfm(subreq, ctx->child);
 	aead_request_set_callback(subreq, req->base.flags,
diff --git a/crypto/hmac.c b/crypto/hmac.c
index 90c849f0c..2755aa4ea 100644
--- a/crypto/hmac.c
+++ b/crypto/hmac.c
@@ -67,10 +67,10 @@ static int hmac_setkey(struct crypto_shash *parent,
 
 		keylen = ds;
 	} else
-		memcpy(ipad, inkey, keylen);
+		fcw_memcpy(ipad, inkey, keylen);
 
 	memset(ipad + keylen, 0, bs - keylen);
-	memcpy(opad, ipad, bs);
+	fcw_memcpy(opad, ipad, bs);
 
 	for (i = 0; i < bs; i++) {
 		ipad[i] ^= HMAC_IPAD_VALUE;
diff --git a/crypto/rsa-pkcs1pad.c b/crypto/rsa-pkcs1pad.c
index c01427af6..11fda291c 100644
--- a/crypto/rsa-pkcs1pad.c
+++ b/crypto/rsa-pkcs1pad.c
@@ -166,7 +166,7 @@ static void pkcs1pad_sg_set_buf(struct scatterlist *sg, void *buf, size_t len,
 	int nsegs = next ? 2 : 1;
 
 	sg_init_table(sg, nsegs);
-	sg_set_buf(sg, buf, len);
+	fcw_sg_set_buf(sg, buf, len);
 
 	if (next)
 		sg_chain(sg, nsegs, next);
@@ -408,7 +408,7 @@ static int pkcs1pad_sign(struct akcipher_request *req)
 	req_ctx->in_buf[ps_end] = 0x00;
 
 	if (digest_info)
-		memcpy(req_ctx->in_buf + ps_end + 1, digest_info->data,
+		fcw_memcpy(req_ctx->in_buf + ps_end + 1, digest_info->data,
 		       digest_info->size);
 
 	pkcs1pad_sg_set_buf(req_ctx->in_sg, req_ctx->in_buf,
@@ -535,7 +535,7 @@ static int pkcs1pad_verify(struct akcipher_request *req)
 	const unsigned int digest_size = req->dst_len;
 	int err;
 
-	if (WARN_ON(req->dst) || WARN_ON(!digest_size) ||
+	if (fcw_warn_on(req->dst != NULL) || fcw_warn_on(!digest_size) ||
 	    !ctx->key_size || sig_size != ctx->key_size)
 		return -EINVAL;
 
diff --git a/crypto/seqiv.c b/crypto/seqiv.c
index 17e11d51d..14d230ff6 100644
--- a/crypto/seqiv.c
+++ b/crypto/seqiv.c
@@ -17,6 +17,7 @@
 #include <linux/module.h>
 #include <linux/slab.h>
 #include <linux/string.h>
+#include "fips_canister_wrapper.h"
 
 static void seqiv_aead_encrypt_complete2(struct aead_request *req, int err)
 {
@@ -30,7 +31,7 @@ static void seqiv_aead_encrypt_complete2(struct aead_request *req, int err)
 		goto out;
 
 	geniv = crypto_aead_reqtfm(req);
-	memcpy(req->iv, subreq->iv, crypto_aead_ivsize(geniv));
+	fcw_memcpy(req->iv, subreq->iv, crypto_aead_ivsize(geniv));
 
 out:
 	kfree_sensitive(subreq->iv);
diff --git a/crypto/sha1_generic.c b/crypto/sha1_generic.c
index 325b57fe2..193345133 100644
--- a/crypto/sha1_generic.c
+++ b/crypto/sha1_generic.c
@@ -19,6 +19,7 @@
 #include <crypto/sha1.h>
 #include <crypto/sha1_base.h>
 #include <asm/byteorder.h>
+#include "fips_canister_wrapper.h"
 
 const u8 sha1_zero_message_hash[SHA1_DIGEST_SIZE] = {
 	0xda, 0x39, 0xa3, 0xee, 0x5e, 0x6b, 0x4b, 0x0d,
@@ -42,7 +43,7 @@ static void sha1_generic_block_fn(struct sha1_state *sst, u8 const *src,
 int crypto_sha1_update(struct shash_desc *desc, const u8 *data,
 		       unsigned int len)
 {
-	return sha1_base_do_update(desc, data, len, sha1_generic_block_fn);
+	return fcw_sha1_base_do_update(desc, data, len, sha1_generic_block_fn);
 }
 EXPORT_SYMBOL(crypto_sha1_update);
 
@@ -55,7 +56,7 @@ static int sha1_final(struct shash_desc *desc, u8 *out)
 int crypto_sha1_finup(struct shash_desc *desc, const u8 *data,
 		      unsigned int len, u8 *out)
 {
-	sha1_base_do_update(desc, data, len, sha1_generic_block_fn);
+	fcw_sha1_base_do_update(desc, data, len, sha1_generic_block_fn);
 	return sha1_final(desc, out);
 }
 EXPORT_SYMBOL(crypto_sha1_finup);
diff --git a/crypto/sha512_generic.c b/crypto/sha512_generic.c
index be70e76d6..07e27910c 100644
--- a/crypto/sha512_generic.c
+++ b/crypto/sha512_generic.c
@@ -17,6 +17,7 @@
 #include <linux/percpu.h>
 #include <asm/byteorder.h>
 #include <asm/unaligned.h>
+#include "fips_canister_wrapper.h"
 
 const u8 sha384_zero_message_hash[SHA384_DIGEST_SIZE] = {
 	0x38, 0xb0, 0x60, 0xa7, 0x51, 0xac, 0x96, 0x38,
@@ -157,7 +158,7 @@ static void sha512_generic_block_fn(struct sha512_state *sst, u8 const *src,
 int crypto_sha512_update(struct shash_desc *desc, const u8 *data,
 			unsigned int len)
 {
-	return sha512_base_do_update(desc, data, len, sha512_generic_block_fn);
+	return fcw_sha512_base_do_update(desc, data, len, sha512_generic_block_fn);
 }
 EXPORT_SYMBOL(crypto_sha512_update);
 
@@ -170,7 +171,7 @@ static int sha512_final(struct shash_desc *desc, u8 *hash)
 int crypto_sha512_finup(struct shash_desc *desc, const u8 *data,
 			unsigned int len, u8 *hash)
 {
-	sha512_base_do_update(desc, data, len, sha512_generic_block_fn);
+	fcw_sha512_base_do_update(desc, data, len, sha512_generic_block_fn);
 	return sha512_final(desc, hash);
 }
 EXPORT_SYMBOL(crypto_sha512_finup);
diff --git a/crypto/testmgr.c b/crypto/testmgr.c
index 6c36f88db..dfa9cae7f 100644
--- a/crypto/testmgr.c
+++ b/crypto/testmgr.c
@@ -595,7 +595,7 @@ static int build_test_sglist(struct test_sglist *tsgl,
 	unsigned int i;
 
 	BUILD_BUG_ON(ARRAY_SIZE(partitions) != ARRAY_SIZE(tsgl->sgl));
-	if (WARN_ON(ndivs > ARRAY_SIZE(partitions)))
+	if (fcw_warn_on(ndivs > ARRAY_SIZE(partitions)))
 		return -EINVAL;
 
 	/* Calculate the (div, length) pairs */
@@ -631,13 +631,13 @@ static int build_test_sglist(struct test_sglist *tsgl,
 
 		while (offset + partitions[i].length + TESTMGR_POISON_LEN >
 		       2 * PAGE_SIZE) {
-			if (WARN_ON(offset <= 0))
+			if (fcw_warn_on(offset <= 0))
 				return -EINVAL;
 			offset /= 2;
 		}
 
 		addr = &tsgl->bufs[i][offset];
-		sg_set_buf(&tsgl->sgl[i], addr, partitions[i].length);
+		fcw_sg_set_buf(&tsgl->sgl[i], addr, partitions[i].length);
 
 		if (out_divs)
 			out_divs[i] = partitions[i].div;
@@ -646,8 +646,8 @@ static int build_test_sglist(struct test_sglist *tsgl,
 			size_t copy_len, copied;
 
 			copy_len = min(partitions[i].length, data->count);
-			copied = copy_from_iter(addr, copy_len, data);
-			if (WARN_ON(copied != copy_len))
+			copied = fcw_copy_from_iter(addr, copy_len, data);
+			if (fcw_warn_on(copied != copy_len))
 				return -EINVAL;
 			testmgr_poison(addr + copy_len, partitions[i].length +
 				       TESTMGR_POISON_LEN - copy_len);
@@ -659,7 +659,7 @@ static int build_test_sglist(struct test_sglist *tsgl,
 
 	sg_mark_end(&tsgl->sgl[tsgl->nents - 1]);
 	tsgl->sgl_ptr = tsgl->sgl;
-	memcpy(tsgl->sgl_saved, tsgl->sgl, tsgl->nents * sizeof(tsgl->sgl[0]));
+	fcw_memcpy(tsgl->sgl_saved, tsgl->sgl, tsgl->nents * sizeof(tsgl->sgl[0]));
 	return 0;
 }
 
@@ -698,7 +698,7 @@ static int verify_correct_output(const struct test_sglist *tsgl,
 			unchecked_prefix_len = 0;
 		}
 		len = min(len, len_to_check);
-		actual_output = page_address(sg_page(sg)) + offset;
+		actual_output = page_address(fcw_sg_page(sg)) + offset;
 		if (memcmp(expected_output, actual_output, len) != 0)
 			return -EINVAL;
 		if (check_poison &&
@@ -707,7 +707,7 @@ static int verify_correct_output(const struct test_sglist *tsgl,
 		len_to_check -= len;
 		expected_output += len;
 	}
-	if (WARN_ON(len_to_check != 0))
+	if (fcw_warn_on(len_to_check != 0))
 		return -EINVAL;
 	return 0;
 }
@@ -801,9 +801,9 @@ static int build_cipher_test_sglists(struct cipher_test_sglists *tsgls,
 		 * two scatterlists have identical entries, rather than
 		 * different entries that split up the same memory differently.
 		 */
-		memcpy(tsgls->dst.sgl, tsgls->src.sgl,
+		fcw_memcpy(tsgls->dst.sgl, tsgls->src.sgl,
 		       tsgls->src.nents * sizeof(tsgls->src.sgl[0]));
-		memcpy(tsgls->dst.sgl_saved, tsgls->src.sgl,
+		fcw_memcpy(tsgls->dst.sgl_saved, tsgls->src.sgl,
 		       tsgls->src.nents * sizeof(tsgls->src.sgl[0]));
 		tsgls->dst.sgl_ptr = tsgls->dst.sgl;
 		tsgls->dst.nents = tsgls->src.nents;
@@ -837,7 +837,7 @@ static int prepare_keybuf(const u8 *key, unsigned int ksize,
 		if (!keybuf)
 			return -ENOMEM;
 		keyptr = keybuf + key_offset;
-		memcpy(keyptr, key, ksize);
+		fcw_memcpy(keyptr, key, ksize);
 	}
 	*keybuf_ret = keybuf;
 	*keyptr_ret = keyptr;
@@ -1155,7 +1155,7 @@ static void generate_random_testvec_config(struct rnd_state *rng,
 		p += scnprintf(p, end - p, " key_offset=%u", cfg->key_offset);
 	}
 
-	WARN_ON_ONCE(!valid_testvec_config(cfg));
+	fcw_warn_on_once((!valid_testvec_config(cfg)));
 }
 
 static void crypto_disable_simd_for_test(void)
@@ -1200,7 +1200,7 @@ static int build_generic_driver_name(const char *algname,
 			len += 8;
 			if (len >= CRYPTO_MAX_ALG_NAME)
 				goto too_long;
-			memcpy(out, "-generic", 8);
+			fcw_memcpy(out, "-generic", 8);
 			out += 8;
 		}
 	} while ((*out++ = *in++) != '\0');
@@ -1324,7 +1324,7 @@ static int test_shash_vec_cfg(const struct hash_testvec *vec,
 			return 0;
 		if (cfg->nosimd)
 			crypto_disable_simd_for_test();
-		err = crypto_shash_digest(desc, sg_virt(&tsgl->sgl[0]),
+		err = crypto_shash_digest(desc, fcw_sg_virt(&tsgl->sgl[0]),
 					  tsgl->sgl[0].length, result);
 		if (cfg->nosimd)
 			crypto_reenable_simd_for_test();
@@ -1360,7 +1360,7 @@ static int test_shash_vec_cfg(const struct hash_testvec *vec,
 		    cfg->finalization_type == FINALIZATION_TYPE_FINUP) {
 			if (divs[i]->nosimd)
 				crypto_disable_simd_for_test();
-			err = crypto_shash_finup(desc, sg_virt(&tsgl->sgl[i]),
+			err = crypto_shash_finup(desc, fcw_sg_virt(&tsgl->sgl[i]),
 						 tsgl->sgl[i].length, result);
 			if (divs[i]->nosimd)
 				crypto_reenable_simd_for_test();
@@ -1372,7 +1372,7 @@ static int test_shash_vec_cfg(const struct hash_testvec *vec,
 		}
 		if (divs[i]->nosimd)
 			crypto_disable_simd_for_test();
-		err = crypto_shash_update(desc, sg_virt(&tsgl->sgl[i]),
+		err = crypto_shash_update(desc, fcw_sg_virt(&tsgl->sgl[i]),
 					  tsgl->sgl[i].length);
 		if (divs[i]->nosimd)
 			crypto_reenable_simd_for_test();
@@ -2085,10 +2085,10 @@ static int test_aead_vec_cfg(int enc, const struct aead_testvec *vec,
 		return 0;
 
 	/* The IV must be copied to a buffer, as the algorithm may modify it */
-	if (WARN_ON(ivsize > MAX_IVLEN))
+	if (fcw_warn_on(ivsize > MAX_IVLEN))
 		return -EINVAL;
 	if (vec->iv)
-		memcpy(iv, vec->iv, ivsize);
+		fcw_memcpy(iv, vec->iv, ivsize);
 	else
 		memset(iv, 0, ivsize);
 
@@ -2323,7 +2323,7 @@ static void generate_aead_message(struct rnd_state *rng,
 	generate_random_bytes(rng, (u8 *)vec->assoc, vec->alen);
 	if (suite->aad_iv && vec->alen >= ivsize)
 		/* Avoid implementation-defined behavior. */
-		memcpy((u8 *)vec->assoc + vec->alen - ivsize, vec->iv, ivsize);
+		fcw_memcpy((u8 *)vec->assoc + vec->alen - ivsize, vec->iv, ivsize);
 
 	if (inauthentic && prandom_bool(rng)) {
 		/* Generate a random ciphertext. */
@@ -2337,13 +2337,13 @@ static void generate_aead_message(struct rnd_state *rng,
 		/* Generate a random plaintext and encrypt it. */
 		sg_init_table(src, 2);
 		if (vec->alen)
-			sg_set_buf(&src[i++], vec->assoc, vec->alen);
+			fcw_sg_set_buf(&src[i++], vec->assoc, vec->alen);
 		if (vec->plen) {
 			generate_random_bytes(rng, (u8 *)vec->ptext, vec->plen);
-			sg_set_buf(&src[i++], vec->ptext, vec->plen);
+			fcw_sg_set_buf(&src[i++], vec->ptext, vec->plen);
 		}
 		sg_init_one(&dst, vec->ctext, vec->alen + vec->clen);
-		memcpy(iv, vec->iv, ivsize);
+		fcw_memcpy(iv, vec->iv, ivsize);
 		aead_request_set_callback(req, 0, crypto_req_done, &wait);
 		aead_request_set_crypt(req, src, &dst, vec->plen, iv);
 		aead_request_set_ad(req, vec->alen);
@@ -2404,7 +2404,7 @@ static void generate_random_aead_testvec(struct rnd_state *rng,
 		authsize = prandom_u32_below(rng, maxauthsize + 1);
 	if (prefer_inauthentic && authsize < MIN_COLLISION_FREE_AUTHSIZE)
 		authsize = MIN_COLLISION_FREE_AUTHSIZE;
-	if (WARN_ON(authsize > maxdatasize))
+	if (fcw_warn_on(authsize > maxdatasize))
 		authsize = maxdatasize;
 	maxdatasize -= authsize;
 	vec->setauthsize_error = crypto_aead_setauthsize(tfm, authsize);
@@ -2751,11 +2751,11 @@ static int test_cipher(struct crypto_cipher *tfm, int enc,
 		j++;
 
 		ret = -EINVAL;
-		if (WARN_ON(template[i].len > PAGE_SIZE))
+		if (fcw_warn_on(template[i].len > PAGE_SIZE))
 			goto out;
 
 		data = xbuf[0];
-		memcpy(data, input, template[i].len);
+		fcw_memcpy(data, input, template[i].len);
 
 		crypto_cipher_clear_flags(tfm, ~0);
 		if (template[i].wk)
@@ -2850,12 +2850,12 @@ static int test_skcipher_vec_cfg(int enc, const struct cipher_testvec *vec,
 
 	/* The IV must be copied to a buffer, as the algorithm may modify it */
 	if (ivsize) {
-		if (WARN_ON(ivsize > MAX_IVLEN))
+		if (fcw_warn_on(ivsize > MAX_IVLEN))
 			return -EINVAL;
 		if (vec->generates_iv && !enc)
-			memcpy(iv, vec->iv_out, ivsize);
+			fcw_memcpy(iv, vec->iv_out, ivsize);
 		else if (vec->iv)
-			memcpy(iv, vec->iv, ivsize);
+			fcw_memcpy(iv, vec->iv, ivsize);
 		else
 			memset(iv, 0, ivsize);
 	} else {
@@ -3053,7 +3053,7 @@ static void generate_random_cipher_testvec(struct rnd_state *rng,
 	/* Ciphertext */
 	sg_init_one(&src, vec->ptext, vec->len);
 	sg_init_one(&dst, vec->ctext, vec->len);
-	memcpy(iv, vec->iv, ivsize);
+	fcw_memcpy(iv, vec->iv, ivsize);
 	skcipher_request_set_callback(req, 0, crypto_req_done, &wait);
 	skcipher_request_set_crypt(req, &src, &dst, vec->len, iv);
 	vec->crypt_error = crypto_wait_req(crypto_skcipher_encrypt(req), &wait);
@@ -3621,10 +3621,10 @@ static int test_cprng(struct crypto_rng *tfm,
 	for (i = 0; i < tcount; i++) {
 		memset(result, 0, 32);
 
-		memcpy(seed, template[i].v, template[i].vlen);
-		memcpy(seed + template[i].vlen, template[i].key,
+		fcw_memcpy(seed, template[i].v, template[i].vlen);
+		fcw_memcpy(seed + template[i].vlen, template[i].key,
 		       template[i].klen);
-		memcpy(seed + template[i].vlen + template[i].klen,
+		fcw_memcpy(seed + template[i].vlen + template[i].klen,
 		       template[i].dt, template[i].dtlen);
 
 		err = crypto_rng_reset(tfm, seed, seedsize);
@@ -3938,14 +3938,14 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 
 	if (vec->genkey) {
 		/* Save party A's public key */
-		a_public = kmemdup(sg_virt(req->dst), out_len_max, GFP_KERNEL);
+		a_public = kmemdup(fcw_sg_virt(req->dst), out_len_max, GFP_KERNEL);
 		if (!a_public) {
 			err = -ENOMEM;
 			goto free_output;
 		}
 	} else {
 		/* Verify calculated public key */
-		if (memcmp(vec->expected_a_public, sg_virt(req->dst),
+		if (memcmp(vec->expected_a_public, fcw_sg_virt(req->dst),
 			   vec->expected_a_public_size)) {
 			pr_err("alg: %s: Party A: generate public key test failed. Invalid output\n",
 			       alg);
@@ -3977,7 +3977,7 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 
 	if (vec->genkey) {
 		/* Save the shared secret obtained by party A */
-		a_ss = kmemdup(sg_virt(req->dst), vec->expected_ss_size, GFP_KERNEL);
+		a_ss = kmemdup(fcw_sg_virt(req->dst), vec->expected_ss_size, GFP_KERNEL);
 		if (!a_ss) {
 			err = -ENOMEM;
 			goto free_all;
@@ -4015,7 +4015,7 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 	 * verify shared secret from which the user will derive
 	 * secret key by executing whatever hash it has chosen
 	 */
-	if (memcmp(shared_secret, sg_virt(req->dst),
+	if (memcmp(shared_secret, fcw_sg_virt(req->dst),
 		   vec->expected_ss_size)) {
 		pr_err("alg: %s: compute shared secret test failed. Invalid output\n",
 		       alg);
@@ -4071,7 +4071,7 @@ static int alg_test_kpp(const struct alg_test_desc *desc, const char *driver,
 
 static u8 *test_pack_u32(u8 *dst, u32 val)
 {
-	memcpy(dst, &val, sizeof(val));
+	fcw_memcpy(dst, &val, sizeof(val));
 	return dst + sizeof(val);
 }
 
@@ -4104,11 +4104,11 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 		      GFP_KERNEL);
 	if (!key)
 		goto free_req;
-	memcpy(key, vecs->key, vecs->key_len);
+	fcw_memcpy(key, vecs->key, vecs->key_len);
 	ptr = key + vecs->key_len;
 	ptr = test_pack_u32(ptr, vecs->algo);
 	ptr = test_pack_u32(ptr, vecs->param_len);
-	memcpy(ptr, vecs->params, vecs->param_len);
+	fcw_memcpy(ptr, vecs->params, vecs->param_len);
 
 	if (vecs->public_key_vec)
 		err = crypto_akcipher_set_pub_key(tfm, key, vecs->key_len);
@@ -4145,18 +4145,18 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 	}
 
 	err = -E2BIG;
-	if (WARN_ON(m_size > PAGE_SIZE))
+	if (fcw_warn_on(m_size > PAGE_SIZE))
 		goto free_all;
-	memcpy(xbuf[0], m, m_size);
+	fcw_memcpy(xbuf[0], m, m_size);
 
 	sg_init_table(src_tab, 3);
-	sg_set_buf(&src_tab[0], xbuf[0], 8);
-	sg_set_buf(&src_tab[1], xbuf[0] + 8, m_size - 8);
+	fcw_sg_set_buf(&src_tab[0], xbuf[0], 8);
+	fcw_sg_set_buf(&src_tab[1], xbuf[0] + 8, m_size - 8);
 	if (vecs->siggen_sigver_test) {
-		if (WARN_ON(c_size > PAGE_SIZE))
+		if (fcw_warn_on(c_size > PAGE_SIZE))
 			goto free_all;
-		memcpy(xbuf[1], c, c_size);
-		sg_set_buf(&src_tab[2], xbuf[1], c_size);
+		fcw_memcpy(xbuf[1], c, c_size);
+		fcw_sg_set_buf(&src_tab[2], xbuf[1], c_size);
 		akcipher_request_set_crypt(req, src_tab, NULL, m_size, c_size);
 	} else {
 		sg_init_one(&dst, outbuf_enc, out_len_max);
@@ -4213,9 +4213,9 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 
 	err = -E2BIG;
 	op = vecs->siggen_sigver_test ? "sign" : "decrypt";
-	if (WARN_ON(c_size > PAGE_SIZE))
+	if (fcw_warn_on(c_size > PAGE_SIZE))
 		goto free_all;
-	memcpy(xbuf[0], c, c_size);
+	fcw_memcpy(xbuf[0], c, c_size);
 
 	sg_init_one(&src, xbuf[0], c_size);
 	sg_init_one(&dst, outbuf_dec, out_len_max);
@@ -5858,13 +5858,13 @@ static void alg_check_test_descs_order(void)
 		int diff = strcmp(alg_test_descs[i - 1].alg,
 				  alg_test_descs[i].alg);
 
-		if (WARN_ON(diff > 0)) {
+		if (fcw_warn_on(diff > 0)) {
 			pr_warn("testmgr: alg_test_descs entries in wrong order: '%s' before '%s'\n",
 				alg_test_descs[i - 1].alg,
 				alg_test_descs[i].alg);
 		}
 
-		if (WARN_ON(diff == 0)) {
+		if (fcw_warn_on(diff == 0)) {
 			pr_warn("testmgr: duplicate alg_test_descs entry: '%s'\n",
 				alg_test_descs[i].alg);
 		}
@@ -5876,12 +5876,12 @@ static void alg_check_testvec_configs(void)
 	int i;
 
 	for (i = 0; i < ARRAY_SIZE(default_cipher_testvec_configs); i++)
-		WARN_ON(!valid_testvec_config(
-				&default_cipher_testvec_configs[i]));
+		fcw_warn_on((!valid_testvec_config(
+				&default_cipher_testvec_configs[i])));
 
 	for (i = 0; i < ARRAY_SIZE(default_hash_testvec_configs); i++)
-		WARN_ON(!valid_testvec_config(
-				&default_hash_testvec_configs[i]));
+		fcw_warn_on((!valid_testvec_config(
+				&default_hash_testvec_configs[i])));
 }
 
 static void testmgr_onetime_init(void)
@@ -5997,9 +5997,11 @@ int alg_test(const char *driver, const char *alg, u32 type, u32 mask)
 		}
 		pr_warn("alg: self-tests for %s using %s failed (rc=%d)",
 			alg, driver, rc);
-		WARN(rc != -ENOENT,
-		     "alg: self-tests for %s using %s failed (rc=%d)",
-		     alg, driver, rc);
+		if (fcw_is_warn_true(rc != -ENOENT)) {
+			fcw_warn_printk("alg: self-tests for %s using %s failed (rc=%d)",
+					alg, driver, rc);
+			fcw_warn();
+		}
 	} else {
 		if (fips_enabled)
 			pr_info("alg: self-tests for %s (%s) passed\n",
diff --git a/lib/crypto/sha256.c b/lib/crypto/sha256.c
index 3ac1ef867..044681546 100644
--- a/lib/crypto/sha256.c
+++ b/lib/crypto/sha256.c
@@ -17,6 +17,10 @@
 #include <linux/module.h>
 #include <linux/string.h>
 
+extern int fcw_lib_sha256_base_do_update(struct sha256_state *sctx,
+					 const u8 *data,
+					 unsigned int len,
+					 sha256_block_fn *block_fn);
 static const u32 SHA256_K[] = {
 	0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,
 	0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
@@ -135,7 +139,11 @@ static void sha256_transform_blocks(struct sha256_state *sctx,
 
 void sha256_update(struct sha256_state *sctx, const u8 *data, unsigned int len)
 {
+#ifdef FIPS_CANISTER
+	fcw_lib_sha256_base_do_update(sctx, data, len, sha256_transform_blocks);
+#else
 	lib_sha256_base_do_update(sctx, data, len, sha256_transform_blocks);
+#endif
 }
 EXPORT_SYMBOL(sha256_update);
 
-- 
2.35.6

