From c4c91dc561cd0fa52f81291a235f699582e1c636 Mon Sep 17 00:00:00 2001
From: Keerthana K <keerthanak@vmware.com>
Date: Wed, 20 Sep 2023 07:43:34 +0000
Subject: [PATCH] FIPS canister creation

Canister creation patch.
 - Makefile changes to generate canister binary (fips_canister.o)
 - Move mutex API out of canister to the wrapper as it expands differently
   depending on .config options. The difference is huge in -rt kernel.
 - Use mutex instead of spinlock in canister. There is no difference to the
   code that use it, but improvement for -rt kernel and simplification for
   the wrapper.
 - Move kernel memory alloc functions out of canister as their implementations
   vary depending on .config options.
 - Move cond_resched function to the wrapper.
 - Add internal static functions to eliminate glue helpers calls.
 - Redo DO_ONCE as it is not supported by integrity code.
 - Do not use latent entropy GCC plugin for canister objects
 - Do not check indirect call destination signatures from canister

Signed-off-by: Alexey Makhalov <amakhalov@vmware.com>
Signed-off-by: Keerthana K <keerthanak@vmware.com>
Signed-off-by: Vamsi Krishna Brahmajosyula <vbrahmajosyula@vmware.com>
---
 arch/x86/crypto/aesni-intel_glue.c |  73 ++++++++++---------
 crypto/Makefile                    |  87 +++++++++++++++++++++++
 crypto/algboss.c                   |   5 +-
 crypto/ccm.c                       |   7 +-
 crypto/cmac.c                      |   3 +-
 crypto/ctr.c                       |   3 +-
 crypto/cts.c                       |   3 +-
 crypto/drbg.c                      |  50 ++++++++-----
 crypto/ecc.c                       |   5 +-
 crypto/ecdh.c                      |   5 +-
 crypto/ecdsa.c                     |   3 +-
 crypto/gcm.c                       |  11 +--
 crypto/ghash-generic.c             |   5 +-
 crypto/hmac.c                      |   3 +-
 crypto/rsa-pkcs1pad.c              |  13 ++--
 crypto/sha3_generic.c              |   5 +-
 crypto/testmgr.c                   | 108 ++++++++++++++++-------------
 crypto/xts.c                       |   3 +-
 include/crypto/drbg.h              |   3 +-
 19 files changed, 261 insertions(+), 134 deletions(-)

diff --git a/arch/x86/crypto/aesni-intel_glue.c b/arch/x86/crypto/aesni-intel_glue.c
index 39d6a62ac..0810c470b 100644
--- a/arch/x86/crypto/aesni-intel_glue.c
+++ b/arch/x86/crypto/aesni-intel_glue.c
@@ -35,7 +35,10 @@
 #include <linux/workqueue.h>
 #include <linux/spinlock.h>
 #include <linux/static_call.h>
+#include <crypto/gf128mul.h>
 
+void fcw_kernel_fpu_begin(void);
+void fcw_kernel_fpu_end(void);
 
 #define AESNI_ALIGN	16
 #define AESNI_ALIGN_ATTR __attribute__ ((__aligned__(AESNI_ALIGN)))
@@ -241,9 +244,9 @@ static int aes_set_key_common(struct crypto_aes_ctx *ctx,
 	if (!crypto_simd_usable())
 		err = aes_expandkey(ctx, in_key, key_len);
 	else {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		err = aesni_set_key(ctx, in_key, key_len);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 	}
 
 	return err;
@@ -263,9 +266,9 @@ static void aesni_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)
 	if (!crypto_simd_usable()) {
 		aes_encrypt(ctx, dst, src);
 	} else {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_enc(ctx, dst, src);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 	}
 }
 
@@ -276,9 +279,9 @@ static void aesni_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)
 	if (!crypto_simd_usable()) {
 		aes_decrypt(ctx, dst, src);
 	} else {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_dec(ctx, dst, src);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 	}
 }
 
@@ -299,10 +302,10 @@ static int ecb_encrypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes)) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_ecb_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			      nbytes & AES_BLOCK_MASK);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		nbytes &= AES_BLOCK_SIZE - 1;
 		err = skcipher_walk_done(&walk, nbytes);
 	}
@@ -321,10 +324,10 @@ static int ecb_decrypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes)) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_ecb_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			      nbytes & AES_BLOCK_MASK);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		nbytes &= AES_BLOCK_SIZE - 1;
 		err = skcipher_walk_done(&walk, nbytes);
 	}
@@ -343,10 +346,10 @@ static int cbc_encrypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes)) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_cbc_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			      nbytes & AES_BLOCK_MASK, walk.iv);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		nbytes &= AES_BLOCK_SIZE - 1;
 		err = skcipher_walk_done(&walk, nbytes);
 	}
@@ -365,10 +368,10 @@ static int cbc_decrypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes)) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		aesni_cbc_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			      nbytes & AES_BLOCK_MASK, walk.iv);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		nbytes &= AES_BLOCK_SIZE - 1;
 		err = skcipher_walk_done(&walk, nbytes);
 	}
@@ -424,10 +427,10 @@ static int cts_cbc_encrypt(struct skcipher_request *req)
 	if (err)
 		return err;
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 	aesni_cts_cbc_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			  walk.nbytes, walk.iv);
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 
 	return skcipher_walk_done(&walk, 0);
 }
@@ -480,10 +483,10 @@ static int cts_cbc_decrypt(struct skcipher_request *req)
 	if (err)
 		return err;
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 	aesni_cts_cbc_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,
 			  walk.nbytes, walk.iv);
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 
 	return skcipher_walk_done(&walk, 0);
 }
@@ -518,7 +521,7 @@ static int ctr_crypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes) > 0) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		if (nbytes & AES_BLOCK_MASK)
 			static_call(aesni_ctr_enc_tfm)(ctx, walk.dst.virt.addr,
 						       walk.src.virt.addr,
@@ -534,7 +537,7 @@ static int ctr_crypt(struct skcipher_request *req)
 			crypto_inc(walk.iv, AES_BLOCK_SIZE);
 			nbytes = 0;
 		}
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		err = skcipher_walk_done(&walk, nbytes);
 	}
 	return err;
@@ -569,7 +572,7 @@ static int xctr_crypt(struct skcipher_request *req)
 	err = skcipher_walk_virt(&walk, req, false);
 
 	while ((nbytes = walk.nbytes) > 0) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		if (nbytes & AES_BLOCK_MASK)
 			aesni_xctr_enc_avx_tfm(ctx, walk.dst.virt.addr,
 				walk.src.virt.addr, nbytes & AES_BLOCK_MASK,
@@ -587,7 +590,7 @@ static int xctr_crypt(struct skcipher_request *req)
 			byte_ctr += nbytes;
 			nbytes = 0;
 		}
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 		err = skcipher_walk_done(&walk, nbytes);
 	}
 	return err;
@@ -666,6 +669,8 @@ static int generic_gcmaes_set_authsize(struct crypto_aead *tfm,
 	return 0;
 }
 
+extern void *fcw_kmalloc(size_t size, gfp_t flags);
+
 static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 			      unsigned int assoclen, u8 *hash_subkey,
 			      u8 *iv, void *aes_ctx, u8 *auth_tag,
@@ -696,7 +701,7 @@ static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 			      GFP_KERNEL : GFP_ATOMIC;
 
 		/* assoc can be any length, so must be on heap */
-		assocmem = kmalloc(assoclen, flags);
+		assocmem = fcw_kmalloc(assoclen, flags);
 		if (unlikely(!assocmem))
 			return -ENOMEM;
 		assoc = assocmem;
@@ -704,7 +709,7 @@ static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 		scatterwalk_map_and_copy(assoc, req->src, 0, assoclen, 0);
 	}
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 	if (static_branch_likely(&gcm_use_avx2) && do_avx2)
 		aesni_gcm_init_avx_gen4(aes_ctx, data, iv, hash_subkey, assoc,
 					assoclen);
@@ -713,7 +718,7 @@ static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 					assoclen);
 	else
 		aesni_gcm_init(aes_ctx, data, iv, hash_subkey, assoc, assoclen);
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 
 	if (!assocmem)
 		scatterwalk_unmap(assoc);
@@ -724,7 +729,7 @@ static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 		  : skcipher_walk_aead_decrypt(&walk, req, false);
 
 	while (walk.nbytes > 0) {
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		if (static_branch_likely(&gcm_use_avx2) && do_avx2) {
 			if (enc)
 				aesni_gcm_enc_update_avx_gen4(aes_ctx, data,
@@ -754,7 +759,7 @@ static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 			aesni_gcm_dec_update(aes_ctx, data, walk.dst.virt.addr,
 					     walk.src.virt.addr, walk.nbytes);
 		}
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 
 		err = skcipher_walk_done(&walk, 0);
 	}
@@ -762,7 +767,7 @@ static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 	if (err)
 		return err;
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 	if (static_branch_likely(&gcm_use_avx2) && do_avx2)
 		aesni_gcm_finalize_avx_gen4(aes_ctx, data, auth_tag,
 					    auth_tag_len);
@@ -771,7 +776,7 @@ static int gcmaes_crypt_by_sg(bool enc, struct aead_request *req,
 					    auth_tag_len);
 	else
 		aesni_gcm_finalize(aes_ctx, data, auth_tag, auth_tag_len);
-	kernel_fpu_end();
+	fcw_kernel_fpu_end();
 
 	return 0;
 }
@@ -936,7 +941,7 @@ static int xts_crypt(struct skcipher_request *req, bool encrypt)
 		tail = 0;
 	}
 
-	kernel_fpu_begin();
+	fcw_kernel_fpu_begin();
 
 	/* calculate first value of T */
 	aesni_enc(aes_ctx(ctx->raw_tweak_ctx), walk.iv, walk.iv);
@@ -955,12 +960,12 @@ static int xts_crypt(struct skcipher_request *req, bool encrypt)
 			aesni_xts_decrypt(aes_ctx(ctx->raw_crypt_ctx),
 					  walk.dst.virt.addr, walk.src.virt.addr,
 					  nbytes, walk.iv);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 
 		err = skcipher_walk_done(&walk, walk.nbytes - nbytes);
 
 		if (walk.nbytes > 0)
-			kernel_fpu_begin();
+			fcw_kernel_fpu_begin();
 	}
 
 	if (unlikely(tail > 0 && !err)) {
@@ -978,7 +983,7 @@ static int xts_crypt(struct skcipher_request *req, bool encrypt)
 		if (err)
 			return err;
 
-		kernel_fpu_begin();
+		fcw_kernel_fpu_begin();
 		if (encrypt)
 			aesni_xts_encrypt(aes_ctx(ctx->raw_crypt_ctx),
 					  walk.dst.virt.addr, walk.src.virt.addr,
@@ -987,7 +992,7 @@ static int xts_crypt(struct skcipher_request *req, bool encrypt)
 			aesni_xts_decrypt(aes_ctx(ctx->raw_crypt_ctx),
 					  walk.dst.virt.addr, walk.src.virt.addr,
 					  walk.nbytes, walk.iv);
-		kernel_fpu_end();
+		fcw_kernel_fpu_end();
 
 		err = skcipher_walk_done(&walk, 0);
 	}
diff --git a/crypto/Makefile b/crypto/Makefile
index 288e8e1e7..7f2a45ca8 100644
--- a/crypto/Makefile
+++ b/crypto/Makefile
@@ -18,9 +18,11 @@ crypto_algapi-y := algapi.o scatterwalk.o $(crypto_algapi-y)
 obj-$(CONFIG_CRYPTO_ALGAPI2) += crypto_algapi.o
 
 obj-$(CONFIG_CRYPTO_AEAD2) += aead.o
+canister += geniv.o
 
 obj-$(CONFIG_CRYPTO_SKCIPHER2) += skcipher.o
 obj-$(CONFIG_CRYPTO_ECHAINIV) += echainiv.o
+canister += seqiv.o
 
 crypto_hash-y += ahash.o
 crypto_hash-y += shash.o
@@ -43,6 +45,7 @@ rsa_generic-y += rsaprivkey.asn1.o
 rsa_generic-y += rsa.o
 rsa_generic-y += rsa_helper.o
 rsa_generic-y += rsa-pkcs1pad.o
+canister += $(rsa_generic-y)
 
 $(obj)/sm2signature.asn1.o: $(obj)/sm2signature.asn1.c $(obj)/sm2signature.asn1.h
 $(obj)/sm2.o: $(obj)/sm2signature.asn1.h
@@ -56,22 +59,30 @@ $(obj)/ecdsasignature.asn1.o: $(obj)/ecdsasignature.asn1.c $(obj)/ecdsasignature
 $(obj)/ecdsa.o: $(obj)/ecdsasignature.asn1.h
 ecdsa_generic-y += ecdsa.o
 ecdsa_generic-y += ecdsasignature.asn1.o
+canister += $(ecdsa_generic-y)
 
 crypto_acompress-y := acompress.o
 crypto_acompress-y += scompress.o
 obj-$(CONFIG_CRYPTO_ACOMP2) += crypto_acompress.o
 
 cryptomgr-y := algboss.o testmgr.o
+canister += $(cryptomgr-y)
 
 obj-$(CONFIG_CRYPTO_USER) += crypto_user.o
 crypto_user-y := crypto_user_base.o
 crypto_user-$(CONFIG_CRYPTO_STATS) += crypto_user_stat.o
+canister += hmac.o
+canister += cmac.o
 obj-$(CONFIG_CRYPTO_VMAC) += vmac.o
 obj-$(CONFIG_CRYPTO_XCBC) += xcbc.o
 obj-$(CONFIG_CRYPTO_NULL2) += crypto_null.o
 obj-$(CONFIG_CRYPTO_MD4) += md4.o
 obj-$(CONFIG_CRYPTO_MD5) += md5.o
 obj-$(CONFIG_CRYPTO_RMD160) += rmd160.o
+canister += sha1_generic.o
+canister += sha256_generic.o
+canister += sha512_generic.o
+canister += sha3_generic.o
 obj-$(CONFIG_CRYPTO_SM3) += sm3.o
 obj-$(CONFIG_CRYPTO_SM3_GENERIC) += sm3_generic.o
 obj-$(CONFIG_CRYPTO_STREEBOG) += streebog_generic.o
@@ -79,13 +90,21 @@ obj-$(CONFIG_CRYPTO_WP512) += wp512.o
 CFLAGS_wp512.o := $(call cc-option,-fno-schedule-insns)  # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=79149
 obj-$(CONFIG_CRYPTO_BLAKE2B) += blake2b_generic.o
 CFLAGS_blake2b_generic.o := -Wframe-larger-than=4096 #  https://gcc.gnu.org/bugzilla/show_bug.cgi?id=105930
+canister += ecb.o
+canister += cbc.o
+canister += cfb.o
 obj-$(CONFIG_CRYPTO_PCBC) += pcbc.o
+canister += cts.o
 obj-$(CONFIG_CRYPTO_LRW) += lrw.o
+canister += xts.o
+canister += ctr.o
 obj-$(CONFIG_CRYPTO_XCTR) += xctr.o
 obj-$(CONFIG_CRYPTO_HCTR2) += hctr2.o
 obj-$(CONFIG_CRYPTO_KEYWRAP) += keywrap.o
 obj-$(CONFIG_CRYPTO_ADIANTUM) += adiantum.o
 obj-$(CONFIG_CRYPTO_NHPOLY1305) += nhpoly1305.o
+canister += gcm.o
+canister += ccm.o
 obj-$(CONFIG_CRYPTO_CHACHA20POLY1305) += chacha20poly1305.o
 obj-$(CONFIG_CRYPTO_AEGIS128) += aegis128.o
 aegis128-y := aegis128-core.o
@@ -120,6 +139,7 @@ obj-$(CONFIG_CRYPTO_TWOFISH) += twofish_generic.o
 obj-$(CONFIG_CRYPTO_TWOFISH_COMMON) += twofish_common.o
 obj-$(CONFIG_CRYPTO_SERPENT) += serpent_generic.o
 CFLAGS_serpent_generic.o := $(call cc-option,-fsched-pressure)  # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=79149
+canister += aes_generic.o
 CFLAGS_aes_generic.o := $(call cc-option,-fno-code-hoisting) # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=83356
 obj-$(CONFIG_CRYPTO_SM4) += sm4.o
 obj-$(CONFIG_CRYPTO_SM4_GENERIC) += sm4_generic.o
@@ -155,6 +175,7 @@ KASAN_SANITIZE_jitterentropy.o = n
 UBSAN_SANITIZE_jitterentropy.o = n
 obj-$(CONFIG_CRYPTO_JITTERENTROPY_TESTINTERFACE) += jitterentropy-testing.o
 obj-$(CONFIG_CRYPTO_TEST) += tcrypt.o
+canister += ghash-generic.o
 obj-$(CONFIG_CRYPTO_POLYVAL) += polyval-generic.o
 obj-$(CONFIG_CRYPTO_USER_API) += af_alg.o
 obj-$(CONFIG_CRYPTO_USER_API_HASH) += algif_hash.o
@@ -163,11 +184,14 @@ obj-$(CONFIG_CRYPTO_USER_API_RNG) += algif_rng.o
 obj-$(CONFIG_CRYPTO_USER_API_AEAD) += algif_aead.o
 obj-$(CONFIG_CRYPTO_ZSTD) += zstd.o
 obj-$(CONFIG_CRYPTO_OFB) += ofb.o
+canister += ecc.o
 obj-$(CONFIG_CRYPTO_ESSIV) += essiv.o
 obj-$(CONFIG_CRYPTO_CURVE25519) += curve25519-generic.o
+canister += drbg.o
 
 ecdh_generic-y += ecdh.o
 ecdh_generic-y += ecdh_helper.o
+canister += $(ecdh_generic-y)
 
 $(obj)/ecrdsa_params.asn1.o: $(obj)/ecrdsa_params.asn1.c $(obj)/ecrdsa_params.asn1.h
 $(obj)/ecrdsa_pub_key.asn1.o: $(obj)/ecrdsa_pub_key.asn1.c $(obj)/ecrdsa_pub_key.asn1.h
@@ -191,6 +215,69 @@ obj-$(CONFIG_CRYPTO_SIMD) += crypto_simd.o
 # Key derivation function
 #
 obj-$(CONFIG_CRYPTO_KDF800108_CTR) += kdf_sp800108.o
+
+aesni-intel-y := aesni-intel_asm.o aesni-intel_glue.o
+aesni-intel-$(CONFIG_64BIT) += aesni-intel_avx-x86_64.o aes_ctrby8_avx-x86_64.o
+OBJECT_FILES_NON_STANDARD_x86-aesni-intel_avx-x86_64.o := y
+
+crypto/x86-%.o: arch/x86/crypto/%.c $(recordmcount_source) $(objtool_dep) FORCE
+	$(call cmd,force_checksrc)
+	$(call if_changed_rule,cc_o_c)
+
+crypto/x86-%.o: arch/x86/crypto/%.S $(objtool_dep)
+	$(call if_changed_rule,as_o_S)
+
+lib-crypto-y := aes.o sha256.o sha1.o
+crypto/lib-crypto-%.o: lib/crypto/%.c $(recordmcount_source) $(objtool_dep) FORCE
+	$(call cmd,force_checksrc)
+	$(call if_changed_rule,cc_o_c)
+
+canister += crypto_self_test.o
+
+canister += fips_integrity.o
+
+extra-y += $(canister)
+$(obj)/canister.o: $(addprefix crypto/x86-,$(aesni-intel-y)) $(addprefix crypto/lib-crypto-,$(lib-crypto-y)) $(addprefix $(obj)/,$(canister))
+	$(LD) -z noexecstack -T $(obj)/canister_combine.lds -r $^ -o $@
+define UPDATE_CFLAGS =
+  CFLAGS_$1 += -DFIPS_CANISTER
+  CFLAGS_REMOVE_$1 += -DLATENT_ENTROPY_PLUGIN -fplugin=./scripts/gcc-plugins/latent_entropy_plugin.so -fplugin-arg-rap_plugin-check=call $(RETPOLINE_CFLAGS) $(RETHUNK_CFLAGS)
+endef
+$(foreach obj,$(canister),$(eval $(call UPDATE_CFLAGS,$(obj))))
+
+define UPDATE_CFLAGS_LIB_CRYPTO =
+  CFLAGS_lib-crypto-$1 += -DFIPS_CANISTER
+  CFLAGS_REMOVE_lib-crypto-$1 += -DLATENT_ENTROPY_PLUGIN -fplugin=./scripts/gcc-plugins/latent_entropy_plugin.so -fplugin-arg-rap_plugin-check=call $(RETPOLINE_CFLAGS) $(RETHUNK_CFLAGS)
+endef
+$(foreach obj,$(lib-crypto-y),$(eval $(call UPDATE_CFLAGS_LIB_CRYPTO,$(obj))))
+
+define UPDATE_CFLAGS_X86 =
+  CFLAGS_x86-$1 += -DFIPS_CANISTER
+  CFLAGS_REMOVE_x86-$1 += -DLATENT_ENTROPY_PLUGIN -fplugin=./scripts/gcc-plugins/latent_entropy_plugin.so -fplugin-arg-rap_plugin-check=call $(RETPOLINE_CFLAGS) $(RETHUNK_CFLAGS)
+endef
+$(foreach obj,$(aesni-intel-y),$(eval $(call UPDATE_CFLAGS_X86,$(obj))))
+
+hostprogs := gen_canister_relocs
+HOSTLDLIBS_gen_canister_relocs = -lelf
+HOSTCFLAGS_gen_canister_relocs = -g
+
+quiet_cmd_gencr = GENCR   $@
+cmd_gencr = $(obj)/gen_canister_relocs $< $@ $(obj)/canister_markers.lds $(obj)/fips_canister-kallsyms
+$(src)/canister_relocs.c: $(obj)/canister.o $(obj)/gen_canister_relocs FORCE
+	$(call if_changed,gencr)
+clean-files += canister_relocs.c
+clean-files += fips_canister-kallsyms
+targets += canister_relocs.o
+$(obj)/canister_markers.lds: $(src)/canister_relocs.c
+
+clean-files += canister_markers.lds
+
+quiet_cmd_update_hmac = HMAC    $@
+cmd_update_hmac = $(obj)/update_canister_hmac.sh $@ $(obj)/canister_markers.lds
+$(obj)/fips_canister.o: $(obj)/canister.o $(obj)/canister_relocs.o $(obj)/canister_markers.lds FORCE
+	$(LD) -z noexecstack -T $(obj)/canister_markers.lds -r $(obj)/canister.o $(obj)/canister_relocs.o -o $@
+	$(call if_changed,update_hmac)
+
 obj-$(CONFIG_CRYPTO_FIPS) += fips_canister_wrapper_asm.o fips_canister_wrapper.o fips_canister.o
 obj-$(CONFIG_CRYPTO_FIPS) += fips_canister_wrapper_internal.o
 
diff --git a/crypto/algboss.c b/crypto/algboss.c
index 0de1e6697..2c64da757 100644
--- a/crypto/algboss.c
+++ b/crypto/algboss.c
@@ -19,6 +19,7 @@
 #include <linux/string.h>
 
 #include "internal.h"
+#include "fips_canister_wrapper.h"
 
 struct cryptomgr_param {
 	struct rtattr *tb[CRYPTO_MAX_ATTRS + 2];
@@ -82,7 +83,7 @@ static int cryptomgr_schedule_probe(struct crypto_larval *larval)
 	if (!try_module_get(THIS_MODULE))
 		goto err;
 
-	param = kzalloc(sizeof(*param), GFP_KERNEL);
+	param = fcw_kzalloc(sizeof(*param), GFP_KERNEL);
 	if (!param)
 		goto err_put_module;
 
@@ -196,7 +197,7 @@ static int cryptomgr_schedule_test(struct crypto_alg *alg)
 	if (!try_module_get(THIS_MODULE))
 		goto err;
 
-	param = kzalloc(sizeof(*param), GFP_KERNEL);
+	param = fcw_kzalloc(sizeof(*param), GFP_KERNEL);
 	if (!param)
 		goto err_put_module;
 
diff --git a/crypto/ccm.c b/crypto/ccm.c
index a9453129c..1b77da008 100644
--- a/crypto/ccm.c
+++ b/crypto/ccm.c
@@ -15,6 +15,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/slab.h>
+#include "fips_canister_wrapper.h"
 
 struct ccm_instance_ctx {
 	struct crypto_skcipher_spawn ctr;
@@ -458,7 +459,7 @@ static int crypto_ccm_create_common(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ictx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ictx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	ictx = aead_instance_ctx(inst);
@@ -715,7 +716,7 @@ static int crypto_rfc4309_create(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
@@ -871,7 +872,7 @@ static int cbcmac_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	spawn = shash_instance_ctx(inst);
diff --git a/crypto/cmac.c b/crypto/cmac.c
index fce6b0f58..e5af76456 100644
--- a/crypto/cmac.c
+++ b/crypto/cmac.c
@@ -16,6 +16,7 @@
 #include <linux/err.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
+#include "fips_canister_wrapper.h"
 
 /*
  * +------------------------
@@ -249,7 +250,7 @@ static int cmac_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	spawn = shash_instance_ctx(inst);
diff --git a/crypto/ctr.c b/crypto/ctr.c
index 23c698b22..1906d0f8c 100644
--- a/crypto/ctr.c
+++ b/crypto/ctr.c
@@ -14,6 +14,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/slab.h>
+#include "fips_canister_wrapper.h"
 
 struct crypto_rfc3686_ctx {
 	struct crypto_skcipher *child;
@@ -267,7 +268,7 @@ static int crypto_rfc3686_create(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
diff --git a/crypto/cts.c b/crypto/cts.c
index 8f604f655..06d08cf25 100644
--- a/crypto/cts.c
+++ b/crypto/cts.c
@@ -51,6 +51,7 @@
 #include <crypto/scatterwalk.h>
 #include <linux/slab.h>
 #include <linux/compiler.h>
+#include "fips_canister_wrapper.h"
 
 struct crypto_cts_ctx {
 	struct crypto_skcipher *child;
@@ -333,7 +334,7 @@ static int crypto_cts_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
diff --git a/crypto/drbg.c b/crypto/drbg.c
index 965b1c8b2..d51275071 100644
--- a/crypto/drbg.c
+++ b/crypto/drbg.c
@@ -101,6 +101,7 @@
 #include <crypto/internal/cipher.h>
 #include <linux/kernel.h>
 #include <linux/jiffies.h>
+#include "fips_canister_wrapper.h"
 
 /***************************************************************
  * Backend cipher definitions available to DRBG
@@ -1341,13 +1342,13 @@ static inline int drbg_alloc_state(struct drbg_state *drbg)
 	if (ret < 0)
 		goto err;
 
-	drbg->Vbuf = kmalloc(drbg_statelen(drbg) + ret, GFP_KERNEL);
+	drbg->Vbuf = fcw_kmalloc(drbg_statelen(drbg) + ret, GFP_KERNEL);
 	if (!drbg->Vbuf) {
 		ret = -ENOMEM;
 		goto fini;
 	}
 	drbg->V = PTR_ALIGN(drbg->Vbuf, ret + 1);
-	drbg->Cbuf = kmalloc(drbg_statelen(drbg) + ret, GFP_KERNEL);
+	drbg->Cbuf = fcw_kmalloc(drbg_statelen(drbg) + ret, GFP_KERNEL);
 	if (!drbg->Cbuf) {
 		ret = -ENOMEM;
 		goto fini;
@@ -1366,7 +1367,7 @@ static inline int drbg_alloc_state(struct drbg_state *drbg)
 		sb_size = drbg_statelen(drbg) + drbg_blocklen(drbg);
 
 	if (0 < sb_size) {
-		drbg->scratchpadbuf = kzalloc(sb_size + ret, GFP_KERNEL);
+		drbg->scratchpadbuf = fcw_kzalloc(sb_size + ret, GFP_KERNEL);
 		if (!drbg->scratchpadbuf) {
 			ret = -ENOMEM;
 			goto fini;
@@ -1375,7 +1376,7 @@ static inline int drbg_alloc_state(struct drbg_state *drbg)
 	}
 
 	if (IS_ENABLED(CONFIG_CRYPTO_FIPS)) {
-		drbg->prev = kzalloc(drbg_sec_strength(drbg->core->flags),
+		drbg->prev = fcw_kzalloc(drbg_sec_strength(drbg->core->flags),
 				     GFP_KERNEL);
 		if (!drbg->prev) {
 			ret = -ENOMEM;
@@ -1572,9 +1573,9 @@ static int drbg_generate_long(struct drbg_state *drbg,
 		unsigned int chunk = 0;
 		slice = ((buflen - len) / drbg_max_request_bytes(drbg));
 		chunk = slice ? drbg_max_request_bytes(drbg) : (buflen - len);
-		mutex_lock(&drbg->drbg_mutex);
+		fcw_mutex_lock(drbg->drbg_mutex);
 		err = drbg_generate(drbg, buf + len, chunk, addtl);
-		mutex_unlock(&drbg->drbg_mutex);
+		fcw_mutex_unlock(drbg->drbg_mutex);
 		if (0 > err)
 			return err;
 		len += chunk;
@@ -1626,7 +1627,7 @@ static int drbg_instantiate(struct drbg_state *drbg, struct drbg_string *pers,
 
 	pr_devel("DRBG: Initializing DRBG core %d with prediction resistance "
 		 "%s\n", coreref, pr ? "enabled" : "disabled");
-	mutex_lock(&drbg->drbg_mutex);
+	fcw_mutex_lock(drbg->drbg_mutex);
 
 	/* 9.1 step 1 is implicit with the selected DRBG type */
 
@@ -1661,15 +1662,15 @@ static int drbg_instantiate(struct drbg_state *drbg, struct drbg_string *pers,
 	if (ret && !reseed)
 		goto free_everything;
 
-	mutex_unlock(&drbg->drbg_mutex);
+	fcw_mutex_unlock(drbg->drbg_mutex);
 	return ret;
 
 unlock:
-	mutex_unlock(&drbg->drbg_mutex);
+	fcw_mutex_unlock(drbg->drbg_mutex);
 	return ret;
 
 free_everything:
-	mutex_unlock(&drbg->drbg_mutex);
+	fcw_mutex_unlock(drbg->drbg_mutex);
 	drbg_uninstantiate(drbg);
 	return ret;
 }
@@ -1708,9 +1709,9 @@ static void drbg_kcapi_set_entropy(struct crypto_rng *tfm,
 {
 	struct drbg_state *drbg = crypto_rng_ctx(tfm);
 
-	mutex_lock(&drbg->drbg_mutex);
+	fcw_mutex_lock(drbg->drbg_mutex);
 	drbg_string_fill(&drbg->test_data, data, len);
-	mutex_unlock(&drbg->drbg_mutex);
+	fcw_mutex_unlock(drbg->drbg_mutex);
 }
 
 /***************************************************************
@@ -1735,7 +1736,7 @@ static int drbg_init_hash_kernel(struct drbg_state *drbg)
 		return PTR_ERR(tfm);
 	}
 	BUG_ON(drbg_blocklen(drbg) != crypto_shash_digestsize(tfm));
-	sdesc = kzalloc(sizeof(struct shash_desc) + crypto_shash_descsize(tfm),
+	sdesc = fcw_kzalloc(sizeof(struct shash_desc) + crypto_shash_descsize(tfm),
 			GFP_KERNEL);
 	if (!sdesc) {
 		crypto_free_shash(tfm);
@@ -1835,7 +1836,7 @@ static int drbg_init_sym_kernel(struct drbg_state *drbg)
 	drbg->ctr_handle = sk_tfm;
 	crypto_init_wait(&drbg->ctr_wait);
 
-	req = skcipher_request_alloc(sk_tfm, GFP_KERNEL);
+	req = fcw_skcipher_request_alloc(sk_tfm, GFP_KERNEL);
 	if (!req) {
 		pr_info("DRBG: could not allocate request queue\n");
 		drbg_fini_sym_kernel(drbg);
@@ -1847,7 +1848,7 @@ static int drbg_init_sym_kernel(struct drbg_state *drbg)
 					crypto_req_done, &drbg->ctr_wait);
 
 	alignmask = crypto_skcipher_alignmask(sk_tfm);
-	drbg->outscratchpadbuf = kmalloc(DRBG_OUTSCRATCHLEN + alignmask,
+	drbg->outscratchpadbuf = fcw_kmalloc(DRBG_OUTSCRATCHLEN + alignmask,
 					 GFP_KERNEL);
 	if (!drbg->outscratchpadbuf) {
 		drbg_fini_sym_kernel(drbg);
@@ -1973,14 +1974,19 @@ static int drbg_kcapi_init(struct crypto_tfm *tfm)
 {
 	struct drbg_state *drbg = crypto_tfm_ctx(tfm);
 
-	mutex_init(&drbg->drbg_mutex);
+	drbg->drbg_mutex = fcw_mutex_init();
+	if (!drbg->drbg_mutex)
+		return -ENOMEM;
 
 	return 0;
 }
 
 static void drbg_kcapi_cleanup(struct crypto_tfm *tfm)
 {
-	drbg_uninstantiate(crypto_tfm_ctx(tfm));
+	struct drbg_state *drbg = crypto_tfm_ctx(tfm);
+
+	drbg_uninstantiate(drbg);
+	kfree(drbg->drbg_mutex);
 }
 
 /*
@@ -2071,11 +2077,16 @@ static inline int __init drbg_healthcheck_sanity(void)
 	drbg_convert_tfm_core("drbg_nopr_hmac_sha256", &coreref, &pr);
 #endif
 
-	drbg = kzalloc(sizeof(struct drbg_state), GFP_KERNEL);
+	drbg = fcw_kzalloc(sizeof(struct drbg_state), GFP_KERNEL);
 	if (!drbg)
 		return -ENOMEM;
 
-	mutex_init(&drbg->drbg_mutex);
+	drbg->drbg_mutex = fcw_mutex_init();
+	if (!drbg->drbg_mutex) {
+		kfree(drbg);
+		return -ENOMEM;
+	}
+
 	drbg->core = &drbg_cores[coreref];
 	drbg->reseed_threshold = drbg_max_requests(drbg);
 
@@ -2106,6 +2117,7 @@ static inline int __init drbg_healthcheck_sanity(void)
 	pr_devel("DRBG: Sanity tests for failure code paths successfully "
 		 "completed\n");
 
+	kfree(drbg->drbg_mutex);
 	kfree(drbg);
 	return rc;
 }
diff --git a/crypto/ecc.c b/crypto/ecc.c
index b2e1a699c..a43831a4e 100644
--- a/crypto/ecc.c
+++ b/crypto/ecc.c
@@ -38,6 +38,7 @@
 #include <linux/fips.h>
 
 #include "ecc_curve_defs.h"
+#include "fips_canister_wrapper.h"
 
 typedef struct {
 	u64 m_low;
@@ -74,7 +75,7 @@ static u64 *ecc_alloc_digits_space(unsigned int ndigits)
 	if (!len)
 		return NULL;
 
-	return kmalloc(len, GFP_KERNEL);
+	return fcw_kmalloc(len, GFP_KERNEL);
 }
 
 static void ecc_free_digits_space(u64 *space)
@@ -84,7 +85,7 @@ static void ecc_free_digits_space(u64 *space)
 
 struct ecc_point *ecc_alloc_point(unsigned int ndigits)
 {
-	struct ecc_point *p = kmalloc(sizeof(*p), GFP_KERNEL);
+	struct ecc_point *p = fcw_kmalloc(sizeof(*p), GFP_KERNEL);
 
 	if (!p)
 		return NULL;
diff --git a/crypto/ecdh.c b/crypto/ecdh.c
index 80afee323..75ae30323 100644
--- a/crypto/ecdh.c
+++ b/crypto/ecdh.c
@@ -11,6 +11,7 @@
 #include <crypto/kpp.h>
 #include <crypto/ecdh.h>
 #include <linux/scatterlist.h>
+#include "fips_canister_wrapper.h"
 
 struct ecdh_ctx {
 	unsigned int curve_id;
@@ -61,12 +62,12 @@ static int ecdh_compute_value(struct kpp_request *req)
 	/* Public part is a point thus it has both coordinates */
 	public_key_sz = 2 * nbytes;
 
-	public_key = kmalloc(public_key_sz, GFP_KERNEL);
+	public_key = fcw_kmalloc(public_key_sz, GFP_KERNEL);
 	if (!public_key)
 		return -ENOMEM;
 
 	if (req->src) {
-		shared_secret = kmalloc(nbytes, GFP_KERNEL);
+		shared_secret = fcw_kmalloc(nbytes, GFP_KERNEL);
 		if (!shared_secret)
 			goto free_pubkey;
 
diff --git a/crypto/ecdsa.c b/crypto/ecdsa.c
index fbd76498a..13eb687bf 100644
--- a/crypto/ecdsa.c
+++ b/crypto/ecdsa.c
@@ -12,6 +12,7 @@
 #include <linux/scatterlist.h>
 
 #include "ecdsasignature.asn1.h"
+#include "fips_canister_wrapper.h"
 
 struct ecc_ctx {
 	unsigned int curve_id;
@@ -151,7 +152,7 @@ static int ecdsa_verify(struct akcipher_request *req)
 	if (unlikely(!ctx->pub_key_set))
 		return -EINVAL;
 
-	buffer = kmalloc(req->src_len + req->dst_len, GFP_KERNEL);
+	buffer = fcw_kmalloc(req->src_len + req->dst_len, GFP_KERNEL);
 	if (!buffer)
 		return -ENOMEM;
 
diff --git a/crypto/gcm.c b/crypto/gcm.c
index 4ba624450..ac5577aa8 100644
--- a/crypto/gcm.c
+++ b/crypto/gcm.c
@@ -18,6 +18,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/slab.h>
+#include "fips_canister_wrapper.h"
 
 struct gcm_instance_ctx {
 	struct crypto_skcipher_spawn ctr;
@@ -113,7 +114,7 @@ static int crypto_gcm_setkey(struct crypto_aead *aead, const u8 *key,
 	if (err)
 		return err;
 
-	data = kzalloc(sizeof(*data) + crypto_skcipher_reqsize(ctr),
+	data = fcw_kzalloc(sizeof(*data) + crypto_skcipher_reqsize(ctr),
 		       GFP_KERNEL);
 	if (!data)
 		return -ENOMEM;
@@ -587,7 +588,7 @@ static int crypto_gcm_create_common(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	ctx = aead_instance_ctx(inst);
@@ -835,7 +836,7 @@ static int crypto_rfc4106_create(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
@@ -1050,7 +1051,7 @@ static int crypto_rfc4543_create(struct crypto_template *tmpl,
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
@@ -1133,7 +1134,7 @@ static int __init crypto_gcm_module_init(void)
 {
 	int err;
 
-	gcm_zeroes = kzalloc(sizeof(*gcm_zeroes), GFP_KERNEL);
+	gcm_zeroes = fcw_kzalloc(sizeof(*gcm_zeroes), GFP_KERNEL);
 	if (!gcm_zeroes)
 		return -ENOMEM;
 
diff --git a/crypto/ghash-generic.c b/crypto/ghash-generic.c
index c70d163c1..81ae2cc2c 100644
--- a/crypto/ghash-generic.c
+++ b/crypto/ghash-generic.c
@@ -42,6 +42,7 @@
 #include <linux/init.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
+#include "fips_canister_wrapper.h"
 
 static int ghash_init(struct shash_desc *desc)
 {
@@ -65,7 +66,7 @@ static int ghash_setkey(struct crypto_shash *tfm,
 		gf128mul_free_4k(ctx->gf128);
 
 	BUILD_BUG_ON(sizeof(k) != GHASH_BLOCK_SIZE);
-	memcpy(&k, key, GHASH_BLOCK_SIZE); /* avoid violating alignment rules */
+	fcw_memcpy(&k, key, GHASH_BLOCK_SIZE); /* avoid violating alignment rules */
 	ctx->gf128 = gf128mul_init_4k_lle(&k);
 	memzero_explicit(&k, GHASH_BLOCK_SIZE);
 
@@ -135,7 +136,7 @@ static int ghash_final(struct shash_desc *desc, u8 *dst)
 	u8 *buf = dctx->buffer;
 
 	ghash_flush(ctx, dctx);
-	memcpy(dst, buf, GHASH_BLOCK_SIZE);
+	fcw_memcpy(dst, buf, GHASH_BLOCK_SIZE);
 
 	return 0;
 }
diff --git a/crypto/hmac.c b/crypto/hmac.c
index ea93f4c55..90c849f0c 100644
--- a/crypto/hmac.c
+++ b/crypto/hmac.c
@@ -21,6 +21,7 @@
 #include <linux/module.h>
 #include <linux/scatterlist.h>
 #include <linux/string.h>
+#include "fips_canister_wrapper.h"
 
 struct hmac_ctx {
 	struct crypto_shash *hash;
@@ -196,7 +197,7 @@ static int hmac_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 	spawn = shash_instance_ctx(inst);
diff --git a/crypto/rsa-pkcs1pad.c b/crypto/rsa-pkcs1pad.c
index d2e5e104f..c01427af6 100644
--- a/crypto/rsa-pkcs1pad.c
+++ b/crypto/rsa-pkcs1pad.c
@@ -15,6 +15,7 @@
 #include <linux/module.h>
 #include <linux/random.h>
 #include <linux/scatterlist.h>
+#include "fips_canister_wrapper.h"
 
 /*
  * Hash algorithm OIDs plus ASN.1 DER wrappings [RFC4880 sec 5.2.2].
@@ -190,7 +191,7 @@ static int pkcs1pad_encrypt_sign_complete(struct akcipher_request *req, int err)
 	if (likely(!pad_len))
 		goto out;
 
-	out_buf = kzalloc(ctx->key_size, GFP_ATOMIC);
+	out_buf = fcw_kzalloc(ctx->key_size, GFP_ATOMIC);
 	err = -ENOMEM;
 	if (!out_buf)
 		goto out;
@@ -242,7 +243,7 @@ static int pkcs1pad_encrypt(struct akcipher_request *req)
 		return -EOVERFLOW;
 	}
 
-	req_ctx->in_buf = kmalloc(ctx->key_size - 1 - req->src_len,
+	req_ctx->in_buf = fcw_kmalloc(ctx->key_size - 1 - req->src_len,
 				  GFP_KERNEL);
 	if (!req_ctx->in_buf)
 		return -ENOMEM;
@@ -348,7 +349,7 @@ static int pkcs1pad_decrypt(struct akcipher_request *req)
 	if (!ctx->key_size || req->src_len != ctx->key_size)
 		return -EINVAL;
 
-	req_ctx->out_buf = kmalloc(ctx->key_size, GFP_KERNEL);
+	req_ctx->out_buf = fcw_kmalloc(ctx->key_size, GFP_KERNEL);
 	if (!req_ctx->out_buf)
 		return -ENOMEM;
 
@@ -396,7 +397,7 @@ static int pkcs1pad_sign(struct akcipher_request *req)
 		return -EOVERFLOW;
 	}
 
-	req_ctx->in_buf = kmalloc(ctx->key_size - 1 - req->src_len,
+	req_ctx->in_buf = fcw_kmalloc(ctx->key_size - 1 - req->src_len,
 				  GFP_KERNEL);
 	if (!req_ctx->in_buf)
 		return -ENOMEM;
@@ -538,7 +539,7 @@ static int pkcs1pad_verify(struct akcipher_request *req)
 	    !ctx->key_size || sig_size != ctx->key_size)
 		return -EINVAL;
 
-	req_ctx->out_buf = kmalloc(ctx->key_size + digest_size, GFP_KERNEL);
+	req_ctx->out_buf = fcw_kmalloc(ctx->key_size + digest_size, GFP_KERNEL);
 	if (!req_ctx->out_buf)
 		return -ENOMEM;
 
@@ -608,7 +609,7 @@ static int pkcs1pad_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (err)
 		return err;
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
diff --git a/crypto/sha3_generic.c b/crypto/sha3_generic.c
index 3e4069935..a18bf7046 100644
--- a/crypto/sha3_generic.c
+++ b/crypto/sha3_generic.c
@@ -14,6 +14,7 @@
 #include <linux/types.h>
 #include <crypto/sha3.h>
 #include <asm/unaligned.h>
+#include "fips_canister_wrapper.h"
 
 /*
  * On some 32-bit architectures (h8300), GCC ends up using
@@ -185,7 +186,7 @@ int crypto_sha3_update(struct shash_desc *desc, const u8 *data,
 	if ((sctx->partial + len) > (sctx->rsiz - 1)) {
 		if (sctx->partial) {
 			done = -sctx->partial;
-			memcpy(sctx->buf + sctx->partial, data,
+			fcw_memcpy(sctx->buf + sctx->partial, data,
 			       done + sctx->rsiz);
 			src = sctx->buf;
 		}
@@ -203,7 +204,7 @@ int crypto_sha3_update(struct shash_desc *desc, const u8 *data,
 
 		sctx->partial = 0;
 	}
-	memcpy(sctx->buf + sctx->partial, src, len - done);
+	fcw_memcpy(sctx->buf + sctx->partial, src, len - done);
 	sctx->partial += (len - done);
 
 	return 0;
diff --git a/crypto/testmgr.c b/crypto/testmgr.c
index f038b7657..6c36f88db 100644
--- a/crypto/testmgr.c
+++ b/crypto/testmgr.c
@@ -37,6 +37,7 @@
 #include <crypto/internal/simd.h>
 
 #include "internal.h"
+#include "fips_canister_wrapper.h"
 
 MODULE_IMPORT_NS(CRYPTO_INTERNAL);
 
@@ -735,7 +736,7 @@ static struct cipher_test_sglists *alloc_cipher_test_sglists(void)
 {
 	struct cipher_test_sglists *tsgls;
 
-	tsgls = kmalloc(sizeof(*tsgls), GFP_KERNEL);
+	tsgls = fcw_kmalloc(sizeof(*tsgls), GFP_KERNEL);
 	if (!tsgls)
 		return NULL;
 
@@ -832,7 +833,7 @@ static int prepare_keybuf(const u8 *key, unsigned int ksize,
 	if (key_offset != 0) {
 		if (cfg->key_offset_relative_to_alignmask)
 			key_offset += alignmask;
-		keybuf = kmalloc(key_offset + ksize, GFP_KERNEL);
+		keybuf = fcw_kmalloc(key_offset + ksize, GFP_KERNEL);
 		if (!keybuf)
 			return -ENOMEM;
 		keyptr = keybuf + key_offset;
@@ -1676,7 +1677,7 @@ static int test_hash_vec(const struct hash_testvec *vec, unsigned int vec_num,
 						req, desc, tsgl, hashstate);
 			if (err)
 				return err;
-			cond_resched();
+			fcw_cond_resched();
 		}
 	}
 #endif
@@ -1782,13 +1783,13 @@ static int test_hash_vs_generic_impl(const char *generic_driver,
 		return err;
 	}
 
-	cfg = kzalloc(sizeof(*cfg), GFP_KERNEL);
+	cfg = fcw_kzalloc(sizeof(*cfg), GFP_KERNEL);
 	if (!cfg) {
 		err = -ENOMEM;
 		goto out;
 	}
 
-	generic_desc = kzalloc(sizeof(*desc) +
+	generic_desc = fcw_kzalloc(sizeof(*desc) +
 			       crypto_shash_descsize(generic_tfm), GFP_KERNEL);
 	if (!generic_desc) {
 		err = -ENOMEM;
@@ -1818,9 +1819,9 @@ static int test_hash_vs_generic_impl(const char *generic_driver,
 	 * the other implementation against them.
 	 */
 
-	vec.key = kmalloc(maxkeysize, GFP_KERNEL);
-	vec.plaintext = kmalloc(maxdatasize, GFP_KERNEL);
-	vec.digest = kmalloc(digestsize, GFP_KERNEL);
+	vec.key = fcw_kmalloc(maxkeysize, GFP_KERNEL);
+	vec.plaintext = fcw_kmalloc(maxdatasize, GFP_KERNEL);
+	vec.digest = fcw_kmalloc(digestsize, GFP_KERNEL);
 	if (!vec.key || !vec.plaintext || !vec.digest) {
 		err = -ENOMEM;
 		goto out;
@@ -1837,7 +1838,7 @@ static int test_hash_vs_generic_impl(const char *generic_driver,
 					req, desc, tsgl, hashstate);
 		if (err)
 			goto out;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	err = 0;
 out:
@@ -1882,7 +1883,7 @@ static int alloc_shash(const char *driver, u32 type, u32 mask,
 		return PTR_ERR(tfm);
 	}
 
-	desc = kmalloc(sizeof(*desc) + crypto_shash_descsize(tfm), GFP_KERNEL);
+	desc = fcw_kmalloc(sizeof(*desc) + crypto_shash_descsize(tfm), GFP_KERNEL);
 	if (!desc) {
 		crypto_free_shash(tfm);
 		return -ENOMEM;
@@ -1922,7 +1923,7 @@ static int __alg_test_hash(const struct hash_testvec *vecs,
 	}
 	driver = crypto_ahash_driver_name(atfm);
 
-	req = ahash_request_alloc(atfm, GFP_KERNEL);
+	req = fcw_ahash_request_alloc(atfm, GFP_KERNEL);
 	if (!req) {
 		pr_err("alg: hash: failed to allocate request for %s\n",
 		       driver);
@@ -1938,7 +1939,7 @@ static int __alg_test_hash(const struct hash_testvec *vecs,
 	if (err)
 		goto out;
 
-	tsgl = kmalloc(sizeof(*tsgl), GFP_KERNEL);
+	tsgl = fcw_kmalloc(sizeof(*tsgl), GFP_KERNEL);
 	if (!tsgl || init_test_sglist(tsgl) != 0) {
 		pr_err("alg: hash: failed to allocate test buffers for %s\n",
 		       driver);
@@ -1951,7 +1952,7 @@ static int __alg_test_hash(const struct hash_testvec *vecs,
 	statesize = crypto_ahash_statesize(atfm);
 	if (stfm)
 		statesize = max(statesize, crypto_shash_statesize(stfm));
-	hashstate = kmalloc(statesize + TESTMGR_POISON_LEN, GFP_KERNEL);
+	hashstate = fcw_kmalloc(statesize + TESTMGR_POISON_LEN, GFP_KERNEL);
 	if (!hashstate) {
 		pr_err("alg: hash: failed to allocate hash state buffer for %s\n",
 		       driver);
@@ -1966,7 +1967,7 @@ static int __alg_test_hash(const struct hash_testvec *vecs,
 		err = test_hash_vec(&vecs[i], i, req, desc, tsgl, hashstate);
 		if (err)
 			goto out;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	err = test_hash_vs_generic_impl(generic_driver, maxkeysize, req,
 					desc, tsgl, hashstate);
@@ -2246,7 +2247,7 @@ static int test_aead_vec(int enc, const struct aead_testvec *vec,
 						&cfg, req, tsgls);
 			if (err)
 				return err;
-			cond_resched();
+			fcw_cond_resched();
 		}
 	}
 #endif
@@ -2476,7 +2477,7 @@ static int test_aead_inauthentic_inputs(struct aead_extra_tests_ctx *ctx)
 			if (err)
 				return err;
 		}
-		cond_resched();
+		fcw_cond_resched();
 	}
 	return 0;
 }
@@ -2520,7 +2521,7 @@ static int test_aead_vs_generic_impl(struct aead_extra_tests_ctx *ctx)
 		return err;
 	}
 
-	generic_req = aead_request_alloc(generic_tfm, GFP_KERNEL);
+	generic_req = fcw_aead_request_alloc(generic_tfm, GFP_KERNEL);
 	if (!generic_req) {
 		err = -ENOMEM;
 		goto out;
@@ -2580,7 +2581,7 @@ static int test_aead_vs_generic_impl(struct aead_extra_tests_ctx *ctx)
 			if (err)
 				goto out;
 		}
-		cond_resched();
+		fcw_cond_resched();
 	}
 	err = 0;
 out:
@@ -2600,7 +2601,7 @@ static int test_aead_extra(const struct alg_test_desc *test_desc,
 	if (noextratests)
 		return 0;
 
-	ctx = kzalloc(sizeof(*ctx), GFP_KERNEL);
+	ctx = fcw_kzalloc(sizeof(*ctx), GFP_KERNEL);
 	if (!ctx)
 		return -ENOMEM;
 	init_rnd_state(&ctx->rng);
@@ -2614,11 +2615,11 @@ static int test_aead_extra(const struct alg_test_desc *test_desc,
 		ctx->maxkeysize = max_t(unsigned int, ctx->maxkeysize,
 					test_desc->suite.aead.vecs[i].klen);
 
-	ctx->vec.key = kmalloc(ctx->maxkeysize, GFP_KERNEL);
-	ctx->vec.iv = kmalloc(crypto_aead_ivsize(ctx->tfm), GFP_KERNEL);
-	ctx->vec.assoc = kmalloc(ctx->maxdatasize, GFP_KERNEL);
-	ctx->vec.ptext = kmalloc(ctx->maxdatasize, GFP_KERNEL);
-	ctx->vec.ctext = kmalloc(ctx->maxdatasize, GFP_KERNEL);
+	ctx->vec.key = fcw_kmalloc(ctx->maxkeysize, GFP_KERNEL);
+	ctx->vec.iv = fcw_kmalloc(crypto_aead_ivsize(ctx->tfm), GFP_KERNEL);
+	ctx->vec.assoc = fcw_kmalloc(ctx->maxdatasize, GFP_KERNEL);
+	ctx->vec.ptext = fcw_kmalloc(ctx->maxdatasize, GFP_KERNEL);
+	ctx->vec.ctext = fcw_kmalloc(ctx->maxdatasize, GFP_KERNEL);
 	if (!ctx->vec.key || !ctx->vec.iv || !ctx->vec.assoc ||
 	    !ctx->vec.ptext || !ctx->vec.ctext) {
 		err = -ENOMEM;
@@ -2659,7 +2660,7 @@ static int test_aead(int enc, const struct aead_test_suite *suite,
 		err = test_aead_vec(enc, &suite->vecs[i], i, req, tsgls);
 		if (err)
 			return err;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	return 0;
 }
@@ -2686,7 +2687,7 @@ static int alg_test_aead(const struct alg_test_desc *desc, const char *driver,
 	}
 	driver = crypto_aead_driver_name(tfm);
 
-	req = aead_request_alloc(tfm, GFP_KERNEL);
+	req = fcw_aead_request_alloc(tfm, GFP_KERNEL);
 	if (!req) {
 		pr_err("alg: aead: failed to allocate request for %s\n",
 		       driver);
@@ -3006,7 +3007,7 @@ static int test_skcipher_vec(int enc, const struct cipher_testvec *vec,
 						    &cfg, req, tsgls);
 			if (err)
 				return err;
-			cond_resched();
+			fcw_cond_resched();
 		}
 	}
 #endif
@@ -3128,13 +3129,13 @@ static int test_skcipher_vs_generic_impl(const char *generic_driver,
 		return err;
 	}
 
-	cfg = kzalloc(sizeof(*cfg), GFP_KERNEL);
+	cfg = fcw_kzalloc(sizeof(*cfg), GFP_KERNEL);
 	if (!cfg) {
 		err = -ENOMEM;
 		goto out;
 	}
 
-	generic_req = skcipher_request_alloc(generic_tfm, GFP_KERNEL);
+	generic_req = fcw_skcipher_request_alloc(generic_tfm, GFP_KERNEL);
 	if (!generic_req) {
 		err = -ENOMEM;
 		goto out;
@@ -3179,10 +3180,10 @@ static int test_skcipher_vs_generic_impl(const char *generic_driver,
 	 * the other implementation against them.
 	 */
 
-	vec.key = kmalloc(maxkeysize, GFP_KERNEL);
-	vec.iv = kmalloc(ivsize, GFP_KERNEL);
-	vec.ptext = kmalloc(maxdatasize, GFP_KERNEL);
-	vec.ctext = kmalloc(maxdatasize, GFP_KERNEL);
+	vec.key = fcw_kmalloc(maxkeysize, GFP_KERNEL);
+	vec.iv = fcw_kmalloc(ivsize, GFP_KERNEL);
+	vec.ptext = fcw_kmalloc(maxdatasize, GFP_KERNEL);
+	vec.ctext = fcw_kmalloc(maxdatasize, GFP_KERNEL);
 	if (!vec.key || !vec.iv || !vec.ptext || !vec.ctext) {
 		err = -ENOMEM;
 		goto out;
@@ -3203,7 +3204,7 @@ static int test_skcipher_vs_generic_impl(const char *generic_driver,
 					    cfg, req, tsgls);
 		if (err)
 			goto out;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	err = 0;
 out:
@@ -3236,7 +3237,7 @@ static int test_skcipher(int enc, const struct cipher_test_suite *suite,
 		err = test_skcipher_vec(enc, &suite->vecs[i], i, req, tsgls);
 		if (err)
 			return err;
-		cond_resched();
+		fcw_cond_resched();
 	}
 	return 0;
 }
@@ -3263,7 +3264,7 @@ static int alg_test_skcipher(const struct alg_test_desc *desc,
 	}
 	driver = crypto_skcipher_driver_name(tfm);
 
-	req = skcipher_request_alloc(tfm, GFP_KERNEL);
+	req = fcw_skcipher_request_alloc(tfm, GFP_KERNEL);
 	if (!req) {
 		pr_err("alg: skcipher: failed to allocate request for %s\n",
 		       driver);
@@ -3305,11 +3306,11 @@ static int test_comp(struct crypto_comp *tfm,
 	unsigned int i;
 	int ret;
 
-	output = kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
+	output = fcw_kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
 	if (!output)
 		return -ENOMEM;
 
-	decomp_output = kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
+	decomp_output = fcw_kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
 	if (!decomp_output) {
 		kfree(output);
 		return -ENOMEM;
@@ -3414,11 +3415,11 @@ static int test_acomp(struct crypto_acomp *tfm,
 	struct acomp_req *req;
 	struct crypto_wait wait;
 
-	output = kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
+	output = fcw_kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
 	if (!output)
 		return -ENOMEM;
 
-	decomp_out = kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
+	decomp_out = fcw_kmalloc(COMP_BUF_SIZE, GFP_KERNEL);
 	if (!decomp_out) {
 		kfree(output);
 		return -ENOMEM;
@@ -3610,7 +3611,7 @@ static int test_cprng(struct crypto_rng *tfm,
 
 	seedsize = crypto_rng_seedsize(tfm);
 
-	seed = kmalloc(seedsize, GFP_KERNEL);
+	seed = fcw_kmalloc(seedsize, GFP_KERNEL);
 	if (!seed) {
 		printk(KERN_ERR "alg: cprng: Failed to allocate seed space "
 		       "for %s\n", algo);
@@ -3802,7 +3803,7 @@ static int drbg_cavs_test(const struct drbg_testvec *test, int pr,
 	struct crypto_rng *drng;
 	struct drbg_test_data test_data;
 	struct drbg_string addtl, pers, testentropy;
-	unsigned char *buf = kzalloc(test->expectedlen, GFP_KERNEL);
+	unsigned char *buf = fcw_kzalloc(test->expectedlen, GFP_KERNEL);
 
 	if (!buf)
 		return -ENOMEM;
@@ -3902,7 +3903,7 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 	int err = -ENOMEM;
 	struct scatterlist src, dst;
 
-	req = kpp_request_alloc(tfm, GFP_KERNEL);
+	req = fcw_kpp_request_alloc(tfm, GFP_KERNEL);
 	if (!req)
 		return err;
 
@@ -3913,7 +3914,7 @@ static int do_test_kpp(struct crypto_kpp *tfm, const struct kpp_testvec *vec,
 		goto free_req;
 
 	out_len_max = crypto_kpp_maxsize(tfm);
-	output_buf = kzalloc(out_len_max, GFP_KERNEL);
+	output_buf = fcw_kzalloc(out_len_max, GFP_KERNEL);
 	if (!output_buf) {
 		err = -ENOMEM;
 		goto free_req;
@@ -4093,13 +4094,13 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 	if (testmgr_alloc_buf(xbuf))
 		return err;
 
-	req = akcipher_request_alloc(tfm, GFP_KERNEL);
+	req = fcw_akcipher_request_alloc(tfm, GFP_KERNEL);
 	if (!req)
 		goto free_xbuf;
 
 	crypto_init_wait(&wait);
 
-	key = kmalloc(vecs->key_len + sizeof(u32) * 2 + vecs->param_len,
+	key = fcw_kmalloc(vecs->key_len + sizeof(u32) * 2 + vecs->param_len,
 		      GFP_KERNEL);
 	if (!key)
 		goto free_req;
@@ -4122,7 +4123,7 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 	 */
 	err = -ENOMEM;
 	out_len_max = crypto_akcipher_maxsize(tfm);
-	outbuf_enc = kzalloc(out_len_max, GFP_KERNEL);
+	outbuf_enc = fcw_kzalloc(out_len_max, GFP_KERNEL);
 	if (!outbuf_enc)
 		goto free_key;
 
@@ -4199,7 +4200,7 @@ static int test_akcipher_one(struct crypto_akcipher *tfm,
 		err = 0;
 		goto free_all;
 	}
-	outbuf_dec = kzalloc(out_len_max, GFP_KERNEL);
+	outbuf_dec = fcw_kzalloc(out_len_max, GFP_KERNEL);
 	if (!outbuf_dec) {
 		err = -ENOMEM;
 		goto free_all;
@@ -5930,13 +5931,22 @@ int alg_test(const char *driver, const char *alg, u32 type, u32 mask)
 	int i;
 	int j;
 	int rc;
+	static bool done = false;
 
 	if (!fips_enabled && notests) {
 		printk_once(KERN_INFO "alg: self-tests disabled\n");
 		return 0;
 	}
 
-	DO_ONCE(testmgr_onetime_init);
+	/* Replace DO_ONCE by this. As DO_ONCE generates jump labels entry
+	 * and its data (__once_key) get changed at early boot time at
+	 * jump_label_init() from setup_arch(). We cannot run
+	 * fips_integrity_init() before that time. So, replace it to
+	 * avoid jump table entry creation. */
+	if (unlikely(!done)) {
+		testmgr_onetime_init();
+		done = true;
+	}
 
 	if ((type & CRYPTO_ALG_TYPE_MASK) == CRYPTO_ALG_TYPE_CIPHER) {
 		char nalg[CRYPTO_MAX_ALG_NAME];
diff --git a/crypto/xts.c b/crypto/xts.c
index 038f60dd5..1fbfc7db6 100644
--- a/crypto/xts.c
+++ b/crypto/xts.c
@@ -20,6 +20,7 @@
 #include <crypto/xts.h>
 #include <crypto/b128ops.h>
 #include <crypto/gf128mul.h>
+#include "fips_canister_wrapper.h"
 
 struct xts_tfm_ctx {
 	struct crypto_skcipher *child;
@@ -355,7 +356,7 @@ static int xts_create(struct crypto_template *tmpl, struct rtattr **tb)
 	if (IS_ERR(cipher_name))
 		return PTR_ERR(cipher_name);
 
-	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
+	inst = fcw_kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);
 	if (!inst)
 		return -ENOMEM;
 
diff --git a/include/crypto/drbg.h b/include/crypto/drbg.h
index af5ad51d3..f3e132d6f 100644
--- a/include/crypto/drbg.h
+++ b/include/crypto/drbg.h
@@ -50,7 +50,6 @@
 #include <crypto/internal/rng.h>
 #include <crypto/rng.h>
 #include <linux/fips.h>
-#include <linux/mutex.h>
 #include <linux/list.h>
 #include <linux/workqueue.h>
 
@@ -112,7 +111,7 @@ enum drbg_seed_state {
 };
 
 struct drbg_state {
-	struct mutex drbg_mutex;	/* lock around DRBG */
+	void *drbg_mutex;	/* lock around DRBG */
 	unsigned char *V;	/* internal state 10.1.1.1 1a) */
 	unsigned char *Vbuf;
 	/* hash: static value 10.1.1.1 1b) hmac / ctr: key */
-- 
2.39.4

