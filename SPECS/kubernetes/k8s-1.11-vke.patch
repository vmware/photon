From 88576818b980641d851d3b61d7c115c51a823f45 Mon Sep 17 00:00:00 2001
From: ejohn <ejohn@vmware.com>
Date: Wed, 2 Jan 2019 18:07:56 +0530
Subject: [PATCH] VCP patch for K8s 1.11.6

---
 api/swagger-spec/apps_v1alpha1.json           |   21 +
 api/swagger-spec/apps_v1beta1.json            |  375 +-
 api/swagger-spec/apps_v1beta2.json            |  529 +-
 api/swagger-spec/batch_v1.json                |  146 +-
 api/swagger-spec/batch_v1beta1.json           |  146 +-
 api/swagger-spec/batch_v2alpha1.json          |  146 +-
 api/swagger-spec/extensions_v1beta1.json      |  617 +-
 .../settings.k8s.io_v1alpha1.json             |  101 +-
 api/swagger-spec/v1.json                      | 1421 +---
 cmd/kube-controller-manager/app/BUILD         |   70 +-
 cmd/kube-controller-manager/app/plugins.go    |   41 +-
 cmd/kubelet/app/BUILD                         |  143 +-
 cmd/kubelet/app/plugins.go                    |   34 +-
 pkg/apis/core/types.go                        |  151 +-
 pkg/apis/core/validation/validation.go        |  393 +-
 pkg/apis/policy/types.go                      |   40 +-
 pkg/cloudprovider/providers/BUILD             |    2 +
 pkg/cloudprovider/providers/cascade/BUILD     |   56 +
 pkg/cloudprovider/providers/cascade/OWNERS    |    3 +
 .../providers/cascade/apitypes.go             |  230 +
 pkg/cloudprovider/providers/cascade/auth.go   |  145 +
 .../providers/cascade/cascade.go              |  219 +
 .../providers/cascade/cascade_disks.go        |  253 +
 .../providers/cascade/cascade_instances.go    |  133 +
 .../cascade/cascade_instances_test.go         |   44 +
 .../providers/cascade/cascade_loadbalancer.go |  295 +
 pkg/cloudprovider/providers/cascade/client.go |  400 +
 .../providers/cascade/oidcclient.go           |  297 +
 .../providers/cascade/restclient.go           |  262 +
 .../providers/cascade/tests_owed              |    5 +
 pkg/cloudprovider/providers/cascade/utils.go  |   29 +
 pkg/cloudprovider/providers/providers.go      |    1 +
 pkg/kubeapiserver/authorizer/config.go        |   20 +-
 pkg/kubeapiserver/authorizer/modes/modes.go   |   20 +-
 pkg/kubeapiserver/options/plugins.go          |    3 +
 pkg/printers/internalversion/describe.go      | 4034 +++++++++
 pkg/security/podsecuritypolicy/util/util.go   |    5 +-
 pkg/volume/cascade_disk/BUILD                 |   43 +
 pkg/volume/cascade_disk/OWNERS                |    2 +
 pkg/volume/cascade_disk/attacher.go           |  264 +
 pkg/volume/cascade_disk/azure_disk_util.go    |  135 +
 pkg/volume/cascade_disk/cascade_disk.go       |  399 +
 pkg/volume/cascade_disk/cascade_util.go       |  217 +
 .../persistentvolume/label/admission.go       |  128 +-
 plugin/pkg/admission/vke/BUILD                |   61 +
 plugin/pkg/admission/vke/admission.go         |  629 ++
 plugin/pkg/admission/vke/admission_test.go    |  960 +++
 plugin/pkg/auth/authorizer/vke/BUILD          |   40 +
 plugin/pkg/auth/authorizer/vke/OWNERS         |    2 +
 .../pkg/auth/authorizer/vke/vke_authorizer.go |  125 +
 .../authorizer/vke/vke_authorizer_test.go     |  230 +
 .../src/k8s.io/api/core/v1/generated.pb.go    | 7422 ++++++++---------
 staging/src/k8s.io/api/core/v1/types.go       |  166 +-
 53 files changed, 14179 insertions(+), 7474 deletions(-)
 create mode 100644 pkg/cloudprovider/providers/cascade/BUILD
 create mode 100644 pkg/cloudprovider/providers/cascade/OWNERS
 create mode 100644 pkg/cloudprovider/providers/cascade/apitypes.go
 create mode 100644 pkg/cloudprovider/providers/cascade/auth.go
 create mode 100644 pkg/cloudprovider/providers/cascade/cascade.go
 create mode 100644 pkg/cloudprovider/providers/cascade/cascade_disks.go
 create mode 100644 pkg/cloudprovider/providers/cascade/cascade_instances.go
 create mode 100644 pkg/cloudprovider/providers/cascade/cascade_instances_test.go
 create mode 100644 pkg/cloudprovider/providers/cascade/cascade_loadbalancer.go
 create mode 100644 pkg/cloudprovider/providers/cascade/client.go
 create mode 100644 pkg/cloudprovider/providers/cascade/oidcclient.go
 create mode 100644 pkg/cloudprovider/providers/cascade/restclient.go
 create mode 100644 pkg/cloudprovider/providers/cascade/tests_owed
 create mode 100644 pkg/cloudprovider/providers/cascade/utils.go
 create mode 100644 pkg/printers/internalversion/describe.go
 create mode 100644 pkg/volume/cascade_disk/BUILD
 create mode 100644 pkg/volume/cascade_disk/OWNERS
 create mode 100644 pkg/volume/cascade_disk/attacher.go
 create mode 100644 pkg/volume/cascade_disk/azure_disk_util.go
 create mode 100644 pkg/volume/cascade_disk/cascade_disk.go
 create mode 100644 pkg/volume/cascade_disk/cascade_util.go
 create mode 100644 plugin/pkg/admission/vke/BUILD
 create mode 100644 plugin/pkg/admission/vke/admission.go
 create mode 100644 plugin/pkg/admission/vke/admission_test.go
 create mode 100644 plugin/pkg/auth/authorizer/vke/BUILD
 create mode 100644 plugin/pkg/auth/authorizer/vke/OWNERS
 create mode 100644 plugin/pkg/auth/authorizer/vke/vke_authorizer.go
 create mode 100644 plugin/pkg/auth/authorizer/vke/vke_authorizer_test.go

diff --git a/api/swagger-spec/apps_v1alpha1.json b/api/swagger-spec/apps_v1alpha1.json
index 6f546623de..0ce6f3f2fc 100644
--- a/api/swagger-spec/apps_v1alpha1.json
+++ b/api/swagger-spec/apps_v1alpha1.json
@@ -1459,6 +1459,10 @@
      "photonPersistentDisk": {
       "$ref": "v1.PhotonPersistentDiskVolumeSource",
       "description": "PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine"
+     },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
      }
     }
    },
@@ -2109,6 +2113,23 @@
      }
     }
    },
+   "v1.CascadeDiskVolumeSource": {
+    "id": "v1.CascadeDiskVolumeSource",
+    "description": "Represents a Cascade persistent disk resource.",
+    "required": [
+     "diskID"
+    ],
+    "properties": {
+     "diskID": {
+      "type": "string",
+      "description": "ID that identifies Cascade persistent disk"
+     },
+     "fsType": {
+      "type": "string",
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
+     }
+    }
+   },
    "v1.Container": {
     "id": "v1.Container",
     "description": "A single application container that you want to run within a pod.",
diff --git a/api/swagger-spec/apps_v1beta1.json b/api/swagger-spec/apps_v1beta1.json
index d829551f17..dfe940052f 100644
--- a/api/swagger-spec/apps_v1beta1.json
+++ b/api/swagger-spec/apps_v1beta1.json
@@ -86,7 +86,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -139,22 +139,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -264,7 +248,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -302,7 +286,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ControllerRevision. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ControllerRevision",
       "nickname": "watchNamespacedControllerRevisionList",
       "parameters": [
        {
@@ -373,7 +357,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -495,14 +479,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -563,14 +539,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -625,7 +593,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -652,14 +620,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -682,11 +642,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -707,7 +662,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind ControllerRevision. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind ControllerRevision",
       "nickname": "watchNamespacedControllerRevision",
       "parameters": [
        {
@@ -778,7 +733,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -897,7 +852,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -929,7 +884,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ControllerRevision. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ControllerRevision",
       "nickname": "watchControllerRevisionListForAllNamespaces",
       "parameters": [
        {
@@ -1000,7 +955,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1103,7 +1058,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1156,22 +1111,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1281,7 +1220,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1319,7 +1258,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Deployment. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Deployment",
       "nickname": "watchNamespacedDeploymentList",
       "parameters": [
        {
@@ -1390,7 +1329,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1512,14 +1451,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1580,14 +1511,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1642,7 +1565,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -1669,14 +1592,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1699,11 +1614,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -1724,7 +1634,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Deployment. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Deployment",
       "nickname": "watchNamespacedDeployment",
       "parameters": [
        {
@@ -1795,7 +1705,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1914,7 +1824,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1946,7 +1856,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Deployment. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Deployment",
       "nickname": "watchDeploymentListForAllNamespaces",
       "parameters": [
        {
@@ -2017,7 +1927,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -2047,7 +1957,7 @@
     "description": "API at /apis/apps/v1beta1",
     "operations": [
      {
-      "type": "v1.Status",
+      "type": "v1beta1.DeploymentRollback",
       "method": "POST",
       "summary": "create rollback of a Deployment",
       "nickname": "createNamespacedDeploymentRollback",
@@ -2068,22 +1978,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2105,17 +1999,17 @@
        {
         "code": 200,
         "message": "OK",
-        "responseModel": "v1.Status"
+        "responseModel": "v1beta1.DeploymentRollback"
        },
        {
         "code": 201,
         "message": "Created",
-        "responseModel": "v1.Status"
+        "responseModel": "v1beta1.DeploymentRollback"
        },
        {
         "code": 202,
         "message": "Accepted",
-        "responseModel": "v1.Status"
+        "responseModel": "v1beta1.DeploymentRollback"
        }
       ],
       "produces": [
@@ -2202,14 +2096,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2270,14 +2156,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2388,14 +2266,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2456,14 +2326,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2579,7 +2441,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2632,22 +2494,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2757,7 +2603,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2795,7 +2641,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of StatefulSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of StatefulSet",
       "nickname": "watchNamespacedStatefulSetList",
       "parameters": [
        {
@@ -2866,7 +2712,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2988,14 +2834,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3056,14 +2894,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3118,7 +2948,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -3145,14 +2975,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3175,11 +2997,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -3200,7 +3017,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind StatefulSet. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind StatefulSet",
       "nickname": "watchNamespacedStatefulSet",
       "parameters": [
        {
@@ -3271,7 +3088,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3390,7 +3207,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -3422,7 +3239,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of StatefulSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of StatefulSet",
       "nickname": "watchStatefulSetListForAllNamespaces",
       "parameters": [
        {
@@ -3493,7 +3310,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -3591,14 +3408,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3659,14 +3468,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3777,14 +3578,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3845,14 +3638,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3957,7 +3742,7 @@
      },
      "continue": {
       "type": "string",
-      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message."
+      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response."
      }
     }
    },
@@ -4071,7 +3856,7 @@
    },
    "v1.OwnerReference": {
     "id": "v1.OwnerReference",
-    "description": "OwnerReference contains enough information to let you identify an owning object. An owning object must be in the same namespace as the dependent, or be cluster-scoped, so there is no namespace field.",
+    "description": "OwnerReference contains enough information to let you identify an owning object. Currently, an owning object must be in the same namespace, so there is no namespace field.",
     "required": [
      "apiVersion",
      "kind",
@@ -4277,13 +4062,6 @@
      "propagationPolicy": {
       "$ref": "v1.DeletionPropagation",
       "description": "Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground."
-     },
-     "dryRun": {
-      "type": "array",
-      "items": {
-       "type": "string"
-      },
-      "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed"
      }
     }
    },
@@ -4544,7 +4322,7 @@
      },
      "shareProcessNamespace": {
       "type": "boolean",
-      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is beta-level and may be disabled with the PodShareProcessNamespace feature."
+      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is alpha-level and is honored only by servers that enable the PodShareProcessNamespace feature."
      },
      "securityContext": {
       "$ref": "v1.PodSecurityContext",
@@ -4606,14 +4384,6 @@
        "$ref": "v1.PodReadinessGate"
       },
       "description": "If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to \"True\" More info: https://github.com/kubernetes/community/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md"
-     },
-     "runtimeClassName": {
-      "type": "string",
-      "description": "RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the \"legacy\" RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://github.com/kubernetes/community/blob/master/keps/sig-node/0014-runtime-class.md This is an alpha feature and may change in the future."
-     },
-     "enableServiceLinks": {
-      "type": "boolean",
-      "description": "EnableServiceLinks indicates whether information about services should be injected into pod's environment variables, matching the syntax of Docker links."
      }
     }
    },
@@ -4720,6 +4490,10 @@
       "$ref": "v1.PhotonPersistentDiskVolumeSource",
       "description": "PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine"
      },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
+     },
      "projected": {
       "$ref": "v1.ProjectedVolumeSource",
       "description": "Items for all in one resources secrets, configmaps, and downward API"
@@ -5451,6 +5225,23 @@
      }
     }
    },
+   "v1.CascadeDiskVolumeSource": {
+    "id": "v1.CascadeDiskVolumeSource",
+    "description": "Represents a Cascade persistent disk resource.",
+    "required": [
+     "diskID"
+    ],
+    "properties": {
+     "diskID": {
+      "type": "string",
+      "description": "ID that identifies Cascade persistent disk"
+     },
+     "fsType": {
+      "type": "string",
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
+     }
+    }
+   },
    "v1.ProjectedVolumeSource": {
     "id": "v1.ProjectedVolumeSource",
     "description": "Represents a projected volume source",
@@ -5627,7 +5418,7 @@
      },
      "storageMode": {
       "type": "string",
-      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned."
+      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned."
      },
      "volumeName": {
       "type": "string",
@@ -5635,7 +5426,7 @@
      },
      "fsType": {
       "type": "string",
-      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\"."
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
      },
      "readOnly": {
       "type": "boolean",
@@ -5725,7 +5516,7 @@
      },
      "resources": {
       "$ref": "v1.ResourceRequirements",
-      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/"
+      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"
      },
      "volumeMounts": {
       "type": "array",
@@ -5739,7 +5530,7 @@
       "items": {
        "$ref": "v1.VolumeDevice"
       },
-      "description": "volumeDevices is the list of block devices to be used by the container. This is a beta feature."
+      "description": "volumeDevices is the list of block devices to be used by the container. This is an alpha feature and may change in the future."
      },
      "livenessProbe": {
       "$ref": "v1.Probe",
@@ -5806,7 +5597,7 @@
      },
      "protocol": {
       "type": "string",
-      "description": "Protocol for port. Must be UDP, TCP, or SCTP. Defaults to \"TCP\"."
+      "description": "Protocol for port. Must be UDP or TCP. Defaults to \"TCP\"."
      },
      "hostIP": {
       "type": "string",
@@ -6203,10 +5994,6 @@
      "allowPrivilegeEscalation": {
       "type": "boolean",
       "description": "AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN"
-     },
-     "procMount": {
-      "$ref": "v1.ProcMountType",
-      "description": "procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled."
      }
     }
    },
@@ -6256,10 +6043,6 @@
      }
     }
    },
-   "v1.ProcMountType": {
-    "id": "v1.ProcMountType",
-    "properties": {}
-   },
    "v1.PodSecurityContext": {
     "id": "v1.PodSecurityContext",
     "description": "PodSecurityContext holds pod-level security attributes and common container settings. Some fields are also present in container.securityContext.  Field values of container.securityContext take precedence over field values of PodSecurityContext.",
@@ -6953,9 +6736,6 @@
    "v1.PersistentVolumeClaimSpec": {
     "id": "v1.PersistentVolumeClaimSpec",
     "description": "PersistentVolumeClaimSpec describes the common attributes of storage devices and allows a Source for provider-specific attributes",
-    "required": [
-     "dataSource"
-    ],
     "properties": {
      "accessModes": {
       "type": "array",
@@ -6982,11 +6762,7 @@
      },
      "volumeMode": {
       "$ref": "v1.PersistentVolumeMode",
-      "description": "volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec. This is a beta feature."
-     },
-     "dataSource": {
-      "$ref": "v1.TypedLocalObjectReference",
-      "description": "This field requires the VolumeSnapshotDataSource alpha feature gate to be enabled and currently VolumeSnapshot is the only supported data source. If the provisioner can support VolumeSnapshot data source, it will create a new volume and data will be restored to the volume at the same time. If the provisioner does not support VolumeSnapshot data source, volume will not be created and the failure will be reported as an event. In the future, we plan to support more data source types and the behavior of the provisioner may change."
+      "description": "volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec. This is an alpha feature and may change in the future."
      }
     }
    },
@@ -6998,29 +6774,6 @@
     "id": "v1.PersistentVolumeMode",
     "properties": {}
    },
-   "v1.TypedLocalObjectReference": {
-    "id": "v1.TypedLocalObjectReference",
-    "description": "TypedLocalObjectReference contains enough information to let you locate the typed referenced object inside the same namespace.",
-    "required": [
-     "apiGroup",
-     "kind",
-     "name"
-    ],
-    "properties": {
-     "apiGroup": {
-      "type": "string",
-      "description": "APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required."
-     },
-     "kind": {
-      "type": "string",
-      "description": "Kind is the type of resource being referenced"
-     },
-     "name": {
-      "type": "string",
-      "description": "Name is the name of resource being referenced"
-     }
-    }
-   },
    "v1.PersistentVolumeClaimStatus": {
     "id": "v1.PersistentVolumeClaimStatus",
     "description": "PersistentVolumeClaimStatus is the current status of a persistent volume claim.",
diff --git a/api/swagger-spec/apps_v1beta2.json b/api/swagger-spec/apps_v1beta2.json
index c20e4236d6..1c607176a2 100644
--- a/api/swagger-spec/apps_v1beta2.json
+++ b/api/swagger-spec/apps_v1beta2.json
@@ -86,7 +86,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -139,22 +139,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -264,7 +248,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -302,7 +286,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ControllerRevision. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ControllerRevision",
       "nickname": "watchNamespacedControllerRevisionList",
       "parameters": [
        {
@@ -373,7 +357,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -495,14 +479,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -563,14 +539,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -625,7 +593,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -652,14 +620,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -682,11 +642,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -707,7 +662,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind ControllerRevision. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind ControllerRevision",
       "nickname": "watchNamespacedControllerRevision",
       "parameters": [
        {
@@ -778,7 +733,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -897,7 +852,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -929,7 +884,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ControllerRevision. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ControllerRevision",
       "nickname": "watchControllerRevisionListForAllNamespaces",
       "parameters": [
        {
@@ -1000,7 +955,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1103,7 +1058,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1156,22 +1111,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1281,7 +1220,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1319,7 +1258,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of DaemonSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of DaemonSet",
       "nickname": "watchNamespacedDaemonSetList",
       "parameters": [
        {
@@ -1390,7 +1329,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1512,14 +1451,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1580,14 +1511,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1642,7 +1565,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -1669,14 +1592,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1699,11 +1614,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -1724,7 +1634,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind DaemonSet. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind DaemonSet",
       "nickname": "watchNamespacedDaemonSet",
       "parameters": [
        {
@@ -1795,7 +1705,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1914,7 +1824,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1946,7 +1856,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of DaemonSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of DaemonSet",
       "nickname": "watchDaemonSetListForAllNamespaces",
       "parameters": [
        {
@@ -2017,7 +1927,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -2115,14 +2025,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2183,14 +2085,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2306,7 +2200,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2359,22 +2253,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2484,7 +2362,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2522,7 +2400,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Deployment. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Deployment",
       "nickname": "watchNamespacedDeploymentList",
       "parameters": [
        {
@@ -2593,7 +2471,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2715,14 +2593,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2783,14 +2653,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2845,7 +2707,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -2872,14 +2734,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2902,11 +2756,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -2927,7 +2776,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Deployment. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Deployment",
       "nickname": "watchNamespacedDeployment",
       "parameters": [
        {
@@ -2998,7 +2847,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3117,7 +2966,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -3149,7 +2998,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Deployment. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Deployment",
       "nickname": "watchDeploymentListForAllNamespaces",
       "parameters": [
        {
@@ -3220,7 +3069,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -3318,14 +3167,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3386,14 +3227,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3504,14 +3337,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3572,14 +3397,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3695,7 +3512,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3748,22 +3565,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3873,7 +3674,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3911,7 +3712,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ReplicaSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ReplicaSet",
       "nickname": "watchNamespacedReplicaSetList",
       "parameters": [
        {
@@ -3982,7 +3783,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -4104,14 +3905,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4172,14 +3965,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4234,7 +4019,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -4261,14 +4046,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4291,11 +4068,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -4316,7 +4088,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind ReplicaSet. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind ReplicaSet",
       "nickname": "watchNamespacedReplicaSet",
       "parameters": [
        {
@@ -4387,7 +4159,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -4506,7 +4278,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -4538,7 +4310,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ReplicaSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ReplicaSet",
       "nickname": "watchReplicaSetListForAllNamespaces",
       "parameters": [
        {
@@ -4609,7 +4381,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -4707,14 +4479,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4775,14 +4539,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4893,14 +4649,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4961,14 +4709,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5084,7 +4824,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -5137,22 +4877,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5262,7 +4986,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -5300,7 +5024,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of StatefulSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of StatefulSet",
       "nickname": "watchNamespacedStatefulSetList",
       "parameters": [
        {
@@ -5371,7 +5095,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -5493,14 +5217,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5561,14 +5277,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5623,7 +5331,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -5650,14 +5358,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5680,11 +5380,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -5705,7 +5400,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind StatefulSet. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind StatefulSet",
       "nickname": "watchNamespacedStatefulSet",
       "parameters": [
        {
@@ -5776,7 +5471,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -5895,7 +5590,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -5927,7 +5622,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of StatefulSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of StatefulSet",
       "nickname": "watchStatefulSetListForAllNamespaces",
       "parameters": [
        {
@@ -5998,7 +5693,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -6096,14 +5791,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6164,14 +5851,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6282,14 +5961,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6350,14 +6021,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6462,7 +6125,7 @@
      },
      "continue": {
       "type": "string",
-      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message."
+      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response."
      }
     }
    },
@@ -6576,7 +6239,7 @@
    },
    "v1.OwnerReference": {
     "id": "v1.OwnerReference",
-    "description": "OwnerReference contains enough information to let you identify an owning object. An owning object must be in the same namespace as the dependent, or be cluster-scoped, so there is no namespace field.",
+    "description": "OwnerReference contains enough information to let you identify an owning object. Currently, an owning object must be in the same namespace, so there is no namespace field.",
     "required": [
      "apiVersion",
      "kind",
@@ -6782,13 +6445,6 @@
      "propagationPolicy": {
       "$ref": "v1.DeletionPropagation",
       "description": "Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground."
-     },
-     "dryRun": {
-      "type": "array",
-      "items": {
-       "type": "string"
-      },
-      "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed"
      }
     }
    },
@@ -7032,7 +6688,7 @@
      },
      "shareProcessNamespace": {
       "type": "boolean",
-      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is beta-level and may be disabled with the PodShareProcessNamespace feature."
+      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is alpha-level and is honored only by servers that enable the PodShareProcessNamespace feature."
      },
      "securityContext": {
       "$ref": "v1.PodSecurityContext",
@@ -7094,14 +6750,6 @@
        "$ref": "v1.PodReadinessGate"
       },
       "description": "If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to \"True\" More info: https://github.com/kubernetes/community/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md"
-     },
-     "runtimeClassName": {
-      "type": "string",
-      "description": "RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the \"legacy\" RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://github.com/kubernetes/community/blob/master/keps/sig-node/0014-runtime-class.md This is an alpha feature and may change in the future."
-     },
-     "enableServiceLinks": {
-      "type": "boolean",
-      "description": "EnableServiceLinks indicates whether information about services should be injected into pod's environment variables, matching the syntax of Docker links."
      }
     }
    },
@@ -7208,6 +6856,10 @@
       "$ref": "v1.PhotonPersistentDiskVolumeSource",
       "description": "PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine"
      },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
+     },
      "projected": {
       "$ref": "v1.ProjectedVolumeSource",
       "description": "Items for all in one resources secrets, configmaps, and downward API"
@@ -7939,6 +7591,23 @@
      }
     }
    },
+   "v1.CascadeDiskVolumeSource": {
+    "id": "v1.CascadeDiskVolumeSource",
+    "description": "Represents a Cascade persistent disk resource.",
+    "required": [
+     "diskID"
+    ],
+    "properties": {
+     "diskID": {
+      "type": "string",
+      "description": "ID that identifies Cascade persistent disk"
+     },
+     "fsType": {
+      "type": "string",
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
+     }
+    }
+   },
    "v1.ProjectedVolumeSource": {
     "id": "v1.ProjectedVolumeSource",
     "description": "Represents a projected volume source",
@@ -8115,7 +7784,7 @@
      },
      "storageMode": {
       "type": "string",
-      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned."
+      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned."
      },
      "volumeName": {
       "type": "string",
@@ -8123,7 +7792,7 @@
      },
      "fsType": {
       "type": "string",
-      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\"."
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
      },
      "readOnly": {
       "type": "boolean",
@@ -8213,7 +7882,7 @@
      },
      "resources": {
       "$ref": "v1.ResourceRequirements",
-      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/"
+      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"
      },
      "volumeMounts": {
       "type": "array",
@@ -8227,7 +7896,7 @@
       "items": {
        "$ref": "v1.VolumeDevice"
       },
-      "description": "volumeDevices is the list of block devices to be used by the container. This is a beta feature."
+      "description": "volumeDevices is the list of block devices to be used by the container. This is an alpha feature and may change in the future."
      },
      "livenessProbe": {
       "$ref": "v1.Probe",
@@ -8294,7 +7963,7 @@
      },
      "protocol": {
       "type": "string",
-      "description": "Protocol for port. Must be UDP, TCP, or SCTP. Defaults to \"TCP\"."
+      "description": "Protocol for port. Must be UDP or TCP. Defaults to \"TCP\"."
      },
      "hostIP": {
       "type": "string",
@@ -8691,10 +8360,6 @@
      "allowPrivilegeEscalation": {
       "type": "boolean",
       "description": "AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN"
-     },
-     "procMount": {
-      "$ref": "v1.ProcMountType",
-      "description": "procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled."
      }
     }
    },
@@ -8744,10 +8409,6 @@
      }
     }
    },
-   "v1.ProcMountType": {
-    "id": "v1.ProcMountType",
-    "properties": {}
-   },
    "v1.PodSecurityContext": {
     "id": "v1.PodSecurityContext",
     "description": "PodSecurityContext holds pod-level security attributes and common container settings. Some fields are also present in container.securityContext.  Field values of container.securityContext take precedence over field values of PodSecurityContext.",
@@ -9771,9 +9432,6 @@
    "v1.PersistentVolumeClaimSpec": {
     "id": "v1.PersistentVolumeClaimSpec",
     "description": "PersistentVolumeClaimSpec describes the common attributes of storage devices and allows a Source for provider-specific attributes",
-    "required": [
-     "dataSource"
-    ],
     "properties": {
      "accessModes": {
       "type": "array",
@@ -9800,11 +9458,7 @@
      },
      "volumeMode": {
       "$ref": "v1.PersistentVolumeMode",
-      "description": "volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec. This is a beta feature."
-     },
-     "dataSource": {
-      "$ref": "v1.TypedLocalObjectReference",
-      "description": "This field requires the VolumeSnapshotDataSource alpha feature gate to be enabled and currently VolumeSnapshot is the only supported data source. If the provisioner can support VolumeSnapshot data source, it will create a new volume and data will be restored to the volume at the same time. If the provisioner does not support VolumeSnapshot data source, volume will not be created and the failure will be reported as an event. In the future, we plan to support more data source types and the behavior of the provisioner may change."
+      "description": "volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec. This is an alpha feature and may change in the future."
      }
     }
    },
@@ -9816,29 +9470,6 @@
     "id": "v1.PersistentVolumeMode",
     "properties": {}
    },
-   "v1.TypedLocalObjectReference": {
-    "id": "v1.TypedLocalObjectReference",
-    "description": "TypedLocalObjectReference contains enough information to let you locate the typed referenced object inside the same namespace.",
-    "required": [
-     "apiGroup",
-     "kind",
-     "name"
-    ],
-    "properties": {
-     "apiGroup": {
-      "type": "string",
-      "description": "APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required."
-     },
-     "kind": {
-      "type": "string",
-      "description": "Kind is the type of resource being referenced"
-     },
-     "name": {
-      "type": "string",
-      "description": "Name is the name of resource being referenced"
-     }
-    }
-   },
    "v1.PersistentVolumeClaimStatus": {
     "id": "v1.PersistentVolumeClaimStatus",
     "description": "PersistentVolumeClaimStatus is the current status of a persistent volume claim.",
diff --git a/api/swagger-spec/batch_v1.json b/api/swagger-spec/batch_v1.json
index b28f65f494..2ed4018106 100644
--- a/api/swagger-spec/batch_v1.json
+++ b/api/swagger-spec/batch_v1.json
@@ -86,7 +86,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -139,22 +139,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -264,7 +248,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -302,7 +286,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Job. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Job",
       "nickname": "watchNamespacedJobList",
       "parameters": [
        {
@@ -373,7 +357,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -495,14 +479,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -563,14 +539,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -625,7 +593,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -652,14 +620,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -682,11 +642,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -707,7 +662,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Job. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Job",
       "nickname": "watchNamespacedJob",
       "parameters": [
        {
@@ -778,7 +733,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -897,7 +852,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -929,7 +884,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Job. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Job",
       "nickname": "watchJobListForAllNamespaces",
       "parameters": [
        {
@@ -1000,7 +955,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1098,14 +1053,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1166,14 +1113,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1278,7 +1217,7 @@
      },
      "continue": {
       "type": "string",
-      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message."
+      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response."
      }
     }
    },
@@ -1388,7 +1327,7 @@
    },
    "v1.OwnerReference": {
     "id": "v1.OwnerReference",
-    "description": "OwnerReference contains enough information to let you identify an owning object. An owning object must be in the same namespace as the dependent, or be cluster-scoped, so there is no namespace field.",
+    "description": "OwnerReference contains enough information to let you identify an owning object. Currently, an owning object must be in the same namespace, so there is no namespace field.",
     "required": [
      "apiVersion",
      "kind",
@@ -1584,11 +1523,6 @@
      "template": {
       "$ref": "v1.PodTemplateSpec",
       "description": "Describes the pod that will be created when executing a job. More info: https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/"
-     },
-     "ttlSecondsAfterFinished": {
-      "type": "integer",
-      "format": "int32",
-      "description": "ttlSecondsAfterFinished limits the lifetime of a Job that has finished execution (either Complete or Failed). If this field is set, ttlSecondsAfterFinished after the Job finishes, it is eligible to be automatically deleted. When the Job is being deleted, its lifecycle guarantees (e.g. finalizers) will be honored. If this field is unset, the Job won't be automatically deleted. If this field is set to zero, the Job becomes eligible to be deleted immediately after it finishes. This field is alpha-level and is only honored by servers that enable the TTLAfterFinished feature."
      }
     }
    },
@@ -1728,7 +1662,7 @@
      },
      "shareProcessNamespace": {
       "type": "boolean",
-      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is beta-level and may be disabled with the PodShareProcessNamespace feature."
+      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is alpha-level and is honored only by servers that enable the PodShareProcessNamespace feature."
      },
      "securityContext": {
       "$ref": "v1.PodSecurityContext",
@@ -1790,14 +1724,6 @@
        "$ref": "v1.PodReadinessGate"
       },
       "description": "If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to \"True\" More info: https://github.com/kubernetes/community/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md"
-     },
-     "runtimeClassName": {
-      "type": "string",
-      "description": "RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the \"legacy\" RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://github.com/kubernetes/community/blob/master/keps/sig-node/0014-runtime-class.md This is an alpha feature and may change in the future."
-     },
-     "enableServiceLinks": {
-      "type": "boolean",
-      "description": "EnableServiceLinks indicates whether information about services should be injected into pod's environment variables, matching the syntax of Docker links."
      }
     }
    },
@@ -1904,6 +1830,10 @@
       "$ref": "v1.PhotonPersistentDiskVolumeSource",
       "description": "PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine"
      },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
+     },
      "projected": {
       "$ref": "v1.ProjectedVolumeSource",
       "description": "Items for all in one resources secrets, configmaps, and downward API"
@@ -2635,6 +2565,23 @@
      }
     }
    },
+   "v1.CascadeDiskVolumeSource": {
+    "id": "v1.CascadeDiskVolumeSource",
+    "description": "Represents a Cascade persistent disk resource.",
+    "required": [
+     "diskID"
+    ],
+    "properties": {
+     "diskID": {
+      "type": "string",
+      "description": "ID that identifies Cascade persistent disk"
+     },
+     "fsType": {
+      "type": "string",
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
+     }
+    }
+   },
    "v1.ProjectedVolumeSource": {
     "id": "v1.ProjectedVolumeSource",
     "description": "Represents a projected volume source",
@@ -2811,7 +2758,7 @@
      },
      "storageMode": {
       "type": "string",
-      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned."
+      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned."
      },
      "volumeName": {
       "type": "string",
@@ -2819,7 +2766,7 @@
      },
      "fsType": {
       "type": "string",
-      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\"."
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
      },
      "readOnly": {
       "type": "boolean",
@@ -2909,7 +2856,7 @@
      },
      "resources": {
       "$ref": "v1.ResourceRequirements",
-      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/"
+      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"
      },
      "volumeMounts": {
       "type": "array",
@@ -2923,7 +2870,7 @@
       "items": {
        "$ref": "v1.VolumeDevice"
       },
-      "description": "volumeDevices is the list of block devices to be used by the container. This is a beta feature."
+      "description": "volumeDevices is the list of block devices to be used by the container. This is an alpha feature and may change in the future."
      },
      "livenessProbe": {
       "$ref": "v1.Probe",
@@ -2990,7 +2937,7 @@
      },
      "protocol": {
       "type": "string",
-      "description": "Protocol for port. Must be UDP, TCP, or SCTP. Defaults to \"TCP\"."
+      "description": "Protocol for port. Must be UDP or TCP. Defaults to \"TCP\"."
      },
      "hostIP": {
       "type": "string",
@@ -3387,10 +3334,6 @@
      "allowPrivilegeEscalation": {
       "type": "boolean",
       "description": "AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN"
-     },
-     "procMount": {
-      "$ref": "v1.ProcMountType",
-      "description": "procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled."
      }
     }
    },
@@ -3440,10 +3383,6 @@
      }
     }
    },
-   "v1.ProcMountType": {
-    "id": "v1.ProcMountType",
-    "properties": {}
-   },
    "v1.PodSecurityContext": {
     "id": "v1.PodSecurityContext",
     "description": "PodSecurityContext holds pod-level security attributes and common container settings. Some fields are also present in container.securityContext.  Field values of container.securityContext take precedence over field values of PodSecurityContext.",
@@ -3918,13 +3857,6 @@
      "propagationPolicy": {
       "$ref": "v1.DeletionPropagation",
       "description": "Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground."
-     },
-     "dryRun": {
-      "type": "array",
-      "items": {
-       "type": "string"
-      },
-      "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed"
      }
     }
    },
diff --git a/api/swagger-spec/batch_v1beta1.json b/api/swagger-spec/batch_v1beta1.json
index e40a742cda..74fcd28e7d 100644
--- a/api/swagger-spec/batch_v1beta1.json
+++ b/api/swagger-spec/batch_v1beta1.json
@@ -86,7 +86,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -139,22 +139,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -264,7 +248,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -302,7 +286,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of CronJob. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of CronJob",
       "nickname": "watchNamespacedCronJobList",
       "parameters": [
        {
@@ -373,7 +357,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -495,14 +479,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -563,14 +539,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -625,7 +593,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -652,14 +620,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -682,11 +642,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -707,7 +662,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind CronJob. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind CronJob",
       "nickname": "watchNamespacedCronJob",
       "parameters": [
        {
@@ -778,7 +733,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -897,7 +852,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -929,7 +884,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of CronJob. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of CronJob",
       "nickname": "watchCronJobListForAllNamespaces",
       "parameters": [
        {
@@ -1000,7 +955,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1098,14 +1053,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1166,14 +1113,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1278,7 +1217,7 @@
      },
      "continue": {
       "type": "string",
-      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message."
+      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response."
      }
     }
    },
@@ -1388,7 +1327,7 @@
    },
    "v1.OwnerReference": {
     "id": "v1.OwnerReference",
-    "description": "OwnerReference contains enough information to let you identify an owning object. An owning object must be in the same namespace as the dependent, or be cluster-scoped, so there is no namespace field.",
+    "description": "OwnerReference contains enough information to let you identify an owning object. Currently, an owning object must be in the same namespace, so there is no namespace field.",
     "required": [
      "apiVersion",
      "kind",
@@ -1639,11 +1578,6 @@
      "template": {
       "$ref": "v1.PodTemplateSpec",
       "description": "Describes the pod that will be created when executing a job. More info: https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/"
-     },
-     "ttlSecondsAfterFinished": {
-      "type": "integer",
-      "format": "int32",
-      "description": "ttlSecondsAfterFinished limits the lifetime of a Job that has finished execution (either Complete or Failed). If this field is set, ttlSecondsAfterFinished after the Job finishes, it is eligible to be automatically deleted. When the Job is being deleted, its lifecycle guarantees (e.g. finalizers) will be honored. If this field is unset, the Job won't be automatically deleted. If this field is set to zero, the Job becomes eligible to be deleted immediately after it finishes. This field is alpha-level and is only honored by servers that enable the TTLAfterFinished feature."
      }
     }
    },
@@ -1783,7 +1717,7 @@
      },
      "shareProcessNamespace": {
       "type": "boolean",
-      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is beta-level and may be disabled with the PodShareProcessNamespace feature."
+      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is alpha-level and is honored only by servers that enable the PodShareProcessNamespace feature."
      },
      "securityContext": {
       "$ref": "v1.PodSecurityContext",
@@ -1845,14 +1779,6 @@
        "$ref": "v1.PodReadinessGate"
       },
       "description": "If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to \"True\" More info: https://github.com/kubernetes/community/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md"
-     },
-     "runtimeClassName": {
-      "type": "string",
-      "description": "RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the \"legacy\" RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://github.com/kubernetes/community/blob/master/keps/sig-node/0014-runtime-class.md This is an alpha feature and may change in the future."
-     },
-     "enableServiceLinks": {
-      "type": "boolean",
-      "description": "EnableServiceLinks indicates whether information about services should be injected into pod's environment variables, matching the syntax of Docker links."
      }
     }
    },
@@ -1959,6 +1885,10 @@
       "$ref": "v1.PhotonPersistentDiskVolumeSource",
       "description": "PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine"
      },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
+     },
      "projected": {
       "$ref": "v1.ProjectedVolumeSource",
       "description": "Items for all in one resources secrets, configmaps, and downward API"
@@ -2690,6 +2620,23 @@
      }
     }
    },
+   "v1.CascadeDiskVolumeSource": {
+    "id": "v1.CascadeDiskVolumeSource",
+    "description": "Represents a Cascade persistent disk resource.",
+    "required": [
+     "diskID"
+    ],
+    "properties": {
+     "diskID": {
+      "type": "string",
+      "description": "ID that identifies Cascade persistent disk"
+     },
+     "fsType": {
+      "type": "string",
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
+     }
+    }
+   },
    "v1.ProjectedVolumeSource": {
     "id": "v1.ProjectedVolumeSource",
     "description": "Represents a projected volume source",
@@ -2866,7 +2813,7 @@
      },
      "storageMode": {
       "type": "string",
-      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned."
+      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned."
      },
      "volumeName": {
       "type": "string",
@@ -2874,7 +2821,7 @@
      },
      "fsType": {
       "type": "string",
-      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\"."
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
      },
      "readOnly": {
       "type": "boolean",
@@ -2964,7 +2911,7 @@
      },
      "resources": {
       "$ref": "v1.ResourceRequirements",
-      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/"
+      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"
      },
      "volumeMounts": {
       "type": "array",
@@ -2978,7 +2925,7 @@
       "items": {
        "$ref": "v1.VolumeDevice"
       },
-      "description": "volumeDevices is the list of block devices to be used by the container. This is a beta feature."
+      "description": "volumeDevices is the list of block devices to be used by the container. This is an alpha feature and may change in the future."
      },
      "livenessProbe": {
       "$ref": "v1.Probe",
@@ -3045,7 +2992,7 @@
      },
      "protocol": {
       "type": "string",
-      "description": "Protocol for port. Must be UDP, TCP, or SCTP. Defaults to \"TCP\"."
+      "description": "Protocol for port. Must be UDP or TCP. Defaults to \"TCP\"."
      },
      "hostIP": {
       "type": "string",
@@ -3442,10 +3389,6 @@
      "allowPrivilegeEscalation": {
       "type": "boolean",
       "description": "AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN"
-     },
-     "procMount": {
-      "$ref": "v1.ProcMountType",
-      "description": "procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled."
      }
     }
    },
@@ -3495,10 +3438,6 @@
      }
     }
    },
-   "v1.ProcMountType": {
-    "id": "v1.ProcMountType",
-    "properties": {}
-   },
    "v1.PodSecurityContext": {
     "id": "v1.PodSecurityContext",
     "description": "PodSecurityContext holds pod-level security attributes and common container settings. Some fields are also present in container.securityContext.  Field values of container.securityContext take precedence over field values of PodSecurityContext.",
@@ -3954,13 +3893,6 @@
      "propagationPolicy": {
       "$ref": "v1.DeletionPropagation",
       "description": "Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground."
-     },
-     "dryRun": {
-      "type": "array",
-      "items": {
-       "type": "string"
-      },
-      "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed"
      }
     }
    },
diff --git a/api/swagger-spec/batch_v2alpha1.json b/api/swagger-spec/batch_v2alpha1.json
index 3e3f32a5c5..3484e13353 100644
--- a/api/swagger-spec/batch_v2alpha1.json
+++ b/api/swagger-spec/batch_v2alpha1.json
@@ -86,7 +86,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -139,22 +139,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -264,7 +248,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -302,7 +286,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of CronJob. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of CronJob",
       "nickname": "watchNamespacedCronJobList",
       "parameters": [
        {
@@ -373,7 +357,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -495,14 +479,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -563,14 +539,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -625,7 +593,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -652,14 +620,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -682,11 +642,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -707,7 +662,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind CronJob. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind CronJob",
       "nickname": "watchNamespacedCronJob",
       "parameters": [
        {
@@ -778,7 +733,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -897,7 +852,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -929,7 +884,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of CronJob. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of CronJob",
       "nickname": "watchCronJobListForAllNamespaces",
       "parameters": [
        {
@@ -1000,7 +955,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1098,14 +1053,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1166,14 +1113,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1278,7 +1217,7 @@
      },
      "continue": {
       "type": "string",
-      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message."
+      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response."
      }
     }
    },
@@ -1388,7 +1327,7 @@
    },
    "v1.OwnerReference": {
     "id": "v1.OwnerReference",
-    "description": "OwnerReference contains enough information to let you identify an owning object. An owning object must be in the same namespace as the dependent, or be cluster-scoped, so there is no namespace field.",
+    "description": "OwnerReference contains enough information to let you identify an owning object. Currently, an owning object must be in the same namespace, so there is no namespace field.",
     "required": [
      "apiVersion",
      "kind",
@@ -1639,11 +1578,6 @@
      "template": {
       "$ref": "v1.PodTemplateSpec",
       "description": "Describes the pod that will be created when executing a job. More info: https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/"
-     },
-     "ttlSecondsAfterFinished": {
-      "type": "integer",
-      "format": "int32",
-      "description": "ttlSecondsAfterFinished limits the lifetime of a Job that has finished execution (either Complete or Failed). If this field is set, ttlSecondsAfterFinished after the Job finishes, it is eligible to be automatically deleted. When the Job is being deleted, its lifecycle guarantees (e.g. finalizers) will be honored. If this field is unset, the Job won't be automatically deleted. If this field is set to zero, the Job becomes eligible to be deleted immediately after it finishes. This field is alpha-level and is only honored by servers that enable the TTLAfterFinished feature."
      }
     }
    },
@@ -1783,7 +1717,7 @@
      },
      "shareProcessNamespace": {
       "type": "boolean",
-      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is beta-level and may be disabled with the PodShareProcessNamespace feature."
+      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is alpha-level and is honored only by servers that enable the PodShareProcessNamespace feature."
      },
      "securityContext": {
       "$ref": "v1.PodSecurityContext",
@@ -1845,14 +1779,6 @@
        "$ref": "v1.PodReadinessGate"
       },
       "description": "If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to \"True\" More info: https://github.com/kubernetes/community/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md"
-     },
-     "runtimeClassName": {
-      "type": "string",
-      "description": "RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the \"legacy\" RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://github.com/kubernetes/community/blob/master/keps/sig-node/0014-runtime-class.md This is an alpha feature and may change in the future."
-     },
-     "enableServiceLinks": {
-      "type": "boolean",
-      "description": "EnableServiceLinks indicates whether information about services should be injected into pod's environment variables, matching the syntax of Docker links."
      }
     }
    },
@@ -1974,6 +1900,10 @@
      "storageos": {
       "$ref": "v1.StorageOSVolumeSource",
       "description": "StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes."
+     },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
      }
     }
    },
@@ -2866,7 +2796,7 @@
      },
      "storageMode": {
       "type": "string",
-      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned."
+      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned."
      },
      "volumeName": {
       "type": "string",
@@ -2874,7 +2804,7 @@
      },
      "fsType": {
       "type": "string",
-      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\"."
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
      },
      "readOnly": {
       "type": "boolean",
@@ -2908,6 +2838,23 @@
      }
     }
    },
+   "v1.CascadeDiskVolumeSource": {
+    "id": "v1.CascadeDiskVolumeSource",
+    "description": "Represents a Cascade persistent disk resource.",
+    "required": [
+     "diskID"
+    ],
+    "properties": {
+     "diskID": {
+      "type": "string",
+      "description": "ID that identifies Cascade persistent disk"
+     },
+     "fsType": {
+      "type": "string",
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
+     }
+    }
+   },
    "v1.Container": {
     "id": "v1.Container",
     "description": "A single application container that you want to run within a pod.",
@@ -2964,7 +2911,7 @@
      },
      "resources": {
       "$ref": "v1.ResourceRequirements",
-      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/"
+      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"
      },
      "volumeMounts": {
       "type": "array",
@@ -2978,7 +2925,7 @@
       "items": {
        "$ref": "v1.VolumeDevice"
       },
-      "description": "volumeDevices is the list of block devices to be used by the container. This is a beta feature."
+      "description": "volumeDevices is the list of block devices to be used by the container. This is an alpha feature and may change in the future."
      },
      "livenessProbe": {
       "$ref": "v1.Probe",
@@ -3045,7 +2992,7 @@
      },
      "protocol": {
       "type": "string",
-      "description": "Protocol for port. Must be UDP, TCP, or SCTP. Defaults to \"TCP\"."
+      "description": "Protocol for port. Must be UDP or TCP. Defaults to \"TCP\"."
      },
      "hostIP": {
       "type": "string",
@@ -3442,10 +3389,6 @@
      "allowPrivilegeEscalation": {
       "type": "boolean",
       "description": "AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN"
-     },
-     "procMount": {
-      "$ref": "v1.ProcMountType",
-      "description": "procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled."
      }
     }
    },
@@ -3495,10 +3438,6 @@
      }
     }
    },
-   "v1.ProcMountType": {
-    "id": "v1.ProcMountType",
-    "properties": {}
-   },
    "v1.PodSecurityContext": {
     "id": "v1.PodSecurityContext",
     "description": "PodSecurityContext holds pod-level security attributes and common container settings. Some fields are also present in container.securityContext.  Field values of container.securityContext take precedence over field values of PodSecurityContext.",
@@ -3954,13 +3893,6 @@
      "propagationPolicy": {
       "$ref": "v1.DeletionPropagation",
       "description": "Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground."
-     },
-     "dryRun": {
-      "type": "array",
-      "items": {
-       "type": "string"
-      },
-      "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed"
      }
     }
    },
diff --git a/api/swagger-spec/extensions_v1beta1.json b/api/swagger-spec/extensions_v1beta1.json
index 9b42ba5de5..26d2578257 100644
--- a/api/swagger-spec/extensions_v1beta1.json
+++ b/api/swagger-spec/extensions_v1beta1.json
@@ -86,7 +86,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -139,22 +139,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -264,7 +248,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -302,7 +286,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of DaemonSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of DaemonSet",
       "nickname": "watchNamespacedDaemonSetList",
       "parameters": [
        {
@@ -373,7 +357,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -495,14 +479,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -563,14 +539,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -625,7 +593,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -652,14 +620,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -682,11 +642,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -707,7 +662,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind DaemonSet. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind DaemonSet",
       "nickname": "watchNamespacedDaemonSet",
       "parameters": [
        {
@@ -778,7 +733,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -897,7 +852,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -929,7 +884,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of DaemonSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of DaemonSet",
       "nickname": "watchDaemonSetListForAllNamespaces",
       "parameters": [
        {
@@ -1000,7 +955,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1098,14 +1053,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1166,14 +1113,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1289,7 +1228,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1342,22 +1281,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1467,7 +1390,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1505,7 +1428,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Deployment. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Deployment",
       "nickname": "watchNamespacedDeploymentList",
       "parameters": [
        {
@@ -1576,7 +1499,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1698,14 +1621,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1766,14 +1681,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1828,7 +1735,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -1855,14 +1762,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1885,11 +1784,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -1910,7 +1804,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Deployment. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Deployment",
       "nickname": "watchNamespacedDeployment",
       "parameters": [
        {
@@ -1981,7 +1875,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2100,7 +1994,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -2132,7 +2026,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Deployment. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Deployment",
       "nickname": "watchDeploymentListForAllNamespaces",
       "parameters": [
        {
@@ -2203,7 +2097,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -2233,7 +2127,7 @@
     "description": "API at /apis/extensions/v1beta1",
     "operations": [
      {
-      "type": "v1.Status",
+      "type": "v1beta1.DeploymentRollback",
       "method": "POST",
       "summary": "create rollback of a Deployment",
       "nickname": "createNamespacedDeploymentRollback",
@@ -2254,22 +2148,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2291,17 +2169,17 @@
        {
         "code": 200,
         "message": "OK",
-        "responseModel": "v1.Status"
+        "responseModel": "v1beta1.DeploymentRollback"
        },
        {
         "code": 201,
         "message": "Created",
-        "responseModel": "v1.Status"
+        "responseModel": "v1beta1.DeploymentRollback"
        },
        {
         "code": 202,
         "message": "Accepted",
-        "responseModel": "v1.Status"
+        "responseModel": "v1beta1.DeploymentRollback"
        }
       ],
       "produces": [
@@ -2388,14 +2266,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2456,14 +2326,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2574,14 +2436,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2642,14 +2496,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2765,7 +2611,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2818,22 +2664,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2943,7 +2773,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2981,7 +2811,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Ingress. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Ingress",
       "nickname": "watchNamespacedIngressList",
       "parameters": [
        {
@@ -3052,7 +2882,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3174,14 +3004,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3242,14 +3064,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3304,7 +3118,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -3331,14 +3145,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3361,11 +3167,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -3386,7 +3187,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Ingress. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Ingress",
       "nickname": "watchNamespacedIngress",
       "parameters": [
        {
@@ -3457,7 +3258,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3576,7 +3377,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -3608,7 +3409,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Ingress. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Ingress",
       "nickname": "watchIngressListForAllNamespaces",
       "parameters": [
        {
@@ -3679,7 +3480,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -3777,14 +3578,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3845,14 +3638,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3968,7 +3753,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -4021,22 +3806,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4146,7 +3915,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -4184,7 +3953,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of NetworkPolicy. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of NetworkPolicy",
       "nickname": "watchNamespacedNetworkPolicyList",
       "parameters": [
        {
@@ -4255,7 +4024,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -4377,14 +4146,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4445,14 +4206,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4507,7 +4260,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -4534,14 +4287,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4564,11 +4309,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -4589,7 +4329,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind NetworkPolicy. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind NetworkPolicy",
       "nickname": "watchNamespacedNetworkPolicy",
       "parameters": [
        {
@@ -4660,7 +4400,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -4779,7 +4519,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -4811,7 +4551,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of NetworkPolicy. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of NetworkPolicy",
       "nickname": "watchNetworkPolicyListForAllNamespaces",
       "parameters": [
        {
@@ -4882,7 +4622,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -4985,7 +4725,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -5029,22 +4769,6 @@
         "description": "",
         "required": true,
         "allowMultiple": false
-       },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
        }
       ],
       "responseMessages": [
@@ -5147,7 +4871,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -5177,7 +4901,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of PodSecurityPolicy. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of PodSecurityPolicy",
       "nickname": "watchPodSecurityPolicyList",
       "parameters": [
        {
@@ -5248,7 +4972,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -5354,14 +5078,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5414,14 +5130,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5468,7 +5176,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -5495,14 +5203,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5517,11 +5217,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -5542,7 +5237,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind PodSecurityPolicy. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind PodSecurityPolicy",
       "nickname": "watchPodSecurityPolicy",
       "parameters": [
        {
@@ -5613,7 +5308,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -5724,7 +5419,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -5777,22 +5472,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5902,7 +5581,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -5940,7 +5619,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ReplicaSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ReplicaSet",
       "nickname": "watchNamespacedReplicaSetList",
       "parameters": [
        {
@@ -6011,7 +5690,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -6133,14 +5812,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6201,14 +5872,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6263,7 +5926,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -6290,14 +5953,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6320,11 +5975,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -6345,7 +5995,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind ReplicaSet. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind ReplicaSet",
       "nickname": "watchNamespacedReplicaSet",
       "parameters": [
        {
@@ -6416,7 +6066,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -6535,7 +6185,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -6567,7 +6217,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ReplicaSet. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ReplicaSet",
       "nickname": "watchReplicaSetListForAllNamespaces",
       "parameters": [
        {
@@ -6638,7 +6288,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -6736,14 +6386,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6804,14 +6446,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6922,14 +6556,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6990,14 +6616,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -7108,14 +6726,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -7176,14 +6786,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -7288,7 +6890,7 @@
      },
      "continue": {
       "type": "string",
-      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message."
+      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response."
      }
     }
    },
@@ -7398,7 +7000,7 @@
    },
    "v1.OwnerReference": {
     "id": "v1.OwnerReference",
-    "description": "OwnerReference contains enough information to let you identify an owning object. An owning object must be in the same namespace as the dependent, or be cluster-scoped, so there is no namespace field.",
+    "description": "OwnerReference contains enough information to let you identify an owning object. Currently, an owning object must be in the same namespace, so there is no namespace field.",
     "required": [
      "apiVersion",
      "kind",
@@ -7728,7 +7330,7 @@
      },
      "shareProcessNamespace": {
       "type": "boolean",
-      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is beta-level and may be disabled with the PodShareProcessNamespace feature."
+      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is alpha-level and is honored only by servers that enable the PodShareProcessNamespace feature."
      },
      "securityContext": {
       "$ref": "v1.PodSecurityContext",
@@ -7790,14 +7392,6 @@
        "$ref": "v1.PodReadinessGate"
       },
       "description": "If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to \"True\" More info: https://github.com/kubernetes/community/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md"
-     },
-     "runtimeClassName": {
-      "type": "string",
-      "description": "RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the \"legacy\" RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://github.com/kubernetes/community/blob/master/keps/sig-node/0014-runtime-class.md This is an alpha feature and may change in the future."
-     },
-     "enableServiceLinks": {
-      "type": "boolean",
-      "description": "EnableServiceLinks indicates whether information about services should be injected into pod's environment variables, matching the syntax of Docker links."
      }
     }
    },
@@ -7919,6 +7513,10 @@
      "storageos": {
       "$ref": "v1.StorageOSVolumeSource",
       "description": "StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes."
+     },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
      }
     }
    },
@@ -8635,6 +8233,23 @@
      }
     }
    },
+   "v1.CascadeDiskVolumeSource": {
+    "id": "v1.CascadeDiskVolumeSource",
+    "description": "Represents a Cascade persistent disk resource.",
+    "required": [
+     "diskID"
+    ],
+    "properties": {
+     "diskID": {
+      "type": "string",
+      "description": "ID that identifies Cascade persistent disk"
+     },
+     "fsType": {
+      "type": "string",
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
+     }
+    }
+   },
    "v1.ProjectedVolumeSource": {
     "id": "v1.ProjectedVolumeSource",
     "description": "Represents a projected volume source",
@@ -8811,7 +8426,7 @@
      },
      "storageMode": {
       "type": "string",
-      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned."
+      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned."
      },
      "volumeName": {
       "type": "string",
@@ -8819,7 +8434,7 @@
      },
      "fsType": {
       "type": "string",
-      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\"."
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
      },
      "readOnly": {
       "type": "boolean",
@@ -8909,7 +8524,7 @@
      },
      "resources": {
       "$ref": "v1.ResourceRequirements",
-      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/"
+      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"
      },
      "volumeMounts": {
       "type": "array",
@@ -8923,7 +8538,7 @@
       "items": {
        "$ref": "v1.VolumeDevice"
       },
-      "description": "volumeDevices is the list of block devices to be used by the container. This is a beta feature."
+      "description": "volumeDevices is the list of block devices to be used by the container. This is an alpha feature and may change in the future."
      },
      "livenessProbe": {
       "$ref": "v1.Probe",
@@ -8990,7 +8605,7 @@
      },
      "protocol": {
       "type": "string",
-      "description": "Protocol for port. Must be UDP, TCP, or SCTP. Defaults to \"TCP\"."
+      "description": "Protocol for port. Must be UDP or TCP. Defaults to \"TCP\"."
      },
      "hostIP": {
       "type": "string",
@@ -9387,10 +9002,6 @@
      "allowPrivilegeEscalation": {
       "type": "boolean",
       "description": "AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN"
-     },
-     "procMount": {
-      "$ref": "v1.ProcMountType",
-      "description": "procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled."
      }
     }
    },
@@ -9440,10 +9051,6 @@
      }
     }
    },
-   "v1.ProcMountType": {
-    "id": "v1.ProcMountType",
-    "properties": {}
-   },
    "v1.PodSecurityContext": {
     "id": "v1.PodSecurityContext",
     "description": "PodSecurityContext holds pod-level security attributes and common container settings. Some fields are also present in container.securityContext.  Field values of container.securityContext take precedence over field values of PodSecurityContext.",
@@ -9965,13 +9572,6 @@
      "propagationPolicy": {
       "$ref": "v1.DeletionPropagation",
       "description": "Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground."
-     },
-     "dryRun": {
-      "type": "array",
-      "items": {
-       "type": "string"
-      },
-      "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed"
      }
     }
    },
@@ -10079,7 +9679,7 @@
      "revisionHistoryLimit": {
       "type": "integer",
       "format": "int32",
-      "description": "The number of old ReplicaSets to retain to allow rollback. This is a pointer to distinguish between explicit zero and not specified. This is set to the max value of int32 (i.e. 2147483647) by default, which means \"retaining all old RelicaSets\"."
+      "description": "The number of old ReplicaSets to retain to allow rollback. This is a pointer to distinguish between explicit zero and not specified."
      },
      "paused": {
       "type": "boolean",
@@ -10092,7 +9692,7 @@
      "progressDeadlineSeconds": {
       "type": "integer",
       "format": "int32",
-      "description": "The maximum time in seconds for a deployment to make progress before it is considered to be failed. The deployment controller will continue to process failed deployments and a condition with a ProgressDeadlineExceeded reason will be surfaced in the deployment status. Note that progress will not be estimated during the time a deployment is paused. This is set to the max value of int32 (i.e. 2147483647) by default, which means \"no deadline\"."
+      "description": "The maximum time in seconds for a deployment to make progress before it is considered to be failed. The deployment controller will continue to process failed deployments and a condition with a ProgressDeadlineExceeded reason will be surfaced in the deployment status. Note that progress will not be estimated during the time a deployment is paused. This is not set by default."
      }
     }
    },
@@ -10612,7 +10212,7 @@
     "properties": {
      "protocol": {
       "$ref": "v1.Protocol",
-      "description": "Optional.  The protocol (TCP, UDP, or SCTP) which traffic must match. If not specified, this field defaults to TCP."
+      "description": "Optional.  The protocol (TCP or UDP) which traffic must match. If not specified, this field defaults to TCP."
      },
      "port": {
       "type": "string",
@@ -10805,10 +10405,6 @@
       "$ref": "v1beta1.RunAsUserStrategyOptions",
       "description": "runAsUser is the strategy that will dictate the allowable RunAsUser values that may be set."
      },
-     "runAsGroup": {
-      "$ref": "v1beta1.RunAsGroupStrategyOptions",
-      "description": "RunAsGroup is the strategy that will dictate the allowable RunAsGroup values that may be set. If this field is omitted, the pod's RunAsGroup can take any value. This field requires the RunAsGroup feature gate to be enabled."
-     },
      "supplementalGroups": {
       "$ref": "v1beta1.SupplementalGroupsStrategyOptions",
       "description": "supplementalGroups is the strategy that will dictate what supplemental groups are used by the SecurityContext."
@@ -10856,13 +10452,6 @@
        "type": "string"
       },
       "description": "forbiddenSysctls is a list of explicitly forbidden sysctls, defaults to none. Each entry is either a plain sysctl name or ends in \"*\" in which case it is considered as a prefix of forbidden sysctls. Single * means all sysctls are forbidden.\n\nExamples: e.g. \"foo/*\" forbids \"foo/bar\", \"foo/baz\", etc. e.g. \"foo.*\" forbids \"foo.bar\", \"foo.baz\", etc."
-     },
-     "allowedProcMountTypes": {
-      "type": "array",
-      "items": {
-       "$ref": "v1.ProcMountType"
-      },
-      "description": "AllowedProcMountTypes is a whitelist of allowed ProcMountTypes. Empty or nil indicates that only the DefaultProcMountType may be used. This requires the ProcMountType feature flag to be enabled."
      }
     }
    },
@@ -10947,26 +10536,6 @@
      }
     }
    },
-   "v1beta1.RunAsGroupStrategyOptions": {
-    "id": "v1beta1.RunAsGroupStrategyOptions",
-    "description": "RunAsGroupStrategyOptions defines the strategy type and any options used to create the strategy. Deprecated: use RunAsGroupStrategyOptions from policy API Group instead.",
-    "required": [
-     "rule"
-    ],
-    "properties": {
-     "rule": {
-      "type": "string",
-      "description": "rule is the strategy that will dictate the allowable RunAsGroup values that may be set."
-     },
-     "ranges": {
-      "type": "array",
-      "items": {
-       "$ref": "v1beta1.IDRange"
-      },
-      "description": "ranges are the allowed ranges of gids that may be used. If you would like to force a single gid then supply a single range with the same start and end. Required for MustRunAs."
-     }
-    }
-   },
    "v1beta1.SupplementalGroupsStrategyOptions": {
     "id": "v1beta1.SupplementalGroupsStrategyOptions",
     "description": "SupplementalGroupsStrategyOptions defines the strategy type and options used to create the strategy. Deprecated: use SupplementalGroupsStrategyOptions from policy API Group instead.",
diff --git a/api/swagger-spec/settings.k8s.io_v1alpha1.json b/api/swagger-spec/settings.k8s.io_v1alpha1.json
index c8d6b2f72b..90c0e0b777 100644
--- a/api/swagger-spec/settings.k8s.io_v1alpha1.json
+++ b/api/swagger-spec/settings.k8s.io_v1alpha1.json
@@ -86,7 +86,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -139,22 +139,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -264,7 +248,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -302,7 +286,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of PodPreset. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of PodPreset",
       "nickname": "watchNamespacedPodPresetList",
       "parameters": [
        {
@@ -373,7 +357,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -495,14 +479,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -563,14 +539,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -625,7 +593,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -652,14 +620,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -682,11 +642,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -707,7 +662,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind PodPreset. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind PodPreset",
       "nickname": "watchNamespacedPodPreset",
       "parameters": [
        {
@@ -778,7 +733,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -897,7 +852,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -929,7 +884,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of PodPreset. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of PodPreset",
       "nickname": "watchPodPresetListForAllNamespaces",
       "parameters": [
        {
@@ -1000,7 +955,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1092,7 +1047,7 @@
      },
      "continue": {
       "type": "string",
-      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message."
+      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response."
      }
     }
    },
@@ -1196,7 +1151,7 @@
    },
    "v1.OwnerReference": {
     "id": "v1.OwnerReference",
-    "description": "OwnerReference contains enough information to let you identify an owning object. An owning object must be in the same namespace as the dependent, or be cluster-scoped, so there is no namespace field.",
+    "description": "OwnerReference contains enough information to let you identify an owning object. Currently, an owning object must be in the same namespace, so there is no namespace field.",
     "required": [
      "apiVersion",
      "kind",
@@ -1721,6 +1676,10 @@
      "storageos": {
       "$ref": "v1.StorageOSVolumeSource",
       "description": "StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes."
+     },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
      }
     }
    },
@@ -2399,6 +2358,23 @@
      }
     }
    },
+   "v1.CascadeDiskVolumeSource": {
+    "id": "v1.CascadeDiskVolumeSource",
+    "description": "Represents a Cascade persistent disk resource.",
+    "required": [
+     "diskID"
+    ],
+    "properties": {
+     "diskID": {
+      "type": "string",
+      "description": "ID that identifies Cascade persistent disk"
+     },
+     "fsType": {
+      "type": "string",
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
+     }
+    }
+   },
    "v1.ProjectedVolumeSource": {
     "id": "v1.ProjectedVolumeSource",
     "description": "Represents a projected volume source",
@@ -2575,7 +2551,7 @@
      },
      "storageMode": {
       "type": "string",
-      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned."
+      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned."
      },
      "volumeName": {
       "type": "string",
@@ -2583,7 +2559,7 @@
      },
      "fsType": {
       "type": "string",
-      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\"."
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
      },
      "readOnly": {
       "type": "boolean",
@@ -2699,13 +2675,6 @@
      "propagationPolicy": {
       "$ref": "v1.DeletionPropagation",
       "description": "Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground."
-     },
-     "dryRun": {
-      "type": "array",
-      "items": {
-       "type": "string"
-      },
-      "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed"
      }
     }
    },
diff --git a/api/swagger-spec/v1.json b/api/swagger-spec/v1.json
index 21d43eb62f..b36450efdf 100644
--- a/api/swagger-spec/v1.json
+++ b/api/swagger-spec/v1.json
@@ -34,22 +34,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -165,7 +149,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -313,7 +297,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -366,22 +350,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -491,7 +459,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -529,7 +497,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ConfigMap. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ConfigMap",
       "nickname": "watchNamespacedConfigMapList",
       "parameters": [
        {
@@ -600,7 +568,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -722,14 +690,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -790,14 +750,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -852,7 +804,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -879,14 +831,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -909,11 +853,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -934,7 +873,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind ConfigMap. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind ConfigMap",
       "nickname": "watchNamespacedConfigMap",
       "parameters": [
        {
@@ -1005,7 +944,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1124,7 +1063,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1156,7 +1095,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ConfigMap. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ConfigMap",
       "nickname": "watchConfigMapListForAllNamespaces",
       "parameters": [
        {
@@ -1227,7 +1166,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -1330,7 +1269,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1383,22 +1322,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1508,7 +1431,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1546,7 +1469,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Endpoints. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Endpoints",
       "nickname": "watchNamespacedEndpointsList",
       "parameters": [
        {
@@ -1617,7 +1540,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -1739,14 +1662,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1807,14 +1722,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1869,7 +1776,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -1896,14 +1803,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -1926,11 +1825,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -1951,7 +1845,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Endpoints. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Endpoints",
       "nickname": "watchNamespacedEndpoints",
       "parameters": [
        {
@@ -2022,7 +1916,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2141,7 +2035,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -2173,7 +2067,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Endpoints. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Endpoints",
       "nickname": "watchEndpointsListForAllNamespaces",
       "parameters": [
        {
@@ -2244,7 +2138,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -2347,7 +2241,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2400,22 +2294,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2525,7 +2403,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2563,7 +2441,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Event. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Event",
       "nickname": "watchNamespacedEventList",
       "parameters": [
        {
@@ -2634,7 +2512,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -2756,14 +2634,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2824,14 +2694,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2886,7 +2748,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -2913,14 +2775,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -2943,11 +2797,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -2968,7 +2817,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Event. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Event",
       "nickname": "watchNamespacedEvent",
       "parameters": [
        {
@@ -3039,7 +2888,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3158,7 +3007,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -3190,7 +3039,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Event. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Event",
       "nickname": "watchEventListForAllNamespaces",
       "parameters": [
        {
@@ -3261,7 +3110,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -3364,7 +3213,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3417,22 +3266,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3542,7 +3375,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3580,7 +3413,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of LimitRange. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of LimitRange",
       "nickname": "watchNamespacedLimitRangeList",
       "parameters": [
        {
@@ -3651,7 +3484,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -3773,14 +3606,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3841,14 +3666,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3903,7 +3720,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -3930,14 +3747,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -3960,11 +3769,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -3985,7 +3789,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind LimitRange. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind LimitRange",
       "nickname": "watchNamespacedLimitRange",
       "parameters": [
        {
@@ -4056,7 +3860,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -4175,7 +3979,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -4207,7 +4011,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of LimitRange. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of LimitRange",
       "nickname": "watchLimitRangeListForAllNamespaces",
       "parameters": [
        {
@@ -4278,7 +4082,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -4381,7 +4185,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -4425,22 +4229,6 @@
         "description": "",
         "required": true,
         "allowMultiple": false
-       },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
        }
       ],
       "responseMessages": [
@@ -4478,7 +4266,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Namespace. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Namespace",
       "nickname": "watchNamespaceList",
       "parameters": [
        {
@@ -4549,7 +4337,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -4655,14 +4443,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4715,14 +4495,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4769,7 +4541,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -4796,14 +4568,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -4818,11 +4582,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -4843,7 +4602,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Namespace. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Namespace",
       "nickname": "watchNamespace",
       "parameters": [
        {
@@ -4914,7 +4673,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -4973,14 +4732,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5078,14 +4829,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5138,14 +4881,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5253,7 +4988,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -5297,22 +5032,6 @@
         "description": "",
         "required": true,
         "allowMultiple": false
-       },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
        }
       ],
       "responseMessages": [
@@ -5415,7 +5134,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -5445,7 +5164,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Node. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Node",
       "nickname": "watchNodeList",
       "parameters": [
        {
@@ -5516,7 +5235,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -5622,14 +5341,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5682,14 +5393,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5736,7 +5439,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -5763,14 +5466,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -5785,11 +5480,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -5810,7 +5500,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Node. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Node",
       "nickname": "watchNode",
       "parameters": [
        {
@@ -5881,7 +5571,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -5936,7 +5626,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        }
@@ -5966,7 +5656,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        }
@@ -5996,7 +5686,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        }
@@ -6026,7 +5716,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        }
@@ -6056,7 +5746,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        }
@@ -6086,7 +5776,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        }
@@ -6116,7 +5806,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        }
@@ -6152,7 +5842,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        },
@@ -6190,7 +5880,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        },
@@ -6228,7 +5918,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        },
@@ -6266,7 +5956,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        },
@@ -6304,7 +5994,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        },
@@ -6342,7 +6032,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        },
@@ -6380,7 +6070,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the NodeProxyOptions",
+        "description": "name of the Node",
         "required": true,
         "allowMultiple": false
        },
@@ -6467,14 +6157,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6527,14 +6209,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6642,7 +6316,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -6695,22 +6369,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -6820,7 +6478,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -6858,7 +6516,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of PersistentVolumeClaim. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of PersistentVolumeClaim",
       "nickname": "watchNamespacedPersistentVolumeClaimList",
       "parameters": [
        {
@@ -6929,7 +6587,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -7051,14 +6709,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -7119,14 +6769,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -7181,7 +6823,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -7208,14 +6850,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -7238,11 +6872,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -7263,7 +6892,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind PersistentVolumeClaim. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind PersistentVolumeClaim",
       "nickname": "watchNamespacedPersistentVolumeClaim",
       "parameters": [
        {
@@ -7334,7 +6963,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -7453,7 +7082,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -7485,7 +7114,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of PersistentVolumeClaim. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of PersistentVolumeClaim",
       "nickname": "watchPersistentVolumeClaimListForAllNamespaces",
       "parameters": [
        {
@@ -7556,7 +7185,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -7654,14 +7283,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -7722,14 +7343,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -7845,7 +7458,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -7882,28 +7495,12 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "v1.PersistentVolume",
-        "paramType": "body",
-        "name": "body",
-        "description": "",
-        "required": true,
-        "allowMultiple": false
-       },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
+       {
+        "type": "v1.PersistentVolume",
+        "paramType": "body",
+        "name": "body",
+        "description": "",
+        "required": true,
         "allowMultiple": false
        }
       ],
@@ -8007,7 +7604,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -8037,7 +7634,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of PersistentVolume. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of PersistentVolume",
       "nickname": "watchPersistentVolumeList",
       "parameters": [
        {
@@ -8108,7 +7705,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -8214,14 +7811,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -8274,14 +7863,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -8328,7 +7909,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -8355,14 +7936,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -8377,11 +7950,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -8402,7 +7970,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind PersistentVolume. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind PersistentVolume",
       "nickname": "watchPersistentVolume",
       "parameters": [
        {
@@ -8473,7 +8041,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -8571,14 +8139,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -8631,14 +8191,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -8746,7 +8298,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -8799,22 +8351,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -8924,7 +8460,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -8962,7 +8498,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Pod. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Pod",
       "nickname": "watchNamespacedPodList",
       "parameters": [
        {
@@ -9033,7 +8569,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -9155,14 +8691,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -9223,14 +8751,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -9285,7 +8805,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -9312,14 +8832,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -9342,11 +8854,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -9367,7 +8874,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Pod. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Pod",
       "nickname": "watchNamespacedPod",
       "parameters": [
        {
@@ -9438,7 +8945,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -9557,7 +9064,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -9589,7 +9096,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Pod. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Pod",
       "nickname": "watchPodListForAllNamespaces",
       "parameters": [
        {
@@ -9660,7 +9167,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -9747,7 +9254,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodAttachOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -9817,7 +9324,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodAttachOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -9857,22 +9364,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -9944,22 +9435,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -10075,7 +9550,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodExecOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10153,7 +9628,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodExecOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10307,7 +9782,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodPortForwardOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10345,7 +9820,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodPortForwardOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10389,7 +9864,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10427,7 +9902,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10465,7 +9940,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10503,7 +9978,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10541,7 +10016,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10579,7 +10054,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10617,7 +10092,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        }
@@ -10661,7 +10136,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        },
@@ -10707,7 +10182,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        },
@@ -10753,7 +10228,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        },
@@ -10799,7 +10274,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        },
@@ -10845,7 +10320,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        },
@@ -10891,7 +10366,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        },
@@ -10937,7 +10412,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the PodProxyOptions",
+        "description": "name of the Pod",
         "required": true,
         "allowMultiple": false
        },
@@ -11032,14 +10507,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -11100,14 +10567,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -11223,7 +10682,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -11276,22 +10735,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -11401,7 +10844,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -11439,7 +10882,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of PodTemplate. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of PodTemplate",
       "nickname": "watchNamespacedPodTemplateList",
       "parameters": [
        {
@@ -11510,7 +10953,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -11632,14 +11075,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -11700,14 +11135,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -11762,7 +11189,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -11789,14 +11216,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -11819,11 +11238,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -11844,7 +11258,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind PodTemplate. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind PodTemplate",
       "nickname": "watchNamespacedPodTemplate",
       "parameters": [
        {
@@ -11915,7 +11329,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -12034,7 +11448,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -12066,7 +11480,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of PodTemplate. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of PodTemplate",
       "nickname": "watchPodTemplateListForAllNamespaces",
       "parameters": [
        {
@@ -12137,7 +11551,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -12240,7 +11654,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -12293,22 +11707,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -12418,7 +11816,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -12456,7 +11854,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ReplicationController. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ReplicationController",
       "nickname": "watchNamespacedReplicationControllerList",
       "parameters": [
        {
@@ -12527,7 +11925,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -12649,14 +12047,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -12717,14 +12107,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -12779,7 +12161,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -12806,14 +12188,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -12836,11 +12210,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -12861,7 +12230,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind ReplicationController. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind ReplicationController",
       "nickname": "watchNamespacedReplicationController",
       "parameters": [
        {
@@ -12932,7 +12301,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -13051,7 +12420,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -13083,7 +12452,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ReplicationController. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ReplicationController",
       "nickname": "watchReplicationControllerListForAllNamespaces",
       "parameters": [
        {
@@ -13154,7 +12523,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -13252,14 +12621,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -13320,14 +12681,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -13438,14 +12791,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -13506,14 +12851,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -13629,7 +12966,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -13676,26 +13013,10 @@
        },
        {
         "type": "v1.ResourceQuota",
-        "paramType": "body",
-        "name": "body",
-        "description": "",
-        "required": true,
-        "allowMultiple": false
-       },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
+        "paramType": "body",
+        "name": "body",
+        "description": "",
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -13807,7 +13128,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -13845,7 +13166,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ResourceQuota. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ResourceQuota",
       "nickname": "watchNamespacedResourceQuotaList",
       "parameters": [
        {
@@ -13916,7 +13237,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -14038,14 +13359,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -14106,14 +13419,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -14168,7 +13473,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -14195,14 +13500,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -14225,11 +13522,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -14250,7 +13542,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind ResourceQuota. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind ResourceQuota",
       "nickname": "watchNamespacedResourceQuota",
       "parameters": [
        {
@@ -14321,7 +13613,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -14440,7 +13732,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -14472,7 +13764,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ResourceQuota. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ResourceQuota",
       "nickname": "watchResourceQuotaListForAllNamespaces",
       "parameters": [
        {
@@ -14543,7 +13835,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -14641,14 +13933,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -14709,14 +13993,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -14832,7 +14108,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -14885,22 +14161,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -15010,7 +14270,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -15048,7 +14308,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Secret. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Secret",
       "nickname": "watchNamespacedSecretList",
       "parameters": [
        {
@@ -15119,7 +14379,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -15241,14 +14501,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -15309,14 +14561,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -15371,7 +14615,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -15398,14 +14642,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -15428,11 +14664,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -15453,7 +14684,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Secret. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Secret",
       "nickname": "watchNamespacedSecret",
       "parameters": [
        {
@@ -15524,7 +14755,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -15643,7 +14874,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -15675,7 +14906,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Secret. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Secret",
       "nickname": "watchSecretListForAllNamespaces",
       "parameters": [
        {
@@ -15746,7 +14977,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -15849,7 +15080,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -15902,22 +15133,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -16027,7 +15242,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -16065,7 +15280,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ServiceAccount. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ServiceAccount",
       "nickname": "watchNamespacedServiceAccountList",
       "parameters": [
        {
@@ -16136,7 +15351,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -16258,14 +15473,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -16326,14 +15533,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -16388,7 +15587,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -16415,14 +15614,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -16445,11 +15636,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -16470,7 +15656,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind ServiceAccount. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind ServiceAccount",
       "nickname": "watchNamespacedServiceAccount",
       "parameters": [
        {
@@ -16541,7 +15727,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -16660,7 +15846,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -16692,7 +15878,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of ServiceAccount. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of ServiceAccount",
       "nickname": "watchServiceAccountListForAllNamespaces",
       "parameters": [
        {
@@ -16763,7 +15949,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -16866,7 +16052,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -16919,22 +16105,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
-       {
-        "type": "boolean",
-        "paramType": "query",
-        "name": "includeUninitialized",
-        "description": "If IncludeUninitialized is specified, the object may be returned without completing initialization.",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -16979,7 +16149,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Service. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Service",
       "nickname": "watchNamespacedServiceList",
       "parameters": [
        {
@@ -17050,7 +16220,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -17172,14 +16342,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -17240,14 +16402,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -17302,7 +16456,7 @@
         "paramType": "body",
         "name": "body",
         "description": "",
-        "required": false,
+        "required": true,
         "allowMultiple": false
        },
        {
@@ -17329,14 +16483,6 @@
         "required": false,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -17359,11 +16505,6 @@
         "code": 200,
         "message": "OK",
         "responseModel": "v1.Status"
-       },
-       {
-        "code": 202,
-        "message": "Accepted",
-        "responseModel": "v1.Status"
        }
       ],
       "produces": [
@@ -17384,7 +16525,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch changes to an object of kind Service. deprecated: use the 'watch' parameter with a list operation instead, filtered to a single item with the 'fieldSelector' parameter.",
+      "summary": "watch changes to an object of kind Service",
       "nickname": "watchNamespacedService",
       "parameters": [
        {
@@ -17455,7 +16596,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        },
@@ -17574,7 +16715,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -17606,7 +16747,7 @@
      {
       "type": "v1.WatchEvent",
       "method": "GET",
-      "summary": "watch individual changes to a list of Service. deprecated: use the 'watch' parameter with a list operation instead.",
+      "summary": "watch individual changes to a list of Service",
       "nickname": "watchServiceListForAllNamespaces",
       "parameters": [
        {
@@ -17677,7 +16818,7 @@
         "type": "string",
         "paramType": "query",
         "name": "continue",
-        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \"next key\".\n\nThis field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
+        "description": "The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server the server will respond with a 410 ResourceExpired error indicating the client must restart their list without the continue field. This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.",
         "required": false,
         "allowMultiple": false
        }
@@ -17732,7 +16873,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        }
@@ -17770,7 +16911,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        }
@@ -17808,7 +16949,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        }
@@ -17846,7 +16987,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        }
@@ -17884,7 +17025,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        }
@@ -17922,7 +17063,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        }
@@ -17960,7 +17101,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        }
@@ -18004,7 +17145,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        },
@@ -18050,7 +17191,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        },
@@ -18096,7 +17237,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        },
@@ -18142,7 +17283,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        },
@@ -18188,7 +17329,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        },
@@ -18234,7 +17375,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        },
@@ -18280,7 +17421,7 @@
         "type": "string",
         "paramType": "path",
         "name": "name",
-        "description": "name of the ServiceProxyOptions",
+        "description": "name of the Service",
         "required": true,
         "allowMultiple": false
        },
@@ -18375,14 +17516,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -18443,14 +17576,6 @@
         "required": true,
         "allowMultiple": false
        },
-       {
-        "type": "string",
-        "paramType": "query",
-        "name": "dryRun",
-        "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed",
-        "required": false,
-        "allowMultiple": false
-       },
        {
         "type": "string",
         "paramType": "path",
@@ -18618,7 +17743,7 @@
    },
    "v1.OwnerReference": {
     "id": "v1.OwnerReference",
-    "description": "OwnerReference contains enough information to let you identify an owning object. An owning object must be in the same namespace as the dependent, or be cluster-scoped, so there is no namespace field.",
+    "description": "OwnerReference contains enough information to let you identify an owning object. Currently, an owning object must be in the same namespace, so there is no namespace field.",
     "required": [
      "apiVersion",
      "kind",
@@ -18738,7 +17863,7 @@
      },
      "continue": {
       "type": "string",
-      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message."
+      "description": "continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response."
      }
     }
    },
@@ -19009,13 +18134,6 @@
      "propagationPolicy": {
       "$ref": "v1.DeletionPropagation",
       "description": "Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground."
-     },
-     "dryRun": {
-      "type": "array",
-      "items": {
-       "type": "string"
-      },
-      "description": "When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed"
      }
     }
    },
@@ -19160,7 +18278,7 @@
      },
      "protocol": {
       "type": "string",
-      "description": "The IP protocol for this port. Must be UDP, TCP, or SCTP. Default is TCP."
+      "description": "The IP protocol for this port. Must be UDP or TCP. Default is TCP."
      }
     }
    },
@@ -19958,9 +19076,6 @@
    "v1.PersistentVolumeClaimSpec": {
     "id": "v1.PersistentVolumeClaimSpec",
     "description": "PersistentVolumeClaimSpec describes the common attributes of storage devices and allows a Source for provider-specific attributes",
-    "required": [
-     "dataSource"
-    ],
     "properties": {
      "accessModes": {
       "type": "array",
@@ -19987,11 +19102,7 @@
      },
      "volumeMode": {
       "$ref": "v1.PersistentVolumeMode",
-      "description": "volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec. This is a beta feature."
-     },
-     "dataSource": {
-      "$ref": "v1.TypedLocalObjectReference",
-      "description": "This field requires the VolumeSnapshotDataSource alpha feature gate to be enabled and currently VolumeSnapshot is the only supported data source. If the provisioner can support VolumeSnapshot data source, it will create a new volume and data will be restored to the volume at the same time. If the provisioner does not support VolumeSnapshot data source, volume will not be created and the failure will be reported as an event. In the future, we plan to support more data source types and the behavior of the provisioner may change."
+      "description": "volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec. This is an alpha feature and may change in the future."
      }
     }
    },
@@ -20059,29 +19170,6 @@
     "id": "v1.PersistentVolumeMode",
     "properties": {}
    },
-   "v1.TypedLocalObjectReference": {
-    "id": "v1.TypedLocalObjectReference",
-    "description": "TypedLocalObjectReference contains enough information to let you locate the typed referenced object inside the same namespace.",
-    "required": [
-     "apiGroup",
-     "kind",
-     "name"
-    ],
-    "properties": {
-     "apiGroup": {
-      "type": "string",
-      "description": "APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required."
-     },
-     "kind": {
-      "type": "string",
-      "description": "Kind is the type of resource being referenced"
-     },
-     "name": {
-      "type": "string",
-      "description": "Name is the name of resource being referenced"
-     }
-    }
-   },
    "v1.PersistentVolumeClaimStatus": {
     "id": "v1.PersistentVolumeClaimStatus",
     "description": "PersistentVolumeClaimStatus is the current status of a persistent volume claim.",
@@ -20217,7 +19305,7 @@
       "description": "HostPath represents a directory on the host. Provisioned by a developer or tester. This is useful for single-node development and testing only! On-host storage is not supported in any way and WILL NOT WORK in a multi-node cluster. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath"
      },
      "glusterfs": {
-      "$ref": "v1.GlusterfsPersistentVolumeSource",
+      "$ref": "v1.GlusterfsVolumeSource",
       "description": "Glusterfs represents a Glusterfs volume that is attached to a host and exposed to the pod. Provisioned by an admin. More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md"
      },
      "nfs": {
@@ -20272,6 +19360,10 @@
       "$ref": "v1.PhotonPersistentDiskVolumeSource",
       "description": "PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine"
      },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
+     },
      "portworxVolume": {
       "$ref": "v1.PortworxVolumeSource",
       "description": "PortworxVolume represents a portworx volume attached and mounted on kubelets host machine"
@@ -20320,7 +19412,7 @@
      },
      "volumeMode": {
       "$ref": "v1.PersistentVolumeMode",
-      "description": "volumeMode defines if a volume is intended to be used with a formatted filesystem or to remain in raw block state. Value of Filesystem is implied when not included in spec. This is a beta feature."
+      "description": "volumeMode defines if a volume is intended to be used with a formatted filesystem or to remain in raw block state. Value of Filesystem is implied when not included in spec. This is an alpha feature and may change in the future."
      },
      "nodeAffinity": {
       "$ref": "v1.VolumeNodeAffinity",
@@ -20401,8 +19493,8 @@
     "id": "v1.HostPathType",
     "properties": {}
    },
-   "v1.GlusterfsPersistentVolumeSource": {
-    "id": "v1.GlusterfsPersistentVolumeSource",
+   "v1.GlusterfsVolumeSource": {
+    "id": "v1.GlusterfsVolumeSource",
     "description": "Represents a Glusterfs mount that lasts the lifetime of a pod. Glusterfs volumes do not support ownership management or SELinux relabeling.",
     "required": [
      "endpoints",
@@ -20420,10 +19512,6 @@
      "readOnly": {
       "type": "boolean",
       "description": "ReadOnly here will force the Glusterfs volume to be mounted with read-only permissions. Defaults to false. More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod"
-     },
-     "endpointsNamespace": {
-      "type": "string",
-      "description": "EndpointsNamespace is the namespace that contains Glusterfs endpoint. If this field is empty, the EndpointNamespace defaults to the same namespace as the bound PVC. More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod"
      }
     }
    },
@@ -20845,6 +19933,23 @@
      }
     }
    },
+   "v1.CascadeDiskVolumeSource": {
+    "id": "v1.CascadeDiskVolumeSource",
+    "description": "Represents a Cascade persistent disk resource.",
+    "required": [
+     "diskID"
+    ],
+    "properties": {
+     "diskID": {
+      "type": "string",
+      "description": "ID that identifies Cascade persistent disk"
+     },
+     "fsType": {
+      "type": "string",
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
+     }
+    }
+   },
    "v1.PortworxVolumeSource": {
     "id": "v1.PortworxVolumeSource",
     "description": "PortworxVolumeSource represents a Portworx volume resource.",
@@ -20901,7 +20006,7 @@
      },
      "storageMode": {
       "type": "string",
-      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned."
+      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned."
      },
      "volumeName": {
       "type": "string",
@@ -20909,7 +20014,7 @@
      },
      "fsType": {
       "type": "string",
-      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\""
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
      },
      "readOnly": {
       "type": "boolean",
@@ -20926,11 +20031,7 @@
     "properties": {
      "path": {
       "type": "string",
-      "description": "The full path to the volume on the node. It can be either a directory or block device (disk, partition, ...)."
-     },
-     "fsType": {
-      "type": "string",
-      "description": "Filesystem type to mount. It applies only when the Path is a block device. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". The default value is to auto-select a fileystem if unspecified."
+      "description": "The full path to the volume on the node. It can be either a directory or block device (disk, partition, ...). Directories can be represented only by PersistentVolume with VolumeMode=Filesystem. Block devices can be represented only by VolumeMode=Block, which also requires the BlockVolume alpha feature gate to be enabled."
      }
     }
    },
@@ -20990,15 +20091,15 @@
      },
      "controllerPublishSecretRef": {
       "$ref": "v1.SecretReference",
-      "description": "ControllerPublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI ControllerPublishVolume and ControllerUnpublishVolume calls. This field is optional, and may be empty if no secret is required. If the secret object contains more than one secret, all secrets are passed."
+      "description": "ControllerPublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI ControllerPublishVolume and ControllerUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secrets are passed."
      },
      "nodeStageSecretRef": {
       "$ref": "v1.SecretReference",
-      "description": "NodeStageSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodeStageVolume and NodeStageVolume and NodeUnstageVolume calls. This field is optional, and may be empty if no secret is required. If the secret object contains more than one secret, all secrets are passed."
+      "description": "NodeStageSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodeStageVolume and NodeStageVolume and NodeUnstageVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secrets are passed."
      },
      "nodePublishSecretRef": {
       "$ref": "v1.SecretReference",
-      "description": "NodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and may be empty if no secret is required. If the secret object contains more than one secret, all secrets are passed."
+      "description": "NodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secrets are passed."
      }
     }
    },
@@ -21225,7 +20326,7 @@
      },
      "shareProcessNamespace": {
       "type": "boolean",
-      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is beta-level and may be disabled with the PodShareProcessNamespace feature."
+      "description": "Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false. This field is alpha-level and is honored only by servers that enable the PodShareProcessNamespace feature."
      },
      "securityContext": {
       "$ref": "v1.PodSecurityContext",
@@ -21287,14 +20388,6 @@
        "$ref": "v1.PodReadinessGate"
       },
       "description": "If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to \"True\" More info: https://github.com/kubernetes/community/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md"
-     },
-     "runtimeClassName": {
-      "type": "string",
-      "description": "RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the \"legacy\" RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://github.com/kubernetes/community/blob/master/keps/sig-node/0014-runtime-class.md This is an alpha feature and may change in the future."
-     },
-     "enableServiceLinks": {
-      "type": "boolean",
-      "description": "EnableServiceLinks indicates whether information about services should be injected into pod's environment variables, matching the syntax of Docker links."
      }
     }
    },
@@ -21416,6 +20509,10 @@
      "storageos": {
       "$ref": "v1.StorageOSVolumeSource",
       "description": "StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes."
+     },
+     "vkeDisk": {
+      "$ref": "v1.CascadeDiskVolumeSource",
+      "description": "vkeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine"
      }
     }
    },
@@ -21572,28 +20669,6 @@
      }
     }
    },
-   "v1.GlusterfsVolumeSource": {
-    "id": "v1.GlusterfsVolumeSource",
-    "description": "Represents a Glusterfs mount that lasts the lifetime of a pod. Glusterfs volumes do not support ownership management or SELinux relabeling.",
-    "required": [
-     "endpoints",
-     "path"
-    ],
-    "properties": {
-     "endpoints": {
-      "type": "string",
-      "description": "EndpointsName is the endpoint name that details Glusterfs topology. More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod"
-     },
-     "path": {
-      "type": "string",
-      "description": "Path is the Glusterfs volume path. More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod"
-     },
-     "readOnly": {
-      "type": "boolean",
-      "description": "ReadOnly here will force the Glusterfs volume to be mounted with read-only permissions. Defaults to false. More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod"
-     }
-    }
-   },
    "v1.PersistentVolumeClaimVolumeSource": {
     "id": "v1.PersistentVolumeClaimVolumeSource",
     "description": "PersistentVolumeClaimVolumeSource references the user's PVC in the same namespace. This volume finds the bound PV and mounts that volume for the pod. A PersistentVolumeClaimVolumeSource is, essentially, a wrapper around another type of volume that is owned by someone else (the system).",
@@ -22031,7 +21106,7 @@
      },
      "storageMode": {
       "type": "string",
-      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned."
+      "description": "Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned."
      },
      "volumeName": {
       "type": "string",
@@ -22039,7 +21114,7 @@
      },
      "fsType": {
       "type": "string",
-      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\"."
+      "description": "Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified."
      },
      "readOnly": {
       "type": "boolean",
@@ -22129,7 +21204,7 @@
      },
      "resources": {
       "$ref": "v1.ResourceRequirements",
-      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/"
+      "description": "Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"
      },
      "volumeMounts": {
       "type": "array",
@@ -22143,7 +21218,7 @@
       "items": {
        "$ref": "v1.VolumeDevice"
       },
-      "description": "volumeDevices is the list of block devices to be used by the container. This is a beta feature."
+      "description": "volumeDevices is the list of block devices to be used by the container. This is an alpha feature and may change in the future."
      },
      "livenessProbe": {
       "$ref": "v1.Probe",
@@ -22210,7 +21285,7 @@
      },
      "protocol": {
       "type": "string",
-      "description": "Protocol for port. Must be UDP, TCP, or SCTP. Defaults to \"TCP\"."
+      "description": "Protocol for port. Must be UDP or TCP. Defaults to \"TCP\"."
      },
      "hostIP": {
       "type": "string",
@@ -22593,10 +21668,6 @@
      "allowPrivilegeEscalation": {
       "type": "boolean",
       "description": "AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN"
-     },
-     "procMount": {
-      "$ref": "v1.ProcMountType",
-      "description": "procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled."
      }
     }
    },
@@ -22646,10 +21717,6 @@
      }
     }
    },
-   "v1.ProcMountType": {
-    "id": "v1.ProcMountType",
-    "properties": {}
-   },
    "v1.PodSecurityContext": {
     "id": "v1.PodSecurityContext",
     "description": "PodSecurityContext holds pod-level security attributes and common container settings. Some fields are also present in container.securityContext.  Field values of container.securityContext take precedence over field values of PodSecurityContext.",
@@ -23843,7 +22910,7 @@
      },
      "protocol": {
       "type": "string",
-      "description": "The IP protocol for this port. Supports \"TCP\", \"UDP\", and \"SCTP\". Default is TCP."
+      "description": "The IP protocol for this port. Supports \"TCP\" and \"UDP\". Default is TCP."
      },
      "port": {
       "type": "integer",
diff --git a/cmd/kube-controller-manager/app/BUILD b/cmd/kube-controller-manager/app/BUILD
index 49d8221b34..0a9bd71e9c 100644
--- a/cmd/kube-controller-manager/app/BUILD
+++ b/cmd/kube-controller-manager/app/BUILD
@@ -29,7 +29,7 @@ go_library(
         "//pkg/apis/autoscaling/install:go_default_library",
         "//pkg/apis/batch/install:go_default_library",
         "//pkg/apis/certificates/install:go_default_library",
-        "//pkg/apis/coordination/install:go_default_library",
+        "//pkg/apis/componentconfig:go_default_library",
         "//pkg/apis/core/install:go_default_library",
         "//pkg/apis/events/install:go_default_library",
         "//pkg/apis/extensions/install:go_default_library",
@@ -38,15 +38,13 @@ go_library(
         "//pkg/apis/scheduling/install:go_default_library",
         "//pkg/apis/settings/install:go_default_library",
         "//pkg/apis/storage/install:go_default_library",
+        "//pkg/cloudprovider:go_default_library",
         "//pkg/cloudprovider/providers:go_default_library",
         "//pkg/controller:go_default_library",
-        "//pkg/controller/apis/config:go_default_library",
         "//pkg/controller/bootstrap:go_default_library",
         "//pkg/controller/certificates/approver:go_default_library",
         "//pkg/controller/certificates/cleaner:go_default_library",
-        "//pkg/controller/certificates/rootcacertpublisher:go_default_library",
         "//pkg/controller/certificates/signer:go_default_library",
-        "//pkg/controller/cloud:go_default_library",
         "//pkg/controller/clusterroleaggregation:go_default_library",
         "//pkg/controller/cronjob:go_default_library",
         "//pkg/controller/daemon:go_default_library",
@@ -70,15 +68,14 @@ go_library(
         "//pkg/controller/serviceaccount:go_default_library",
         "//pkg/controller/statefulset:go_default_library",
         "//pkg/controller/ttl:go_default_library",
-        "//pkg/controller/ttlafterfinished:go_default_library",
         "//pkg/controller/volume/attachdetach:go_default_library",
         "//pkg/controller/volume/expand:go_default_library",
         "//pkg/controller/volume/persistentvolume:go_default_library",
         "//pkg/controller/volume/pvcprotection:go_default_library",
         "//pkg/controller/volume/pvprotection:go_default_library",
         "//pkg/features:go_default_library",
-        "//pkg/quota/v1/generic:go_default_library",
-        "//pkg/quota/v1/install:go_default_library",
+        "//pkg/quota/generic:go_default_library",
+        "//pkg/quota/install:go_default_library",
         "//pkg/serviceaccount:go_default_library",
         "//pkg/util/configz:go_default_library",
         "//pkg/util/flag:go_default_library",
@@ -86,15 +83,16 @@ go_library(
         "//pkg/version:go_default_library",
         "//pkg/version/verflag:go_default_library",
         "//pkg/volume:go_default_library",
-        "//pkg/volume/awsebs:go_default_library",
+        "//pkg/volume/aws_ebs:go_default_library",
         "//pkg/volume/azure_dd:go_default_library",
         "//pkg/volume/azure_file:go_default_library",
+        "//pkg/volume/cascade_disk:go_default_library",
         "//pkg/volume/cinder:go_default_library",
         "//pkg/volume/csi:go_default_library",
         "//pkg/volume/fc:go_default_library",
         "//pkg/volume/flexvolume:go_default_library",
         "//pkg/volume/flocker:go_default_library",
-        "//pkg/volume/gcepd:go_default_library",
+        "//pkg/volume/gce_pd:go_default_library",
         "//pkg/volume/glusterfs:go_default_library",
         "//pkg/volume/host_path:go_default_library",
         "//pkg/volume/iscsi:go_default_library",
@@ -108,37 +106,28 @@ go_library(
         "//pkg/volume/storageos:go_default_library",
         "//pkg/volume/util:go_default_library",
         "//pkg/volume/vsphere_volume:go_default_library",
-        "//staging/src/k8s.io/api/core/v1:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/runtime/schema:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/util/runtime:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/util/sets:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/util/uuid:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/util/wait:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/server:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/server/healthz:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/server/mux:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/util/feature:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/util/flag:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/util/globalflag:go_default_library",
-        "//staging/src/k8s.io/client-go/discovery/cached:go_default_library",
-        "//staging/src/k8s.io/client-go/dynamic:go_default_library",
-        "//staging/src/k8s.io/client-go/informers:go_default_library",
-        "//staging/src/k8s.io/client-go/kubernetes:go_default_library",
-        "//staging/src/k8s.io/client-go/rest:go_default_library",
-        "//staging/src/k8s.io/client-go/restmapper:go_default_library",
-        "//staging/src/k8s.io/client-go/scale:go_default_library",
-        "//staging/src/k8s.io/client-go/tools/leaderelection:go_default_library",
-        "//staging/src/k8s.io/client-go/tools/leaderelection/resourcelock:go_default_library",
-        "//staging/src/k8s.io/client-go/util/cert:go_default_library",
-        "//staging/src/k8s.io/client-go/util/flowcontrol:go_default_library",
-        "//staging/src/k8s.io/cloud-provider:go_default_library",
-        "//staging/src/k8s.io/csi-api/pkg/client/clientset/versioned:go_default_library",
-        "//staging/src/k8s.io/metrics/pkg/client/clientset/versioned/typed/metrics/v1beta1:go_default_library",
-        "//staging/src/k8s.io/metrics/pkg/client/custom_metrics:go_default_library",
-        "//staging/src/k8s.io/metrics/pkg/client/external_metrics:go_default_library",
+        "//vendor/github.com/golang/glog:go_default_library",
         "//vendor/github.com/spf13/cobra:go_default_library",
-        "//vendor/k8s.io/klog:go_default_library",
-        "//vendor/k8s.io/utils/exec:go_default_library",
+        "//vendor/k8s.io/api/core/v1:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/runtime/schema:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/runtime:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/sets:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/uuid:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/wait:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/util/feature:go_default_library",
+        "//vendor/k8s.io/client-go/discovery/cached:go_default_library",
+        "//vendor/k8s.io/client-go/dynamic:go_default_library",
+        "//vendor/k8s.io/client-go/informers:go_default_library",
+        "//vendor/k8s.io/client-go/kubernetes:go_default_library",
+        "//vendor/k8s.io/client-go/rest:go_default_library",
+        "//vendor/k8s.io/client-go/restmapper:go_default_library",
+        "//vendor/k8s.io/client-go/scale:go_default_library",
+        "//vendor/k8s.io/client-go/tools/leaderelection:go_default_library",
+        "//vendor/k8s.io/client-go/tools/leaderelection/resourcelock:go_default_library",
+        "//vendor/k8s.io/client-go/util/cert:go_default_library",
+        "//vendor/k8s.io/metrics/pkg/client/clientset_generated/clientset/typed/metrics/v1beta1:go_default_library",
+        "//vendor/k8s.io/metrics/pkg/client/custom_metrics:go_default_library",
+        "//vendor/k8s.io/metrics/pkg/client/external_metrics:go_default_library",
     ],
 )
 
@@ -147,8 +136,8 @@ go_test(
     srcs = ["controller_manager_test.go"],
     embed = [":go_default_library"],
     deps = [
-        "//staging/src/k8s.io/apimachinery/pkg/util/sets:go_default_library",
         "//vendor/github.com/stretchr/testify/assert:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/sets:go_default_library",
     ],
 )
 
@@ -165,7 +154,6 @@ filegroup(
         ":package-srcs",
         "//cmd/kube-controller-manager/app/config:all-srcs",
         "//cmd/kube-controller-manager/app/options:all-srcs",
-        "//cmd/kube-controller-manager/app/testing:all-srcs",
     ],
     tags = ["automanaged"],
     visibility = ["//visibility:public"],
diff --git a/cmd/kube-controller-manager/app/plugins.go b/cmd/kube-controller-manager/app/plugins.go
index e56752b22a..e729785006 100644
--- a/cmd/kube-controller-manager/app/plugins.go
+++ b/cmd/kube-controller-manager/app/plugins.go
@@ -23,22 +23,24 @@ import (
 
 	"fmt"
 
-	"k8s.io/klog"
-
 	// Cloud providers
-	cloudprovider "k8s.io/cloud-provider"
+	"k8s.io/kubernetes/pkg/apis/componentconfig"
 	_ "k8s.io/kubernetes/pkg/cloudprovider/providers"
+
 	// Volume plugins
+	"github.com/golang/glog"
+	"k8s.io/kubernetes/pkg/cloudprovider"
 	"k8s.io/kubernetes/pkg/volume"
-	"k8s.io/kubernetes/pkg/volume/awsebs"
+	"k8s.io/kubernetes/pkg/volume/aws_ebs"
 	"k8s.io/kubernetes/pkg/volume/azure_dd"
 	"k8s.io/kubernetes/pkg/volume/azure_file"
+	"k8s.io/kubernetes/pkg/volume/cascade_disk"
 	"k8s.io/kubernetes/pkg/volume/cinder"
 	"k8s.io/kubernetes/pkg/volume/csi"
 	"k8s.io/kubernetes/pkg/volume/fc"
 	"k8s.io/kubernetes/pkg/volume/flexvolume"
 	"k8s.io/kubernetes/pkg/volume/flocker"
-	"k8s.io/kubernetes/pkg/volume/gcepd"
+	"k8s.io/kubernetes/pkg/volume/gce_pd"
 	"k8s.io/kubernetes/pkg/volume/glusterfs"
 	"k8s.io/kubernetes/pkg/volume/host_path"
 	"k8s.io/kubernetes/pkg/volume/iscsi"
@@ -54,9 +56,7 @@ import (
 	"k8s.io/kubernetes/pkg/volume/vsphere_volume"
 
 	utilfeature "k8s.io/apiserver/pkg/util/feature"
-	kubectrlmgrconfig "k8s.io/kubernetes/pkg/controller/apis/config"
 	"k8s.io/kubernetes/pkg/features"
-	"k8s.io/utils/exec"
 )
 
 // ProbeAttachableVolumePlugins collects all volume plugins for the attach/
@@ -66,8 +66,8 @@ import (
 func ProbeAttachableVolumePlugins() []volume.VolumePlugin {
 	allPlugins := []volume.VolumePlugin{}
 
-	allPlugins = append(allPlugins, awsebs.ProbeVolumePlugins()...)
-	allPlugins = append(allPlugins, gcepd.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, aws_ebs.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, gce_pd.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, cinder.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, portworx.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, vsphere_volume.ProbeVolumePlugins()...)
@@ -78,6 +78,7 @@ func ProbeAttachableVolumePlugins() []volume.VolumePlugin {
 	allPlugins = append(allPlugins, fc.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, iscsi.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, rbd.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, cascade_disk.ProbeVolumePlugins()...)
 	if utilfeature.DefaultFeatureGate.Enabled(features.CSIPersistentVolume) {
 		allPlugins = append(allPlugins, csi.ProbeVolumePlugins()...)
 	}
@@ -87,16 +88,16 @@ func ProbeAttachableVolumePlugins() []volume.VolumePlugin {
 // GetDynamicPluginProber gets the probers of dynamically discoverable plugins
 // for the attach/detach controller.
 // Currently only Flexvolume plugins are dynamically discoverable.
-func GetDynamicPluginProber(config kubectrlmgrconfig.VolumeConfiguration) volume.DynamicPluginProber {
-	return flexvolume.GetDynamicPluginProber(config.FlexVolumePluginDir, exec.New() /*exec.Interface*/)
+func GetDynamicPluginProber(config componentconfig.VolumeConfiguration) volume.DynamicPluginProber {
+	return flexvolume.GetDynamicPluginProber(config.FlexVolumePluginDir)
 }
 
 // ProbeExpandableVolumePlugins returns volume plugins which are expandable
-func ProbeExpandableVolumePlugins(config kubectrlmgrconfig.VolumeConfiguration) []volume.VolumePlugin {
+func ProbeExpandableVolumePlugins(config componentconfig.VolumeConfiguration) []volume.VolumePlugin {
 	allPlugins := []volume.VolumePlugin{}
 
-	allPlugins = append(allPlugins, awsebs.ProbeVolumePlugins()...)
-	allPlugins = append(allPlugins, gcepd.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, aws_ebs.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, gce_pd.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, cinder.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, portworx.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, vsphere_volume.ProbeVolumePlugins()...)
@@ -108,13 +109,14 @@ func ProbeExpandableVolumePlugins(config kubectrlmgrconfig.VolumeConfiguration)
 	allPlugins = append(allPlugins, scaleio.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, storageos.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, fc.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, cascade_disk.ProbeVolumePlugins()...)
 	return allPlugins
 }
 
 // ProbeControllerVolumePlugins collects all persistent volume plugins into an
 // easy to use list. Only volume plugins that implement any of
 // provisioner/recycler/deleter interface should be returned.
-func ProbeControllerVolumePlugins(cloud cloudprovider.Interface, config kubectrlmgrconfig.VolumeConfiguration) []volume.VolumePlugin {
+func ProbeControllerVolumePlugins(cloud cloudprovider.Interface, config componentconfig.VolumeConfiguration) []volume.VolumePlugin {
 	allPlugins := []volume.VolumePlugin{}
 
 	// The list of plugins to probe is decided by this binary, not
@@ -133,7 +135,7 @@ func ProbeControllerVolumePlugins(cloud cloudprovider.Interface, config kubectrl
 		ProvisioningEnabled:      config.EnableHostPathProvisioning,
 	}
 	if err := AttemptToLoadRecycler(config.PersistentVolumeRecyclerConfiguration.PodTemplateFilePathHostPath, &hostPathConfig); err != nil {
-		klog.Fatalf("Could not create hostpath recycler pod from file %s: %+v", config.PersistentVolumeRecyclerConfiguration.PodTemplateFilePathHostPath, err)
+		glog.Fatalf("Could not create hostpath recycler pod from file %s: %+v", config.PersistentVolumeRecyclerConfiguration.PodTemplateFilePathHostPath, err)
 	}
 	allPlugins = append(allPlugins, host_path.ProbeVolumePlugins(hostPathConfig)...)
 
@@ -143,7 +145,7 @@ func ProbeControllerVolumePlugins(cloud cloudprovider.Interface, config kubectrl
 		RecyclerPodTemplate:      volume.NewPersistentVolumeRecyclerPodTemplate(),
 	}
 	if err := AttemptToLoadRecycler(config.PersistentVolumeRecyclerConfiguration.PodTemplateFilePathNFS, &nfsConfig); err != nil {
-		klog.Fatalf("Could not create NFS recycler pod from file %s: %+v", config.PersistentVolumeRecyclerConfiguration.PodTemplateFilePathNFS, err)
+		glog.Fatalf("Could not create NFS recycler pod from file %s: %+v", config.PersistentVolumeRecyclerConfiguration.PodTemplateFilePathNFS, err)
 	}
 	allPlugins = append(allPlugins, nfs.ProbeVolumePlugins(nfsConfig)...)
 	allPlugins = append(allPlugins, glusterfs.ProbeVolumePlugins()...)
@@ -158,12 +160,13 @@ func ProbeControllerVolumePlugins(cloud cloudprovider.Interface, config kubectrl
 	allPlugins = append(allPlugins, local.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, storageos.ProbeVolumePlugins()...)
 
-	allPlugins = append(allPlugins, awsebs.ProbeVolumePlugins()...)
-	allPlugins = append(allPlugins, gcepd.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, aws_ebs.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, gce_pd.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, cinder.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, vsphere_volume.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, azure_dd.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, photon_pd.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, cascade_disk.ProbeVolumePlugins()...)
 
 	return allPlugins
 }
diff --git a/cmd/kubelet/app/BUILD b/cmd/kubelet/app/BUILD
index 59e5a93605..278970c4cb 100644
--- a/cmd/kubelet/app/BUILD
+++ b/cmd/kubelet/app/BUILD
@@ -8,41 +8,71 @@ load(
 
 go_test(
     name = "go_default_test",
-    srcs = [
-        "server_bootstrap_test.go",
-        "server_test.go",
-    ],
+    srcs = ["server_test.go"],
     embed = [":go_default_library"],
-    deps = [
-        "//staging/src/k8s.io/api/certificates/v1beta1:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/apis/meta/v1:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/runtime:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/types:go_default_library",
-        "//staging/src/k8s.io/client-go/rest:go_default_library",
-        "//staging/src/k8s.io/client-go/util/cert:go_default_library",
-        "//vendor/github.com/cloudflare/cfssl/config:go_default_library",
-        "//vendor/github.com/cloudflare/cfssl/signer:go_default_library",
-        "//vendor/github.com/cloudflare/cfssl/signer/local:go_default_library",
-    ],
 )
 
 go_library(
     name = "go_default_library",
     srcs = [
         "auth.go",
-        "init_others.go",
-        "init_windows.go",
         "plugins.go",
         "server.go",
-        "server_linux.go",
-        "server_unsupported.go",
-    ],
+    ] + select({
+        "@io_bazel_rules_go//go/platform:android": [
+            "init_others.go",
+            "server_unsupported.go",
+        ],
+        "@io_bazel_rules_go//go/platform:darwin": [
+            "init_others.go",
+            "server_unsupported.go",
+        ],
+        "@io_bazel_rules_go//go/platform:dragonfly": [
+            "init_others.go",
+            "server_unsupported.go",
+        ],
+        "@io_bazel_rules_go//go/platform:freebsd": [
+            "init_others.go",
+            "server_unsupported.go",
+        ],
+        "@io_bazel_rules_go//go/platform:linux": [
+            "init_others.go",
+            "server_linux.go",
+        ],
+        "@io_bazel_rules_go//go/platform:nacl": [
+            "init_others.go",
+            "server_unsupported.go",
+        ],
+        "@io_bazel_rules_go//go/platform:netbsd": [
+            "init_others.go",
+            "server_unsupported.go",
+        ],
+        "@io_bazel_rules_go//go/platform:openbsd": [
+            "init_others.go",
+            "server_unsupported.go",
+        ],
+        "@io_bazel_rules_go//go/platform:plan9": [
+            "init_others.go",
+            "server_unsupported.go",
+        ],
+        "@io_bazel_rules_go//go/platform:solaris": [
+            "init_others.go",
+            "server_unsupported.go",
+        ],
+        "@io_bazel_rules_go//go/platform:windows": [
+            "init_windows.go",
+            "server_unsupported.go",
+        ],
+        "//conditions:default": [],
+    }),
     importpath = "k8s.io/kubernetes/cmd/kubelet/app",
     deps = [
         "//cmd/kubelet/app/options:go_default_library",
         "//pkg/api/legacyscheme:go_default_library",
         "//pkg/apis/core:go_default_library",
         "//pkg/capabilities:go_default_library",
+        "//pkg/client/chaosclient:go_default_library",
+        "//pkg/cloudprovider:go_default_library",
         "//pkg/cloudprovider/providers:go_default_library",
         "//pkg/credentialprovider:go_default_library",
         "//pkg/credentialprovider/aws:go_default_library",
@@ -51,9 +81,10 @@ go_library(
         "//pkg/credentialprovider/rancher:go_default_library",
         "//pkg/features:go_default_library",
         "//pkg/kubelet:go_default_library",
-        "//pkg/kubelet/apis/config:go_default_library",
-        "//pkg/kubelet/apis/config/scheme:go_default_library",
-        "//pkg/kubelet/apis/config/validation:go_default_library",
+        "//pkg/kubelet/apis/kubeletconfig:go_default_library",
+        "//pkg/kubelet/apis/kubeletconfig/scheme:go_default_library",
+        "//pkg/kubelet/apis/kubeletconfig/v1beta1:go_default_library",
+        "//pkg/kubelet/apis/kubeletconfig/validation:go_default_library",
         "//pkg/kubelet/cadvisor:go_default_library",
         "//pkg/kubelet/certificate:go_default_library",
         "//pkg/kubelet/certificate/bootstrap:go_default_library",
@@ -61,6 +92,9 @@ go_library(
         "//pkg/kubelet/config:go_default_library",
         "//pkg/kubelet/container:go_default_library",
         "//pkg/kubelet/dockershim:go_default_library",
+        "//pkg/kubelet/dockershim/network:go_default_library",
+        "//pkg/kubelet/dockershim/network/cni:go_default_library",
+        "//pkg/kubelet/dockershim/network/kubenet:go_default_library",
         "//pkg/kubelet/dockershim/remote:go_default_library",
         "//pkg/kubelet/eviction:go_default_library",
         "//pkg/kubelet/eviction/api:go_default_library",
@@ -73,6 +107,7 @@ go_library(
         "//pkg/util/filesystem:go_default_library",
         "//pkg/util/flag:go_default_library",
         "//pkg/util/flock:go_default_library",
+        "//pkg/util/io:go_default_library",
         "//pkg/util/mount:go_default_library",
         "//pkg/util/node:go_default_library",
         "//pkg/util/nsenter:go_default_library",
@@ -81,19 +116,20 @@ go_library(
         "//pkg/version:go_default_library",
         "//pkg/version/verflag:go_default_library",
         "//pkg/volume:go_default_library",
-        "//pkg/volume/awsebs:go_default_library",
+        "//pkg/volume/aws_ebs:go_default_library",
         "//pkg/volume/azure_dd:go_default_library",
         "//pkg/volume/azure_file:go_default_library",
+        "//pkg/volume/cascade_disk:go_default_library",
         "//pkg/volume/cephfs:go_default_library",
         "//pkg/volume/cinder:go_default_library",
         "//pkg/volume/configmap:go_default_library",
         "//pkg/volume/csi:go_default_library",
         "//pkg/volume/downwardapi:go_default_library",
-        "//pkg/volume/emptydir:go_default_library",
+        "//pkg/volume/empty_dir:go_default_library",
         "//pkg/volume/fc:go_default_library",
         "//pkg/volume/flexvolume:go_default_library",
         "//pkg/volume/flocker:go_default_library",
-        "//pkg/volume/gcepd:go_default_library",
+        "//pkg/volume/gce_pd:go_default_library",
         "//pkg/volume/git_repo:go_default_library",
         "//pkg/volume/glusterfs:go_default_library",
         "//pkg/volume/host_path:go_default_library",
@@ -109,42 +145,37 @@ go_library(
         "//pkg/volume/secret:go_default_library",
         "//pkg/volume/storageos:go_default_library",
         "//pkg/volume/vsphere_volume:go_default_library",
-        "//staging/src/k8s.io/api/core/v1:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/api/resource:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/apis/meta/v1:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/types:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/util/runtime:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/util/sets:go_default_library",
-        "//staging/src/k8s.io/apimachinery/pkg/util/wait:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/authentication/authenticator:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/authentication/authenticatorfactory:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/authorization/authorizer:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/authorization/authorizerfactory:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/server/healthz:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/util/feature:go_default_library",
-        "//staging/src/k8s.io/apiserver/pkg/util/flag:go_default_library",
-        "//staging/src/k8s.io/client-go/dynamic:go_default_library",
-        "//staging/src/k8s.io/client-go/kubernetes:go_default_library",
-        "//staging/src/k8s.io/client-go/kubernetes/typed/authentication/v1beta1:go_default_library",
-        "//staging/src/k8s.io/client-go/kubernetes/typed/authorization/v1beta1:go_default_library",
-        "//staging/src/k8s.io/client-go/kubernetes/typed/certificates/v1beta1:go_default_library",
-        "//staging/src/k8s.io/client-go/kubernetes/typed/core/v1:go_default_library",
-        "//staging/src/k8s.io/client-go/rest:go_default_library",
-        "//staging/src/k8s.io/client-go/tools/clientcmd:go_default_library",
-        "//staging/src/k8s.io/client-go/tools/record:go_default_library",
-        "//staging/src/k8s.io/client-go/util/cert:go_default_library",
-        "//staging/src/k8s.io/client-go/util/certificate:go_default_library",
-        "//staging/src/k8s.io/cloud-provider:go_default_library",
-        "//staging/src/k8s.io/csi-api/pkg/client/clientset/versioned:go_default_library",
-        "//staging/src/k8s.io/kubelet/config/v1beta1:go_default_library",
         "//vendor/github.com/coreos/go-systemd/daemon:go_default_library",
+        "//vendor/github.com/golang/glog:go_default_library",
         "//vendor/github.com/spf13/cobra:go_default_library",
         "//vendor/github.com/spf13/pflag:go_default_library",
-        "//vendor/k8s.io/klog:go_default_library",
+        "//vendor/k8s.io/api/core/v1:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/api/resource:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/apis/meta/v1:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/types:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/runtime:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/sets:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/wait:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/authentication/authenticator:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/authentication/authenticatorfactory:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/authorization/authorizer:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/authorization/authorizerfactory:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/server/healthz:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/util/feature:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/util/flag:go_default_library",
+        "//vendor/k8s.io/client-go/kubernetes:go_default_library",
+        "//vendor/k8s.io/client-go/kubernetes/typed/authentication/v1beta1:go_default_library",
+        "//vendor/k8s.io/client-go/kubernetes/typed/authorization/v1beta1:go_default_library",
+        "//vendor/k8s.io/client-go/kubernetes/typed/core/v1:go_default_library",
+        "//vendor/k8s.io/client-go/rest:go_default_library",
+        "//vendor/k8s.io/client-go/tools/clientcmd:go_default_library",
+        "//vendor/k8s.io/client-go/tools/record:go_default_library",
+        "//vendor/k8s.io/client-go/util/cert:go_default_library",
+        "//vendor/k8s.io/client-go/util/certificate:go_default_library",
         "//vendor/k8s.io/utils/exec:go_default_library",
     ] + select({
         "@io_bazel_rules_go//go/platform:linux": [
-            "//vendor/github.com/sigma/go-inotify:go_default_library",
+            "//vendor/golang.org/x/exp/inotify:go_default_library",
         ],
         "@io_bazel_rules_go//go/platform:windows": [
             "//pkg/windows/service:go_default_library",
diff --git a/cmd/kubelet/app/plugins.go b/cmd/kubelet/app/plugins.go
index 5f8ceed7b0..540e5016a1 100644
--- a/cmd/kubelet/app/plugins.go
+++ b/cmd/kubelet/app/plugins.go
@@ -23,22 +23,26 @@ import (
 	_ "k8s.io/kubernetes/pkg/credentialprovider/azure"
 	_ "k8s.io/kubernetes/pkg/credentialprovider/gcp"
 	_ "k8s.io/kubernetes/pkg/credentialprovider/rancher"
-	"k8s.io/utils/exec"
+	// Network plugins
+	"k8s.io/kubernetes/pkg/kubelet/dockershim/network"
+	"k8s.io/kubernetes/pkg/kubelet/dockershim/network/cni"
+	"k8s.io/kubernetes/pkg/kubelet/dockershim/network/kubenet"
 	// Volume plugins
 	"k8s.io/kubernetes/pkg/volume"
-	"k8s.io/kubernetes/pkg/volume/awsebs"
+	"k8s.io/kubernetes/pkg/volume/aws_ebs"
 	"k8s.io/kubernetes/pkg/volume/azure_dd"
 	"k8s.io/kubernetes/pkg/volume/azure_file"
+	"k8s.io/kubernetes/pkg/volume/cascade_disk"
 	"k8s.io/kubernetes/pkg/volume/cephfs"
 	"k8s.io/kubernetes/pkg/volume/cinder"
 	"k8s.io/kubernetes/pkg/volume/configmap"
 	"k8s.io/kubernetes/pkg/volume/csi"
 	"k8s.io/kubernetes/pkg/volume/downwardapi"
-	"k8s.io/kubernetes/pkg/volume/emptydir"
+	"k8s.io/kubernetes/pkg/volume/empty_dir"
 	"k8s.io/kubernetes/pkg/volume/fc"
 	"k8s.io/kubernetes/pkg/volume/flexvolume"
 	"k8s.io/kubernetes/pkg/volume/flocker"
-	"k8s.io/kubernetes/pkg/volume/gcepd"
+	"k8s.io/kubernetes/pkg/volume/gce_pd"
 	"k8s.io/kubernetes/pkg/volume/git_repo"
 	"k8s.io/kubernetes/pkg/volume/glusterfs"
 	"k8s.io/kubernetes/pkg/volume/host_path"
@@ -71,9 +75,9 @@ func ProbeVolumePlugins() []volume.VolumePlugin {
 	//
 	// Kubelet does not currently need to configure volume plugins.
 	// If/when it does, see kube-controller-manager/app/plugins.go for example of using volume.VolumeConfig
-	allPlugins = append(allPlugins, awsebs.ProbeVolumePlugins()...)
-	allPlugins = append(allPlugins, emptydir.ProbeVolumePlugins()...)
-	allPlugins = append(allPlugins, gcepd.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, aws_ebs.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, empty_dir.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, gce_pd.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, git_repo.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, host_path.ProbeVolumePlugins(volume.VolumeConfig{})...)
 	allPlugins = append(allPlugins, nfs.ProbeVolumePlugins(volume.VolumeConfig{})...)
@@ -97,6 +101,7 @@ func ProbeVolumePlugins() []volume.VolumePlugin {
 	allPlugins = append(allPlugins, scaleio.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, local.ProbeVolumePlugins()...)
 	allPlugins = append(allPlugins, storageos.ProbeVolumePlugins()...)
+	allPlugins = append(allPlugins, cascade_disk.ProbeVolumePlugins()...)
 	if utilfeature.DefaultFeatureGate.Enabled(features.CSIPersistentVolume) {
 		allPlugins = append(allPlugins, csi.ProbeVolumePlugins()...)
 	}
@@ -106,6 +111,17 @@ func ProbeVolumePlugins() []volume.VolumePlugin {
 // GetDynamicPluginProber gets the probers of dynamically discoverable plugins
 // for kubelet.
 // Currently only Flexvolume plugins are dynamically discoverable.
-func GetDynamicPluginProber(pluginDir string, runner exec.Interface) volume.DynamicPluginProber {
-	return flexvolume.GetDynamicPluginProber(pluginDir, runner)
+func GetDynamicPluginProber(pluginDir string) volume.DynamicPluginProber {
+	return flexvolume.GetDynamicPluginProber(pluginDir)
+}
+
+// ProbeNetworkPlugins collects all compiled-in plugins
+func ProbeNetworkPlugins(cniConfDir string, cniBinDirs []string) []network.NetworkPlugin {
+	allPlugins := []network.NetworkPlugin{}
+
+	// for each existing plugin, add to the list
+	allPlugins = append(allPlugins, cni.ProbeNetworkPlugins(cniConfDir, cniBinDirs)...)
+	allPlugins = append(allPlugins, kubenet.NewPlugin(cniBinDirs))
+
+	return allPlugins
 }
diff --git a/pkg/apis/core/types.go b/pkg/apis/core/types.go
index 251547f601..60ba08e91b 100644
--- a/pkg/apis/core/types.go
+++ b/pkg/apis/core/types.go
@@ -26,19 +26,17 @@ import (
 
 const (
 	// NamespaceDefault means the object is in the default namespace which is applied when not specified by clients
-	NamespaceDefault = "default"
+	NamespaceDefault string = "default"
 	// NamespaceAll is the default argument to specify on a context when you want to list or filter resources across all namespaces
-	NamespaceAll = ""
+	NamespaceAll string = ""
 	// NamespaceNone is the argument for a context when there is no namespace.
-	NamespaceNone = ""
+	NamespaceNone string = ""
 	// NamespaceSystem is the system namespace where we place system components.
-	NamespaceSystem = "kube-system"
+	NamespaceSystem string = "kube-system"
 	// NamespacePublic is the namespace where we place public info (ConfigMaps)
-	NamespacePublic = "kube-public"
-	// NamespaceNodeLease is the namespace where we place node lease objects (used for node heartbeats)
-	NamespaceNodeLease = "kube-node-lease"
+	NamespacePublic string = "kube-public"
 	// TerminationMessagePathDefault means the default path to capture the application termination message running in a container
-	TerminationMessagePathDefault = "/dev/termination-log"
+	TerminationMessagePathDefault string = "/dev/termination-log"
 )
 
 // Volume represents a named volume in a pod that may be accessed by any containers in the pod.
@@ -154,6 +152,8 @@ type VolumeSource struct {
 	// StorageOS represents a StorageOS volume that is attached to the kubelet's host machine and mounted into the pod
 	// +optional
 	StorageOS *StorageOSVolumeSource
+	// CascadeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine
+	CascadeDisk *CascadeDiskVolumeSource
 }
 
 // Similar to VolumeSource but meant for the administrator who creates PVs.
@@ -175,7 +175,7 @@ type PersistentVolumeSource struct {
 	HostPath *HostPathVolumeSource
 	// Glusterfs represents a Glusterfs volume that is attached to a host and exposed to the pod
 	// +optional
-	Glusterfs *GlusterfsPersistentVolumeSource
+	Glusterfs *GlusterfsVolumeSource
 	// NFS represents an NFS mount on the host that shares a pod's lifetime
 	// +optional
 	NFS *NFSVolumeSource
@@ -229,9 +229,11 @@ type PersistentVolumeSource struct {
 	// More info: https://releases.k8s.io/HEAD/examples/volumes/storageos/README.md
 	// +optional
 	StorageOS *StorageOSPersistentVolumeSource
-	// CSI (Container Storage Interface) represents storage that handled by an external CSI driver.
+	// CSI (Container Storage Interface) represents storage that handled by an external CSI driver (Beta feature).
 	// +optional
 	CSI *CSIPersistentVolumeSource
+	// CascadeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine
+	CascadeDisk *CascadeDiskVolumeSource
 }
 
 type PersistentVolumeClaimVolumeSource struct {
@@ -298,7 +300,7 @@ type PersistentVolumeSpec struct {
 	MountOptions []string
 	// volumeMode defines if a volume is intended to be used with a formatted filesystem
 	// or to remain in raw block state. Value of Filesystem is implied when not included in spec.
-	// This is a beta feature.
+	// This is an alpha feature and may change in the future.
 	// +optional
 	VolumeMode *PersistentVolumeMode
 	// NodeAffinity defines constraints that limit what nodes this volume can be accessed from.
@@ -410,19 +412,9 @@ type PersistentVolumeClaimSpec struct {
 	StorageClassName *string
 	// volumeMode defines what type of volume is required by the claim.
 	// Value of Filesystem is implied when not included in claim spec.
-	// This is a beta feature.
+	// This is an alpha feature and may change in the future.
 	// +optional
 	VolumeMode *PersistentVolumeMode
-	// This field requires the VolumeSnapshotDataSource alpha feature gate to be
-	// enabled and currently VolumeSnapshot is the only supported data source.
-	// If the provisioner can support VolumeSnapshot data source, it will create
-	// a new volume and data will be restored to the volume at the same time.
-	// If the provisioner does not support VolumeSnapshot data source, volume will
-	// not be created and the failure will be reported as an event.
-	// In the future, we plan to support more data source types and the behavior
-	// of the provisioner may change.
-	// +optional
-	DataSource *TypedLocalObjectReference
 }
 
 type PersistentVolumeClaimConditionType string
@@ -574,8 +566,6 @@ const (
 	ProtocolTCP Protocol = "TCP"
 	// ProtocolUDP is the UDP protocol.
 	ProtocolUDP Protocol = "UDP"
-	// ProtocolSCTP is the SCTP protocol.
-	ProtocolSCTP Protocol = "SCTP"
 )
 
 // Represents a Persistent Disk resource in Google Compute Engine.
@@ -935,30 +925,6 @@ type GlusterfsVolumeSource struct {
 	ReadOnly bool
 }
 
-// Represents a Glusterfs mount that lasts the lifetime of a pod.
-// Glusterfs volumes do not support ownership management or SELinux relabeling.
-type GlusterfsPersistentVolumeSource struct {
-	// EndpointsName is the endpoint name that details Glusterfs topology.
-	// More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod
-	EndpointsName string
-
-	// Path is the Glusterfs volume path.
-	// More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod
-	Path string
-
-	// ReadOnly here will force the Glusterfs volume to be mounted with read-only permissions.
-	// Defaults to false.
-	// More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod
-	// +optional
-	ReadOnly bool
-
-	// EndpointsNamespace is the namespace that contains Glusterfs endpoint.
-	// If this field is empty, the EndpointNamespace defaults to the same namespace as the bound PVC.
-	// More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod
-	// +optional
-	EndpointsNamespace *string
-}
-
 // Represents a Rados Block Device mount that lasts the lifetime of a pod.
 // RBD volumes support ownership management and SELinux relabeling.
 type RBDVolumeSource struct {
@@ -1302,7 +1268,6 @@ type ScaleIOVolumeSource struct {
 	// +optional
 	StoragePool string
 	// Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned.
-	// Default is ThinProvisioned.
 	// +optional
 	StorageMode string
 	// The name of a volume already created in the ScaleIO system
@@ -1310,8 +1275,7 @@ type ScaleIOVolumeSource struct {
 	VolumeName string
 	// Filesystem type to mount.
 	// Must be a filesystem type supported by the host operating system.
-	// Ex. "ext4", "xfs", "ntfs".
-	// Default is "xfs".
+	// Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
 	// +optional
 	FSType string
 	// Defaults to false (read/write). ReadOnly here will force
@@ -1340,7 +1304,6 @@ type ScaleIOPersistentVolumeSource struct {
 	// +optional
 	StoragePool string
 	// Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned.
-	// Default is ThinProvisioned.
 	// +optional
 	StorageMode string
 	// The name of a volume created in the ScaleIO system
@@ -1348,8 +1311,7 @@ type ScaleIOPersistentVolumeSource struct {
 	VolumeName string
 	// Filesystem type to mount.
 	// Must be a filesystem type supported by the host operating system.
-	// Ex. "ext4", "xfs", "ntfs".
-	// Default is "xfs".
+	// Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
 	// +optional
 	FSType string
 	// Defaults to false (read/write). ReadOnly here will force
@@ -1414,6 +1376,16 @@ type StorageOSPersistentVolumeSource struct {
 	SecretRef *ObjectReference
 }
 
+// Represents a Cascade persistent disk resource.
+type CascadeDiskVolumeSource struct {
+	// ID that identifies Cascade persistent disk
+	DiskID string
+	// Filesystem type to mount.
+	// Must be a filesystem type supported by the host operating system.
+	// Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
+	FSType string
+}
+
 // Adapts a ConfigMap into a volume.
 //
 // The contents of the target ConfigMap's Data field will be presented in a
@@ -1537,17 +1509,13 @@ type KeyToPath struct {
 type LocalVolumeSource struct {
 	// The full path to the volume on the node.
 	// It can be either a directory or block device (disk, partition, ...).
+	// Directories can be represented only by PersistentVolume with VolumeMode=Filesystem.
+	// Block devices can be represented only by VolumeMode=Block, which also requires the
+	// BlockVolume alpha feature gate to be enabled.
 	Path string
-
-	// Filesystem type to mount.
-	// It applies only when the Path is a block device.
-	// Must be a filesystem type supported by the host operating system.
-	// Ex. "ext4", "xfs", "ntfs". The default value is to auto-select a fileystem if unspecified.
-	// +optional
-	FSType *string
 }
 
-// Represents storage that is managed by an external CSI volume driver.
+// Represents storage that is managed by an external CSI volume driver (Beta feature)
 type CSIPersistentVolumeSource struct {
 	// Driver is the name of the driver to use for this volume.
 	// Required.
@@ -1576,7 +1544,7 @@ type CSIPersistentVolumeSource struct {
 	// ControllerPublishSecretRef is a reference to the secret object containing
 	// sensitive information to pass to the CSI driver to complete the CSI
 	// ControllerPublishVolume and ControllerUnpublishVolume calls.
-	// This field is optional, and may be empty if no secret is required. If the
+	// This field is optional, and  may be empty if no secret is required. If the
 	// secret object contains more than one secret, all secrets are passed.
 	// +optional
 	ControllerPublishSecretRef *SecretReference
@@ -1584,7 +1552,7 @@ type CSIPersistentVolumeSource struct {
 	// NodeStageSecretRef is a reference to the secret object containing sensitive
 	// information to pass to the CSI driver to complete the CSI NodeStageVolume
 	// and NodeStageVolume and NodeUnstageVolume calls.
-	// This field is optional, and may be empty if no secret is required. If the
+	// This field is optional, and  may be empty if no secret is required. If the
 	// secret object contains more than one secret, all secrets are passed.
 	// +optional
 	NodeStageSecretRef *SecretReference
@@ -1592,7 +1560,7 @@ type CSIPersistentVolumeSource struct {
 	// NodePublishSecretRef is a reference to the secret object containing
 	// sensitive information to pass to the CSI driver to complete the CSI
 	// NodePublishVolume and NodeUnpublishVolume calls.
-	// This field is optional, and may be empty if no secret is required. If the
+	// This field is optional, and  may be empty if no secret is required. If the
 	// secret object contains more than one secret, all secrets are passed.
 	// +optional
 	NodePublishSecretRef *SecretReference
@@ -1610,7 +1578,7 @@ type ContainerPort struct {
 	HostPort int32
 	// Required: This must be a valid port number, 0 < x < 65536.
 	ContainerPort int32
-	// Required: Supports "TCP", "UDP" and "SCTP"
+	// Required: Supports "TCP" and "UDP".
 	// +optional
 	Protocol Protocol
 	// Optional: What host IP to bind the external port to.
@@ -1968,7 +1936,7 @@ type Container struct {
 	// +optional
 	VolumeMounts []VolumeMount
 	// volumeDevices is the list of block devices to be used by the container.
-	// This is a beta feature.
+	// This is an alpha feature and may change in the future.
 	// +optional
 	VolumeDevices []VolumeDevice
 	// +optional
@@ -2613,19 +2581,6 @@ type PodSpec struct {
 	// More info: https://github.com/kubernetes/community/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md
 	// +optional
 	ReadinessGates []PodReadinessGate
-	// RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used
-	// to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run.
-	// If unset or empty, the "legacy" RuntimeClass will be used, which is an implicit class with an
-	// empty definition that uses the default runtime handler.
-	// More info: https://github.com/kubernetes/community/blob/master/keps/sig-node/0014-runtime-class.md
-	// This is an alpha feature and may change in the future.
-	// +optional
-	RuntimeClassName *string
-	// EnableServiceLinks indicates whether information about services should be injected into pod's
-	// environment variables, matching the syntax of Docker links.
-	// If not specified, the default is true.
-	// +optional
-	EnableServiceLinks *bool
 }
 
 // HostAlias holds the mapping between IP and hostnames that will be injected as an entry in the
@@ -2668,7 +2623,7 @@ type PodSecurityContext struct {
 	// in the same pod, and the first process in each container will not be assigned PID 1.
 	// HostPID and ShareProcessNamespace cannot both be set.
 	// Optional: Default to false.
-	// This field is beta-level and may be disabled with the PodShareProcessNamespace feature.
+	// This field is alpha-level and is honored only by servers that enable the PodShareProcessNamespace feature.
 	// +k8s:conversion-gen=false
 	// +optional
 	ShareProcessNamespace *bool
@@ -3220,7 +3175,7 @@ type ServicePort struct {
 	// the 'Name' field in EndpointPort objects.
 	Name string
 
-	// The IP protocol for this port.  Supports "TCP", "UDP", and "SCTP".
+	// The IP protocol for this port.  Supports "TCP" and "UDP".
 	Protocol Protocol
 
 	// The port that will be exposed on the service.
@@ -4003,19 +3958,6 @@ type LocalObjectReference struct {
 	Name string
 }
 
-// TypedLocalObjectReference contains enough information to let you locate the typed referenced object inside the same namespace.
-type TypedLocalObjectReference struct {
-	// APIGroup is the group for the resource being referenced.
-	// If APIGroup is not specified, the specified Kind must be in the core API group.
-	// For any other third-party types, APIGroup is required.
-	// +optional
-	APIGroup *string
-	// Kind is the type of resource being referenced
-	Kind string
-	// Name is the name of resource being referenced
-	Name string
-}
-
 // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
 
 type SerializedReference struct {
@@ -4652,27 +4594,8 @@ type SecurityContext struct {
 	// the no_new_privs flag will be set on the container process.
 	// +optional
 	AllowPrivilegeEscalation *bool
-	// ProcMount denotes the type of proc mount to use for the containers.
-	// The default is DefaultProcMount which uses the container runtime defaults for
-	// readonly paths and masked paths.
-	// +optional
-	ProcMount *ProcMountType
 }
 
-type ProcMountType string
-
-const (
-	// DefaultProcMount uses the container runtime defaults for readonly and masked
-	// paths for /proc.  Most container runtimes mask certain paths in /proc to avoid
-	// accidental security exposure of special devices or information.
-	DefaultProcMount ProcMountType = "Default"
-
-	// UnmaskedProcMount bypasses the default masking behavior of the container
-	// runtime and ensures the newly created /proc the container stays intact with
-	// no modifications.
-	UnmaskedProcMount ProcMountType = "Unmasked"
-)
-
 // SELinuxOptions are the labels to be applied to the container.
 type SELinuxOptions struct {
 	// SELinux user label
diff --git a/pkg/apis/core/validation/validation.go b/pkg/apis/core/validation/validation.go
index 2b56826fbb..cf15bb705d 100644
--- a/pkg/apis/core/validation/validation.go
+++ b/pkg/apis/core/validation/validation.go
@@ -27,7 +27,7 @@ import (
 	"regexp"
 	"strings"
 
-	"k8s.io/klog"
+	"github.com/golang/glog"
 
 	"k8s.io/api/core/v1"
 	apiequality "k8s.io/apimachinery/pkg/api/equality"
@@ -36,7 +36,6 @@ import (
 	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
 	unversionedvalidation "k8s.io/apimachinery/pkg/apis/meta/v1/validation"
 	"k8s.io/apimachinery/pkg/labels"
-	"k8s.io/apimachinery/pkg/runtime/schema"
 	"k8s.io/apimachinery/pkg/util/diff"
 	"k8s.io/apimachinery/pkg/util/intstr"
 	"k8s.io/apimachinery/pkg/util/sets"
@@ -196,23 +195,23 @@ type ValidateNameFunc apimachineryvalidation.ValidateNameFunc
 // ValidatePodName can be used to check whether the given pod name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
 // trailing dashes are allowed.
-var ValidatePodName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidatePodName = NameIsDNSSubdomain
 
 // ValidateReplicationControllerName can be used to check whether the given replication
 // controller name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
 // trailing dashes are allowed.
-var ValidateReplicationControllerName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidateReplicationControllerName = NameIsDNSSubdomain
 
 // ValidateServiceName can be used to check whether the given service name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
 // trailing dashes are allowed.
-var ValidateServiceName = apimachineryvalidation.NameIsDNS1035Label
+var ValidateServiceName = NameIsDNS1035Label
 
 // ValidateNodeName can be used to check whether the given node name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
 // trailing dashes are allowed.
-var ValidateNodeName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidateNodeName = NameIsDNSSubdomain
 
 // ValidateNamespaceName can be used to check whether the given namespace name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
@@ -222,18 +221,18 @@ var ValidateNamespaceName = apimachineryvalidation.ValidateNamespaceName
 // ValidateLimitRangeName can be used to check whether the given limit range name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
 // trailing dashes are allowed.
-var ValidateLimitRangeName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidateLimitRangeName = NameIsDNSSubdomain
 
 // ValidateResourceQuotaName can be used to check whether the given
 // resource quota name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
 // trailing dashes are allowed.
-var ValidateResourceQuotaName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidateResourceQuotaName = NameIsDNSSubdomain
 
 // ValidateSecretName can be used to check whether the given secret name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
 // trailing dashes are allowed.
-var ValidateSecretName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidateSecretName = NameIsDNSSubdomain
 
 // ValidateServiceAccountName can be used to check whether the given service account name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
@@ -243,7 +242,7 @@ var ValidateServiceAccountName = apimachineryvalidation.ValidateServiceAccountNa
 // ValidateEndpointsName can be used to check whether the given endpoints name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
 // trailing dashes are allowed.
-var ValidateEndpointsName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidateEndpointsName = NameIsDNSSubdomain
 
 // ValidateClusterName can be used to check whether the given cluster name is valid.
 var ValidateClusterName = apimachineryvalidation.ValidateClusterName
@@ -251,21 +250,21 @@ var ValidateClusterName = apimachineryvalidation.ValidateClusterName
 // ValidateClassName can be used to check whether the given class name is valid.
 // It is defined here to avoid import cycle between pkg/apis/storage/validation
 // (where it should be) and this file.
-var ValidateClassName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidateClassName = NameIsDNSSubdomain
 
 // ValidatePiorityClassName can be used to check whether the given priority
 // class name is valid.
-var ValidatePriorityClassName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidatePriorityClassName = NameIsDNSSubdomain
 
-// ValidateRuntimeClassName can be used to check whether the given RuntimeClass name is valid.
-// Prefix indicates this name will be used as part of generation, in which case
-// trailing dashes are allowed.
-func ValidateRuntimeClassName(name string, fldPath *field.Path) field.ErrorList {
-	var allErrs field.ErrorList
-	for _, msg := range apimachineryvalidation.NameIsDNSSubdomain(name, false) {
-		allErrs = append(allErrs, field.Invalid(fldPath, name, msg))
-	}
-	return allErrs
+// TODO update all references to these functions to point to the apimachineryvalidation ones
+// NameIsDNSSubdomain is a ValidateNameFunc for names that must be a DNS subdomain.
+func NameIsDNSSubdomain(name string, prefix bool) []string {
+	return apimachineryvalidation.NameIsDNSSubdomain(name, prefix)
+}
+
+// NameIsDNS1035Label is a ValidateNameFunc for names that must be a DNS 952 label.
+func NameIsDNS1035Label(name string, prefix bool) []string {
+	return apimachineryvalidation.NameIsDNS1035Label(name, prefix)
 }
 
 // Validates that given value is not negative.
@@ -412,8 +411,14 @@ func validateVolumeSource(source *core.VolumeSource, fldPath *field.Path, volNam
 	allErrs := field.ErrorList{}
 	if source.EmptyDir != nil {
 		numVolumes++
-		if source.EmptyDir.SizeLimit != nil && source.EmptyDir.SizeLimit.Cmp(resource.Quantity{}) < 0 {
-			allErrs = append(allErrs, field.Forbidden(fldPath.Child("emptyDir").Child("sizeLimit"), "SizeLimit field must be a valid resource quantity"))
+		if !utilfeature.DefaultFeatureGate.Enabled(features.LocalStorageCapacityIsolation) {
+			if source.EmptyDir.SizeLimit != nil && source.EmptyDir.SizeLimit.Cmp(resource.Quantity{}) != 0 {
+				allErrs = append(allErrs, field.Forbidden(fldPath.Child("emptyDir").Child("sizeLimit"), "SizeLimit field disabled by feature-gate for EmptyDir volumes"))
+			}
+		} else {
+			if source.EmptyDir.SizeLimit != nil && source.EmptyDir.SizeLimit.Cmp(resource.Quantity{}) < 0 {
+				allErrs = append(allErrs, field.Forbidden(fldPath.Child("emptyDir").Child("sizeLimit"), "SizeLimit field must be a valid resource quantity"))
+			}
 		}
 		if !utilfeature.DefaultFeatureGate.Enabled(features.HugePages) && source.EmptyDir.Medium == core.StorageMediumHugePages {
 			allErrs = append(allErrs, field.Forbidden(fldPath.Child("emptyDir").Child("medium"), "HugePages medium is disabled by feature-gate for EmptyDir volumes"))
@@ -633,6 +638,14 @@ func validateVolumeSource(source *core.VolumeSource, fldPath *field.Path, volNam
 			allErrs = append(allErrs, validateScaleIOVolumeSource(source.ScaleIO, fldPath.Child("scaleIO"))...)
 		}
 	}
+	if source.CascadeDisk != nil {
+		if numVolumes > 0 {
+			allErrs = append(allErrs, field.Forbidden(fldPath.Child("cascadeDisk"), "may not specify more than 1 volume type"))
+		} else {
+			numVolumes++
+			allErrs = append(allErrs, validateCascadeDiskVolumeSource(source.CascadeDisk, fldPath.Child("cascadeDisk"))...)
+		}
+	}
 
 	if numVolumes == 0 {
 		allErrs = append(allErrs, field.Required(fldPath, "must specify a volume type"))
@@ -897,26 +910,6 @@ func validateGlusterfsVolumeSource(glusterfs *core.GlusterfsVolumeSource, fldPat
 	}
 	return allErrs
 }
-func validateGlusterfsPersistentVolumeSource(glusterfs *core.GlusterfsPersistentVolumeSource, fldPath *field.Path) field.ErrorList {
-	allErrs := field.ErrorList{}
-	if len(glusterfs.EndpointsName) == 0 {
-		allErrs = append(allErrs, field.Required(fldPath.Child("endpoints"), ""))
-	}
-	if len(glusterfs.Path) == 0 {
-		allErrs = append(allErrs, field.Required(fldPath.Child("path"), ""))
-	}
-	if glusterfs.EndpointsNamespace != nil {
-		endpointNs := glusterfs.EndpointsNamespace
-		if *endpointNs == "" {
-			allErrs = append(allErrs, field.Invalid(fldPath.Child("endpointsNamespace"), *endpointNs, "if the endpointnamespace is set, it must be a valid namespace name"))
-		} else {
-			for _, msg := range ValidateNamespaceName(*endpointNs, false) {
-				allErrs = append(allErrs, field.Invalid(fldPath.Child("endpointsNamespace"), *endpointNs, msg))
-			}
-		}
-	}
-	return allErrs
-}
 
 func validateFlockerVolumeSource(flocker *core.FlockerVolumeSource, fldPath *field.Path) field.ErrorList {
 	allErrs := field.ErrorList{}
@@ -1037,7 +1030,7 @@ func validateProjectionSources(projection *core.ProjectedVolumeSource, projectio
 				}
 			}
 		}
-		if projPath := srcPath.Child("serviceAccountToken"); source.ServiceAccountToken != nil {
+		if projPath := fldPath.Child("serviceAccountToken"); source.ServiceAccountToken != nil {
 			numSources++
 			if !utilfeature.DefaultFeatureGate.Enabled(features.TokenRequestProjection) {
 				allErrs = append(allErrs, field.Forbidden(projPath, "TokenRequestProjection feature is not enabled"))
@@ -1129,6 +1122,10 @@ func validateMountPropagation(mountPropagation *core.MountPropagationMode, conta
 	if mountPropagation == nil {
 		return allErrs
 	}
+	if !utilfeature.DefaultFeatureGate.Enabled(features.MountPropagation) {
+		allErrs = append(allErrs, field.Forbidden(fldPath, "mount propagation is disabled by feature-gate"))
+		return allErrs
+	}
 
 	supportedMountPropagations := sets.NewString(string(core.MountPropagationBidirectional), string(core.MountPropagationHostToContainer), string(core.MountPropagationNone))
 	if !supportedMountPropagations.Has(string(*mountPropagation)) {
@@ -1437,27 +1434,24 @@ func validateStorageOSPersistentVolumeSource(storageos *core.StorageOSPersistent
 	return allErrs
 }
 
-func ValidateCSIDriverName(driverName string, fldPath *field.Path) field.ErrorList {
+func validateCSIPersistentVolumeSource(csi *core.CSIPersistentVolumeSource, fldPath *field.Path) field.ErrorList {
 	allErrs := field.ErrorList{}
 
-	if len(driverName) == 0 {
-		allErrs = append(allErrs, field.Required(fldPath, ""))
+	if !utilfeature.DefaultFeatureGate.Enabled(features.CSIPersistentVolume) {
+		allErrs = append(allErrs, field.Forbidden(fldPath, "CSIPersistentVolume disabled by feature-gate"))
 	}
 
-	if len(driverName) > 63 {
-		allErrs = append(allErrs, field.TooLong(fldPath, driverName, 63))
+	if len(csi.Driver) == 0 {
+		allErrs = append(allErrs, field.Required(fldPath.Child("driver"), ""))
 	}
 
-	if !csiDriverNameRexp.MatchString(driverName) {
-		allErrs = append(allErrs, field.Invalid(fldPath, driverName, validation.RegexError(csiDriverNameRexpErrMsg, csiDriverNameRexpFmt, "csi-hostpath")))
+	if len(csi.Driver) > 63 {
+		allErrs = append(allErrs, field.TooLong(fldPath.Child("driver"), csi.Driver, 63))
 	}
-	return allErrs
-}
 
-func validateCSIPersistentVolumeSource(csi *core.CSIPersistentVolumeSource, fldPath *field.Path) field.ErrorList {
-	allErrs := field.ErrorList{}
-
-	allErrs = append(allErrs, ValidateCSIDriverName(csi.Driver, fldPath.Child("driver"))...)
+	if !csiDriverNameRexp.MatchString(csi.Driver) {
+		allErrs = append(allErrs, field.Invalid(fldPath.Child("driver"), csi.Driver, validation.RegexError(csiDriverNameRexpErrMsg, csiDriverNameRexpFmt, "csi-hostpath")))
+	}
 
 	if len(csi.VolumeHandle) == 0 {
 		allErrs = append(allErrs, field.Required(fldPath.Child("volumeHandle"), ""))
@@ -1505,9 +1499,17 @@ func validateCSIPersistentVolumeSource(csi *core.CSIPersistentVolumeSource, fldP
 	return allErrs
 }
 
+func validateCascadeDiskVolumeSource(cd *core.CascadeDiskVolumeSource, fldPath *field.Path) field.ErrorList {
+	allErrs := field.ErrorList{}
+	if len(cd.DiskID) == 0 {
+		allErrs = append(allErrs, field.Required(fldPath.Child("diskID"), ""))
+	}
+	return allErrs
+}
+
 // ValidatePersistentVolumeName checks that a name is appropriate for a
 // PersistentVolumeName object.
-var ValidatePersistentVolumeName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidatePersistentVolumeName = NameIsDNSSubdomain
 
 var supportedAccessModes = sets.NewString(string(core.ReadWriteOnce), string(core.ReadOnlyMany), string(core.ReadWriteMany))
 
@@ -1515,10 +1517,6 @@ var supportedReclaimPolicy = sets.NewString(string(core.PersistentVolumeReclaimD
 
 var supportedVolumeModes = sets.NewString(string(core.PersistentVolumeBlock), string(core.PersistentVolumeFilesystem))
 
-var supportedDataSourceAPIGroupKinds = map[schema.GroupKind]bool{
-	{Group: "snapshot.storage.k8s.io", Kind: "VolumeSnapshot"}: true,
-}
-
 func ValidatePersistentVolume(pv *core.PersistentVolume) field.ErrorList {
 	metaPath := field.NewPath("metadata")
 	allErrs := ValidateObjectMeta(&pv.ObjectMeta, false, ValidatePersistentVolumeName, metaPath)
@@ -1584,7 +1582,7 @@ func ValidatePersistentVolume(pv *core.PersistentVolume) field.ErrorList {
 			allErrs = append(allErrs, field.Forbidden(specPath.Child("glusterfs"), "may not specify more than 1 volume type"))
 		} else {
 			numVolumes++
-			allErrs = append(allErrs, validateGlusterfsPersistentVolumeSource(pv.Spec.Glusterfs, specPath.Child("glusterfs"))...)
+			allErrs = append(allErrs, validateGlusterfsVolumeSource(pv.Spec.Glusterfs, specPath.Child("glusterfs"))...)
 		}
 	}
 	if pv.Spec.Flocker != nil {
@@ -1743,6 +1741,15 @@ func ValidatePersistentVolume(pv *core.PersistentVolume) field.ErrorList {
 		}
 	}
 
+	if pv.Spec.CascadeDisk != nil {
+		if numVolumes > 0 {
+			allErrs = append(allErrs, field.Forbidden(specPath.Child("cascadeDisk"), "may not specify more than 1 volume type"))
+		} else {
+			numVolumes++
+			allErrs = append(allErrs, validateCascadeDiskVolumeSource(pv.Spec.CascadeDisk, specPath.Child("cascadeDisk"))...)
+		}
+	}
+
 	if numVolumes == 0 {
 		allErrs = append(allErrs, field.Required(specPath, "must specify a volume type"))
 	}
@@ -1757,7 +1764,9 @@ func ValidatePersistentVolume(pv *core.PersistentVolume) field.ErrorList {
 			allErrs = append(allErrs, field.Invalid(specPath.Child("storageClassName"), pv.Spec.StorageClassName, msg))
 		}
 	}
-	if pv.Spec.VolumeMode != nil && !supportedVolumeModes.Has(string(*pv.Spec.VolumeMode)) {
+	if pv.Spec.VolumeMode != nil && !utilfeature.DefaultFeatureGate.Enabled(features.BlockVolume) {
+		allErrs = append(allErrs, field.Forbidden(specPath.Child("volumeMode"), "PersistentVolume volumeMode is disabled by feature-gate"))
+	} else if pv.Spec.VolumeMode != nil && !supportedVolumeModes.Has(string(*pv.Spec.VolumeMode)) {
 		allErrs = append(allErrs, field.NotSupported(specPath.Child("volumeMode"), *pv.Spec.VolumeMode, supportedVolumeModes.List()))
 	}
 	return allErrs
@@ -1773,13 +1782,18 @@ func ValidatePersistentVolumeUpdate(newPv, oldPv *core.PersistentVolume) field.E
 	if !apiequality.Semantic.DeepEqual(newPv.Spec.PersistentVolumeSource, oldPv.Spec.PersistentVolumeSource) {
 		allErrs = append(allErrs, field.Forbidden(field.NewPath("spec", "persistentvolumesource"), "is immutable after creation"))
 	}
+
 	newPv.Status = oldPv.Status
 
-	allErrs = append(allErrs, ValidateImmutableField(newPv.Spec.VolumeMode, oldPv.Spec.VolumeMode, field.NewPath("volumeMode"))...)
+	if utilfeature.DefaultFeatureGate.Enabled(features.BlockVolume) {
+		allErrs = append(allErrs, ValidateImmutableField(newPv.Spec.VolumeMode, oldPv.Spec.VolumeMode, field.NewPath("volumeMode"))...)
+	}
 
-	// Allow setting NodeAffinity if oldPv NodeAffinity was not set
-	if oldPv.Spec.NodeAffinity != nil {
-		allErrs = append(allErrs, ValidateImmutableField(newPv.Spec.NodeAffinity, oldPv.Spec.NodeAffinity, field.NewPath("nodeAffinity"))...)
+	if utilfeature.DefaultFeatureGate.Enabled(features.VolumeScheduling) {
+		// Allow setting NodeAffinity if oldPv NodeAffinity was not set
+		if oldPv.Spec.NodeAffinity != nil {
+			allErrs = append(allErrs, ValidateImmutableField(newPv.Spec.NodeAffinity, oldPv.Spec.NodeAffinity, field.NewPath("nodeAffinity"))...)
+		}
 	}
 
 	return allErrs
@@ -1830,30 +1844,11 @@ func ValidatePersistentVolumeClaimSpec(spec *core.PersistentVolumeClaimSpec, fld
 			allErrs = append(allErrs, field.Invalid(fldPath.Child("storageClassName"), *spec.StorageClassName, msg))
 		}
 	}
-	if spec.VolumeMode != nil && !supportedVolumeModes.Has(string(*spec.VolumeMode)) {
+	if spec.VolumeMode != nil && !utilfeature.DefaultFeatureGate.Enabled(features.BlockVolume) {
+		allErrs = append(allErrs, field.Forbidden(fldPath.Child("volumeMode"), "PersistentVolumeClaim volumeMode is disabled by feature-gate"))
+	} else if spec.VolumeMode != nil && !supportedVolumeModes.Has(string(*spec.VolumeMode)) {
 		allErrs = append(allErrs, field.NotSupported(fldPath.Child("volumeMode"), *spec.VolumeMode, supportedVolumeModes.List()))
 	}
-
-	if spec.DataSource != nil && !utilfeature.DefaultFeatureGate.Enabled(features.VolumeSnapshotDataSource) {
-		allErrs = append(allErrs, field.Forbidden(fldPath.Child("dataSource"), "VolumeSnapshotDataSource is disabled by feature-gate"))
-	} else if spec.DataSource != nil {
-		if len(spec.DataSource.Name) == 0 {
-			allErrs = append(allErrs, field.Required(fldPath.Child("dataSource", "name"), ""))
-		}
-
-		groupKind := schema.GroupKind{Group: "", Kind: spec.DataSource.Kind}
-		if spec.DataSource.APIGroup != nil {
-			groupKind.Group = string(*spec.DataSource.APIGroup)
-		}
-		groupKindList := make([]string, 0, len(supportedDataSourceAPIGroupKinds))
-		for grp := range supportedDataSourceAPIGroupKinds {
-			groupKindList = append(groupKindList, grp.String())
-		}
-		if !supportedDataSourceAPIGroupKinds[groupKind] {
-			allErrs = append(allErrs, field.NotSupported(fldPath.Child("dataSource"), groupKind.String(), groupKindList))
-		}
-	}
-
 	return allErrs
 }
 
@@ -1905,8 +1900,9 @@ func ValidatePersistentVolumeClaimUpdate(newPvc, oldPvc *core.PersistentVolumeCl
 		}
 	}
 
-	allErrs = append(allErrs, ValidateImmutableField(newPvc.Spec.VolumeMode, oldPvc.Spec.VolumeMode, field.NewPath("volumeMode"))...)
-
+	if utilfeature.DefaultFeatureGate.Enabled(features.BlockVolume) {
+		allErrs = append(allErrs, ValidateImmutableField(newPvc.Spec.VolumeMode, oldPvc.Spec.VolumeMode, field.NewPath("volumeMode"))...)
+	}
 	return allErrs
 }
 
@@ -1947,7 +1943,7 @@ func ValidatePersistentVolumeClaimStatusUpdate(newPvc, oldPvc *core.PersistentVo
 	return allErrs
 }
 
-var supportedPortProtocols = sets.NewString(string(core.ProtocolTCP), string(core.ProtocolUDP), string(core.ProtocolSCTP))
+var supportedPortProtocols = sets.NewString(string(core.ProtocolTCP), string(core.ProtocolUDP))
 
 func validateContainerPorts(ports []core.ContainerPort, fldPath *field.Path) field.ErrorList {
 	allErrs := field.ErrorList{}
@@ -1980,8 +1976,6 @@ func validateContainerPorts(ports []core.ContainerPort, fldPath *field.Path) fie
 		}
 		if len(port.Protocol) == 0 {
 			allErrs = append(allErrs, field.Required(idxPath.Child("protocol"), ""))
-		} else if !utilfeature.DefaultFeatureGate.Enabled(features.SCTPSupport) && port.Protocol == core.ProtocolSCTP {
-			allErrs = append(allErrs, field.NotSupported(idxPath.Child("protocol"), port.Protocol, []string{string(core.ProtocolTCP), string(core.ProtocolUDP)}))
 		} else if !supportedPortProtocols.Has(string(port.Protocol)) {
 			allErrs = append(allErrs, field.NotSupported(idxPath.Child("protocol"), port.Protocol, supportedPortProtocols.List()))
 		}
@@ -2111,6 +2105,8 @@ func validateContainerResourceFieldSelector(fs *core.ResourceFieldSelector, expr
 		allErrs = append(allErrs, field.Required(fldPath.Child("resource"), ""))
 	} else if !expressions.Has(fs.Resource) {
 		allErrs = append(allErrs, field.NotSupported(fldPath.Child("resource"), fs.Resource, expressions.List()))
+	} else if fsResourceIsEphemeralStorage(fs.Resource) && !utilfeature.DefaultFeatureGate.Enabled(features.LocalStorageCapacityIsolation) {
+		allErrs = append(allErrs, field.Forbidden(fldPath, "Containers' ephemeral storage requests/limits disabled by feature-gate for Downward API"))
 	}
 	allErrs = append(allErrs, validateContainerResourceDivisor(fs.Resource, fs.Divisor, fldPath)...)
 	return allErrs
@@ -2281,7 +2277,11 @@ func ValidateVolumeMounts(mounts []core.VolumeMount, voldevices map[string]strin
 		}
 
 		if len(mnt.SubPath) > 0 {
-			allErrs = append(allErrs, validateLocalDescendingPath(mnt.SubPath, fldPath.Child("subPath"))...)
+			if !utilfeature.DefaultFeatureGate.Enabled(features.VolumeSubpath) {
+				allErrs = append(allErrs, field.Forbidden(fldPath.Child("subPath"), "subPath is disabled by feature-gate"))
+			} else {
+				allErrs = append(allErrs, validateLocalDescendingPath(mnt.SubPath, fldPath.Child("subPath"))...)
+			}
 		}
 
 		if mnt.MountPropagation != nil {
@@ -2296,6 +2296,10 @@ func ValidateVolumeDevices(devices []core.VolumeDevice, volmounts map[string]str
 	devicepath := sets.NewString()
 	devicename := sets.NewString()
 
+	if devices != nil && !utilfeature.DefaultFeatureGate.Enabled(features.BlockVolume) {
+		allErrs = append(allErrs, field.Forbidden(fldPath.Child("volumeDevices"), "Container volumeDevices is disabled by feature-gate"))
+		return allErrs
+	}
 	if devices != nil {
 		for i, dev := range devices {
 			idxPath := fldPath.Index(i)
@@ -2934,20 +2938,6 @@ func ValidatePod(pod *core.Pod) field.ErrorList {
 	// this was done to preserve backwards compatibility
 	specPath := field.NewPath("spec")
 
-	if pod.Spec.ServiceAccountName == "" {
-		for vi, volume := range pod.Spec.Volumes {
-			path := specPath.Child("volumes").Index(vi).Child("projected")
-			if volume.Projected != nil {
-				for si, source := range volume.Projected.Sources {
-					saPath := path.Child("sources").Index(si).Child("serviceAccountToken")
-					if source.ServiceAccountToken != nil {
-						allErrs = append(allErrs, field.Forbidden(saPath, "must not be specified when serviceAccountName is not set"))
-					}
-				}
-			}
-		}
-	}
-
 	allErrs = append(allErrs, validateContainersOnlyForPod(pod.Spec.Containers, specPath.Child("containers"))...)
 	allErrs = append(allErrs, validateContainersOnlyForPod(pod.Spec.InitContainers, specPath.Child("initContainers"))...)
 
@@ -3024,15 +3014,13 @@ func ValidatePodSpec(spec *core.PodSpec, fldPath *field.Path) field.ErrorList {
 	}
 
 	if len(spec.PriorityClassName) > 0 {
-		for _, msg := range ValidatePriorityClassName(spec.PriorityClassName, false) {
-			allErrs = append(allErrs, field.Invalid(fldPath.Child("priorityClassName"), spec.PriorityClassName, msg))
+		if utilfeature.DefaultFeatureGate.Enabled(features.PodPriority) {
+			for _, msg := range ValidatePriorityClassName(spec.PriorityClassName, false) {
+				allErrs = append(allErrs, field.Invalid(fldPath.Child("priorityClassName"), spec.PriorityClassName, msg))
+			}
 		}
 	}
 
-	if spec.RuntimeClassName != nil {
-		allErrs = append(allErrs, ValidateRuntimeClassName(*spec.RuntimeClassName, fldPath.Child("runtimeClassName"))...)
-	}
-
 	return allErrs
 }
 
@@ -3124,50 +3112,30 @@ func ValidateNodeSelector(nodeSelector *core.NodeSelector, fldPath *field.Path)
 	return allErrs
 }
 
-// validateTopologySelectorLabelRequirement tests that the specified TopologySelectorLabelRequirement fields has valid data,
-// and constructs a set containing all of its Values.
-func validateTopologySelectorLabelRequirement(rq core.TopologySelectorLabelRequirement, fldPath *field.Path) (sets.String, field.ErrorList) {
+// validateTopologySelectorLabelRequirement tests that the specified TopologySelectorLabelRequirement fields has valid data
+func validateTopologySelectorLabelRequirement(rq core.TopologySelectorLabelRequirement, fldPath *field.Path) field.ErrorList {
 	allErrs := field.ErrorList{}
-	valueSet := make(sets.String)
-	valuesPath := fldPath.Child("values")
 	if len(rq.Values) == 0 {
-		allErrs = append(allErrs, field.Required(valuesPath, ""))
+		allErrs = append(allErrs, field.Forbidden(fldPath.Child("values"), "must specify as least one value"))
 	}
-
-	// Validate set property of Values field
-	for i, value := range rq.Values {
-		if valueSet.Has(value) {
-			allErrs = append(allErrs, field.Duplicate(valuesPath.Index(i), value))
-		}
-		valueSet.Insert(value)
-	}
-
 	allErrs = append(allErrs, unversionedvalidation.ValidateLabelName(rq.Key, fldPath.Child("key"))...)
 
-	return valueSet, allErrs
+	return allErrs
 }
 
-// ValidateTopologySelectorTerm tests that the specified topology selector term has valid data,
-// and constructs a map representing the term in raw form.
-func ValidateTopologySelectorTerm(term core.TopologySelectorTerm, fldPath *field.Path) (map[string]sets.String, field.ErrorList) {
+// ValidateTopologySelectorTerm tests that the specified topology selector term has valid data
+func ValidateTopologySelectorTerm(term core.TopologySelectorTerm, fldPath *field.Path) field.ErrorList {
 	allErrs := field.ErrorList{}
-	exprMap := make(map[string]sets.String)
-	exprPath := fldPath.Child("matchLabelExpressions")
-
-	// Allow empty MatchLabelExpressions, in case this field becomes optional in the future.
-	for i, req := range term.MatchLabelExpressions {
-		idxPath := exprPath.Index(i)
-		valueSet, exprErrs := validateTopologySelectorLabelRequirement(req, idxPath)
-		allErrs = append(allErrs, exprErrs...)
 
-		// Validate no duplicate keys exist.
-		if _, exists := exprMap[req.Key]; exists {
-			allErrs = append(allErrs, field.Duplicate(idxPath.Child("key"), req.Key))
+	if utilfeature.DefaultFeatureGate.Enabled(features.DynamicProvisioningScheduling) {
+		for i, req := range term.MatchLabelExpressions {
+			allErrs = append(allErrs, validateTopologySelectorLabelRequirement(req, fldPath.Child("matchLabelExpressions").Index(i))...)
 		}
-		exprMap[req.Key] = valueSet
+	} else if len(term.MatchLabelExpressions) != 0 {
+		allErrs = append(allErrs, field.Forbidden(fldPath, "field is disabled by feature-gate DynamicProvisioningScheduling"))
 	}
 
-	return exprMap, allErrs
+	return allErrs
 }
 
 // ValidateAvoidPodsInNodeAnnotations tests that the serialized AvoidPods in Node.Annotations has valid data
@@ -3439,6 +3407,7 @@ func ValidatePodSecurityContext(securityContext *core.PodSecurityContext, spec *
 				allErrs = append(allErrs, field.Invalid(fldPath.Child("runAsGroup"), *(securityContext.RunAsGroup), msg))
 			}
 		}
+
 		for g, gid := range securityContext.SupplementalGroups {
 			for _, msg := range validation.IsValidGroupID(gid) {
 				allErrs = append(allErrs, field.Invalid(fldPath.Child("supplementalGroups").Index(g), gid, msg))
@@ -3764,10 +3733,8 @@ func ValidateService(service *core.Service) field.ErrorList {
 		includeProtocols := sets.NewString()
 		for i := range service.Spec.Ports {
 			portPath := portsPath.Index(i)
-			if !utilfeature.DefaultFeatureGate.Enabled(features.SCTPSupport) && service.Spec.Ports[i].Protocol == core.ProtocolSCTP {
-				allErrs = append(allErrs, field.NotSupported(portPath.Child("protocol"), service.Spec.Ports[i].Protocol, []string{string(core.ProtocolTCP), string(core.ProtocolUDP)}))
-			} else if !supportedPortProtocols.Has(string(service.Spec.Ports[i].Protocol)) {
-				allErrs = append(allErrs, field.Invalid(portPath.Child("protocol"), service.Spec.Ports[i].Protocol, "cannot create an external load balancer with non-TCP/UDP/SCTP ports"))
+			if !supportedPortProtocols.Has(string(service.Spec.Ports[i].Protocol)) {
+				allErrs = append(allErrs, field.Invalid(portPath.Child("protocol"), service.Spec.Ports[i].Protocol, "cannot create an external load balancer with non-TCP/UDP ports"))
 			} else {
 				includeProtocols.Insert(string(service.Spec.Ports[i].Protocol))
 			}
@@ -3865,8 +3832,6 @@ func validateServicePort(sp *core.ServicePort, requireName, isHeadlessService bo
 
 	if len(sp.Protocol) == 0 {
 		allErrs = append(allErrs, field.Required(fldPath.Child("protocol"), ""))
-	} else if !utilfeature.DefaultFeatureGate.Enabled(features.SCTPSupport) && sp.Protocol == core.ProtocolSCTP {
-		allErrs = append(allErrs, field.NotSupported(fldPath.Child("protocol"), sp.Protocol, []string{string(core.ProtocolTCP), string(core.ProtocolUDP)}))
 	} else if !supportedPortProtocols.Has(string(sp.Protocol)) {
 		allErrs = append(allErrs, field.NotSupported(fldPath.Child("protocol"), sp.Protocol, supportedPortProtocols.List()))
 	}
@@ -4028,7 +3993,7 @@ func ValidatePodTemplateSpecForRC(template *core.PodTemplateSpec, selectorMap ma
 			allErrs = append(allErrs, field.NotSupported(fldPath.Child("spec", "restartPolicy"), template.Spec.RestartPolicy, []string{string(core.RestartPolicyAlways)}))
 		}
 		if template.Spec.ActiveDeadlineSeconds != nil {
-			allErrs = append(allErrs, field.Forbidden(fldPath.Child("spec", "activeDeadlineSeconds"), "activeDeadlineSeconds in ReplicationController is not Supported"))
+			allErrs = append(allErrs, field.Invalid(fldPath.Child("spec", "activeDeadlineSeconds"), template.Spec.ActiveDeadlineSeconds, "must not be specified"))
 		}
 	}
 	return allErrs
@@ -4147,6 +4112,16 @@ func ValidateNode(node *core.Node) field.ErrorList {
 	// That said, if specified, we need to ensure they are valid.
 	allErrs = append(allErrs, ValidateNodeResources(node)...)
 
+	// Only allow Spec.ConfigSource and Status.Config to be set if the DynamicKubeletConfig feature gate is enabled
+	if !utilfeature.DefaultFeatureGate.Enabled(features.DynamicKubeletConfig) {
+		if node.Spec.ConfigSource != nil {
+			allErrs = append(allErrs, field.Forbidden(field.NewPath("spec", "configSource"), "configSource may only be set if the DynamicKubeletConfig feature gate is enabled)"))
+		}
+		if node.Status.Config != nil {
+			allErrs = append(allErrs, field.Forbidden(field.NewPath("status", "config"), "config may only be set if the DynamicKubeletConfig feature gate is enabled)"))
+		}
+	}
+
 	if len(node.Spec.PodCIDR) != 0 {
 		_, err := ValidateCIDR(node.Spec.PodCIDR)
 		if err != nil {
@@ -4229,14 +4204,17 @@ func ValidateNodeUpdate(node, oldNode *core.Node) field.ErrorList {
 		}
 	}
 
-	if node.Spec.ConfigSource != nil {
-		allErrs = append(allErrs, validateNodeConfigSourceSpec(node.Spec.ConfigSource, field.NewPath("spec", "configSource"))...)
-	}
-	oldNode.Spec.ConfigSource = node.Spec.ConfigSource
-	if node.Status.Config != nil {
-		allErrs = append(allErrs, validateNodeConfigStatus(node.Status.Config, field.NewPath("status", "config"))...)
+	// Allow and validate updates to Node.Spec.ConfigSource and Node.Status.Config if DynamicKubeletConfig feature gate is enabled
+	if utilfeature.DefaultFeatureGate.Enabled(features.DynamicKubeletConfig) {
+		if node.Spec.ConfigSource != nil {
+			allErrs = append(allErrs, validateNodeConfigSourceSpec(node.Spec.ConfigSource, field.NewPath("spec", "configSource"))...)
+		}
+		oldNode.Spec.ConfigSource = node.Spec.ConfigSource
+		if node.Status.Config != nil {
+			allErrs = append(allErrs, validateNodeConfigStatus(node.Status.Config, field.NewPath("status", "config"))...)
+		}
+		oldNode.Status.Config = node.Status.Config
 	}
-	oldNode.Status.Config = node.Status.Config
 
 	// TODO: move reset function to its own location
 	// Ignore metadata changes now that they have been tested
@@ -4257,7 +4235,7 @@ func ValidateNodeUpdate(node, oldNode *core.Node) field.ErrorList {
 	// We made allowed changes to oldNode, and now we compare oldNode to node. Any remaining differences indicate changes to protected fields.
 	// TODO: Add a 'real' error type for this error and provide print actual diffs.
 	if !apiequality.Semantic.DeepEqual(oldNode, node) {
-		klog.V(4).Infof("Update failed validation %#v vs %#v", oldNode, node)
+		glog.V(4).Infof("Update failed validation %#v vs %#v", oldNode, node)
 		allErrs = append(allErrs, field.Forbidden(field.NewPath(""), "node updates may only change labels, taints, or capacity (or configSource, if the DynamicKubeletConfig feature gate is enabled)"))
 	}
 
@@ -4419,7 +4397,9 @@ func isLocalStorageResource(name string) bool {
 // Refer to docs/design/resources.md for more details.
 func ValidateResourceQuotaResourceName(value string, fldPath *field.Path) field.ErrorList {
 	allErrs := validateResourceName(value, fldPath)
-
+	if isLocalStorageResource(value) && !utilfeature.DefaultFeatureGate.Enabled(features.LocalStorageCapacityIsolation) {
+		return append(allErrs, field.Forbidden(fldPath, "ResourceEphemeralStorage field disabled by feature-gate for ResourceQuota"))
+	}
 	if len(strings.Split(value, "/")) == 1 {
 		if !helper.IsStandardQuotaResourceName(value) {
 			return append(allErrs, field.Invalid(fldPath, value, isInvalidQuotaResource))
@@ -4450,6 +4430,10 @@ func validateLimitRangeTypeName(value string, fldPath *field.Path) field.ErrorLi
 // Validate limit range resource name
 // limit types (other than Pod/Container) could contain storage not just cpu or memory
 func validateLimitRangeResourceName(limitType core.LimitType, value string, fldPath *field.Path) field.ErrorList {
+	allErrs := field.ErrorList{}
+	if value == string(core.ResourceEphemeralStorage) && !utilfeature.DefaultFeatureGate.Enabled(features.LocalStorageCapacityIsolation) {
+		return append(allErrs, field.Forbidden(fldPath, "ResourceEphemeralStorage field disabled by feature-gate for Resource LimitRange"))
+	}
 	switch limitType {
 	case core.LimitTypePod, core.LimitTypeContainer:
 		return validateContainerResourceName(value, fldPath)
@@ -4695,7 +4679,7 @@ func ValidateSecretUpdate(newSecret, oldSecret *core.Secret) field.ErrorList {
 // ValidateConfigMapName can be used to check whether the given ConfigMap name is valid.
 // Prefix indicates this name will be used as part of generation, in which case
 // trailing dashes are allowed.
-var ValidateConfigMapName = apimachineryvalidation.NameIsDNSSubdomain
+var ValidateConfigMapName = NameIsDNSSubdomain
 
 // ValidateConfigMap tests whether required fields in the ConfigMap are set.
 func ValidateConfigMap(cfg *core.ConfigMap) field.ErrorList {
@@ -4764,6 +4748,9 @@ func ValidateResourceRequirements(requirements *core.ResourceRequirements, fldPa
 		// Validate resource quantity.
 		allErrs = append(allErrs, ValidateResourceQuantityValue(string(resourceName), quantity, fldPath)...)
 
+		if resourceName == core.ResourceEphemeralStorage && !utilfeature.DefaultFeatureGate.Enabled(features.LocalStorageCapacityIsolation) {
+			allErrs = append(allErrs, field.Forbidden(limPath, "ResourceEphemeralStorage field disabled by feature-gate for ResourceRequirements"))
+		}
 		if helper.IsHugePageResourceName(resourceName) {
 			if !utilfeature.DefaultFeatureGate.Enabled(features.HugePages) {
 				allErrs = append(allErrs, field.Forbidden(limPath, fmt.Sprintf("%s field disabled by feature-gate for ResourceRequirements", resourceName)))
@@ -4875,7 +4862,7 @@ func validateScopedResourceSelectorRequirement(resourceQuotaSpec *core.ResourceQ
 		case core.ScopeSelectorOpIn, core.ScopeSelectorOpNotIn:
 			if len(req.Values) == 0 {
 				allErrs = append(allErrs, field.Required(fldPath.Child("values"),
-					"must be at least one value when `operator` is 'In' or 'NotIn' for scope selector"))
+					"must be atleast one value when `operator` is 'In' or 'NotIn' for scope selector"))
 			}
 		case core.ScopeSelectorOpExists, core.ScopeSelectorOpDoesNotExist:
 			if len(req.Values) != 0 {
@@ -5087,16 +5074,50 @@ func ValidateNamespaceFinalizeUpdate(newNamespace, oldNamespace *core.Namespace)
 	return allErrs
 }
 
+// Construct lookup map of old subset IPs to NodeNames.
+func updateEpAddrToNodeNameMap(ipToNodeName map[string]string, addresses []core.EndpointAddress) {
+	for n := range addresses {
+		if addresses[n].NodeName == nil {
+			continue
+		}
+		ipToNodeName[addresses[n].IP] = *addresses[n].NodeName
+	}
+}
+
+// Build a map across all subsets of IP -> NodeName
+func buildEndpointAddressNodeNameMap(subsets []core.EndpointSubset) map[string]string {
+	ipToNodeName := make(map[string]string)
+	for i := range subsets {
+		updateEpAddrToNodeNameMap(ipToNodeName, subsets[i].Addresses)
+		updateEpAddrToNodeNameMap(ipToNodeName, subsets[i].NotReadyAddresses)
+	}
+	return ipToNodeName
+}
+
+func validateEpAddrNodeNameTransition(addr *core.EndpointAddress, ipToNodeName map[string]string, fldPath *field.Path) field.ErrorList {
+	errList := field.ErrorList{}
+	existingNodeName, found := ipToNodeName[addr.IP]
+	if !found {
+		return errList
+	}
+	if addr.NodeName == nil || *addr.NodeName == existingNodeName {
+		return errList
+	}
+	// NodeName entry found for this endpoint IP, but user is attempting to change NodeName
+	return append(errList, field.Forbidden(fldPath, fmt.Sprintf("Cannot change NodeName for %s to %s", addr.IP, *addr.NodeName)))
+}
+
 // ValidateEndpoints tests if required fields are set.
 func ValidateEndpoints(endpoints *core.Endpoints) field.ErrorList {
 	allErrs := ValidateObjectMeta(&endpoints.ObjectMeta, true, ValidateEndpointsName, field.NewPath("metadata"))
 	allErrs = append(allErrs, ValidateEndpointsSpecificAnnotations(endpoints.Annotations, field.NewPath("annotations"))...)
-	allErrs = append(allErrs, validateEndpointSubsets(endpoints.Subsets, field.NewPath("subsets"))...)
+	allErrs = append(allErrs, validateEndpointSubsets(endpoints.Subsets, []core.EndpointSubset{}, field.NewPath("subsets"))...)
 	return allErrs
 }
 
-func validateEndpointSubsets(subsets []core.EndpointSubset, fldPath *field.Path) field.ErrorList {
+func validateEndpointSubsets(subsets []core.EndpointSubset, oldSubsets []core.EndpointSubset, fldPath *field.Path) field.ErrorList {
 	allErrs := field.ErrorList{}
+	ipToNodeName := buildEndpointAddressNodeNameMap(oldSubsets)
 	for i := range subsets {
 		ss := &subsets[i]
 		idxPath := fldPath.Index(i)
@@ -5107,10 +5128,10 @@ func validateEndpointSubsets(subsets []core.EndpointSubset, fldPath *field.Path)
 			allErrs = append(allErrs, field.Required(idxPath, "must specify `addresses` or `notReadyAddresses`"))
 		}
 		for addr := range ss.Addresses {
-			allErrs = append(allErrs, validateEndpointAddress(&ss.Addresses[addr], idxPath.Child("addresses").Index(addr))...)
+			allErrs = append(allErrs, validateEndpointAddress(&ss.Addresses[addr], idxPath.Child("addresses").Index(addr), ipToNodeName)...)
 		}
 		for addr := range ss.NotReadyAddresses {
-			allErrs = append(allErrs, validateEndpointAddress(&ss.NotReadyAddresses[addr], idxPath.Child("notReadyAddresses").Index(addr))...)
+			allErrs = append(allErrs, validateEndpointAddress(&ss.NotReadyAddresses[addr], idxPath.Child("notReadyAddresses").Index(addr), ipToNodeName)...)
 		}
 		for port := range ss.Ports {
 			allErrs = append(allErrs, validateEndpointPort(&ss.Ports[port], len(ss.Ports) > 1, idxPath.Child("ports").Index(port))...)
@@ -5120,7 +5141,7 @@ func validateEndpointSubsets(subsets []core.EndpointSubset, fldPath *field.Path)
 	return allErrs
 }
 
-func validateEndpointAddress(address *core.EndpointAddress, fldPath *field.Path) field.ErrorList {
+func validateEndpointAddress(address *core.EndpointAddress, fldPath *field.Path, ipToNodeName map[string]string) field.ErrorList {
 	allErrs := field.ErrorList{}
 	for _, msg := range validation.IsValidIP(address.IP) {
 		allErrs = append(allErrs, field.Invalid(fldPath.Child("ip"), address.IP, msg))
@@ -5134,6 +5155,10 @@ func validateEndpointAddress(address *core.EndpointAddress, fldPath *field.Path)
 			allErrs = append(allErrs, field.Invalid(fldPath.Child("nodeName"), *address.NodeName, msg))
 		}
 	}
+	allErrs = append(allErrs, validateEpAddrNodeNameTransition(address, ipToNodeName, fldPath.Child("nodeName"))...)
+	if len(allErrs) > 0 {
+		return allErrs
+	}
 	allErrs = append(allErrs, validateNonSpecialIP(address.IP, fldPath.Child("ip"))...)
 	return allErrs
 }
@@ -5176,8 +5201,6 @@ func validateEndpointPort(port *core.EndpointPort, requireName bool, fldPath *fi
 	}
 	if len(port.Protocol) == 0 {
 		allErrs = append(allErrs, field.Required(fldPath.Child("protocol"), ""))
-	} else if !utilfeature.DefaultFeatureGate.Enabled(features.SCTPSupport) && port.Protocol == core.ProtocolSCTP {
-		allErrs = append(allErrs, field.NotSupported(fldPath.Child("protocol"), port.Protocol, []string{string(core.ProtocolTCP), string(core.ProtocolUDP)}))
 	} else if !supportedPortProtocols.Has(string(port.Protocol)) {
 		allErrs = append(allErrs, field.NotSupported(fldPath.Child("protocol"), port.Protocol, supportedPortProtocols.List()))
 	}
@@ -5185,11 +5208,9 @@ func validateEndpointPort(port *core.EndpointPort, requireName bool, fldPath *fi
 }
 
 // ValidateEndpointsUpdate tests to make sure an endpoints update can be applied.
-// NodeName changes are allowed during update to accommodate the case where nodeIP or PodCIDR is reused.
-// An existing endpoint ip will have a different nodeName if this happens.
 func ValidateEndpointsUpdate(newEndpoints, oldEndpoints *core.Endpoints) field.ErrorList {
 	allErrs := ValidateObjectMetaUpdate(&newEndpoints.ObjectMeta, &oldEndpoints.ObjectMeta, field.NewPath("metadata"))
-	allErrs = append(allErrs, validateEndpointSubsets(newEndpoints.Subsets, field.NewPath("subsets"))...)
+	allErrs = append(allErrs, validateEndpointSubsets(newEndpoints.Subsets, oldEndpoints.Subsets, field.NewPath("subsets"))...)
 	allErrs = append(allErrs, ValidateEndpointsSpecificAnnotations(newEndpoints.Annotations, field.NewPath("annotations"))...)
 	return allErrs
 }
@@ -5220,12 +5241,6 @@ func ValidateSecurityContext(sc *core.SecurityContext, fldPath *field.Path) fiel
 		}
 	}
 
-	if sc.ProcMount != nil {
-		if err := ValidateProcMountType(fldPath.Child("procMount"), *sc.ProcMount); err != nil {
-			allErrs = append(allErrs, err)
-		}
-	}
-
 	if sc.AllowPrivilegeEscalation != nil && !*sc.AllowPrivilegeEscalation {
 		if sc.Privileged != nil && *sc.Privileged {
 			allErrs = append(allErrs, field.Invalid(fldPath, sc, "cannot set `allowPrivilegeEscalation` to false and `privileged` to true"))
@@ -5295,6 +5310,10 @@ func validateVolumeNodeAffinity(nodeAffinity *core.VolumeNodeAffinity, fldPath *
 		return false, allErrs
 	}
 
+	if !utilfeature.DefaultFeatureGate.Enabled(features.VolumeScheduling) {
+		allErrs = append(allErrs, field.Forbidden(fldPath, "Volume node affinity is disabled by feature-gate"))
+	}
+
 	if nodeAffinity.Required != nil {
 		allErrs = append(allErrs, ValidateNodeSelector(nodeAffinity.Required, fldPath.Child("required"))...)
 	} else {
@@ -5322,13 +5341,3 @@ func IsDecremented(update, old *int32) bool {
 	}
 	return *update < *old
 }
-
-// ValidateProcMountType tests that the argument is a valid ProcMountType.
-func ValidateProcMountType(fldPath *field.Path, procMountType core.ProcMountType) *field.Error {
-	switch procMountType {
-	case core.DefaultProcMount, core.UnmaskedProcMount:
-		return nil
-	default:
-		return field.NotSupported(fldPath, procMountType, []string{string(core.DefaultProcMount), string(core.UnmaskedProcMount)})
-	}
-}
diff --git a/pkg/apis/policy/types.go b/pkg/apis/policy/types.go
index a94711bdb3..174d0fc876 100644
--- a/pkg/apis/policy/types.go
+++ b/pkg/apis/policy/types.go
@@ -63,7 +63,6 @@ type PodDisruptionBudgetStatus struct {
 	// the list automatically by PodDisruptionBudget controller after some time.
 	// If everything goes smooth this map should be empty for the most of the time.
 	// Large number of entries in the map may indicate problems with pod deletions.
-	// +optional
 	DisruptedPods map[string]metav1.Time
 
 	// Number of pod disruptions that are currently allowed.
@@ -182,10 +181,6 @@ type PodSecurityPolicySpec struct {
 	SELinux SELinuxStrategyOptions
 	// RunAsUser is the strategy that will dictate the allowable RunAsUser values that may be set.
 	RunAsUser RunAsUserStrategyOptions
-	// RunAsGroup is the strategy that will dictate the allowable RunAsGroup values that may be set.
-	// If this field is omitted, the pod's RunAsGroup can take any value. This field requires the
-	// RunAsGroup feature gate to be enabled.
-	RunAsGroup *RunAsGroupStrategyOptions
 	// SupplementalGroups is the strategy that will dictate what supplemental groups are used by the SecurityContext.
 	SupplementalGroups SupplementalGroupsStrategyOptions
 	// FSGroup is the strategy that will dictate what fs group is used by the SecurityContext.
@@ -232,10 +227,6 @@ type PodSecurityPolicySpec struct {
 	// e.g. "foo.*" forbids "foo.bar", "foo.baz", etc.
 	// +optional
 	ForbiddenSysctls []string
-	// AllowedProcMountTypes is a whitelist of allowed ProcMountTypes.
-	// Empty or nil indicates that only the DefaultProcMountType may be used.
-	// +optional
-	AllowedProcMountTypes []api.ProcMountType
 }
 
 // AllowedHostPath defines the host volume conditions that will be enabled by a policy
@@ -299,6 +290,7 @@ var (
 	PortworxVolume        FSType = "portworxVolume"
 	ScaleIO               FSType = "scaleIO"
 	CSI                   FSType = "csi"
+	CascadeDisk           FSType = "cascadeDisk"
 	All                   FSType = "*"
 )
 
@@ -339,16 +331,6 @@ type RunAsUserStrategyOptions struct {
 	Ranges []IDRange
 }
 
-// RunAsGroupStrategyOptions defines the strategy type and any options used to create the strategy.
-type RunAsGroupStrategyOptions struct {
-	// Rule is the strategy that will dictate the allowable RunAsGroup values that may be set.
-	Rule RunAsGroupStrategy
-	// Ranges are the allowed ranges of gids that may be used. If you would like to force a single gid
-	// then supply a single range with the same start and end. Required for MustRunAs.
-	// +optional
-	Ranges []IDRange
-}
-
 // IDRange provides a min/max of an allowed range of IDs.
 type IDRange struct {
 	// Min is the start of the range, inclusive.
@@ -370,20 +352,6 @@ const (
 	RunAsUserStrategyRunAsAny RunAsUserStrategy = "RunAsAny"
 )
 
-// RunAsGroupStrategy denotes strategy types for generating RunAsGroup values for a
-// SecurityContext.
-type RunAsGroupStrategy string
-
-const (
-	// RunAsGroupStrategyMayRunAs means that container does not need to run with a particular gid.
-	// However, when RunAsGroup are specified, they have to fall in the defined range.
-	RunAsGroupStrategyMayRunAs RunAsGroupStrategy = "MayRunAs"
-	// RunAsGroupStrategyMustRunAs means that container must run as a particular gid.
-	RunAsGroupStrategyMustRunAs RunAsGroupStrategy = "MustRunAs"
-	// RunAsGroupStrategyRunAsAny means that container may make requests for any gid.
-	RunAsGroupStrategyRunAsAny RunAsGroupStrategy = "RunAsAny"
-)
-
 // FSGroupStrategyOptions defines the strategy type and options used to create the strategy.
 type FSGroupStrategyOptions struct {
 	// Rule is the strategy that will dictate what FSGroup is used in the SecurityContext.
@@ -400,9 +368,6 @@ type FSGroupStrategyOptions struct {
 type FSGroupStrategyType string
 
 const (
-	// FSGroupStrategyMayRunAs means that container does not need to have FSGroup of X applied.
-	// However, when FSGroups are specified, they have to fall in the defined range.
-	FSGroupStrategyMayRunAs FSGroupStrategyType = "MayRunAs"
 	// FSGroupStrategyMustRunAs means that container must have FSGroup of X applied.
 	FSGroupStrategyMustRunAs FSGroupStrategyType = "MustRunAs"
 	// FSGroupStrategyRunAsAny means that container may make requests for any FSGroup labels.
@@ -425,9 +390,6 @@ type SupplementalGroupsStrategyOptions struct {
 type SupplementalGroupsStrategyType string
 
 const (
-	// SupplementalGroupsStrategyMayRunAs means that container does not need to run with a particular gid.
-	// However, when gids are specified, they have to fall in the defined range.
-	SupplementalGroupsStrategyMayRunAs SupplementalGroupsStrategyType = "MayRunAs"
 	// SupplementalGroupsStrategyMustRunAs means that container must run as a particular gid.
 	SupplementalGroupsStrategyMustRunAs SupplementalGroupsStrategyType = "MustRunAs"
 	// SupplementalGroupsStrategyRunAsAny means that container may make requests for any gid.
diff --git a/pkg/cloudprovider/providers/BUILD b/pkg/cloudprovider/providers/BUILD
index aeccfa1e5b..4313576203 100644
--- a/pkg/cloudprovider/providers/BUILD
+++ b/pkg/cloudprovider/providers/BUILD
@@ -12,6 +12,7 @@ go_library(
     deps = [
         "//pkg/cloudprovider/providers/aws:go_default_library",
         "//pkg/cloudprovider/providers/azure:go_default_library",
+        "//pkg/cloudprovider/providers/cascade:go_default_library",
         "//pkg/cloudprovider/providers/cloudstack:go_default_library",
         "//pkg/cloudprovider/providers/gce:go_default_library",
         "//pkg/cloudprovider/providers/openstack:go_default_library",
@@ -34,6 +35,7 @@ filegroup(
         ":package-srcs",
         "//pkg/cloudprovider/providers/aws:all-srcs",
         "//pkg/cloudprovider/providers/azure:all-srcs",
+        "//pkg/cloudprovider/providers/cascade:all-srcs",
         "//pkg/cloudprovider/providers/cloudstack:all-srcs",
         "//pkg/cloudprovider/providers/fake:all-srcs",
         "//pkg/cloudprovider/providers/gce:all-srcs",
diff --git a/pkg/cloudprovider/providers/cascade/BUILD b/pkg/cloudprovider/providers/cascade/BUILD
new file mode 100644
index 0000000000..4089166732
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/BUILD
@@ -0,0 +1,56 @@
+package(default_visibility = ["//visibility:public"])
+
+load(
+    "@io_bazel_rules_go//go:def.bzl",
+    "go_library",
+)
+
+go_library(
+    name = "go_default_library",
+    srcs = [
+        "apitypes.go",
+        "auth.go",
+        "cascade.go",
+        "cascade_disks.go",
+        "cascade_instances.go",
+        "cascade_loadbalancer.go",
+        "client.go",
+        "oidcclient.go",
+        "restclient.go",
+        "utils.go"
+        ],
+    deps = [
+        "//pkg/api/v1/helper:go_default_library",
+        "//pkg/cloudprovider:go_default_library",
+        "//pkg/controller:go_default_library",
+        "//vendor/github.com/golang/glog:go_default_library",
+        "//vendor/gopkg.in/gcfg.v1:go_default_library",
+        "//vendor/k8s.io/api/core/v1:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/types:go_default_library",
+    ],
+)
+
+go_test(
+    name = "go_default_test",
+    srcs = [
+        "cascade_instances_test.go",
+    ],
+    embed = [":go_default_library"],
+    deps = [
+        "//vendor/k8s.io/api/core/v1:go_default_library",
+        "//vendor/github.com/stretchr/testify/assert:go_default_library",
+    ],
+)
+
+filegroup(
+    name = "package-srcs",
+    srcs = glob(["**"]),
+    tags = ["automanaged"],
+    visibility = ["//visibility:private"],
+)
+
+filegroup(
+    name = "all-srcs",
+    srcs = [":package-srcs"],
+    tags = ["automanaged"],
+)
diff --git a/pkg/cloudprovider/providers/cascade/OWNERS b/pkg/cloudprovider/providers/cascade/OWNERS
new file mode 100644
index 0000000000..70efc9dc1c
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/OWNERS
@@ -0,0 +1,3 @@
+maintainers:
+- ashokc
+- ysheng
diff --git a/pkg/cloudprovider/providers/cascade/apitypes.go b/pkg/cloudprovider/providers/cascade/apitypes.go
new file mode 100644
index 0000000000..d437394462
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/apitypes.go
@@ -0,0 +1,230 @@
+package cascade
+
+import "fmt"
+
+const (
+	NotFoundError     = 1408
+	VMNotFoundError   = 2006
+	DiskNotFoundError = 3011
+	DiskInUseError    = 3012
+
+	DiskStateAttached = "ATTACHED"
+)
+
+// Represents APIError returned by the API in case of an error.
+type APIError struct {
+	Code           *string           `json:"code"`
+	Data           map[string]string `json:"data"`
+	ErrorCode      int32             `json:"errorCode,omitempty"`
+	Message        *string           `json:"message"`
+	HttpStatusCode int               `json:"-"` // Not part of API contract
+}
+
+// Implement Go error interface for ApiError.
+func (e APIError) Error() string {
+	return fmt.Sprintf(
+		"Cascade: { HTTP status: '%d', code: '%s', message: '%s', data: '%v', errorcode: '%d' }",
+		e.HttpStatusCode, StringVal(e.Code), StringVal(e.Message), e.Data, e.ErrorCode)
+}
+
+// Used to represent a generic HTTP error, i.e. an unexpected HTTP 500.
+type HttpError struct {
+	StatusCode int
+	Message    string
+}
+
+// Implementation of error interface for HttpError.
+func (e HttpError) Error() string {
+	return fmt.Sprintf("Cascade: HTTP %d: %v", e.StatusCode, e.Message)
+}
+
+// Represents a task which gets returned for long running API calls.
+type Task struct {
+	EndTime            int64       `json:"endTime,omitempty"`
+	Entity             *Entity     `json:"entity,omitempty"`
+	ID                 *string     `json:"id"`
+	Operation          string      `json:"operation,omitempty"`
+	QueuedTime         *int64      `json:"queuedTime"`
+	ResourceProperties interface{} `json:"resourceProperties,omitempty"`
+	SelfLink           string      `json:"selfLink,omitempty"`
+	StartedTime        *int64      `json:"startedTime"`
+	State              *string     `json:"state"`
+	Steps              []*Step     `json:"steps"`
+}
+
+// Represents the entity associated with the task.
+type Entity struct {
+	ID   *string `json:"id"`
+	Kind *string `json:"kind"`
+}
+
+// Represents a task that has entered into an error state. Task errors can be caught and type-checked against with the
+// usual Go idiom.
+type TaskError struct {
+	ID   string `json:"id"`
+	Step Step   `json:"step,omitempty"`
+}
+
+// Implement Go error interface for TaskError.
+func (e TaskError) Error() string {
+	return fmt.Sprintf("Cascade: Task '%s' is in error state: {@step==%s}", e.ID, GetStep(e.Step))
+}
+
+// An error representing a timeout while waiting for a task to complete.
+type TaskTimeoutError struct {
+	ID string
+}
+
+// Implement Go error interface for TaskTimeoutError.
+func (e TaskTimeoutError) Error() string {
+	return fmt.Sprintf("Cascade: Timed out waiting for task '%s'. "+
+		"Task may not be in error state, examine task for full details.", e.ID)
+}
+
+// Represents a step in a task.
+type Step struct {
+	EndTime     int64             `json:"endTime,omitempty"`
+	Errors      []*APIError       `json:"errors"`
+	Operation   string            `json:"operation,omitempty"`
+	Options     map[string]string `json:"options,omitempty"`
+	QueuedTime  *int64            `json:"queuedTime"`
+	Sequence    int32             `json:"sequence,omitempty"`
+	StartedTime *int64            `json:"startedTime"`
+	State       *string           `json:"state"`
+	Warnings    []*APIError       `json:"warnings"`
+}
+
+// Implement Go error interface for Step.
+func GetStep(s Step) string {
+	return fmt.Sprintf("{\"operation\"=>\"%s\",\"state\"=>\"%s}", s.Operation, StringVal(s.State))
+}
+
+// Represents the VM response returned by the API.
+type VM struct {
+	AttachedDisks          []*AttachedDisk  `json:"attachedDisks"`
+	Cost                   []*QuotaLineItem `json:"cost"`
+	Flavor                 *string          `json:"flavor"`
+	FloatingIP             string           `json:"floatingIp,omitempty"`
+	HighAvailableVMGroupID string           `json:"highAvailableVMGroupID,omitempty"`
+	ID                     *string          `json:"id"`
+	Kind                   string           `json:"kind"`
+	Name                   *string          `json:"name"`
+	SelfLink               string           `json:"selfLink,omitempty"`
+	SourceImageID          string           `json:"sourceImageId,omitempty"`
+	State                  *string          `json:"state"`
+	Subnets                []string         `json:"subnets"`
+	Tags                   []string         `json:"tags"`
+}
+
+// Represents the listVMs response returned by the API.
+type VMList struct {
+	Items            []*VM  `json:"items"`
+	NextPageLink     string `json:"nextPageLink,omitempty"`
+	PreviousPageLink string `json:"previousPageLink,omitempty"`
+}
+
+// Represents multiple VMs returned by the API.
+type VMs struct {
+	Items []VM `json:"items"`
+}
+
+// Represents the disks attached to the VMs.
+type AttachedDisk struct {
+	BootDisk   *bool   `json:"bootDisk"`
+	CapacityGb *int32  `json:"capacityGb"`
+	Flavor     *string `json:"flavor"`
+	ID         *string `json:"id"`
+	Kind       *string `json:"kind"`
+	Name       *string `json:"name"`
+	State      *string `json:"state"`
+}
+
+// Represents an attach disk operation request.
+type VMDiskOperation struct {
+	Arguments map[string]string `json:"arguments,omitempty"`
+	DiskID    *string           `json:"diskId"`
+}
+
+// Represents the quota line items for the VM.
+type QuotaLineItem struct {
+	Key   *string  `json:"key"`
+	Unit  *string  `json:"unit"`
+	Value *float64 `json:"value"`
+}
+
+// Represents a persistent disk
+type PersistentDisk struct {
+	CapacityGB  int32            `json:"capacityGb,omitempty"`
+	Cost        []*QuotaLineItem `json:"cost"`
+	Datastore   string           `json:"datastore,omitempty"`
+	Flavor      *string          `json:"flavor"`
+	ID          *string          `json:"id"`
+	Kind        string           `json:"kind"`
+	Name        *string          `json:"name"`
+	SelfLink    string           `json:"selfLink,omitempty"`
+	State       *string          `json:"state"`
+	Tags        []string         `json:"tags"`
+	VM          string           `json:"vm"`
+	MountDevice string           `json:"mountDevice,omitempty"`
+	Zone        *string          `json:"zone"`
+}
+
+// Represents the spec for creating a disk.
+type DiskCreateSpec struct {
+	Affinities []*LocalitySpec `json:"affinities"`
+	CapacityGB *int32          `json:"capacityGb"`
+	Flavor     *string         `json:"flavor"`
+	Kind       *string         `json:"kind"`
+	Name       *string         `json:"name"`
+	Tags       []string        `json:"tags"`
+	Zone       *string         `json:"zone"`
+	Encrypted  *bool           `json:"encrypted"`
+}
+
+// Represents the spec for specifying affinity for a disk with another entity.
+type LocalitySpec struct {
+	ID   *string `json:"id"`
+	Kind *string `json:"kind"`
+}
+
+// Represens the LoadBalancer response returned by the API.
+type LoadBalancer struct {
+	Endpoint *string `json:"endpoint"`
+}
+
+// Represents the spec for creating a LoadBalancer.
+type LoadBalancerCreateSpec struct {
+	HealthCheck *LoadBalancerHealthCheck `json:"healthCheck"`
+	Name        *string                  `json:"name"`
+	PortMaps    []*LoadBalancerPortMap   `json:"portMaps"`
+	Type        *string                  `json:"type"`
+	SubDomain   *string                  `json:"subDomain"`
+}
+
+// Represents the health check spec for a load balancer.
+type LoadBalancerHealthCheck struct {
+	HealthyThreshold  int64   `json:"healthyThreshold,omitempty"`
+	IntervalInSeconds int64   `json:"intervalInSeconds,omitempty"`
+	Path              *string `json:"path,omitempty"`
+	Port              *int64  `json:"port"`
+	Protocol          *string `json:"protocol"`
+}
+
+// Represents a port mapping spec for a load balancer.
+type LoadBalancerPortMap struct {
+	AllowedCidrs         []*string `json:"allowedCidrs"`
+	InstancePort         *int64    `json:"instancePort"`
+	InstanceProtocol     *string   `json:"instanceProtocol"`
+	LoadBalancerPort     *int64    `json:"loadBalancerPort"`
+	LoadBalancerProtocol *string   `json:"loadBalancerProtocol"`
+}
+
+// Represents a VM to be registered with or deregistered from the load balancer.
+type LoadBalancerVM struct {
+	ID *string `json:"id"`
+}
+
+// Represents a list of VMs to be registered with or deregistered from the load balancer.
+type LoadBalancerVMUpdate struct {
+	VMIds []*LoadBalancerVM `json:"vmIds"`
+}
diff --git a/pkg/cloudprovider/providers/cascade/auth.go b/pkg/cloudprovider/providers/cascade/auth.go
new file mode 100644
index 0000000000..fc9237767f
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/auth.go
@@ -0,0 +1,145 @@
+package cascade
+
+import (
+	"fmt"
+	"strings"
+	"github.com/golang/glog"
+	"os/exec"
+)
+
+const (
+	tScope = "openid offline_access rs_admin_server at_groups rs_vmdir"
+
+	afdCli                     = "/opt/vmware/bin/vmafd-cli"
+	afdCliMachineAccountCmd    = "get-machine-account-info"
+	afdCliPasswordPrefix       = "Password: "
+	afdCliSeparator            = "\n"
+)
+
+// AuthConfig contains configuration information for the authentication client.
+type AuthConfig struct {
+	tenantName string
+	authEndpoint string
+	machineAccountName string
+}
+
+// AuthClient defines functions related to authentication.
+type AuthClient struct {
+	cfg *AuthConfig
+}
+
+// NewAuthClient creates a new authentication client
+func NewAuthClient(cascadeCfg *CascadeConfig) (*AuthClient, error) {
+	return &AuthClient{
+		cfg: &AuthConfig{
+			tenantName: cascadeCfg.Global.TenantName,
+			authEndpoint: cascadeCfg.Global.AuthEndpoint,
+			machineAccountName: fmt.Sprintf("%s@%s", cascadeCfg.Global.DNSName, cascadeCfg.Global.DomainName),
+		},
+	}, nil
+}
+
+func (c *AuthClient) GetTokensByMachineAccount() (*TokenOptions, error) {
+	// Use the VMAFD CLI to get the machine account password
+	cmd := exec.Command(afdCli, afdCliMachineAccountCmd)
+	output, err := cmd.Output()
+	if err != nil {
+		glog.Errorf("Cascade Cloud Provider: Failed to get machine account credentials. Cannot create Client.")
+		return nil, fmt.Errorf("Failed to get machine account credentials, err: %v", err)
+	}
+
+	password, err := parseMachineAccountInfo(output)
+	if err != nil {
+		glog.Errorf("Cascade Cloud Provider: Failed to parse machine account credentials. Cannot create Client.")
+		return nil, fmt.Errorf("Failed to parse machine account credentials, err: %v", err)
+	}
+
+	return c.GetTokensByCredentials(c.cfg.machineAccountName, password)
+}
+
+// GetTokensByPassword gets tokens using username and password
+func (c *AuthClient) GetTokensByCredentials(username, password string) (*TokenOptions, error) {
+	// Parse tenant part from username
+	parts := strings.Split(username, "@")
+	if len(parts) != 2 {
+		return nil, fmt.Errorf("Invalid full user name '%s': expected user@tenant", username)
+	}
+	tenant := parts[1]
+
+	oidcClient, err := buildOIDCClient(c.cfg.authEndpoint)
+	if err != nil {
+		return nil, err
+	}
+
+	tokenResponse, err := oidcClient.GetTokenByPasswordGrant(tenant, username, password)
+	if err != nil {
+		return nil, err
+	}
+
+	return toTokenOptions(tokenResponse), nil
+}
+
+// GetTokensByRefreshToken gets tokens using refresh token
+func (c *AuthClient) GetTokensByRefreshToken(refreshtoken string) (*TokenOptions, error) {
+	oidcClient, err := buildOIDCClient(c.cfg.authEndpoint)
+	if err != nil {
+		return nil, err
+	}
+
+	tokenResponse, err := oidcClient.GetTokenByRefreshTokenGrant(c.cfg.tenantName, refreshtoken)
+	if err != nil {
+		return nil, err
+	}
+
+	return toTokenOptions(tokenResponse), nil
+}
+
+func buildOIDCClient(authEndpoint string) (*OIDCClient, error) {
+	options := &OIDCClientOptions{
+		IgnoreCertificate: false,
+		RootCAs:           nil,
+		TokenScope:        tScope,
+	}
+
+	return NewOIDCClient(authEndpoint, options, nil), nil
+}
+
+func toTokenOptions(response *OIDCTokenResponse) *TokenOptions {
+	return &TokenOptions{
+		AccessToken:  response.AccessToken,
+		ExpiresIn:    response.ExpiresIn,
+		RefreshToken: response.RefreshToken,
+		IDToken:      response.IDToken,
+		TokenType:    response.TokenType,
+	}
+}
+
+// parseMachineAccountInfo parses the machine account password from the machine-account-info output which looks like
+// this:
+//MachineAccount: photon-8rwdscr1.lw-testdom.com
+//Password: FT`])}]d/3\EPwRpz9k1
+func parseMachineAccountInfo(output []byte) (string, error) {
+	if len(output) <= 0 {
+		return "", fmt.Errorf("account info is not specified")
+	}
+
+	strOut := string(output)
+	strOutLen := len(strOut)
+
+	pwdStart := strings.Index(strOut, afdCliPasswordPrefix)
+	if pwdStart < 0 {
+		return "", fmt.Errorf("account info is not in expected format")
+	}
+	pwdStart = pwdStart + len(afdCliPasswordPrefix)
+	if pwdStart >= strOutLen {
+		return "", fmt.Errorf("account info is not in expected format")
+	}
+	pwdEnd := strings.LastIndex(strOut, afdCliSeparator)
+	if pwdEnd < 0 || pwdEnd <= pwdStart || pwdEnd >= strOutLen {
+		return "", fmt.Errorf("account info is not in expected format")
+	}
+
+	pwd := strOut[pwdStart:pwdEnd]
+
+	return pwd, nil
+}
\ No newline at end of file
diff --git a/pkg/cloudprovider/providers/cascade/cascade.go b/pkg/cloudprovider/providers/cascade/cascade.go
new file mode 100644
index 0000000000..b9fafb92e1
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/cascade.go
@@ -0,0 +1,219 @@
+// The use of Cascade cloud provider requires the kubelet, kube-apiserver, and kube-controller-manager to be started
+// with config flag: '--cloud-provider=cascade --cloud-config=[path_to_config_file]'.
+package cascade
+
+import (
+	"context"
+	"errors"
+	"fmt"
+	"github.com/golang/glog"
+	"gopkg.in/gcfg.v1"
+	"io"
+	k8stypes "k8s.io/apimachinery/pkg/types"
+	"k8s.io/kubernetes/pkg/cloudprovider"
+	"k8s.io/kubernetes/pkg/controller"
+	"os"
+	"strings"
+)
+
+const (
+	ProviderName = "vke"
+	DiskSpecKind = "persistent-disk"
+	MasterPrefix = "master"
+)
+
+// CascadeCloud is an implementation of the cloud provider interface for Cascade Controller.
+type CascadeCloud struct {
+	cfg *CascadeConfig
+	// Authentication client to get token for Cascade API calls
+	authClient *AuthClient
+	// API Client to make Cascade API calls
+	apiClient *Client
+	// local $HOSTNAME
+	localHostname string
+	// hostname from K8S, could be overridden
+	localK8sHostname string
+}
+
+// CascadeCloud represents Cascade cloud provider's configuration.
+type CascadeConfig struct {
+	Global struct {
+		// the Cascade Controller endpoint
+		CloudTarget string `gcfg:"target"`
+		// Cascade Controller tenantName name
+		TenantName string `gcfg:"tenantName"`
+		// Cascade Controller cluster ID
+		ClusterID string `gcfg:"clusterID"`
+		// Authentication server endpoint for Cascade Controller
+		AuthEndpoint string `gcfg:"authEndpoint"`
+		// Lightwave domain name for the node
+		DomainName string `gcfg:"domainName"`
+		// DNS name of the node.
+		DNSName string `gcfg:"dnsName"`
+		// Region in which the cluster is in
+		Region string `gcfg:"region"`
+		// Availability zone in which the cluster is in
+		Zone string `gcfg:"zone"`
+		// IP address of the node.
+		IPAddress string `gcfg:"ipAddress"`
+	}
+}
+
+// Disks is interface for manipulation with Cascade Controller Persistent Disks.
+type Disks interface {
+	// AttachDisk attaches given disk to given node. Current node
+	// is used when nodeName is empty string.
+	AttachDisk(diskID string, nodeName k8stypes.NodeName) (string, error)
+
+	// DetachDisk detaches given disk to given node. Current node
+	// is used when nodeName is empty string.
+	DetachDisk(diskID string, nodeName k8stypes.NodeName) error
+
+	// DiskIsAttached checks if a disk is attached to the given node.
+	DiskIsAttached(diskID string, nodeName k8stypes.NodeName) (bool, error)
+
+	// DisksAreAttached is a batch function to check if a list of disks are attached
+	// to the node with the specified NodeName.
+	DisksAreAttached(diskID []string, nodeName k8stypes.NodeName) (map[string]bool, error)
+
+	// CreateDisk creates a new PD with given properties.
+	CreateDisk(volumeOptions *VolumeOptions) (diskID string, err error)
+
+	// DeleteDisk deletes PD.
+	DeleteDisk(diskID string) error
+
+	// Get labels to apply to volume on creation.
+	GetVolumeLabels(diskID string) (map[string]string, error)
+}
+
+// VolumeOptions specifies capacity, tags, name and flavorID for a volume.
+type VolumeOptions struct {
+	CapacityGB        int
+	Tags              map[string]string
+	Name              string
+	Type              string
+	ZonePresent       bool
+	ZonesPresent      bool
+	AvailabilityZone  string
+	AvailabilityZones string
+	Encrypted         bool
+}
+
+func readConfig(config io.Reader) (*CascadeConfig, error) {
+	if config == nil {
+		err := fmt.Errorf("Cascade Cloud Provider: config file is missing. Please restart with " +
+			"--cloud-provider=cascade --cloud-config=[path_to_config_file]")
+		return nil, err
+	}
+
+	var cfg CascadeConfig
+	err := gcfg.ReadInto(&cfg, config)
+	return &cfg, err
+}
+
+func init() {
+	cloudprovider.RegisterCloudProvider(ProviderName, func(config io.Reader) (cloudprovider.Interface, error) {
+		cfg, err := readConfig(config)
+		if err != nil {
+			glog.Errorf("Cascade Cloud Provider: failed to read in cloud provider config file. Error[%v]", err)
+			return nil, err
+		}
+		return newCascadeCloud(cfg)
+	})
+}
+
+func newCascadeCloud(cfg *CascadeConfig) (*CascadeCloud, error) {
+	if len(cfg.Global.CloudTarget) == 0 {
+		return nil, fmt.Errorf("Cascade Controller endpoint was not specified.")
+	}
+
+	// Get local hostname
+	hostname, err := os.Hostname()
+	if err != nil {
+		glog.Errorf("Cascade Cloud Provider: get hostname failed. Error[%v]", err)
+		return nil, err
+	}
+
+	cc := CascadeCloud{
+		cfg:              cfg,
+		localHostname:    hostname,
+		localK8sHostname: "",
+	}
+
+	// Instantiate the auth and API clients only on the master nodes. Kubelets running on the workers don't need them as
+	// they are used primarily for making API calls to Cascade.
+	if strings.HasPrefix(hostname, MasterPrefix) {
+		if cc.authClient, err = NewAuthClient(cfg); err != nil {
+			return nil, err
+		}
+
+		if cc.apiClient, err = NewClient(cfg, cc.authClient); err != nil {
+			return nil, err
+		}
+	}
+
+	return &cc, nil
+}
+
+// Initialize passes a Kubernetes clientBuilder interface to the cloud provider
+func (cc *CascadeCloud) Initialize(clientBuilder controller.ControllerClientBuilder) {}
+
+// Instances returns an implementation of Instances for Cascade Controller.
+func (cc *CascadeCloud) Instances() (cloudprovider.Instances, bool) {
+	return cc, true
+}
+
+func (cc *CascadeCloud) Clusters() (cloudprovider.Clusters, bool) {
+	return nil, true
+}
+
+// ProviderName returns the cloud provider ID.
+func (cc *CascadeCloud) ProviderName() string {
+	return ProviderName
+}
+
+// LoadBalancer returns an implementation of LoadBalancer for Cascade Controller.
+func (cc *CascadeCloud) LoadBalancer() (cloudprovider.LoadBalancer, bool) {
+	return cc, true
+}
+
+// Zones returns an implementation of Zones for Cascade Controller.
+func (cc *CascadeCloud) Zones() (cloudprovider.Zones, bool) {
+	return cc, true
+}
+
+func (cc *CascadeCloud) GetZone(ctx context.Context) (cloudprovider.Zone, error) {
+	return cloudprovider.Zone{
+		Region:        cc.cfg.Global.Region,
+		FailureDomain: cc.cfg.Global.Zone,
+	}, nil
+}
+
+// GetZoneByProviderID implements Zones.GetZoneByProviderID
+// This is particularly useful in external cloud providers where the kubelet
+// does not initialize node data.
+func (cc *CascadeCloud) GetZoneByProviderID(ctx context.Context, providerID string) (cloudprovider.Zone, error) {
+	return cloudprovider.Zone{}, errors.New("unimplemented")
+}
+
+// GetZoneByNodeName implements Zones.GetZoneByNodeName
+// This is particularly useful in external cloud providers where the kubelet
+// does not initialize node data.
+func (cc *CascadeCloud) GetZoneByNodeName(ctx context.Context, nodeName k8stypes.NodeName) (cloudprovider.Zone, error) {
+	return cloudprovider.Zone{}, errors.New("unimeplemented")
+}
+
+// Routes returns a false since the interface is not supported for Cascade controller.
+func (cc *CascadeCloud) Routes() (cloudprovider.Routes, bool) {
+	return nil, false
+}
+
+// ScrubDNS filters DNS settings for pods.
+func (cc *CascadeCloud) ScrubDNS(nameservers, searches []string) (nsOut, srchOut []string) {
+	return nameservers, searches
+}
+
+// HasClusterID returns true if the cluster has a clusterID
+func (cc *CascadeCloud) HasClusterID() bool {
+	return true
+}
diff --git a/pkg/cloudprovider/providers/cascade/cascade_disks.go b/pkg/cloudprovider/providers/cascade/cascade_disks.go
new file mode 100644
index 0000000000..e889a28951
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/cascade_disks.go
@@ -0,0 +1,253 @@
+package cascade
+
+import (
+	"context"
+	"fmt"
+	"github.com/golang/glog"
+	k8stypes "k8s.io/apimachinery/pkg/types"
+	"k8s.io/apimachinery/pkg/util/sets"
+	"k8s.io/kubernetes/pkg/kubelet/apis"
+	"k8s.io/kubernetes/pkg/volume"
+	volumeutil "k8s.io/kubernetes/pkg/volume/util"
+)
+
+// Attaches given virtual disk volume to the node running kubelet.
+func (cc *CascadeCloud) AttachDisk(diskID string, nodeName k8stypes.NodeName) (string, error) {
+	// Check if disk is already attached to that node.
+	attached, err := cc.DiskIsAttached(diskID, nodeName)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: cc.DiskIsAttached failed during AttachDisk. Error[%v]", err)
+		return "", err
+	}
+
+	// If not already attached, attach the disk.
+	if !attached {
+		operation := &VMDiskOperation{
+			DiskID: StringPtr(diskID),
+		}
+
+		vmID, err := cc.InstanceID(context.TODO(), nodeName)
+		if err != nil {
+			glog.Errorf("VKE Cloud Provider: cc.InstanceID failed for AttachDisk. Error[%v]", err)
+			return "", err
+		}
+
+		task, err := cc.apiClient.AttachDisk(vmID, operation)
+		if err != nil {
+			glog.Errorf("VKE Cloud Provider: Failed to attach disk with ID %s. Error[%v]", diskID, err)
+			return "", err
+		}
+
+		_, err = cc.apiClient.WaitForTask(StringVal(task.ID))
+		if err != nil {
+			glog.Errorf("VKE Cloud Provider: Failed to wait for task to attach disk with ID %s. Error[%v]",
+				diskID, err)
+			return "", err
+		}
+	}
+
+	// Get mount device of the attached disk.
+	disk, err := cc.apiClient.GetDisk(diskID)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to Get disk with diskID %s. Error[%v]", diskID, err)
+		return "", err
+	}
+
+	return disk.MountDevice, nil
+}
+
+// Detaches given virtual disk volume from the node running kubelet.
+func (cc *CascadeCloud) DetachDisk(diskID string, nodeName k8stypes.NodeName) error {
+	operation := &VMDiskOperation{
+		DiskID: StringPtr(diskID),
+	}
+
+	vmID, err := cc.InstanceID(context.TODO(), nodeName)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: cc.InstanceID failed for DetachDisk. Error[%v]", err)
+		return err
+	}
+
+	task, err := cc.apiClient.DetachDisk(vmID, operation)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to detach disk with pdID %s. Error[%v]", diskID, err)
+		return err
+	}
+
+	_, err = cc.apiClient.WaitForTask(StringVal(task.ID))
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to wait for task to detach disk with pdID %s. Error[%v]",
+			diskID, err)
+		return err
+	}
+
+	return nil
+}
+
+// DiskIsAttached returns if disk is attached to the VM using controllers supported by the plugin.
+func (cc *CascadeCloud) DiskIsAttached(diskID string, nodeName k8stypes.NodeName) (bool, error) {
+	vmID, err := cc.InstanceID(context.TODO(), nodeName)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: cc.InstanceID failed for DiskIsAttached. Error[%v]", err)
+		return false, err
+	}
+
+	_, err = cc.apiClient.GetVM(vmID)
+	if err != nil {
+		switch err.(type) {
+		case APIError:
+			if err.(APIError).ErrorCode == VMNotFoundError {
+				// If instance no longer exists, we will assume that the volume is not attached.
+				glog.Warningf("VKE Cloud Provider: Instance %s does not exist. DiskIsAttached will assume"+
+					" disk %s is not attached to it.", nodeName, diskID)
+				return false, nil
+			}
+		}
+		return false, err
+	}
+
+	disk, err := cc.apiClient.GetDisk(diskID)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to Get disk with diskID %s. Error[%v]", diskID, err)
+		return false, err
+	}
+
+	if disk.VM == vmID && StringVal(disk.State) == DiskStateAttached {
+		return true, nil
+	}
+
+	return false, nil
+}
+
+// DisksAreAttached returns if disks are attached to the VM using controllers supported by the plugin.
+func (cc *CascadeCloud) DisksAreAttached(diskIDs []string, nodeName k8stypes.NodeName) (map[string]bool, error) {
+	attached := make(map[string]bool)
+	for _, diskID := range diskIDs {
+		attached[diskID] = false
+	}
+
+	vmID, err := cc.InstanceID(context.TODO(), nodeName)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: cc.InstanceID failed for DiskIsAttached. Error[%v]", err)
+		return attached, err
+	}
+
+	for _, diskID := range diskIDs {
+		disk, err := cc.apiClient.GetDisk(diskID)
+		if err != nil {
+			glog.Warningf("VKE Cloud Provider: failed to get VMs for persistent disk %s, err [%v]",
+				diskID, err)
+		} else {
+			if disk.VM == vmID && StringVal(disk.State) == DiskStateAttached {
+				attached[diskID] = true
+			}
+		}
+	}
+
+	return attached, nil
+}
+
+// Create a volume of given size (in GB).
+func (cc *CascadeCloud) CreateDisk(volumeOptions *VolumeOptions) (diskID string, err error) {
+	// Get Zones for the cluster
+	zones, err := cc.apiClient.GetZones()
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to Get zones for the cluster. Error[%v]", err)
+		return "", err
+	}
+
+	// Pick a zone to place the disk in.
+	zoneSet := sets.NewString()
+	for _, zone := range zones {
+		zoneSet.Insert(zone)
+	}
+	var zone string
+	if !volumeOptions.ZonePresent && !volumeOptions.ZonesPresent {
+		zone = volumeutil.ChooseZoneForVolume(zoneSet, volumeOptions.Name)
+	}
+	if !volumeOptions.ZonePresent && volumeOptions.ZonesPresent {
+		userZoneSet, err := volumeutil.ZonesToSet(volumeOptions.AvailabilityZones)
+		if err != nil {
+			return "", err
+		}
+		if !zoneSet.IsSuperset(userZoneSet) {
+			return "", fmt.Errorf("VKE Cloud Provider: Zones '%s' is invalid. "+
+				"Please use one or more of the following zones: %v", volumeOptions.AvailabilityZones, zoneSet.List())
+		}
+		zone = volumeutil.ChooseZoneForVolume(userZoneSet, volumeOptions.Name)
+	}
+	if volumeOptions.ZonePresent && !volumeOptions.ZonesPresent {
+		if err := volumeutil.ValidateZone(volumeOptions.AvailabilityZone); err != nil {
+			return "", err
+		}
+		if !zoneSet.Has(volumeOptions.AvailabilityZone) {
+			return "", fmt.Errorf("VKE Cloud Provider: Zone '%s' is invalid. "+
+				"Please use one of the following zones: %v", volumeOptions.AvailabilityZone, zoneSet.List())
+		}
+		zone = volumeOptions.AvailabilityZone
+	}
+
+	diskSpec := DiskCreateSpec{}
+	diskSpec.Name = StringPtr(volumeOptions.Name)
+	diskSpec.Flavor = StringPtr(volumeOptions.Type)
+	diskSpec.CapacityGB = Int32Ptr(int32(volumeOptions.CapacityGB))
+	diskSpec.Kind = StringPtr(DiskSpecKind)
+	diskSpec.Zone = StringPtr(zone)
+	diskSpec.Encrypted = BoolPtr(volumeOptions.Encrypted)
+
+	task, err := cc.apiClient.CreateDisk(&diskSpec)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to CreateDisk. Error[%v]", err)
+		return "", err
+	}
+
+	waitTask, err := cc.apiClient.WaitForTask(StringVal(task.ID))
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to wait for task to CreateDisk. Error[%v]", err)
+		return "", err
+	}
+
+	return StringVal(waitTask.Entity.ID), nil
+}
+
+// Deletes a volume given volume name.
+func (cc *CascadeCloud) DeleteDisk(diskID string) error {
+	task, err := cc.apiClient.DeleteDisk(diskID)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to DeleteDisk. Error[%v]", err)
+		// If we get a DiskNotFound error, we assume that the disk is already deleted. So we don't return an error here.
+		switch err.(type) {
+		case APIError:
+			if err.(APIError).ErrorCode == DiskNotFoundError {
+				return nil
+			}
+			if err.(APIError).ErrorCode == DiskInUseError {
+				return volume.NewDeletedVolumeInUseError(err.Error())
+			}
+		}
+		return err
+	}
+
+	_, err = cc.apiClient.WaitForTask(StringVal(task.ID))
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to wait for task to DeleteDisk. Error[%v]", err)
+		return err
+	}
+
+	return nil
+}
+
+// Gets the zone and region for the volume.
+func (cc *CascadeCloud) GetVolumeLabels(diskID string) (map[string]string, error) {
+	disk, err := cc.apiClient.GetDisk(diskID)
+	if err != nil {
+		glog.Errorf("VKE Cloud Provider: Failed to GetDisk for GetVolumeLabels. Error[%v]", err)
+		return nil, err
+	}
+
+	labels := make(map[string]string)
+	labels[apis.LabelZoneFailureDomain] = StringVal(disk.Zone)
+	labels[apis.LabelZoneRegion] = cc.cfg.Global.Region
+
+	return labels, nil
+}
diff --git a/pkg/cloudprovider/providers/cascade/cascade_instances.go b/pkg/cloudprovider/providers/cascade/cascade_instances.go
new file mode 100644
index 0000000000..9f3f17c169
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/cascade_instances.go
@@ -0,0 +1,133 @@
+package cascade
+
+import (
+	"context"
+	"errors"
+	"github.com/golang/glog"
+	"os"
+	"strings"
+
+	"k8s.io/api/core/v1"
+	k8stypes "k8s.io/apimachinery/pkg/types"
+	"k8s.io/kubernetes/pkg/cloudprovider"
+)
+
+// NodeAddresses is an implementation of Instances.NodeAddresses. In the future, private IP address, external IP, etc.
+// will be added based on need.
+func (cc *CascadeCloud) NodeAddresses(ctx context.Context, nodeName k8stypes.NodeName) ([]v1.NodeAddress, error) {
+	return []v1.NodeAddress{
+		{Type: v1.NodeInternalIP, Address: cc.cfg.Global.IPAddress},
+		{Type: v1.NodeInternalDNS, Address: cc.cfg.Global.DNSName},
+	}, nil
+}
+
+// NodeAddressesByProviderID returns the node addresses of an instances with the specified unique providerID
+// This method will not be called from the node that is requesting this ID. i.e. metadata service
+// and other local methods cannot be used here
+func (cc *CascadeCloud) NodeAddressesByProviderID(ctx context.Context, providerID string) ([]v1.NodeAddress, error) {
+	// Get the name of the VM using the ID and generate the DNS name based on the VM name.
+	vm, err := cc.apiClient.GetVM(providerID)
+	if err != nil {
+		return nil, err
+	}
+	// Get the DNS name for the master VM and replace the VM name portion with the requested VM name.
+	dnsNameParts := strings.SplitN(cc.cfg.Global.DNSName, ".", 2)
+	if len(dnsNameParts) != 2 {
+		return nil, errors.New("Cascade cloud provider: Invalid DNS name specified in the configuation. " +
+			"Cannot get NodeAddressByProviderID.")
+	}
+	dnsAddress := StringVal(vm.Name) + dnsNameParts[1]
+	addresses := []v1.NodeAddress{}
+	addresses = append(addresses, v1.NodeAddress{Type: v1.NodeInternalDNS, Address: dnsAddress})
+	return addresses, nil
+}
+
+func (cc *CascadeCloud) AddSSHKeyToAllInstances(ctx context.Context, user string, keyData []byte) error {
+	return errors.New("unimplemented")
+}
+
+// Current node name returns node name based on host name. For Cascade Kubernetes nodes, we will use host name as the
+// node name.
+func (cc *CascadeCloud) CurrentNodeName(ctx context.Context, hostname string) (k8stypes.NodeName, error) {
+	cc.localK8sHostname = hostname
+	return k8stypes.NodeName(hostname), nil
+}
+
+// ExternalID returns the cloud provider ID of the specified instance (deprecated).
+// Note: We call Cascade Controller here to check if the instance is alive or not. That check is used by Kubernetes
+// to proactively remove nodes that the cloud provider believes is no longer available. Even otherwise, Kubernetes
+// will remove those nodes eventually.
+
+func (cc *CascadeCloud) ExternalID(ctx context.Context, nodeName k8stypes.NodeName) (string, error) {
+	return getInstanceIDAndLivelinessFromNodeName(cc, nodeName)
+}
+
+// InstanceExistsByProviderID returns true if the instance with the given provider id still exists and is running.
+// If false is returned with no error, the instance will be immediately deleted by the cloud controller manager.
+func (cc *CascadeCloud) InstanceExistsByProviderID(ctx context.Context, providerID string) (bool, error) {
+	return false, errors.New("unimplemented")
+}
+
+// InstanceID returns the cloud provider ID of the specified instance.
+// Note: We call Cascade Controller here to check if the instance is alive or not. That check is used by Kubernetes
+// to proactively remove nodes that the cloud provider believes is no longer available.
+func (cc *CascadeCloud) InstanceID(ctx context.Context, nodeName k8stypes.NodeName) (string, error) {
+	return getInstanceIDAndLivelinessFromNodeName(cc, nodeName)
+}
+
+// This gets the Cascade VM ID from the Kubernetes node name.
+func getInstanceIDFromNodeName(nodeName k8stypes.NodeName) (string, error) {
+	// nodeName is of the format master-instance-id or worker-instance-id. To compute the instance ID, we need to just
+	// get the portion after master- or worker-. That is what we do below.
+	nodeParts := strings.SplitN(string(nodeName), "-", 2)
+	if len(nodeParts) != 2 {
+		return "", errors.New("Cascade cloud provider: Invalid node name. Cannot fetch instance ID.")
+	}
+	return nodeParts[1], nil
+}
+
+// This gets the Cascade VM ID and its liveliness from the Kubernetes node name.
+func getInstanceIDAndLivelinessFromNodeName(cc *CascadeCloud, nodeName k8stypes.NodeName) (string, error) {
+	instanceID, err := getInstanceIDFromNodeName(nodeName)
+	if err != nil {
+		return "", err
+	}
+	// Get local hostname. We need to do this check to make sure we call VKE controller only from master nodes
+	// because worker nodes cannot login to VKE controller.
+	hostname, err := os.Hostname()
+	if err != nil {
+		glog.Errorf("Cascade Cloud Provider: get hostname failed. Error[%v]", err)
+		return "", err
+	}
+	// Note: Kubelet running on the worker node do not need to call VKE.
+	if strings.HasPrefix(hostname, MasterPrefix) {
+		_, err := cc.apiClient.GetVM(instanceID)
+		if err != nil {
+			switch err.(type) {
+			case APIError:
+				if err.(APIError).ErrorCode == VMNotFoundError {
+					// If instance no longer exists, we will return instance not found error
+					glog.Warningf("Cascade Cloud Provider: VM %s does not exist", instanceID)
+					return "", cloudprovider.InstanceNotFound
+				}
+			}
+		}
+	}
+	return instanceID, nil
+}
+
+// InstanceTypeByProviderID returns the cloudprovider instance type of the node with the specified unique providerID
+// This method will not be called from the node that is requesting this ID. i.e. metadata service
+// and other local methods cannot be used here
+func (cc *CascadeCloud) InstanceTypeByProviderID(ctx context.Context, providerID string) (string, error) {
+	return "", errors.New("unimplemented")
+}
+
+func (cc *CascadeCloud) InstanceType(ctx context.Context, nodeName k8stypes.NodeName) (string, error) {
+	return "", nil
+}
+
+// InstanceShutdownByProviderID returns true if the instance is in safe state to detach volumes
+func (cc *CascadeCloud) InstanceShutdownByProviderID(ctx context.Context, providerID string) (bool, error) {
+	return false, cloudprovider.NotImplemented
+}
diff --git a/pkg/cloudprovider/providers/cascade/cascade_instances_test.go b/pkg/cloudprovider/providers/cascade/cascade_instances_test.go
new file mode 100644
index 0000000000..8fb314def1
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/cascade_instances_test.go
@@ -0,0 +1,44 @@
+package cascade
+
+import (
+	"context"
+	"strings"
+	"testing"
+
+	"github.com/stretchr/testify/assert"
+	"k8s.io/api/core/v1"
+)
+
+const configFile = `
+[Global]
+target = target
+tenantName = tenant
+clusterID = cluster-id
+authEndpoint = auth-endpoint
+domainName = domain.test
+dnsName = node.domain.test
+region = region
+zone = zone
+ipAddress = 1.1.1.1
+`
+
+func getCascadeInstance() (*CascadeCloud, error) {
+	cfg, err := readConfig(strings.NewReader(configFile))
+	return &CascadeCloud{
+		cfg:              cfg,
+		localHostname:    "hostname",
+		localK8sHostname: "",
+	}, err
+}
+
+func TestNodeAddresses(t *testing.T) {
+	cc, err := getCascadeInstance()
+	assert.Nil(t, err)
+	expectedNodeAddresses := []v1.NodeAddress{
+		{Type: v1.NodeInternalIP, Address: "1.1.1.1"},
+		{Type: v1.NodeInternalDNS, Address: "node.domain.test"},
+	}
+	actualNodeAddresses, err := cc.NodeAddresses(context.TODO(), "node")
+	assert.Nil(t, err)
+	assert.Equal(t, expectedNodeAddresses, actualNodeAddresses)
+}
diff --git a/pkg/cloudprovider/providers/cascade/cascade_loadbalancer.go b/pkg/cloudprovider/providers/cascade/cascade_loadbalancer.go
new file mode 100644
index 0000000000..c2a62c2ff7
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/cascade_loadbalancer.go
@@ -0,0 +1,295 @@
+package cascade
+
+import (
+	"context"
+	"fmt"
+	"github.com/golang/glog"
+	"k8s.io/api/core/v1"
+	"k8s.io/apimachinery/pkg/types"
+	"k8s.io/kubernetes/pkg/api/v1/service"
+	"k8s.io/kubernetes/pkg/cloudprovider"
+)
+
+const TCP_PROTOCOL = "TCP"
+
+const HTTP_PROTOCOL = "HTTP"
+
+const ServiceAnnotationLoadBalancerInternal = "service.beta.kubernetes.io/vke-load-balancer-internal"
+
+// EnsureLoadBalancer creates or updates a Cascade load balancer
+func (cc *CascadeCloud) EnsureLoadBalancer(ctx context.Context, clusterName string, k8sService *v1.Service, nodes []*v1.Node) (*v1.LoadBalancerStatus, error) {
+	logger := newLoadBalancerLogger(clusterName, k8sService, "EnsureLoadBalancer")
+
+	loadBalancerName := cloudprovider.GetLoadBalancerName(k8sService)
+	logger.Infof("Load balancer name: %s", loadBalancerName)
+
+	// Sanity checks
+	if k8sService.Spec.SessionAffinity != v1.ServiceAffinityNone {
+		logger.Errorf("Unsupported load balancer session affinity: %+v", k8sService.Spec.SessionAffinity)
+		return nil, fmt.Errorf("Unsupported load balancer session affinity: %+v", k8sService.Spec.SessionAffinity)
+	}
+
+	if len(k8sService.Spec.Ports) == 0 {
+		logger.Errorf("No port mapping is specified")
+		return nil, fmt.Errorf("No port mapping is specified")
+	}
+
+	// Create load balancer port maps
+	portMaps := []*LoadBalancerPortMap{}
+	for _, port := range k8sService.Spec.Ports {
+		if port.Protocol != v1.ProtocolTCP {
+			logger.Warningf("Ignoring port that does not use TCP protocol: %+v", port)
+			continue
+		}
+
+		if port.NodePort == 0 {
+			logger.Warningf("Ignoring port without node port defined: %+v", port)
+			continue
+		}
+
+		// TODO: For now we only support SSL pass through. All port mappings are using TCP protocol.
+		//       Also note that we allow all external traffic to access the ports.
+		portMap := &LoadBalancerPortMap{
+			InstancePort:         Int64Ptr(int64(port.NodePort)),
+			InstanceProtocol:     StringPtr(TCP_PROTOCOL),
+			LoadBalancerPort:     Int64Ptr(int64(port.Port)),
+			LoadBalancerProtocol: StringPtr(TCP_PROTOCOL),
+		}
+		portMaps = append(portMaps, portMap)
+	}
+
+	// Create load balancer health check
+	healthCheck := &LoadBalancerHealthCheck{
+		HealthyThreshold:  5,
+		IntervalInSeconds: 10,
+	}
+	if healthCheckPath, healthCheckNodePort := service.GetServiceHealthCheckPathPort(k8sService); healthCheckPath != "" {
+		logger.Infof("HTTP health checks on: %s:%d", healthCheckPath, healthCheckNodePort)
+		healthCheck.Path = StringPtr(healthCheckPath)
+		healthCheck.Port = Int64Ptr(int64(healthCheckNodePort))
+		healthCheck.Protocol = StringPtr(HTTP_PROTOCOL)
+	} else {
+		logger.Infof("TCP health check on port: %d", Int64Val(portMaps[0].InstancePort))
+		healthCheck.Port = portMaps[0].InstancePort
+		healthCheck.Protocol = StringPtr(TCP_PROTOCOL)
+	}
+
+	// Create load balancer
+	createSpec := &LoadBalancerCreateSpec{
+		Name:        StringPtr(loadBalancerName),
+		Type:        StringPtr(getLoadBalancerType(k8sService)),
+		PortMaps:    portMaps,
+		HealthCheck: healthCheck,
+		SubDomain:   StringPtr(k8sService.Name),
+	}
+	logger.Infof("Load balancer create spec: %+v", *createSpec)
+
+	task, err := cc.apiClient.CreateOrUpdateLoadBalancer(createSpec)
+	if err != nil {
+		logger.Errorf("Failed to create or update load balancer. Error: [%v]", err)
+		return nil, err
+	}
+
+	_, err = cc.apiClient.WaitForTask(StringVal(task.ID))
+	if err != nil {
+		logger.Errorf("Failed to poll task status of creating or updating load balancer. Error: [%v]", err)
+		return nil, err
+	}
+
+	// Apply VM update to load balancer
+	err = cc.updateLoadBalancerVMs(nodes, loadBalancerName, logger)
+	if err != nil {
+		// The private function already did logging. No need to log again.
+		return nil, err
+	}
+
+	// Get load balancer
+	loadBalancer, err := cc.apiClient.GetLoadBalancer(StringPtr(loadBalancerName))
+	if err != nil {
+		glog.Errorf("Failed to get load balancer. Error: [%v]", err)
+		return nil, err
+	}
+
+	return toLoadBalancerStatus(loadBalancer), nil
+}
+
+// GetLoadBalancer returns the information about a Cascade load balancer
+func (cc *CascadeCloud) GetLoadBalancer(ctx context.Context, clusterName string, k8sService *v1.Service) (*v1.LoadBalancerStatus, bool, error) {
+	logger := newLoadBalancerLogger(clusterName, k8sService, "GetLoadBalancer")
+
+	loadBalancerName := cloudprovider.GetLoadBalancerName(k8sService)
+	logger.Infof("Load balancer name: %s", loadBalancerName)
+
+	// Get load balancer
+	loadBalancer, err := cc.apiClient.GetLoadBalancer(StringPtr(loadBalancerName))
+	if err != nil {
+		logger.Errorf("Failed to get load balancer. Error: [%v]", err)
+		// Do not return error here because we want the caller of this function to determine
+		// what to do with the not-found situation.
+		switch err.(type) {
+		case APIError:
+			if err.(APIError).ErrorCode == NotFoundError {
+				return nil, false, nil
+			}
+		}
+		return nil, false, err
+	}
+
+	return toLoadBalancerStatus(loadBalancer), true, nil
+}
+
+// UpdateLoadBalancer updates the node information of a Cascade load balancer
+func (cc *CascadeCloud) UpdateLoadBalancer(ctx context.Context, clusterName string, k8sService *v1.Service, nodes []*v1.Node) error {
+	logger := newLoadBalancerLogger(clusterName, k8sService, "UpdateLoadBalancer")
+
+	loadBalancerName := cloudprovider.GetLoadBalancerName(k8sService)
+	logger.Infof("Load balancer name: %s", loadBalancerName)
+
+	err := cc.updateLoadBalancerVMs(nodes, loadBalancerName, logger)
+	if err != nil {
+		// The private function already did logging. No need to log again.
+		return err
+	}
+
+	return nil
+}
+
+// EnsureLoadBalancerDeleted deletes a Cascade load balancer
+func (cc *CascadeCloud) EnsureLoadBalancerDeleted(ctx context.Context, clusterName string, k8sService *v1.Service) error {
+	logger := newLoadBalancerLogger(clusterName, k8sService, "EnsureLoadBalancerDeleted")
+
+	loadBalancerName := cloudprovider.GetLoadBalancerName(k8sService)
+	logger.Infof("Load balancer name: %s", loadBalancerName)
+
+	task, err := cc.apiClient.DeleteLoadBalancer(StringPtr(loadBalancerName), k8sService.Name)
+	if err != nil {
+		logger.Errorf("Failed to delete load balancer. Error: [%v]", err)
+		// If we get a NotFound error, we assume that the load balancer is already deleted. So we don't return an error
+		// here.
+		switch err.(type) {
+		case APIError:
+			if err.(APIError).ErrorCode == NotFoundError {
+				return nil
+			}
+		}
+		return err
+	}
+
+	_, err = cc.apiClient.WaitForTask(StringVal(task.ID))
+	if err != nil {
+		logger.Errorf("Failed to poll task status of deleting load balancer. Error: [%v]", err)
+		return err
+	}
+
+	return nil
+}
+
+func (cc *CascadeCloud) updateLoadBalancerVMs(
+	nodes []*v1.Node, loadBalancerName string, logger *loadBalancerLogger) error {
+
+	// Apply VM update to the load balancer
+	loadBalancerVMs := make([]*LoadBalancerVM, 0)
+
+	for _, node := range nodes {
+		// If the node does not have a name, we cannot derive its instance ID. Therefore we skip this node.
+		if len(node.Name) == 0 {
+			logger.Warningf("Node %s does not have a name. Skip updating this VM for load balancer", node.UID)
+			continue
+		}
+
+		// If we cannot get the instance ID, something is wrong on the Cascade Controller side.
+		// However, we should tolerate such failure and continue the load balancer VM update
+		// by skipping this VM.
+		instanceID, err := cc.InstanceID(context.TODO(), types.NodeName(node.Name))
+		if err != nil {
+			logger.Warningf("Unable to get instance ID for node %s, skip updating this VM for load balancer. Error [%v]", node.Name, err)
+			continue
+		}
+
+		loadBalancerVMs = append(loadBalancerVMs, &LoadBalancerVM{
+			ID: StringPtr(instanceID),
+		})
+	}
+
+	if len(loadBalancerVMs) == 0 {
+		logger.Infof("No nodes to be added to the load balancer. Skip updating load balancer VMs")
+		return nil
+	}
+
+	vmUpdate := &LoadBalancerVMUpdate{
+		VMIds: loadBalancerVMs,
+	}
+	logger.Infof("Load balancer VM update spec: %+v", vmUpdate.VMIds)
+
+	task, err := cc.apiClient.ApplyVMsToLoadBalancer(StringPtr(loadBalancerName), vmUpdate)
+	if err != nil {
+		logger.Errorf("Failed to update load balancer VMs. Error: [%v]", err)
+		return err
+	}
+
+	_, err = cc.apiClient.WaitForTask(StringVal(task.ID))
+	if err != nil {
+		logger.Errorf("Failed to poll task status of updating load balancer VMs. Error: [%v]", err)
+		return err
+	}
+
+	return nil
+}
+
+func toLoadBalancerStatus(lb *LoadBalancer) *v1.LoadBalancerStatus {
+	var endpoint string
+	if lb != nil && lb.Endpoint != nil {
+		endpoint = StringVal(lb.Endpoint)
+	}
+
+	return &v1.LoadBalancerStatus{
+		Ingress: []v1.LoadBalancerIngress{
+			{
+				Hostname: endpoint,
+			},
+		},
+	}
+}
+
+type loadBalancerLogger struct {
+	clusterName string
+	k8sService  *v1.Service
+	callingFunc string
+}
+
+func newLoadBalancerLogger(clusterName string, k8sService *v1.Service, callingFunc string) *loadBalancerLogger {
+	return &loadBalancerLogger{
+		clusterName: clusterName,
+		k8sService:  k8sService,
+		callingFunc: callingFunc,
+	}
+}
+
+func (l *loadBalancerLogger) getLogMsg(
+	msgTemplate string, args ...interface{}) string {
+
+	errorMsg := fmt.Sprintf("Cascade Cloud Provider::%s::Cluster [%s] Service [%s]: %s",
+		l.callingFunc, l.clusterName, l.k8sService.Name,
+		msgTemplate)
+	return fmt.Sprintf(errorMsg, args)
+}
+
+func (l *loadBalancerLogger) Errorf(msgTemplate string, args ...interface{}) {
+	glog.Errorln(l.getLogMsg(msgTemplate, args))
+}
+
+func (l *loadBalancerLogger) Warningf(msgTemplate string, args ...interface{}) {
+	glog.Warningln(l.getLogMsg(msgTemplate, args))
+}
+
+func (l *loadBalancerLogger) Infof(msgTemplate string, args ...interface{}) {
+	glog.Infoln(l.getLogMsg(msgTemplate, args))
+}
+
+// Check if service requires an internal load balancer.
+func getLoadBalancerType(service *v1.Service) string {
+	if _, found := service.Annotations[ServiceAnnotationLoadBalancerInternal]; found {
+		return "PRIVATE"
+	}
+	return "PUBLIC"
+}
diff --git a/pkg/cloudprovider/providers/cascade/client.go b/pkg/cloudprovider/providers/cascade/client.go
new file mode 100644
index 0000000000..400e3777d0
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/client.go
@@ -0,0 +1,400 @@
+package cascade
+
+import (
+	"bytes"
+	"crypto/tls"
+	"crypto/x509"
+	"encoding/json"
+	"fmt"
+	"github.com/golang/glog"
+	"net/http"
+	"strings"
+	"time"
+)
+
+// Represents stateless context needed to call Cascade APIs.
+// Note that we are implementing the Cascade APIs manually instead of using the swagger generated code
+// because swagger uses a different version of openapi library than kubernetes. It is difficult to
+// address the version conflict to make it compile.
+type Client struct {
+	cfg        *ClientConfig
+	options    ClientOptions
+	restClient *restClient
+}
+
+type ClientConfig struct {
+	tenantName string
+	clusterID  string
+	region     string
+	endpoint   string
+}
+
+// Represents Tokens
+type TokenOptions struct {
+	AccessToken  string `json:"access_token"`
+	ExpiresIn    int    `json:"expires_in"`
+	RefreshToken string `json:"refresh_token,omitempty"`
+	IDToken      string `json:"id_token"`
+	TokenType    string `json:"token_type"`
+}
+
+type TokenCallback func(string)
+
+// Options for Client
+type ClientOptions struct {
+	// When using the Tasks.Wait APIs, defines the duration of how long
+	// we should continue to poll the server. Default is 30 minutes.
+	// TasksAPI.WaitTimeout() can be used to specify timeout on
+	// individual calls.
+	TaskPollTimeout time.Duration
+
+	// Whether or not to ignore any TLS errors when talking to Cascade,
+	// false by default.
+	IgnoreCertificate bool
+
+	// List of root CA's to use for server validation
+	// nil by default.
+	RootCAs *x509.CertPool
+
+	// For tasks APIs, defines the number of retries to make in the event
+	// of an error. Default is 3.
+	TaskRetryCount int
+
+	// Tokens for user authentication. Default is empty.
+	TokenOptions *TokenOptions
+}
+
+const minimumTaskPollDelay = 500 * time.Millisecond
+
+// Creates a new Cascade client which can be used to make API calls to Cascade.
+func NewClient(cfg *CascadeConfig, authClient *AuthClient) (c *Client, err error) {
+	tokenOptions, err := authClient.GetTokensByMachineAccount()
+	if err != nil {
+		glog.Errorf("Cascade Cloud Provider: Failed to create new client due to error: %+v", err)
+		return
+	}
+
+	options := &ClientOptions{
+		TaskPollTimeout:   30 * time.Minute,
+		TaskRetryCount:    3,
+		TokenOptions:      tokenOptions,
+		IgnoreCertificate: false,
+		RootCAs:           nil,
+	}
+
+	tr := &http.Transport{
+		TLSClientConfig: &tls.Config{
+			InsecureSkipVerify: options.IgnoreCertificate,
+			RootCAs:            options.RootCAs},
+	}
+
+	tokenCallback := func(newToken string) {
+		c.options.TokenOptions.AccessToken = newToken
+	}
+
+	restClient := &restClient{
+		authClient:                authClient,
+		httpClient:                &http.Client{Transport: tr},
+		UpdateAccessTokenCallback: tokenCallback,
+	}
+
+	clientConfig := &ClientConfig{
+		tenantName: cfg.Global.TenantName,
+		clusterID:  cfg.Global.ClusterID,
+		region:     cfg.Global.Region,
+		endpoint:   strings.TrimRight(cfg.Global.CloudTarget, "/"),
+	}
+
+	c = &Client{
+		cfg:        clientConfig,
+		restClient: restClient,
+		// Ensure a copy of options is made, rather than using a pointer
+		// which may change out from underneath if misused by the caller.
+		options: *options,
+	}
+
+	return
+}
+
+// Gets VM with the specified ID.
+func (api *Client) GetVM(vmID string) (vm *VM, err error) {
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/vms/%s", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID, vmID)
+	res, err := api.restClient.Get(uri, api.options.TokenOptions)
+	if err != nil {
+		return
+	}
+	defer res.Body.Close()
+	res, err = getError(res)
+	if err != nil {
+		return
+	}
+	vm = &VM{}
+	err = json.NewDecoder(res.Body).Decode(vm)
+	return
+}
+
+// Gets disk with the specified ID.
+func (api *Client) GetDisk(diskID string) (disk *PersistentDisk, err error) {
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/disks/%s", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID, diskID)
+	res, err := api.restClient.Get(uri, api.options.TokenOptions)
+	if err != nil {
+		return
+	}
+	defer res.Body.Close()
+	res, err = getError(res)
+	if err != nil {
+		return
+	}
+	disk = &PersistentDisk{}
+	err = json.NewDecoder(res.Body).Decode(disk)
+	return
+}
+
+// Creates a disk under the cluster.
+func (api *Client) CreateDisk(spec *DiskCreateSpec) (task *Task, err error) {
+	body, err := json.Marshal(spec)
+	if err != nil {
+		return
+	}
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/disks", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID)
+	res, err := api.restClient.Post(uri, "application/json", bytes.NewReader(body), api.options.TokenOptions)
+	if err != nil {
+		return
+	}
+	defer res.Body.Close()
+	task, err = getTask(getError(res))
+	return
+}
+
+// Deletes a disk with the specified ID.
+func (api *Client) DeleteDisk(diskID string) (task *Task, err error) {
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/disks/%s", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID, diskID)
+	res, err := api.restClient.Delete(uri, api.options.TokenOptions)
+	if err != nil {
+		return
+	}
+	defer res.Body.Close()
+	task, err = getTask(getError(res))
+	return
+}
+
+// Attaches a disk to the specified VM.
+func (api *Client) AttachDisk(vmID string, op *VMDiskOperation) (task *Task, err error) {
+	body, err := json.Marshal(op)
+	if err != nil {
+		return
+	}
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/vms/%s/attach_disk", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID, vmID)
+	res, err := api.restClient.Post(uri, "application/json", bytes.NewReader(body), api.options.TokenOptions)
+	if err != nil {
+		return
+	}
+	defer res.Body.Close()
+	task, err = getTask(getError(res))
+	return
+}
+
+// Detaches a disk from the specified VM.
+func (api *Client) DetachDisk(vmID string, op *VMDiskOperation) (task *Task, err error) {
+	body, err := json.Marshal(op)
+	if err != nil {
+		return
+	}
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/vms/%s/detach_disk", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID, vmID)
+	res, err := api.restClient.Post(uri, "application/json", bytes.NewReader(body), api.options.TokenOptions)
+	if err != nil {
+		return
+	}
+	defer res.Body.Close()
+	task, err = getTask(getError(res))
+	return
+}
+
+// Gets a task by ID.
+func (api *Client) GetTask(taskID string) (task *Task, err error) {
+	uri := fmt.Sprintf("%s/v1/tenants/%s/tasks/%s?region=%s", api.cfg.endpoint, api.cfg.tenantName,
+		taskID, api.cfg.region)
+	res, err := api.restClient.Get(uri, api.options.TokenOptions)
+	if err != nil {
+		return
+	}
+	defer res.Body.Close()
+	result, err := getTask(getError(res))
+	return result, err
+}
+
+// Waits for a task to complete by polling the tasks API until a task returns with the state COMPLETED or ERROR.
+func (api *Client) WaitForTask(taskID string) (task *Task, err error) {
+	start := time.Now()
+	numErrors := 0
+	maxErrors := api.options.TaskRetryCount
+	backoffMultiplier := 1
+
+	for time.Since(start) < api.options.TaskPollTimeout {
+		task, err = api.GetTask(taskID)
+		if err != nil {
+			switch err.(type) {
+			// If an ApiError comes back, something is wrong, return the error to the caller
+			case APIError:
+				return
+				// For other errors, retry before giving up
+			default:
+				numErrors++
+				if numErrors > maxErrors {
+					return
+				}
+			}
+		} else {
+			// Reset the error count any time a successful call is made
+			numErrors = 0
+			if StringVal(task.State) == "COMPLETED" {
+				return
+			}
+			if StringVal(task.State) == "ERROR" {
+				err = TaskError{StringVal(task.ID), getFailedStep(task)}
+				return
+			}
+		}
+
+		// Perform backoff based on how long it has been since we started polling. The logic is as follows:
+		// For the first 10 seconds, poll every 500 milliseconds.
+		// From there till the first 1 minute, poll every 1 second.
+		// From there till the first 10 minutes, poll every 5 seconds.
+		// From there till the timeout (30 minutes), poll every 10 seconds.
+		elapsedTime := time.Since(start)
+		if elapsedTime > 10*time.Second && elapsedTime <= 60*time.Second {
+			backoffMultiplier = 2
+		} else if elapsedTime > 60*time.Second && elapsedTime <= 600*time.Second {
+			backoffMultiplier = 10
+		} else if elapsedTime > 600*time.Second && elapsedTime <= api.options.TaskPollTimeout {
+			backoffMultiplier = 20
+		}
+		time.Sleep(time.Duration(backoffMultiplier) * minimumTaskPollDelay)
+	}
+	err = TaskTimeoutError{taskID}
+	return
+}
+
+// CreateOrUpdateLoadBalancer creates a load balancer if not existed, or update one otherwise
+func (api *Client) CreateOrUpdateLoadBalancer(spec *LoadBalancerCreateSpec) (*Task, error) {
+	body, err := json.Marshal(spec)
+	if err != nil {
+		return nil, err
+	}
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/loadbalancers", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID)
+	res, err := api.restClient.Post(uri, "application/json", bytes.NewReader(body), api.options.TokenOptions)
+	if err != nil {
+		return nil, err
+	}
+	defer res.Body.Close()
+	return getTask(getError(res))
+}
+
+// GetLoadBalancer returns a load balancer by name
+func (api *Client) GetLoadBalancer(loadBalancerName *string) (*LoadBalancer, error) {
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/loadbalancers/%s", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID, StringVal(loadBalancerName))
+	res, err := api.restClient.Get(uri, api.options.TokenOptions)
+	if err != nil {
+		return nil, err
+	}
+	defer res.Body.Close()
+	res, err = getError(res)
+	if err != nil {
+		return nil, err
+	}
+	loadBalancer := &LoadBalancer{}
+	err = json.NewDecoder(res.Body).Decode(loadBalancer)
+	return loadBalancer, err
+}
+
+// DeleteLoadBalancer deletes a load balancer by name
+func (api *Client) DeleteLoadBalancer(loadBalancerName *string, subDomain string) (*Task, error) {
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/loadbalancers/%s", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID, StringVal(loadBalancerName))
+
+	if len(subDomain) > 0 {
+		uri = fmt.Sprintf(uri+"?sub-domain=%s", subDomain)
+	}
+
+	res, err := api.restClient.Delete(uri, api.options.TokenOptions)
+	if err != nil {
+		return nil, err
+	}
+	return getTask(getError(res))
+}
+
+// ApplyVMsToLoadBalancer updates the instances that are registered with the load balancer
+func (api *Client) ApplyVMsToLoadBalancer(loadBalancerName *string, update *LoadBalancerVMUpdate) (*Task, error) {
+	body, err := json.Marshal(update)
+	if err != nil {
+		return nil, err
+	}
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/loadbalancers/%s/update_vms", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID, StringVal(loadBalancerName))
+	res, err := api.restClient.Post(uri, "application/json", bytes.NewReader(body), api.options.TokenOptions)
+	if err != nil {
+		return nil, err
+	}
+	defer res.Body.Close()
+	return getTask(getError(res))
+}
+
+// Gets all the zones in which the cluster has the VMs in.
+func (api *Client) GetZones() (zones []string, err error) {
+	// Call the version 2 zones API to use generic zones.
+	uri := fmt.Sprintf("%s/v1/tenants/%s/clusters/%s/zones?version=2", api.cfg.endpoint, api.cfg.tenantName,
+		api.cfg.clusterID)
+	res, err := api.restClient.Get(uri, api.options.TokenOptions)
+	if err != nil {
+		return
+	}
+	defer res.Body.Close()
+	res, err = getError(res)
+	if err != nil {
+		return
+	}
+	err = json.NewDecoder(res.Body).Decode(&zones)
+	return
+}
+
+// Reads a task object out of the HTTP response. Takes an error argument
+// so that GetTask can easily wrap GetError. This function will do nothing
+// if e is not nil.
+// e.g. res, err := getTask(getError(someApi.Get()))
+func getTask(res *http.Response, e error) (*Task, error) {
+	if e != nil {
+		return nil, e
+	}
+	var task Task
+	err := json.NewDecoder(res.Body).Decode(&task)
+	if err != nil {
+		return nil, err
+	}
+	if StringVal(task.State) == "ERROR" {
+		// Critical: return task as well, so that it can be examined
+		// for error details.
+		return &task, TaskError{StringVal(task.ID), getFailedStep(&task)}
+	}
+	return &task, nil
+}
+
+// Gets the failed step in the task to get error details for failed task.
+func getFailedStep(task *Task) (step Step) {
+	var errorStep Step
+	for _, s := range task.Steps {
+		if StringVal(s.State) == "ERROR" {
+			errorStep = *s
+			break
+		}
+	}
+
+	return errorStep
+}
diff --git a/pkg/cloudprovider/providers/cascade/oidcclient.go b/pkg/cloudprovider/providers/cascade/oidcclient.go
new file mode 100644
index 0000000000..6a71cc184f
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/oidcclient.go
@@ -0,0 +1,297 @@
+package cascade
+
+import (
+	"crypto/tls"
+	"crypto/x509"
+	"encoding/json"
+	"encoding/pem"
+	"fmt"
+	"io/ioutil"
+	"log"
+	"net/http"
+	"net/url"
+	"strings"
+)
+
+const tokenScope string = "openid offline_access"
+
+// OIDCClient is client for OIDC
+type OIDCClient struct {
+	httpClient *http.Client
+	logger     *log.Logger
+
+	Endpoint string
+	Options  *OIDCClientOptions
+}
+
+// OIDCClientOptions is OIDC client options
+type OIDCClientOptions struct {
+	// Whether or not to ignore any TLS errors when talking to Cascade,
+	// false by default.
+	IgnoreCertificate bool
+
+	// List of root CA's to use for server validation
+	// nil by default.
+	RootCAs *x509.CertPool
+
+	// The scope values to use when requesting tokens
+	TokenScope string
+}
+
+// NewOIDCClient creates an instance of OIDCClient
+func NewOIDCClient(endpoint string, options *OIDCClientOptions, logger *log.Logger) (c *OIDCClient) {
+	if logger == nil {
+		logger = log.New(ioutil.Discard, "", log.LstdFlags)
+	}
+
+	options = buildOptions(options)
+	tr := &http.Transport{
+		TLSClientConfig: &tls.Config{
+			InsecureSkipVerify: options.IgnoreCertificate,
+			RootCAs:            options.RootCAs},
+	}
+
+	c = &OIDCClient{
+		httpClient: &http.Client{Transport: tr},
+		logger:     logger,
+		Endpoint:   strings.TrimRight(endpoint, "/"),
+		Options:    options,
+	}
+	return
+}
+
+func buildOptions(options *OIDCClientOptions) (result *OIDCClientOptions) {
+	result = &OIDCClientOptions{
+		TokenScope: tokenScope,
+	}
+
+	if options == nil {
+		return
+	}
+
+	result.IgnoreCertificate = options.IgnoreCertificate
+
+	if options.RootCAs != nil {
+		result.RootCAs = options.RootCAs
+	}
+
+	if options.TokenScope != "" {
+		result.TokenScope = options.TokenScope
+	}
+
+	return
+}
+
+func (client *OIDCClient) buildURL(path string) (url string) {
+	return fmt.Sprintf("%s%s", client.Endpoint, path)
+}
+
+// Cert download helper
+
+const certDownloadPath string = "/afd/vecs/ssl"
+
+type lightWaveCert struct {
+	Value string `json:"encoded"`
+}
+
+// GetRootCerts gets root certs
+func (client *OIDCClient) GetRootCerts() (certList []*x509.Certificate, err error) {
+	// turn TLS verification off for
+	originalTr := client.httpClient.Transport
+	defer client.setTransport(originalTr)
+
+	tr := &http.Transport{
+		TLSClientConfig: &tls.Config{
+			InsecureSkipVerify: false,
+		},
+	}
+	client.setTransport(tr)
+
+	// get the certs
+	resp, err := client.httpClient.Get(client.buildURL(certDownloadPath))
+	if err != nil {
+		return
+	}
+	defer resp.Body.Close()
+	if resp.StatusCode != 200 {
+		err = fmt.Errorf("Unexpected error retrieving auth server certs: %v %s", resp.StatusCode, resp.Status)
+		return
+	}
+
+	// parse the certs
+	certsData := &[]lightWaveCert{}
+	err = json.NewDecoder(resp.Body).Decode(certsData)
+	if err != nil {
+		return
+	}
+
+	certList = make([]*x509.Certificate, len(*certsData))
+	for idx, cert := range *certsData {
+		block, _ := pem.Decode([]byte(cert.Value))
+		if block == nil {
+			err = fmt.Errorf("Unexpected response format: %v", certsData)
+			return nil, err
+		}
+
+		decodedCert, err := x509.ParseCertificate(block.Bytes)
+		if err != nil {
+			return nil, err
+		}
+
+		certList[idx] = decodedCert
+	}
+
+	return
+}
+
+func (client *OIDCClient) setTransport(tr http.RoundTripper) {
+	client.httpClient.Transport = tr
+}
+
+// Metadata request helpers
+const metadataPathFormat string = "/openidconnect/%s/.well-known/openid-configuration"
+
+// OIDCMetadataResponse is the response for Metadata request
+type OIDCMetadataResponse struct {
+	TokenEndpoint         string `json:"token_endpoint"`
+	AuthorizationEndpoint string `json:"authorization_endpoint"`
+	EndSessionEndpoint    string `json:"end_session_endpoint"`
+}
+
+func (client *OIDCClient) getMetadata(domain string) (metadata *OIDCMetadataResponse, err error) {
+	metadataPath := fmt.Sprintf(metadataPathFormat, domain)
+	request, err := http.NewRequest("GET", client.buildURL(metadataPath), nil)
+	if err != nil {
+		return nil, err
+	}
+
+	resp, err := client.httpClient.Do(request)
+	if err != nil {
+		return nil, err
+	}
+	defer resp.Body.Close()
+
+	err = client.checkResponse(resp)
+	if err != nil {
+		return nil, err
+	}
+
+	metadata = &OIDCMetadataResponse{}
+	err = json.NewDecoder(resp.Body).Decode(metadata)
+	if err != nil {
+		return nil, err
+	}
+
+	return
+}
+
+// Token request helpers
+
+const passwordGrantFormatString = "grant_type=password&username=%s&password=%s&scope=%s"
+const refreshTokenGrantFormatString = "grant_type=refresh_token&refresh_token=%s"
+const clientGrantFormatString = "grant_type=password&username=%s&password=%s&scope=%s&client_id=%s"
+
+// OIDCTokenResponse is the response for OIDC request
+type OIDCTokenResponse struct {
+	AccessToken  string `json:"access_token"`
+	ExpiresIn    int    `json:"expires_in"`
+	RefreshToken string `json:"refresh_token,omitempty"`
+	IDToken      string `json:"id_token"`
+	TokenType    string `json:"token_type"`
+}
+
+// GetTokenByPasswordGrant gets OIDC tokens by password
+func (client *OIDCClient) GetTokenByPasswordGrant(domain, username, password string) (tokens *OIDCTokenResponse, err error) {
+	metadata, err := client.getMetadata(domain)
+	if err != nil {
+		return nil, err
+	}
+
+	username = url.QueryEscape(username)
+	password = url.QueryEscape(password)
+	body := fmt.Sprintf(passwordGrantFormatString, username, password, client.Options.TokenScope)
+	return client.getToken(metadata.TokenEndpoint, body)
+}
+
+// GetClientTokenByPasswordGrant gets OIDC tokens by password
+func (client *OIDCClient) GetClientTokenByPasswordGrant(domain, username, password, clientID string) (tokens *OIDCTokenResponse, err error) {
+	metadata, err := client.getMetadata(domain)
+	if err != nil {
+		return nil, err
+	}
+
+	username = url.QueryEscape(username)
+	password = url.QueryEscape(password)
+	clientID = url.QueryEscape(clientID)
+	body := fmt.Sprintf(clientGrantFormatString, username, password, client.Options.TokenScope, clientID)
+	return client.getToken(metadata.TokenEndpoint, body)
+}
+
+// GetTokenByRefreshTokenGrant gets OIDC tokens by refresh token
+func (client *OIDCClient) GetTokenByRefreshTokenGrant(domain, refreshToken string) (tokens *OIDCTokenResponse, err error) {
+	metadata, err := client.getMetadata(domain)
+	if err != nil {
+		return nil, err
+	}
+
+	body := fmt.Sprintf(refreshTokenGrantFormatString, refreshToken)
+	return client.getToken(metadata.TokenEndpoint, body)
+}
+
+func (client *OIDCClient) getToken(tokenEndpoint, body string) (tokens *OIDCTokenResponse, err error) {
+	request, err := http.NewRequest("POST", tokenEndpoint, strings.NewReader(body))
+	if err != nil {
+		return nil, err
+	}
+	request.Header.Add("Content-Type", "application/x-www-form-urlencoded")
+
+	resp, err := client.httpClient.Do(request)
+	if err != nil {
+		return nil, err
+	}
+	defer resp.Body.Close()
+
+	err = client.checkResponse(resp)
+	if err != nil {
+		return nil, err
+	}
+
+	tokens = &OIDCTokenResponse{}
+	err = json.NewDecoder(resp.Body).Decode(tokens)
+	if err != nil {
+		return nil, err
+	}
+
+	return
+}
+
+// OIDCError is OIDC error
+type OIDCError struct {
+	Code    string `json:"error"`
+	Message string `json:"error_description"`
+}
+
+func (e OIDCError) Error() string {
+	return fmt.Sprintf("%v: %v", e.Code, e.Message)
+}
+
+func (client *OIDCClient) checkResponse(response *http.Response) (err error) {
+	if response.StatusCode/100 == 2 {
+		return
+	}
+
+	respBody, readErr := ioutil.ReadAll(response.Body)
+	if readErr != nil {
+		return fmt.Errorf(
+			"Status: %v, Body: %v [%v]", response.Status, string(respBody[:]), readErr)
+	}
+
+	var oidcErr OIDCError
+	err = json.Unmarshal(respBody, &oidcErr)
+	if err != nil || oidcErr.Code == "" {
+		return fmt.Errorf(
+			"Status: %v, Body: %v [%v]", response.Status, string(respBody[:]), readErr)
+	}
+
+	return oidcErr
+}
diff --git a/pkg/cloudprovider/providers/cascade/restclient.go b/pkg/cloudprovider/providers/cascade/restclient.go
new file mode 100644
index 0000000000..71d8d1c164
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/restclient.go
@@ -0,0 +1,262 @@
+package cascade
+
+import (
+	"bytes"
+	"encoding/json"
+	"io"
+	"io/ioutil"
+	"net/http"
+)
+
+type restClient struct {
+	httpClient                *http.Client
+	authClient                *AuthClient
+	UpdateAccessTokenCallback TokenCallback
+}
+
+type request struct {
+	Method      string
+	URL         string
+	ContentType string
+	Body        io.Reader
+	Tokens      *TokenOptions
+}
+
+type page struct {
+	Items            []interface{} `json:"items"`
+	NextPageLink     string        `json:"nextPageLink"`
+	PreviousPageLink string        `json:"previousPageLink"`
+}
+
+type documentList struct {
+	Items []interface{}
+}
+
+type bodyRewinder func() io.Reader
+
+const appJson string = "application/json"
+const expiredAuthToken int32 = 1904
+
+func (client *restClient) AppendSlice(origSlice []interface{}, dataToAppend []interface{}) []interface{} {
+	origLen := len(origSlice)
+	newLen := origLen + len(dataToAppend)
+
+	if newLen > cap(origSlice) {
+		newSlice := make([]interface{}, (newLen+1)*2)
+		copy(newSlice, origSlice)
+		origSlice = newSlice
+	}
+
+	origSlice = origSlice[0:newLen]
+	copy(origSlice[origLen:newLen], dataToAppend)
+
+	return origSlice
+}
+
+func (client *restClient) Get(url string, tokens *TokenOptions) (res *http.Response, err error) {
+	req := request{"GET", url, "", nil, tokens}
+	res, err = client.SendRequest(&req, nil)
+	return
+}
+
+func (client *restClient) GetList(endpoint string, url string, tokens *TokenOptions) (result []byte, err error) {
+	req := request{"GET", url, "", nil, tokens}
+	res, err := client.SendRequest(&req, nil)
+	if err != nil {
+		return
+	}
+	res, err = getError(res)
+	if err != nil {
+		return
+	}
+
+	decoder := json.NewDecoder(res.Body)
+	decoder.UseNumber()
+
+	page := &page{}
+	err = decoder.Decode(page)
+	if err != nil {
+		return
+	}
+
+	documentList := &documentList{}
+	documentList.Items = client.AppendSlice(documentList.Items, page.Items)
+
+	for page.NextPageLink != "" {
+		req = request{"GET", endpoint + page.NextPageLink, "", nil, tokens}
+		res, err = client.SendRequest(&req, nil)
+		if err != nil {
+			return
+		}
+		res, err = getError(res)
+		if err != nil {
+			return
+		}
+
+		decoder = json.NewDecoder(res.Body)
+		decoder.UseNumber()
+
+		page.NextPageLink = ""
+		page.PreviousPageLink = ""
+
+		err = decoder.Decode(page)
+		if err != nil {
+			return
+		}
+
+		documentList.Items = client.AppendSlice(documentList.Items, page.Items)
+	}
+
+	result, err = json.Marshal(documentList)
+
+	return
+}
+
+func (client *restClient) Post(url string, contentType string, body io.ReadSeeker, tokens *TokenOptions) (res *http.Response, err error) {
+	if contentType == "" {
+		contentType = appJson
+	}
+
+	req := request{"POST", url, contentType, body, tokens}
+	rewinder := func() io.Reader {
+		body.Seek(0, 0)
+		return body
+	}
+	res, err = client.SendRequest(&req, rewinder)
+	return
+}
+
+func (client *restClient) Patch(url string, contentType string, body io.ReadSeeker, tokens *TokenOptions) (res *http.Response, err error) {
+	if contentType == "" {
+		contentType = appJson
+	}
+
+	req := request{"PATCH", url, contentType, body, tokens}
+	rewinder := func() io.Reader {
+		body.Seek(0, 0)
+		return body
+	}
+	res, err = client.SendRequest(&req, rewinder)
+	return
+}
+
+func (client *restClient) Put(url string, contentType string, body io.ReadSeeker, tokens *TokenOptions) (res *http.Response, err error) {
+	if contentType == "" {
+		contentType = appJson
+	}
+
+	req := request{"PUT", url, contentType, body, tokens}
+	rewinder := func() io.Reader {
+		body.Seek(0, 0)
+		return body
+	}
+	res, err = client.SendRequest(&req, rewinder)
+	return
+}
+
+func (client *restClient) Delete(url string, tokens *TokenOptions) (res *http.Response, err error) {
+	req := request{"DELETE", url, "", nil, tokens}
+	res, err = client.SendRequest(&req, nil)
+	return
+}
+
+func (client *restClient) SendRequest(req *request, bodyRewinder bodyRewinder) (res *http.Response, err error) {
+	res, err = client.sendRequestHelper(req)
+	// In most cases, we'll return immediately
+	// If the operation succeeded, but we got a 401 response and if we're using
+	// authentication, then we'll look into the body to see if the token expired
+	if err != nil {
+		return res, err
+	}
+	if res.StatusCode != 401 {
+		// It's not a 401, so the token didn't expire
+		return res, err
+	}
+	if req.Tokens == nil || req.Tokens.AccessToken == "" {
+		// We don't have a token, so we can't renew the token, no need to proceed
+		return res, err
+	}
+
+	// We're going to look in the body to see if it failed because the token expired
+	// This means we need to read the body, but the functions that call us also
+	// expect to read the body. So we read the body, then create a new reader
+	// so they can read the body as normal.
+	body, err := ioutil.ReadAll(res.Body)
+	if err != nil {
+		return res, err
+	}
+	res.Body = ioutil.NopCloser(bytes.NewReader(body))
+
+	// Now see if we had an expired token or not
+	var apiError APIError
+	err = json.Unmarshal(body, &apiError)
+	if err != nil {
+		return res, err
+	}
+	if apiError.ErrorCode != expiredAuthToken {
+		return res, nil
+	}
+
+	// We were told that the access token expired, so we acquire a new token using the refresh token.
+	newTokens, err := client.authClient.GetTokensByRefreshToken(req.Tokens.RefreshToken)
+	// If there is an error during token refresh, we assume that the refresh token also expired. So we login again using
+	// the machine account.
+	if err != nil {
+		newTokens, err = client.authClient.GetTokensByMachineAccount()
+		if err != nil {
+			return res, err
+		}
+	}
+	req.Tokens.AccessToken = newTokens.AccessToken
+	if client.UpdateAccessTokenCallback != nil {
+		client.UpdateAccessTokenCallback(newTokens.AccessToken)
+	}
+	if req.Body != nil && bodyRewinder != nil {
+		req.Body = bodyRewinder()
+	}
+	res, err = client.sendRequestHelper(req)
+	return res, nil
+}
+
+func (client *restClient) sendRequestHelper(req *request) (res *http.Response, err error) {
+	r, err := http.NewRequest(req.Method, req.URL, req.Body)
+	if err != nil {
+		return
+	}
+	if req.ContentType != "" {
+		r.Header.Add("Content-Type", req.ContentType)
+	}
+	if req.Tokens != nil && req.Tokens.AccessToken != "" {
+		r.Header.Add("Authorization", "Bearer "+req.Tokens.AccessToken)
+	}
+	res, err = client.httpClient.Do(r)
+	if err != nil {
+		return
+	}
+
+	return
+}
+
+// Reads an error out of the HTTP response, or does nothing if
+// no error occured.
+func getError(res *http.Response) (*http.Response, error) {
+	// Do nothing if the response is a successful 2xx
+	if res.StatusCode/100 == 2 {
+		return res, nil
+	}
+	var apiError APIError
+	// ReadAll is usually a bad practice, but here we need to read the response all
+	// at once because we may attempt to use the data twice. It's preferable to use
+	// methods that take io.Reader, e.g. json.NewDecoder
+	body, err := ioutil.ReadAll(res.Body)
+	if err != nil {
+		return nil, err
+	}
+	err = json.Unmarshal(body, &apiError)
+	if err != nil {
+		// If deserializing into ApiError fails, return a generic HttpError instead
+		return nil, HttpError{res.StatusCode, string(body[:])}
+	}
+	apiError.HttpStatusCode = res.StatusCode
+	return nil, apiError
+}
diff --git a/pkg/cloudprovider/providers/cascade/tests_owed b/pkg/cloudprovider/providers/cascade/tests_owed
new file mode 100644
index 0000000000..dff5ab1dcd
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/tests_owed
@@ -0,0 +1,5 @@
+
+Yu Sheng
+Change-Id: Ifc11818f65a3e018aeea6988d9e2c0719b592920
+
+
diff --git a/pkg/cloudprovider/providers/cascade/utils.go b/pkg/cloudprovider/providers/cascade/utils.go
new file mode 100644
index 0000000000..866f853b42
--- /dev/null
+++ b/pkg/cloudprovider/providers/cascade/utils.go
@@ -0,0 +1,29 @@
+package cascade
+
+func StringPtr(s string) *string {
+	return &s
+}
+
+// StringVal returns string from string pointer, nil returns ""
+func StringVal(p *string) (s string) {
+	if p != nil {
+		s = *p
+	}
+	return
+}
+
+func Int64Ptr(s int64) *int64 {
+	return &s
+}
+
+func Int64Val(s *int64) int64 {
+	return *s
+}
+
+func Int32Ptr(s int32) *int32 {
+	return &s
+}
+
+func BoolPtr(s bool) *bool {
+	return &s
+}
diff --git a/pkg/cloudprovider/providers/providers.go b/pkg/cloudprovider/providers/providers.go
index 7de9ca9a41..a65547783a 100644
--- a/pkg/cloudprovider/providers/providers.go
+++ b/pkg/cloudprovider/providers/providers.go
@@ -21,6 +21,7 @@ import (
 	_ "k8s.io/kubernetes/pkg/cloudprovider/providers/aws"
 	_ "k8s.io/kubernetes/pkg/cloudprovider/providers/azure"
 	_ "k8s.io/kubernetes/pkg/cloudprovider/providers/cloudstack"
+	_ "k8s.io/kubernetes/pkg/cloudprovider/providers/cascade"
 	_ "k8s.io/kubernetes/pkg/cloudprovider/providers/gce"
 	_ "k8s.io/kubernetes/pkg/cloudprovider/providers/openstack"
 	_ "k8s.io/kubernetes/pkg/cloudprovider/providers/ovirt"
diff --git a/pkg/kubeapiserver/authorizer/config.go b/pkg/kubeapiserver/authorizer/config.go
index 5a3d88aabb..be1f0a7bdd 100644
--- a/pkg/kubeapiserver/authorizer/config.go
+++ b/pkg/kubeapiserver/authorizer/config.go
@@ -27,14 +27,15 @@ import (
 	versionedinformers "k8s.io/client-go/informers"
 	"k8s.io/kubernetes/pkg/auth/authorizer/abac"
 	"k8s.io/kubernetes/pkg/auth/nodeidentifier"
+	informers "k8s.io/kubernetes/pkg/client/informers/informers_generated/internalversion"
 	"k8s.io/kubernetes/pkg/kubeapiserver/authorizer/modes"
 	"k8s.io/kubernetes/plugin/pkg/auth/authorizer/node"
 	"k8s.io/kubernetes/plugin/pkg/auth/authorizer/rbac"
 	"k8s.io/kubernetes/plugin/pkg/auth/authorizer/rbac/bootstrappolicy"
+	"k8s.io/kubernetes/plugin/pkg/auth/authorizer/vke"
 )
 
-// Config contains the data on how to authorize a request to the Kube API Server
-type Config struct {
+type AuthorizationConfig struct {
 	AuthorizationModes []string
 
 	// Options for ModeABAC
@@ -51,12 +52,13 @@ type Config struct {
 	// TTL for caching of unauthorized responses from the webhook server.
 	WebhookCacheUnauthorizedTTL time.Duration
 
+	InformerFactory          informers.SharedInformerFactory
 	VersionedInformerFactory versionedinformers.SharedInformerFactory
 }
 
 // New returns the right sort of union of multiple authorizer.Authorizer objects
 // based on the authorizationMode or an error.
-func (config Config) New() (authorizer.Authorizer, authorizer.RuleResolver, error) {
+func (config AuthorizationConfig) New() (authorizer.Authorizer, authorizer.RuleResolver, error) {
 	if len(config.AuthorizationModes) == 0 {
 		return nil, nil, fmt.Errorf("at least one authorization mode must be passed")
 	}
@@ -73,14 +75,20 @@ func (config Config) New() (authorizer.Authorizer, authorizer.RuleResolver, erro
 			graph := node.NewGraph()
 			node.AddGraphEventHandlers(
 				graph,
-				config.VersionedInformerFactory.Core().V1().Nodes(),
-				config.VersionedInformerFactory.Core().V1().Pods(),
-				config.VersionedInformerFactory.Core().V1().PersistentVolumes(),
+				config.InformerFactory.Core().InternalVersion().Nodes(),
+				config.InformerFactory.Core().InternalVersion().Pods(),
+				config.InformerFactory.Core().InternalVersion().PersistentVolumes(),
 				config.VersionedInformerFactory.Storage().V1beta1().VolumeAttachments(),
 			)
 			nodeAuthorizer := node.NewAuthorizer(graph, nodeidentifier.NewDefaultNodeIdentifier(), bootstrappolicy.NodeRules())
 			authorizers = append(authorizers, nodeAuthorizer)
 
+		case modes.ModeVKE:
+			vkeAuthorizer, err := vke.NewAuthorizer()
+			if err != nil {
+				return nil, nil, err
+			}
+			authorizers = append(authorizers, vkeAuthorizer)
 		case modes.ModeAlwaysAllow:
 			alwaysAllowAuthorizer := authorizerfactory.NewAlwaysAllowAuthorizer()
 			authorizers = append(authorizers, alwaysAllowAuthorizer)
diff --git a/pkg/kubeapiserver/authorizer/modes/modes.go b/pkg/kubeapiserver/authorizer/modes/modes.go
index 501b98a95c..73a763ff14 100644
--- a/pkg/kubeapiserver/authorizer/modes/modes.go
+++ b/pkg/kubeapiserver/authorizer/modes/modes.go
@@ -19,22 +19,16 @@ package modes
 import "k8s.io/apimachinery/pkg/util/sets"
 
 const (
-	// ModeAlwaysAllow is the mode to set all requests as authorized
 	ModeAlwaysAllow string = "AlwaysAllow"
-	// ModeAlwaysDeny is the mode to set no requests as authorized
-	ModeAlwaysDeny string = "AlwaysDeny"
-	// ModeABAC is the mode to use Attribute Based Access Control to authorize
-	ModeABAC string = "ABAC"
-	// ModeWebhook is the mode to make an external webhook call to authorize
-	ModeWebhook string = "Webhook"
-	// ModeRBAC is the mode to use Role Based Access Control to authorize
-	ModeRBAC string = "RBAC"
-	// ModeNode is an authorization mode that authorizes API requests made by kubelets.
-	ModeNode string = "Node"
+	ModeAlwaysDeny  string = "AlwaysDeny"
+	ModeABAC        string = "ABAC"
+	ModeWebhook     string = "Webhook"
+	ModeRBAC        string = "RBAC"
+	ModeNode        string = "Node"
+	ModeVKE         string = "VKE"
 )
 
-// AuthorizationModeChoices is the list of supported authorization modes
-var AuthorizationModeChoices = []string{ModeAlwaysAllow, ModeAlwaysDeny, ModeABAC, ModeWebhook, ModeRBAC, ModeNode}
+var AuthorizationModeChoices = []string{ModeAlwaysAllow, ModeAlwaysDeny, ModeABAC, ModeWebhook, ModeRBAC, ModeNode, ModeVKE}
 
 // IsValidAuthorizationMode returns true if the given authorization mode is a valid one for the apiserver
 func IsValidAuthorizationMode(authzMode string) bool {
diff --git a/pkg/kubeapiserver/options/plugins.go b/pkg/kubeapiserver/options/plugins.go
index abcb5b4673..292fcdd1dc 100644
--- a/pkg/kubeapiserver/options/plugins.go
+++ b/pkg/kubeapiserver/options/plugins.go
@@ -57,6 +57,7 @@ import (
 	"k8s.io/apiserver/pkg/admission/plugin/namespace/lifecycle"
 	mutatingwebhook "k8s.io/apiserver/pkg/admission/plugin/webhook/mutating"
 	validatingwebhook "k8s.io/apiserver/pkg/admission/plugin/webhook/validating"
+	"k8s.io/kubernetes/plugin/pkg/admission/vke"
 	utilfeature "k8s.io/apiserver/pkg/util/feature"
 	"k8s.io/kubernetes/pkg/features"
 )
@@ -93,6 +94,7 @@ var AllOrderedPlugins = []string{
 	initialization.PluginName,               // Initializers
 	validatingwebhook.PluginName,            // ValidatingAdmissionWebhook
 	resourcequota.PluginName,                // ResourceQuota
+	vke.PluginName,                          // VMwareAdmissionController
 	deny.PluginName,                         // AlwaysDeny
 }
 
@@ -125,6 +127,7 @@ func RegisterAllAdmissionPlugins(plugins *admission.Plugins) {
 	setdefault.Register(plugins)
 	resize.Register(plugins)
 	storageobjectinuseprotection.Register(plugins)
+	vke.Register(plugins)
 }
 
 // DefaultOffAdmissionPlugins get admission plugins off by default for kube-apiserver.
diff --git a/pkg/printers/internalversion/describe.go b/pkg/printers/internalversion/describe.go
new file mode 100644
index 0000000000..f6b18a7f16
--- /dev/null
+++ b/pkg/printers/internalversion/describe.go
@@ -0,0 +1,4034 @@
+/*
+Copyright 2014 The Kubernetes Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+*/
+
+package internalversion
+
+import (
+	"bytes"
+	"crypto/x509"
+	"fmt"
+	"io"
+	"net"
+	"net/url"
+	"reflect"
+	"sort"
+	"strconv"
+	"strings"
+	"text/tabwriter"
+	"time"
+
+	"github.com/golang/glog"
+
+	"github.com/fatih/camelcase"
+
+	appsv1 "k8s.io/api/apps/v1"
+	rbacv1 "k8s.io/api/rbac/v1"
+	"k8s.io/apimachinery/pkg/api/errors"
+	"k8s.io/apimachinery/pkg/api/meta"
+	"k8s.io/apimachinery/pkg/api/resource"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/fields"
+	"k8s.io/apimachinery/pkg/labels"
+	"k8s.io/apimachinery/pkg/runtime/schema"
+	"k8s.io/apimachinery/pkg/types"
+	"k8s.io/apimachinery/pkg/util/intstr"
+	"k8s.io/apimachinery/pkg/util/sets"
+	"k8s.io/client-go/dynamic"
+	externalclient "k8s.io/client-go/kubernetes"
+	"k8s.io/client-go/rest"
+	"k8s.io/kubernetes/pkg/api/events"
+	"k8s.io/kubernetes/pkg/api/legacyscheme"
+	"k8s.io/kubernetes/pkg/api/ref"
+	resourcehelper "k8s.io/kubernetes/pkg/api/resource"
+	"k8s.io/kubernetes/pkg/apis/apps"
+	"k8s.io/kubernetes/pkg/apis/autoscaling"
+	"k8s.io/kubernetes/pkg/apis/batch"
+	"k8s.io/kubernetes/pkg/apis/certificates"
+	api "k8s.io/kubernetes/pkg/apis/core"
+	"k8s.io/kubernetes/pkg/apis/core/helper"
+	"k8s.io/kubernetes/pkg/apis/core/helper/qos"
+	"k8s.io/kubernetes/pkg/apis/extensions"
+	"k8s.io/kubernetes/pkg/apis/networking"
+	"k8s.io/kubernetes/pkg/apis/policy"
+	"k8s.io/kubernetes/pkg/apis/rbac"
+	rbacv1helpers "k8s.io/kubernetes/pkg/apis/rbac/v1"
+	"k8s.io/kubernetes/pkg/apis/scheduling"
+	"k8s.io/kubernetes/pkg/apis/storage"
+	storageutil "k8s.io/kubernetes/pkg/apis/storage/util"
+	clientset "k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset"
+	coreclient "k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/core/internalversion"
+	deploymentutil "k8s.io/kubernetes/pkg/controller/deployment/util"
+	"k8s.io/kubernetes/pkg/fieldpath"
+	"k8s.io/kubernetes/pkg/printers"
+	"k8s.io/kubernetes/pkg/registry/rbac/validation"
+	"k8s.io/kubernetes/pkg/util/slice"
+)
+
+// Each level has 2 spaces for PrefixWriter
+const (
+	LEVEL_0 = iota
+	LEVEL_1
+	LEVEL_2
+	LEVEL_3
+)
+
+// PrefixWriter can write text at various indentation levels.
+type PrefixWriter interface {
+	// Write writes text with the specified indentation level.
+	Write(level int, format string, a ...interface{})
+	// WriteLine writes an entire line with no indentation level.
+	WriteLine(a ...interface{})
+	// Flush forces indentation to be reset.
+	Flush()
+}
+
+// prefixWriter implements PrefixWriter
+type prefixWriter struct {
+	out io.Writer
+}
+
+var _ PrefixWriter = &prefixWriter{}
+
+// NewPrefixWriter creates a new PrefixWriter.
+func NewPrefixWriter(out io.Writer) PrefixWriter {
+	return &prefixWriter{out: out}
+}
+
+func (pw *prefixWriter) Write(level int, format string, a ...interface{}) {
+	levelSpace := "  "
+	prefix := ""
+	for i := 0; i < level; i++ {
+		prefix += levelSpace
+	}
+	fmt.Fprintf(pw.out, prefix+format, a...)
+}
+
+func (pw *prefixWriter) WriteLine(a ...interface{}) {
+	fmt.Fprintln(pw.out, a...)
+}
+
+func (pw *prefixWriter) Flush() {
+	if f, ok := pw.out.(flusher); ok {
+		f.Flush()
+	}
+}
+
+func describerMap(clientConfig *rest.Config) (map[schema.GroupKind]printers.Describer, error) {
+	c, err := clientset.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	externalclient, err := externalclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+
+	m := map[schema.GroupKind]printers.Describer{
+		api.Kind("Pod"):                   &PodDescriber{c},
+		api.Kind("ReplicationController"): &ReplicationControllerDescriber{c},
+		api.Kind("Secret"):                &SecretDescriber{c},
+		api.Kind("Service"):               &ServiceDescriber{c},
+		api.Kind("ServiceAccount"):        &ServiceAccountDescriber{c},
+		api.Kind("Node"):                  &NodeDescriber{c},
+		api.Kind("LimitRange"):            &LimitRangeDescriber{c},
+		api.Kind("ResourceQuota"):         &ResourceQuotaDescriber{c},
+		api.Kind("PersistentVolume"):      &PersistentVolumeDescriber{c},
+		api.Kind("PersistentVolumeClaim"): &PersistentVolumeClaimDescriber{c},
+		api.Kind("Namespace"):             &NamespaceDescriber{c},
+		api.Kind("Endpoints"):             &EndpointsDescriber{c},
+		api.Kind("ConfigMap"):             &ConfigMapDescriber{c},
+		api.Kind("PriorityClass"):         &PriorityClassDescriber{c},
+
+		extensions.Kind("ReplicaSet"):                  &ReplicaSetDescriber{c},
+		extensions.Kind("NetworkPolicy"):               &NetworkPolicyDescriber{c},
+		extensions.Kind("PodSecurityPolicy"):           &PodSecurityPolicyDescriber{c},
+		autoscaling.Kind("HorizontalPodAutoscaler"):    &HorizontalPodAutoscalerDescriber{c},
+		extensions.Kind("DaemonSet"):                   &DaemonSetDescriber{c},
+		extensions.Kind("Deployment"):                  &DeploymentDescriber{c, externalclient},
+		extensions.Kind("Ingress"):                     &IngressDescriber{c},
+		batch.Kind("Job"):                              &JobDescriber{c},
+		batch.Kind("CronJob"):                          &CronJobDescriber{c, externalclient},
+		apps.Kind("StatefulSet"):                       &StatefulSetDescriber{c},
+		apps.Kind("Deployment"):                        &DeploymentDescriber{c, externalclient},
+		apps.Kind("DaemonSet"):                         &DaemonSetDescriber{c},
+		apps.Kind("ReplicaSet"):                        &ReplicaSetDescriber{c},
+		certificates.Kind("CertificateSigningRequest"): &CertificateSigningRequestDescriber{c},
+		storage.Kind("StorageClass"):                   &StorageClassDescriber{c},
+		policy.Kind("PodDisruptionBudget"):             &PodDisruptionBudgetDescriber{c},
+		rbac.Kind("Role"):                              &RoleDescriber{externalclient},
+		rbac.Kind("ClusterRole"):                       &ClusterRoleDescriber{externalclient},
+		rbac.Kind("RoleBinding"):                       &RoleBindingDescriber{externalclient},
+		rbac.Kind("ClusterRoleBinding"):                &ClusterRoleBindingDescriber{externalclient},
+		networking.Kind("NetworkPolicy"):               &NetworkPolicyDescriber{c},
+		scheduling.Kind("PriorityClass"):               &PriorityClassDescriber{c},
+	}
+
+	return m, nil
+}
+
+// DescriberFor returns the default describe functions for each of the standard
+// Kubernetes types.
+func DescriberFor(kind schema.GroupKind, clientConfig *rest.Config) (printers.Describer, bool) {
+	describers, err := describerMap(clientConfig)
+	if err != nil {
+		glog.V(1).Info(err)
+		return nil, false
+	}
+
+	f, ok := describers[kind]
+	return f, ok
+}
+
+// GenericDescriberFor returns a generic describer for the specified mapping
+// that uses only information available from runtime.Unstructured
+func GenericDescriberFor(mapping *meta.RESTMapping, dynamic dynamic.Interface, events coreclient.EventsGetter) printers.Describer {
+	return &genericDescriber{mapping, dynamic, events}
+}
+
+type genericDescriber struct {
+	mapping *meta.RESTMapping
+	dynamic dynamic.Interface
+	events  coreclient.EventsGetter
+}
+
+func (g *genericDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (output string, err error) {
+	obj, err := g.dynamic.Resource(g.mapping.Resource).Namespace(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = g.events.Events(namespace).Search(legacyscheme.Scheme, obj)
+	}
+
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", obj.GetName())
+		w.Write(LEVEL_0, "Namespace:\t%s\n", obj.GetNamespace())
+		printLabelsMultiline(w, "Labels", obj.GetLabels())
+		printAnnotationsMultiline(w, "Annotations", obj.GetAnnotations())
+		printUnstructuredContent(w, LEVEL_0, obj.UnstructuredContent(), "", ".metadata.name", ".metadata.namespace", ".metadata.labels", ".metadata.annotations")
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+func printUnstructuredContent(w PrefixWriter, level int, content map[string]interface{}, skipPrefix string, skip ...string) {
+	fields := []string{}
+	for field := range content {
+		fields = append(fields, field)
+	}
+	sort.Strings(fields)
+
+	for _, field := range fields {
+		value := content[field]
+		switch typedValue := value.(type) {
+		case map[string]interface{}:
+			skipExpr := fmt.Sprintf("%s.%s", skipPrefix, field)
+			if slice.ContainsString(skip, skipExpr, nil) {
+				continue
+			}
+			w.Write(level, "%s:\n", smartLabelFor(field))
+			printUnstructuredContent(w, level+1, typedValue, skipExpr, skip...)
+
+		case []interface{}:
+			skipExpr := fmt.Sprintf("%s.%s", skipPrefix, field)
+			if slice.ContainsString(skip, skipExpr, nil) {
+				continue
+			}
+			w.Write(level, "%s:\n", smartLabelFor(field))
+			for _, child := range typedValue {
+				switch typedChild := child.(type) {
+				case map[string]interface{}:
+					printUnstructuredContent(w, level+1, typedChild, skipExpr, skip...)
+				default:
+					w.Write(level+1, "%v\n", typedChild)
+				}
+			}
+
+		default:
+			skipExpr := fmt.Sprintf("%s.%s", skipPrefix, field)
+			if slice.ContainsString(skip, skipExpr, nil) {
+				continue
+			}
+			w.Write(level, "%s:\t%v\n", smartLabelFor(field), typedValue)
+		}
+	}
+}
+
+func smartLabelFor(field string) string {
+	commonAcronyms := []string{"API", "URL", "UID", "OSB", "GUID"}
+
+	splitted := camelcase.Split(field)
+	for i := 0; i < len(splitted); i++ {
+		part := splitted[i]
+
+		if slice.ContainsString(commonAcronyms, strings.ToUpper(part), nil) {
+			part = strings.ToUpper(part)
+		} else {
+			part = strings.Title(part)
+		}
+		splitted[i] = part
+	}
+
+	return strings.Join(splitted, " ")
+}
+
+// DefaultObjectDescriber can describe the default Kubernetes objects.
+var DefaultObjectDescriber printers.ObjectDescriber
+
+func init() {
+	d := &Describers{}
+	err := d.Add(
+		describeLimitRange,
+		describeQuota,
+		describePod,
+		describeService,
+		describeReplicationController,
+		describeDaemonSet,
+		describeNode,
+		describeNamespace,
+	)
+	if err != nil {
+		glog.Fatalf("Cannot register describers: %v", err)
+	}
+	DefaultObjectDescriber = d
+}
+
+// NamespaceDescriber generates information about a namespace
+type NamespaceDescriber struct {
+	clientset.Interface
+}
+
+func (d *NamespaceDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	ns, err := d.Core().Namespaces().Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+	resourceQuotaList, err := d.Core().ResourceQuotas(name).List(metav1.ListOptions{})
+	if err != nil {
+		if errors.IsNotFound(err) {
+			// Server does not support resource quotas.
+			// Not an error, will not show resource quotas information.
+			resourceQuotaList = nil
+		} else {
+			return "", err
+		}
+	}
+	limitRangeList, err := d.Core().LimitRanges(name).List(metav1.ListOptions{})
+	if err != nil {
+		if errors.IsNotFound(err) {
+			// Server does not support limit ranges.
+			// Not an error, will not show limit ranges information.
+			limitRangeList = nil
+		} else {
+			return "", err
+		}
+	}
+	return describeNamespace(ns, resourceQuotaList, limitRangeList)
+}
+
+func describeNamespace(namespace *api.Namespace, resourceQuotaList *api.ResourceQuotaList, limitRangeList *api.LimitRangeList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", namespace.Name)
+		printLabelsMultiline(w, "Labels", namespace.Labels)
+		printAnnotationsMultiline(w, "Annotations", namespace.Annotations)
+		w.Write(LEVEL_0, "Status:\t%s\n", string(namespace.Status.Phase))
+		if resourceQuotaList != nil {
+			w.Write(LEVEL_0, "\n")
+			DescribeResourceQuotas(resourceQuotaList, w)
+		}
+		if limitRangeList != nil {
+			w.Write(LEVEL_0, "\n")
+			DescribeLimitRanges(limitRangeList, w)
+		}
+		return nil
+	})
+}
+
+func describeLimitRangeSpec(spec api.LimitRangeSpec, prefix string, w PrefixWriter) {
+	for i := range spec.Limits {
+		item := spec.Limits[i]
+		maxResources := item.Max
+		minResources := item.Min
+		defaultLimitResources := item.Default
+		defaultRequestResources := item.DefaultRequest
+		ratio := item.MaxLimitRequestRatio
+
+		set := map[api.ResourceName]bool{}
+		for k := range maxResources {
+			set[k] = true
+		}
+		for k := range minResources {
+			set[k] = true
+		}
+		for k := range defaultLimitResources {
+			set[k] = true
+		}
+		for k := range defaultRequestResources {
+			set[k] = true
+		}
+		for k := range ratio {
+			set[k] = true
+		}
+
+		for k := range set {
+			// if no value is set, we output -
+			maxValue := "-"
+			minValue := "-"
+			defaultLimitValue := "-"
+			defaultRequestValue := "-"
+			ratioValue := "-"
+
+			maxQuantity, maxQuantityFound := maxResources[k]
+			if maxQuantityFound {
+				maxValue = maxQuantity.String()
+			}
+
+			minQuantity, minQuantityFound := minResources[k]
+			if minQuantityFound {
+				minValue = minQuantity.String()
+			}
+
+			defaultLimitQuantity, defaultLimitQuantityFound := defaultLimitResources[k]
+			if defaultLimitQuantityFound {
+				defaultLimitValue = defaultLimitQuantity.String()
+			}
+
+			defaultRequestQuantity, defaultRequestQuantityFound := defaultRequestResources[k]
+			if defaultRequestQuantityFound {
+				defaultRequestValue = defaultRequestQuantity.String()
+			}
+
+			ratioQuantity, ratioQuantityFound := ratio[k]
+			if ratioQuantityFound {
+				ratioValue = ratioQuantity.String()
+			}
+
+			msg := "%s%s\t%v\t%v\t%v\t%v\t%v\t%v\n"
+			w.Write(LEVEL_0, msg, prefix, item.Type, k, minValue, maxValue, defaultRequestValue, defaultLimitValue, ratioValue)
+		}
+	}
+}
+
+// DescribeLimitRanges merges a set of limit range items into a single tabular description
+func DescribeLimitRanges(limitRanges *api.LimitRangeList, w PrefixWriter) {
+	if len(limitRanges.Items) == 0 {
+		w.Write(LEVEL_0, "No resource limits.\n")
+		return
+	}
+	w.Write(LEVEL_0, "Resource Limits\n Type\tResource\tMin\tMax\tDefault Request\tDefault Limit\tMax Limit/Request Ratio\n")
+	w.Write(LEVEL_0, " ----\t--------\t---\t---\t---------------\t-------------\t-----------------------\n")
+	for _, limitRange := range limitRanges.Items {
+		describeLimitRangeSpec(limitRange.Spec, " ", w)
+	}
+}
+
+// DescribeResourceQuotas merges a set of quota items into a single tabular description of all quotas
+func DescribeResourceQuotas(quotas *api.ResourceQuotaList, w PrefixWriter) {
+	if len(quotas.Items) == 0 {
+		w.Write(LEVEL_0, "No resource quota.\n")
+		return
+	}
+	sort.Sort(SortableResourceQuotas(quotas.Items))
+
+	w.Write(LEVEL_0, "Resource Quotas")
+	for _, q := range quotas.Items {
+		w.Write(LEVEL_0, "\n Name:\t%s\n", q.Name)
+		if len(q.Spec.Scopes) > 0 {
+			scopes := make([]string, 0, len(q.Spec.Scopes))
+			for _, scope := range q.Spec.Scopes {
+				scopes = append(scopes, string(scope))
+			}
+			sort.Strings(scopes)
+			w.Write(LEVEL_0, " Scopes:\t%s\n", strings.Join(scopes, ", "))
+			for _, scope := range scopes {
+				helpText := helpTextForResourceQuotaScope(api.ResourceQuotaScope(scope))
+				if len(helpText) > 0 {
+					w.Write(LEVEL_0, "  * %s\n", helpText)
+				}
+			}
+		}
+
+		w.Write(LEVEL_0, " Resource\tUsed\tHard\n")
+		w.Write(LEVEL_0, " --------\t---\t---\n")
+
+		resources := make([]api.ResourceName, 0, len(q.Status.Hard))
+		for resource := range q.Status.Hard {
+			resources = append(resources, resource)
+		}
+		sort.Sort(SortableResourceNames(resources))
+
+		for _, resource := range resources {
+			hardQuantity := q.Status.Hard[resource]
+			usedQuantity := q.Status.Used[resource]
+			w.Write(LEVEL_0, " %s\t%s\t%s\n", string(resource), usedQuantity.String(), hardQuantity.String())
+		}
+	}
+}
+
+// LimitRangeDescriber generates information about a limit range
+type LimitRangeDescriber struct {
+	clientset.Interface
+}
+
+func (d *LimitRangeDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	lr := d.Core().LimitRanges(namespace)
+
+	limitRange, err := lr.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+	return describeLimitRange(limitRange)
+}
+
+func describeLimitRange(limitRange *api.LimitRange) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", limitRange.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", limitRange.Namespace)
+		w.Write(LEVEL_0, "Type\tResource\tMin\tMax\tDefault Request\tDefault Limit\tMax Limit/Request Ratio\n")
+		w.Write(LEVEL_0, "----\t--------\t---\t---\t---------------\t-------------\t-----------------------\n")
+		describeLimitRangeSpec(limitRange.Spec, "", w)
+		return nil
+	})
+}
+
+// ResourceQuotaDescriber generates information about a resource quota
+type ResourceQuotaDescriber struct {
+	clientset.Interface
+}
+
+func (d *ResourceQuotaDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	rq := d.Core().ResourceQuotas(namespace)
+
+	resourceQuota, err := rq.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	return describeQuota(resourceQuota)
+}
+
+func helpTextForResourceQuotaScope(scope api.ResourceQuotaScope) string {
+	switch scope {
+	case api.ResourceQuotaScopeTerminating:
+		return "Matches all pods that have an active deadline. These pods have a limited lifespan on a node before being actively terminated by the system."
+	case api.ResourceQuotaScopeNotTerminating:
+		return "Matches all pods that do not have an active deadline. These pods usually include long running pods whose container command is not expected to terminate."
+	case api.ResourceQuotaScopeBestEffort:
+		return "Matches all pods that do not have resource requirements set. These pods have a best effort quality of service."
+	case api.ResourceQuotaScopeNotBestEffort:
+		return "Matches all pods that have at least one resource requirement set. These pods have a burstable or guaranteed quality of service."
+	default:
+		return ""
+	}
+}
+func describeQuota(resourceQuota *api.ResourceQuota) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", resourceQuota.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", resourceQuota.Namespace)
+		if len(resourceQuota.Spec.Scopes) > 0 {
+			scopes := make([]string, 0, len(resourceQuota.Spec.Scopes))
+			for _, scope := range resourceQuota.Spec.Scopes {
+				scopes = append(scopes, string(scope))
+			}
+			sort.Strings(scopes)
+			w.Write(LEVEL_0, "Scopes:\t%s\n", strings.Join(scopes, ", "))
+			for _, scope := range scopes {
+				helpText := helpTextForResourceQuotaScope(api.ResourceQuotaScope(scope))
+				if len(helpText) > 0 {
+					w.Write(LEVEL_0, " * %s\n", helpText)
+				}
+			}
+		}
+		w.Write(LEVEL_0, "Resource\tUsed\tHard\n")
+		w.Write(LEVEL_0, "--------\t----\t----\n")
+
+		resources := make([]api.ResourceName, 0, len(resourceQuota.Status.Hard))
+		for resource := range resourceQuota.Status.Hard {
+			resources = append(resources, resource)
+		}
+		sort.Sort(SortableResourceNames(resources))
+
+		msg := "%v\t%v\t%v\n"
+		for i := range resources {
+			resource := resources[i]
+			hardQuantity := resourceQuota.Status.Hard[resource]
+			usedQuantity := resourceQuota.Status.Used[resource]
+			w.Write(LEVEL_0, msg, resource, usedQuantity.String(), hardQuantity.String())
+		}
+		return nil
+	})
+}
+
+// PodDescriber generates information about a pod and the replication controllers that
+// create it.
+type PodDescriber struct {
+	clientset.Interface
+}
+
+func (d *PodDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	pod, err := d.Core().Pods(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		if describerSettings.ShowEvents {
+			eventsInterface := d.Core().Events(namespace)
+			selector := eventsInterface.GetFieldSelector(&name, &namespace, nil, nil)
+			options := metav1.ListOptions{FieldSelector: selector.String()}
+			events, err2 := eventsInterface.List(options)
+			if describerSettings.ShowEvents && err2 == nil && len(events.Items) > 0 {
+				return tabbedString(func(out io.Writer) error {
+					w := NewPrefixWriter(out)
+					w.Write(LEVEL_0, "Pod '%v': error '%v', but found events.\n", name, err)
+					DescribeEvents(events, w)
+					return nil
+				})
+			}
+		}
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		if ref, err := ref.GetReference(legacyscheme.Scheme, pod); err != nil {
+			glog.Errorf("Unable to construct reference to '%#v': %v", pod, err)
+		} else {
+			ref.Kind = ""
+			events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, ref)
+		}
+	}
+
+	return describePod(pod, events)
+}
+
+func describePod(pod *api.Pod, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", pod.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", pod.Namespace)
+		if pod.Spec.Priority != nil {
+			w.Write(LEVEL_0, "Priority:\t%d\n", *pod.Spec.Priority)
+			w.Write(LEVEL_0, "PriorityClassName:\t%s\n", stringOrNone(pod.Spec.PriorityClassName))
+		}
+		if pod.Spec.NodeName == "" {
+			w.Write(LEVEL_0, "Node:\t<none>\n")
+		} else {
+			w.Write(LEVEL_0, "Node:\t%s\n", pod.Spec.NodeName+"/"+pod.Status.HostIP)
+		}
+		if pod.Status.StartTime != nil {
+			w.Write(LEVEL_0, "Start Time:\t%s\n", pod.Status.StartTime.Time.Format(time.RFC1123Z))
+		}
+		printLabelsMultiline(w, "Labels", pod.Labels)
+		printAnnotationsMultiline(w, "Annotations", pod.Annotations)
+		if pod.DeletionTimestamp != nil {
+			w.Write(LEVEL_0, "Status:\tTerminating (lasts %s)\n", translateTimestamp(*pod.DeletionTimestamp))
+			w.Write(LEVEL_0, "Termination Grace Period:\t%ds\n", *pod.DeletionGracePeriodSeconds)
+		} else {
+			w.Write(LEVEL_0, "Status:\t%s\n", string(pod.Status.Phase))
+		}
+		if len(pod.Status.Reason) > 0 {
+			w.Write(LEVEL_0, "Reason:\t%s\n", pod.Status.Reason)
+		}
+		if len(pod.Status.Message) > 0 {
+			w.Write(LEVEL_0, "Message:\t%s\n", pod.Status.Message)
+		}
+		w.Write(LEVEL_0, "IP:\t%s\n", pod.Status.PodIP)
+		if controlledBy := printController(pod); len(controlledBy) > 0 {
+			w.Write(LEVEL_0, "Controlled By:\t%s\n", controlledBy)
+		}
+		if len(pod.Status.NominatedNodeName) > 0 {
+			w.Write(LEVEL_0, "NominatedNodeName:\t%s\n", pod.Status.NominatedNodeName)
+		}
+
+		if len(pod.Spec.InitContainers) > 0 {
+			describeContainers("Init Containers", pod.Spec.InitContainers, pod.Status.InitContainerStatuses, EnvValueRetriever(pod), w, "")
+		}
+		describeContainers("Containers", pod.Spec.Containers, pod.Status.ContainerStatuses, EnvValueRetriever(pod), w, "")
+		if len(pod.Status.Conditions) > 0 {
+			w.Write(LEVEL_0, "Conditions:\n  Type\tStatus\n")
+			for _, c := range pod.Status.Conditions {
+				w.Write(LEVEL_1, "%v \t%v \n",
+					c.Type,
+					c.Status)
+			}
+		}
+		describeVolumes(pod.Spec.Volumes, w, "")
+		if pod.Status.QOSClass != "" {
+			w.Write(LEVEL_0, "QoS Class:\t%s\n", pod.Status.QOSClass)
+		} else {
+			w.Write(LEVEL_0, "QoS Class:\t%s\n", qos.GetPodQOS(pod))
+		}
+		printLabelsMultiline(w, "Node-Selectors", pod.Spec.NodeSelector)
+		printPodTolerationsMultiline(w, "Tolerations", pod.Spec.Tolerations)
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+func printController(controllee metav1.Object) string {
+	if controllerRef := metav1.GetControllerOf(controllee); controllerRef != nil {
+		return fmt.Sprintf("%s/%s", controllerRef.Kind, controllerRef.Name)
+	}
+	return ""
+}
+
+func describeVolumes(volumes []api.Volume, w PrefixWriter, space string) {
+	if volumes == nil || len(volumes) == 0 {
+		w.Write(LEVEL_0, "%sVolumes:\t<none>\n", space)
+		return
+	}
+	w.Write(LEVEL_0, "%sVolumes:\n", space)
+	for _, volume := range volumes {
+		nameIndent := ""
+		if len(space) > 0 {
+			nameIndent = " "
+		}
+		w.Write(LEVEL_1, "%s%v:\n", nameIndent, volume.Name)
+		switch {
+		case volume.VolumeSource.HostPath != nil:
+			printHostPathVolumeSource(volume.VolumeSource.HostPath, w)
+		case volume.VolumeSource.EmptyDir != nil:
+			printEmptyDirVolumeSource(volume.VolumeSource.EmptyDir, w)
+		case volume.VolumeSource.GCEPersistentDisk != nil:
+			printGCEPersistentDiskVolumeSource(volume.VolumeSource.GCEPersistentDisk, w)
+		case volume.VolumeSource.AWSElasticBlockStore != nil:
+			printAWSElasticBlockStoreVolumeSource(volume.VolumeSource.AWSElasticBlockStore, w)
+		case volume.VolumeSource.GitRepo != nil:
+			printGitRepoVolumeSource(volume.VolumeSource.GitRepo, w)
+		case volume.VolumeSource.Secret != nil:
+			printSecretVolumeSource(volume.VolumeSource.Secret, w)
+		case volume.VolumeSource.ConfigMap != nil:
+			printConfigMapVolumeSource(volume.VolumeSource.ConfigMap, w)
+		case volume.VolumeSource.NFS != nil:
+			printNFSVolumeSource(volume.VolumeSource.NFS, w)
+		case volume.VolumeSource.ISCSI != nil:
+			printISCSIVolumeSource(volume.VolumeSource.ISCSI, w)
+		case volume.VolumeSource.Glusterfs != nil:
+			printGlusterfsVolumeSource(volume.VolumeSource.Glusterfs, w)
+		case volume.VolumeSource.PersistentVolumeClaim != nil:
+			printPersistentVolumeClaimVolumeSource(volume.VolumeSource.PersistentVolumeClaim, w)
+		case volume.VolumeSource.RBD != nil:
+			printRBDVolumeSource(volume.VolumeSource.RBD, w)
+		case volume.VolumeSource.Quobyte != nil:
+			printQuobyteVolumeSource(volume.VolumeSource.Quobyte, w)
+		case volume.VolumeSource.DownwardAPI != nil:
+			printDownwardAPIVolumeSource(volume.VolumeSource.DownwardAPI, w)
+		case volume.VolumeSource.AzureDisk != nil:
+			printAzureDiskVolumeSource(volume.VolumeSource.AzureDisk, w)
+		case volume.VolumeSource.VsphereVolume != nil:
+			printVsphereVolumeSource(volume.VolumeSource.VsphereVolume, w)
+		case volume.VolumeSource.Cinder != nil:
+			printCinderVolumeSource(volume.VolumeSource.Cinder, w)
+		case volume.VolumeSource.PhotonPersistentDisk != nil:
+			printPhotonPersistentDiskVolumeSource(volume.VolumeSource.PhotonPersistentDisk, w)
+		case volume.VolumeSource.PortworxVolume != nil:
+			printPortworxVolumeSource(volume.VolumeSource.PortworxVolume, w)
+		case volume.VolumeSource.ScaleIO != nil:
+			printScaleIOVolumeSource(volume.VolumeSource.ScaleIO, w)
+		case volume.VolumeSource.CephFS != nil:
+			printCephFSVolumeSource(volume.VolumeSource.CephFS, w)
+		case volume.VolumeSource.StorageOS != nil:
+			printStorageOSVolumeSource(volume.VolumeSource.StorageOS, w)
+		case volume.VolumeSource.FC != nil:
+			printFCVolumeSource(volume.VolumeSource.FC, w)
+		case volume.VolumeSource.AzureFile != nil:
+			printAzureFileVolumeSource(volume.VolumeSource.AzureFile, w)
+		case volume.VolumeSource.FlexVolume != nil:
+			printFlexVolumeSource(volume.VolumeSource.FlexVolume, w)
+		case volume.VolumeSource.Flocker != nil:
+			printFlockerVolumeSource(volume.VolumeSource.Flocker, w)
+		case volume.VolumeSource.CascadeDisk != nil:
+			printCascadeDiskVolumeSource(volume.VolumeSource.CascadeDisk, w)
+		default:
+			w.Write(LEVEL_1, "<unknown>\n")
+		}
+	}
+}
+
+func printHostPathVolumeSource(hostPath *api.HostPathVolumeSource, w PrefixWriter) {
+	hostPathType := "<none>"
+	if hostPath.Type != nil {
+		hostPathType = string(*hostPath.Type)
+	}
+	w.Write(LEVEL_2, "Type:\tHostPath (bare host directory volume)\n"+
+		"    Path:\t%v\n"+
+		"    HostPathType:\t%v\n",
+		hostPath.Path, hostPathType)
+}
+
+func printEmptyDirVolumeSource(emptyDir *api.EmptyDirVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tEmptyDir (a temporary directory that shares a pod's lifetime)\n"+
+		"    Medium:\t%v\n", emptyDir.Medium)
+}
+
+func printGCEPersistentDiskVolumeSource(gce *api.GCEPersistentDiskVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tGCEPersistentDisk (a Persistent Disk resource in Google Compute Engine)\n"+
+		"    PDName:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    Partition:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		gce.PDName, gce.FSType, gce.Partition, gce.ReadOnly)
+}
+
+func printAWSElasticBlockStoreVolumeSource(aws *api.AWSElasticBlockStoreVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tAWSElasticBlockStore (a Persistent Disk resource in AWS)\n"+
+		"    VolumeID:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    Partition:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		aws.VolumeID, aws.FSType, aws.Partition, aws.ReadOnly)
+}
+
+func printGitRepoVolumeSource(git *api.GitRepoVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tGitRepo (a volume that is pulled from git when the pod is created)\n"+
+		"    Repository:\t%v\n"+
+		"    Revision:\t%v\n",
+		git.Repository, git.Revision)
+}
+
+func printSecretVolumeSource(secret *api.SecretVolumeSource, w PrefixWriter) {
+	optional := secret.Optional != nil && *secret.Optional
+	w.Write(LEVEL_2, "Type:\tSecret (a volume populated by a Secret)\n"+
+		"    SecretName:\t%v\n"+
+		"    Optional:\t%v\n",
+		secret.SecretName, optional)
+}
+
+func printConfigMapVolumeSource(configMap *api.ConfigMapVolumeSource, w PrefixWriter) {
+	optional := configMap.Optional != nil && *configMap.Optional
+	w.Write(LEVEL_2, "Type:\tConfigMap (a volume populated by a ConfigMap)\n"+
+		"    Name:\t%v\n"+
+		"    Optional:\t%v\n",
+		configMap.Name, optional)
+}
+
+func printNFSVolumeSource(nfs *api.NFSVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tNFS (an NFS mount that lasts the lifetime of a pod)\n"+
+		"    Server:\t%v\n"+
+		"    Path:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		nfs.Server, nfs.Path, nfs.ReadOnly)
+}
+
+func printQuobyteVolumeSource(quobyte *api.QuobyteVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tQuobyte (a Quobyte mount on the host that shares a pod's lifetime)\n"+
+		"    Registry:\t%v\n"+
+		"    Volume:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		quobyte.Registry, quobyte.Volume, quobyte.ReadOnly)
+}
+
+func printPortworxVolumeSource(pwxVolume *api.PortworxVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tPortworxVolume (a Portworx Volume resource)\n"+
+		"    VolumeID:\t%v\n",
+		pwxVolume.VolumeID)
+}
+
+func printISCSIVolumeSource(iscsi *api.ISCSIVolumeSource, w PrefixWriter) {
+	initiator := "<none>"
+	if iscsi.InitiatorName != nil {
+		initiator = *iscsi.InitiatorName
+	}
+	w.Write(LEVEL_2, "Type:\tISCSI (an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod)\n"+
+		"    TargetPortal:\t%v\n"+
+		"    IQN:\t%v\n"+
+		"    Lun:\t%v\n"+
+		"    ISCSIInterface\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    ReadOnly:\t%v\n"+
+		"    Portals:\t%v\n"+
+		"    DiscoveryCHAPAuth:\t%v\n"+
+		"    SessionCHAPAuth:\t%v\n"+
+		"    SecretRef:\t%v\n"+
+		"    InitiatorName:\t%v\n",
+		iscsi.TargetPortal, iscsi.IQN, iscsi.Lun, iscsi.ISCSIInterface, iscsi.FSType, iscsi.ReadOnly, iscsi.Portals, iscsi.DiscoveryCHAPAuth, iscsi.SessionCHAPAuth, iscsi.SecretRef, initiator)
+}
+
+func printISCSIPersistentVolumeSource(iscsi *api.ISCSIPersistentVolumeSource, w PrefixWriter) {
+	initiatorName := "<none>"
+	if iscsi.InitiatorName != nil {
+		initiatorName = *iscsi.InitiatorName
+	}
+	w.Write(LEVEL_2, "Type:\tISCSI (an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod)\n"+
+		"    TargetPortal:\t%v\n"+
+		"    IQN:\t%v\n"+
+		"    Lun:\t%v\n"+
+		"    ISCSIInterface\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    ReadOnly:\t%v\n"+
+		"    Portals:\t%v\n"+
+		"    DiscoveryCHAPAuth:\t%v\n"+
+		"    SessionCHAPAuth:\t%v\n"+
+		"    SecretRef:\t%v\n"+
+		"    InitiatorName:\t%v\n",
+		iscsi.TargetPortal, iscsi.IQN, iscsi.Lun, iscsi.ISCSIInterface, iscsi.FSType, iscsi.ReadOnly, iscsi.Portals, iscsi.DiscoveryCHAPAuth, iscsi.SessionCHAPAuth, iscsi.SecretRef, initiatorName)
+}
+
+func printGlusterfsVolumeSource(glusterfs *api.GlusterfsVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tGlusterfs (a Glusterfs mount on the host that shares a pod's lifetime)\n"+
+		"    EndpointsName:\t%v\n"+
+		"    Path:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		glusterfs.EndpointsName, glusterfs.Path, glusterfs.ReadOnly)
+}
+
+func printPersistentVolumeClaimVolumeSource(claim *api.PersistentVolumeClaimVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tPersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)\n"+
+		"    ClaimName:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		claim.ClaimName, claim.ReadOnly)
+}
+
+func printRBDVolumeSource(rbd *api.RBDVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tRBD (a Rados Block Device mount on the host that shares a pod's lifetime)\n"+
+		"    CephMonitors:\t%v\n"+
+		"    RBDImage:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    RBDPool:\t%v\n"+
+		"    RadosUser:\t%v\n"+
+		"    Keyring:\t%v\n"+
+		"    SecretRef:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		rbd.CephMonitors, rbd.RBDImage, rbd.FSType, rbd.RBDPool, rbd.RadosUser, rbd.Keyring, rbd.SecretRef, rbd.ReadOnly)
+}
+
+func printRBDPersistentVolumeSource(rbd *api.RBDPersistentVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tRBD (a Rados Block Device mount on the host that shares a pod's lifetime)\n"+
+		"    CephMonitors:\t%v\n"+
+		"    RBDImage:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    RBDPool:\t%v\n"+
+		"    RadosUser:\t%v\n"+
+		"    Keyring:\t%v\n"+
+		"    SecretRef:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		rbd.CephMonitors, rbd.RBDImage, rbd.FSType, rbd.RBDPool, rbd.RadosUser, rbd.Keyring, rbd.SecretRef, rbd.ReadOnly)
+}
+
+func printDownwardAPIVolumeSource(d *api.DownwardAPIVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tDownwardAPI (a volume populated by information about the pod)\n    Items:\n")
+	for _, mapping := range d.Items {
+		if mapping.FieldRef != nil {
+			w.Write(LEVEL_3, "%v -> %v\n", mapping.FieldRef.FieldPath, mapping.Path)
+		}
+		if mapping.ResourceFieldRef != nil {
+			w.Write(LEVEL_3, "%v -> %v\n", mapping.ResourceFieldRef.Resource, mapping.Path)
+		}
+	}
+}
+
+func printAzureDiskVolumeSource(d *api.AzureDiskVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tAzureDisk (an Azure Data Disk mount on the host and bind mount to the pod)\n"+
+		"    DiskName:\t%v\n"+
+		"    DiskURI:\t%v\n"+
+		"    Kind: \t%v\n"+
+		"    FSType:\t%v\n"+
+		"    CachingMode:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		d.DiskName, d.DataDiskURI, *d.Kind, *d.FSType, *d.CachingMode, *d.ReadOnly)
+}
+
+func printVsphereVolumeSource(vsphere *api.VsphereVirtualDiskVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tvSphereVolume (a Persistent Disk resource in vSphere)\n"+
+		"    VolumePath:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    StoragePolicyName:\t%v\n",
+		vsphere.VolumePath, vsphere.FSType, vsphere.StoragePolicyName)
+}
+
+func printPhotonPersistentDiskVolumeSource(photon *api.PhotonPersistentDiskVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tPhotonPersistentDisk (a Persistent Disk resource in photon platform)\n"+
+		"    PdID:\t%v\n"+
+		"    FSType:\t%v\n",
+		photon.PdID, photon.FSType)
+}
+
+func printCinderVolumeSource(cinder *api.CinderVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tCinder (a Persistent Disk resource in OpenStack)\n"+
+		"    VolumeID:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		"    SecretRef:\t%v\n"+
+			cinder.VolumeID, cinder.FSType, cinder.ReadOnly, cinder.SecretRef)
+}
+
+func printCinderPersistentVolumeSource(cinder *api.CinderPersistentVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tCinder (a Persistent Disk resource in OpenStack)\n"+
+		"    VolumeID:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		"    SecretRef:\t%v\n"+
+			cinder.VolumeID, cinder.SecretRef, cinder.FSType, cinder.ReadOnly, cinder.SecretRef)
+}
+
+func printScaleIOVolumeSource(sio *api.ScaleIOVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tScaleIO (a persistent volume backed by a block device in ScaleIO)\n"+
+		"    Gateway:\t%v\n"+
+		"    System:\t%v\n"+
+		"    Protection Domain:\t%v\n"+
+		"    Storage Pool:\t%v\n"+
+		"    Storage Mode:\t%v\n"+
+		"    VolumeName:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		sio.Gateway, sio.System, sio.ProtectionDomain, sio.StoragePool, sio.StorageMode, sio.VolumeName, sio.FSType, sio.ReadOnly)
+}
+
+func printScaleIOPersistentVolumeSource(sio *api.ScaleIOPersistentVolumeSource, w PrefixWriter) {
+	var secretNS, secretName string
+	if sio.SecretRef != nil {
+		secretName = sio.SecretRef.Name
+		secretNS = sio.SecretRef.Namespace
+	}
+	w.Write(LEVEL_2, "Type:\tScaleIO (a persistent volume backed by a block device in ScaleIO)\n"+
+		"    Gateway:\t%v\n"+
+		"    System:\t%v\n"+
+		"    Protection Domain:\t%v\n"+
+		"    Storage Pool:\t%v\n"+
+		"    Storage Mode:\t%v\n"+
+		"    VolumeName:\t%v\n"+
+		"    SecretName:\t%v\n"+
+		"    SecretNamespace:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		sio.Gateway, sio.System, sio.ProtectionDomain, sio.StoragePool, sio.StorageMode, sio.VolumeName, secretName, secretNS, sio.FSType, sio.ReadOnly)
+}
+
+func printLocalVolumeSource(ls *api.LocalVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tLocalVolume (a persistent volume backed by local storage on a node)\n"+
+		"    Path:\t%v\n",
+		ls.Path)
+}
+
+func printCephFSVolumeSource(cephfs *api.CephFSVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tCephFS (a CephFS mount on the host that shares a pod's lifetime)\n"+
+		"    Monitors:\t%v\n"+
+		"    Path:\t%v\n"+
+		"    User:\t%v\n"+
+		"    SecretFile:\t%v\n"+
+		"    SecretRef:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		cephfs.Monitors, cephfs.Path, cephfs.User, cephfs.SecretFile, cephfs.SecretRef, cephfs.ReadOnly)
+}
+
+func printCephFSPersistentVolumeSource(cephfs *api.CephFSPersistentVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tCephFS (a CephFS mount on the host that shares a pod's lifetime)\n"+
+		"    Monitors:\t%v\n"+
+		"    Path:\t%v\n"+
+		"    User:\t%v\n"+
+		"    SecretFile:\t%v\n"+
+		"    SecretRef:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		cephfs.Monitors, cephfs.Path, cephfs.User, cephfs.SecretFile, cephfs.SecretRef, cephfs.ReadOnly)
+}
+
+func printStorageOSVolumeSource(storageos *api.StorageOSVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tStorageOS (a StorageOS Persistent Disk resource)\n"+
+		"    VolumeName:\t%v\n"+
+		"    VolumeNamespace:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		storageos.VolumeName, storageos.VolumeNamespace, storageos.FSType, storageos.ReadOnly)
+}
+
+func printStorageOSPersistentVolumeSource(storageos *api.StorageOSPersistentVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tStorageOS (a StorageOS Persistent Disk resource)\n"+
+		"    VolumeName:\t%v\n"+
+		"    VolumeNamespace:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		storageos.VolumeName, storageos.VolumeNamespace, storageos.FSType, storageos.ReadOnly)
+}
+
+func printFCVolumeSource(fc *api.FCVolumeSource, w PrefixWriter) {
+	lun := "<none>"
+	if fc.Lun != nil {
+		lun = strconv.Itoa(int(*fc.Lun))
+	}
+	w.Write(LEVEL_2, "Type:\tFC (a Fibre Channel disk)\n"+
+		"    TargetWWNs:\t%v\n"+
+		"    LUN:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		strings.Join(fc.TargetWWNs, ", "), lun, fc.FSType, fc.ReadOnly)
+}
+
+func printAzureFileVolumeSource(azureFile *api.AzureFileVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tAzureFile (an Azure File Service mount on the host and bind mount to the pod)\n"+
+		"    SecretName:\t%v\n"+
+		"    ShareName:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		azureFile.SecretName, azureFile.ShareName, azureFile.ReadOnly)
+}
+
+func printAzureFilePersistentVolumeSource(azureFile *api.AzureFilePersistentVolumeSource, w PrefixWriter) {
+	ns := ""
+	if azureFile.SecretNamespace != nil {
+		ns = *azureFile.SecretNamespace
+	}
+	w.Write(LEVEL_2, "Type:\tAzureFile (an Azure File Service mount on the host and bind mount to the pod)\n"+
+		"    SecretName:\t%v\n"+
+		"    SecretNamespace:\t%v\n"+
+		"    ShareName:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		azureFile.SecretName, ns, azureFile.ShareName, azureFile.ReadOnly)
+}
+
+func printFlexPersistentVolumeSource(flex *api.FlexPersistentVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tFlexVolume (a generic volume resource that is provisioned/attached using an exec based plugin)\n"+
+		"    Driver:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    SecretRef:\t%v\n"+
+		"    ReadOnly:\t%v\n"+
+		"    Options:\t%v\n",
+		flex.Driver, flex.FSType, flex.SecretRef, flex.ReadOnly, flex.Options)
+}
+
+func printFlexVolumeSource(flex *api.FlexVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tFlexVolume (a generic volume resource that is provisioned/attached using an exec based plugin)\n"+
+		"    Driver:\t%v\n"+
+		"    FSType:\t%v\n"+
+		"    SecretRef:\t%v\n"+
+		"    ReadOnly:\t%v\n"+
+		"    Options:\t%v\n",
+		flex.Driver, flex.FSType, flex.SecretRef, flex.ReadOnly, flex.Options)
+}
+
+func printFlockerVolumeSource(flocker *api.FlockerVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tFlocker (a Flocker volume mounted by the Flocker agent)\n"+
+		"    DatasetName:\t%v\n"+
+		"    DatasetUUID:\t%v\n",
+		flocker.DatasetName, flocker.DatasetUUID)
+}
+
+func printCSIPersistentVolumeSource(csi *api.CSIPersistentVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tCSI (a Container Storage Interface (CSI) volume source)\n"+
+		"    Driver:\t%v\n"+
+		"    VolumeHandle:\t%v\n"+
+		"    ReadOnly:\t%v\n",
+		csi.Driver, csi.VolumeHandle, csi.ReadOnly)
+}
+
+func printCascadeDiskVolumeSource(cascade *api.CascadeDiskVolumeSource, w PrefixWriter) {
+	w.Write(LEVEL_2, "Type:\tVKEDisk (a Persistent Disk resource in VKE)\n"+
+		"    DiskID:\t%v\n"+
+		"    FSType:\t%v\n",
+		cascade.DiskID, cascade.FSType)
+}
+
+type PersistentVolumeDescriber struct {
+	clientset.Interface
+}
+
+func (d *PersistentVolumeDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	c := d.Core().PersistentVolumes()
+
+	pv, err := c.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, pv)
+	}
+
+	return describePersistentVolume(pv, events)
+}
+
+func printVolumeNodeAffinity(w PrefixWriter, affinity *api.VolumeNodeAffinity) {
+	w.Write(LEVEL_0, "Node Affinity:\t")
+	if affinity == nil || affinity.Required == nil {
+		w.WriteLine("<none>")
+		return
+	}
+	w.WriteLine("")
+
+	if affinity.Required != nil {
+		w.Write(LEVEL_1, "Required Terms:\t")
+		if len(affinity.Required.NodeSelectorTerms) == 0 {
+			w.WriteLine("<none>")
+		} else {
+			w.WriteLine("")
+			for i, term := range affinity.Required.NodeSelectorTerms {
+				printNodeSelectorTermsMultilineWithIndent(w, LEVEL_2, fmt.Sprintf("Term %v", i), "\t", term.MatchExpressions)
+			}
+		}
+	}
+}
+
+// printLabelsMultiline prints multiple labels with a user-defined alignment.
+func printNodeSelectorTermsMultilineWithIndent(w PrefixWriter, indentLevel int, title, innerIndent string, reqs []api.NodeSelectorRequirement) {
+	w.Write(indentLevel, "%s:%s", title, innerIndent)
+
+	if len(reqs) == 0 {
+		w.WriteLine("<none>")
+		return
+	}
+
+	for i, req := range reqs {
+		if i != 0 {
+			w.Write(indentLevel, "%s", innerIndent)
+		}
+		exprStr := fmt.Sprintf("%s %s", req.Key, strings.ToLower(string(req.Operator)))
+		if len(req.Values) > 0 {
+			exprStr = fmt.Sprintf("%s [%s]", exprStr, strings.Join(req.Values, ", "))
+		}
+		w.Write(LEVEL_0, "%s\n", exprStr)
+	}
+}
+
+func describePersistentVolume(pv *api.PersistentVolume, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", pv.Name)
+		printLabelsMultiline(w, "Labels", pv.Labels)
+		printAnnotationsMultiline(w, "Annotations", pv.Annotations)
+		w.Write(LEVEL_0, "Finalizers:\t%v\n", pv.ObjectMeta.Finalizers)
+		w.Write(LEVEL_0, "StorageClass:\t%s\n", helper.GetPersistentVolumeClass(pv))
+		if pv.ObjectMeta.DeletionTimestamp != nil {
+			w.Write(LEVEL_0, "Status:\tTerminating (lasts %s)\n", translateTimestamp(*pv.ObjectMeta.DeletionTimestamp))
+		} else {
+			w.Write(LEVEL_0, "Status:\t%v\n", pv.Status.Phase)
+		}
+		if pv.Spec.ClaimRef != nil {
+			w.Write(LEVEL_0, "Claim:\t%s\n", pv.Spec.ClaimRef.Namespace+"/"+pv.Spec.ClaimRef.Name)
+		} else {
+			w.Write(LEVEL_0, "Claim:\t%s\n", "")
+		}
+		w.Write(LEVEL_0, "Reclaim Policy:\t%v\n", pv.Spec.PersistentVolumeReclaimPolicy)
+		w.Write(LEVEL_0, "Access Modes:\t%s\n", helper.GetAccessModesAsString(pv.Spec.AccessModes))
+		if pv.Spec.VolumeMode != nil {
+			w.Write(LEVEL_0, "VolumeMode:\t%v\n", *pv.Spec.VolumeMode)
+		}
+		storage := pv.Spec.Capacity[api.ResourceStorage]
+		w.Write(LEVEL_0, "Capacity:\t%s\n", storage.String())
+		printVolumeNodeAffinity(w, pv.Spec.NodeAffinity)
+		w.Write(LEVEL_0, "Message:\t%s\n", pv.Status.Message)
+		w.Write(LEVEL_0, "Source:\n")
+
+		switch {
+		case pv.Spec.HostPath != nil:
+			printHostPathVolumeSource(pv.Spec.HostPath, w)
+		case pv.Spec.GCEPersistentDisk != nil:
+			printGCEPersistentDiskVolumeSource(pv.Spec.GCEPersistentDisk, w)
+		case pv.Spec.AWSElasticBlockStore != nil:
+			printAWSElasticBlockStoreVolumeSource(pv.Spec.AWSElasticBlockStore, w)
+		case pv.Spec.NFS != nil:
+			printNFSVolumeSource(pv.Spec.NFS, w)
+		case pv.Spec.ISCSI != nil:
+			printISCSIPersistentVolumeSource(pv.Spec.ISCSI, w)
+		case pv.Spec.Glusterfs != nil:
+			printGlusterfsVolumeSource(pv.Spec.Glusterfs, w)
+		case pv.Spec.RBD != nil:
+			printRBDPersistentVolumeSource(pv.Spec.RBD, w)
+		case pv.Spec.Quobyte != nil:
+			printQuobyteVolumeSource(pv.Spec.Quobyte, w)
+		case pv.Spec.VsphereVolume != nil:
+			printVsphereVolumeSource(pv.Spec.VsphereVolume, w)
+		case pv.Spec.Cinder != nil:
+			printCinderPersistentVolumeSource(pv.Spec.Cinder, w)
+		case pv.Spec.AzureDisk != nil:
+			printAzureDiskVolumeSource(pv.Spec.AzureDisk, w)
+		case pv.Spec.PhotonPersistentDisk != nil:
+			printPhotonPersistentDiskVolumeSource(pv.Spec.PhotonPersistentDisk, w)
+		case pv.Spec.PortworxVolume != nil:
+			printPortworxVolumeSource(pv.Spec.PortworxVolume, w)
+		case pv.Spec.ScaleIO != nil:
+			printScaleIOPersistentVolumeSource(pv.Spec.ScaleIO, w)
+		case pv.Spec.Local != nil:
+			printLocalVolumeSource(pv.Spec.Local, w)
+		case pv.Spec.CephFS != nil:
+			printCephFSPersistentVolumeSource(pv.Spec.CephFS, w)
+		case pv.Spec.StorageOS != nil:
+			printStorageOSPersistentVolumeSource(pv.Spec.StorageOS, w)
+		case pv.Spec.FC != nil:
+			printFCVolumeSource(pv.Spec.FC, w)
+		case pv.Spec.AzureFile != nil:
+			printAzureFilePersistentVolumeSource(pv.Spec.AzureFile, w)
+		case pv.Spec.FlexVolume != nil:
+			printFlexPersistentVolumeSource(pv.Spec.FlexVolume, w)
+		case pv.Spec.Flocker != nil:
+			printFlockerVolumeSource(pv.Spec.Flocker, w)
+		case pv.Spec.CSI != nil:
+			printCSIPersistentVolumeSource(pv.Spec.CSI, w)
+		case pv.Spec.CascadeDisk != nil:
+			printCascadeDiskVolumeSource(pv.Spec.CascadeDisk, w)
+		default:
+			w.Write(LEVEL_1, "<unknown>\n")
+		}
+
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+type PersistentVolumeClaimDescriber struct {
+	clientset.Interface
+}
+
+func (d *PersistentVolumeClaimDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	c := d.Core().PersistentVolumeClaims(namespace)
+
+	pvc, err := c.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	events, _ := d.Core().Events(namespace).Search(legacyscheme.Scheme, pvc)
+
+	return describePersistentVolumeClaim(pvc, events)
+}
+
+func describePersistentVolumeClaim(pvc *api.PersistentVolumeClaim, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", pvc.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", pvc.Namespace)
+		w.Write(LEVEL_0, "StorageClass:\t%s\n", helper.GetPersistentVolumeClaimClass(pvc))
+		if pvc.ObjectMeta.DeletionTimestamp != nil {
+			w.Write(LEVEL_0, "Status:\tTerminating (lasts %s)\n", translateTimestamp(*pvc.ObjectMeta.DeletionTimestamp))
+		} else {
+			w.Write(LEVEL_0, "Status:\t%v\n", pvc.Status.Phase)
+		}
+		w.Write(LEVEL_0, "Volume:\t%s\n", pvc.Spec.VolumeName)
+		printLabelsMultiline(w, "Labels", pvc.Labels)
+		printAnnotationsMultiline(w, "Annotations", pvc.Annotations)
+		w.Write(LEVEL_0, "Finalizers:\t%v\n", pvc.ObjectMeta.Finalizers)
+		storage := pvc.Spec.Resources.Requests[api.ResourceStorage]
+		capacity := ""
+		accessModes := ""
+		if pvc.Spec.VolumeName != "" {
+			accessModes = helper.GetAccessModesAsString(pvc.Status.AccessModes)
+			storage = pvc.Status.Capacity[api.ResourceStorage]
+			capacity = storage.String()
+		}
+		w.Write(LEVEL_0, "Capacity:\t%s\n", capacity)
+		w.Write(LEVEL_0, "Access Modes:\t%s\n", accessModes)
+		if pvc.Spec.VolumeMode != nil {
+			w.Write(LEVEL_0, "VolumeMode:\t%v\n", *pvc.Spec.VolumeMode)
+		}
+		if len(pvc.Status.Conditions) > 0 {
+			w.Write(LEVEL_0, "Conditions:\n")
+			w.Write(LEVEL_1, "Type\tStatus\tLastProbeTime\tLastTransitionTime\tReason\tMessage\n")
+			w.Write(LEVEL_1, "----\t------\t-----------------\t------------------\t------\t-------\n")
+			for _, c := range pvc.Status.Conditions {
+				w.Write(LEVEL_1, "%v \t%v \t%s \t%s \t%v \t%v\n",
+					c.Type,
+					c.Status,
+					c.LastProbeTime.Time.Format(time.RFC1123Z),
+					c.LastTransitionTime.Time.Format(time.RFC1123Z),
+					c.Reason,
+					c.Message)
+			}
+		}
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+func describeContainers(label string, containers []api.Container, containerStatuses []api.ContainerStatus,
+	resolverFn EnvVarResolverFunc, w PrefixWriter, space string) {
+	statuses := map[string]api.ContainerStatus{}
+	for _, status := range containerStatuses {
+		statuses[status.Name] = status
+	}
+
+	describeContainersLabel(containers, label, space, w)
+
+	for _, container := range containers {
+		status, ok := statuses[container.Name]
+		describeContainerBasicInfo(container, status, ok, space, w)
+		describeContainerCommand(container, w)
+		if ok {
+			describeContainerState(status, w)
+		}
+		describeContainerResource(container, w)
+		describeContainerProbe(container, w)
+		if len(container.EnvFrom) > 0 {
+			describeContainerEnvFrom(container, resolverFn, w)
+		}
+		describeContainerEnvVars(container, resolverFn, w)
+		describeContainerVolumes(container, w)
+	}
+}
+
+func describeContainersLabel(containers []api.Container, label, space string, w PrefixWriter) {
+	none := ""
+	if len(containers) == 0 {
+		none = " <none>"
+	}
+	w.Write(LEVEL_0, "%s%s:%s\n", space, label, none)
+}
+
+func describeContainerBasicInfo(container api.Container, status api.ContainerStatus, ok bool, space string, w PrefixWriter) {
+	nameIndent := ""
+	if len(space) > 0 {
+		nameIndent = " "
+	}
+	w.Write(LEVEL_1, "%s%v:\n", nameIndent, container.Name)
+	if ok {
+		w.Write(LEVEL_2, "Container ID:\t%s\n", status.ContainerID)
+	}
+	w.Write(LEVEL_2, "Image:\t%s\n", container.Image)
+	if ok {
+		w.Write(LEVEL_2, "Image ID:\t%s\n", status.ImageID)
+	}
+	portString := describeContainerPorts(container.Ports)
+	if strings.Contains(portString, ",") {
+		w.Write(LEVEL_2, "Ports:\t%s\n", portString)
+	} else {
+		w.Write(LEVEL_2, "Port:\t%s\n", stringOrNone(portString))
+	}
+	hostPortString := describeContainerHostPorts(container.Ports)
+	if strings.Contains(hostPortString, ",") {
+		w.Write(LEVEL_2, "Host Ports:\t%s\n", hostPortString)
+	} else {
+		w.Write(LEVEL_2, "Host Port:\t%s\n", stringOrNone(hostPortString))
+	}
+}
+
+func describeContainerPorts(cPorts []api.ContainerPort) string {
+	ports := make([]string, 0, len(cPorts))
+	for _, cPort := range cPorts {
+		ports = append(ports, fmt.Sprintf("%d/%s", cPort.ContainerPort, cPort.Protocol))
+	}
+	return strings.Join(ports, ", ")
+}
+
+func describeContainerHostPorts(cPorts []api.ContainerPort) string {
+	ports := make([]string, 0, len(cPorts))
+	for _, cPort := range cPorts {
+		ports = append(ports, fmt.Sprintf("%d/%s", cPort.HostPort, cPort.Protocol))
+	}
+	return strings.Join(ports, ", ")
+}
+
+func describeContainerCommand(container api.Container, w PrefixWriter) {
+	if len(container.Command) > 0 {
+		w.Write(LEVEL_2, "Command:\n")
+		for _, c := range container.Command {
+			w.Write(LEVEL_3, "%s\n", c)
+		}
+	}
+	if len(container.Args) > 0 {
+		w.Write(LEVEL_2, "Args:\n")
+		for _, arg := range container.Args {
+			w.Write(LEVEL_3, "%s\n", arg)
+		}
+	}
+}
+
+func describeContainerResource(container api.Container, w PrefixWriter) {
+	resources := container.Resources
+	if len(resources.Limits) > 0 {
+		w.Write(LEVEL_2, "Limits:\n")
+	}
+	for _, name := range SortedResourceNames(resources.Limits) {
+		quantity := resources.Limits[name]
+		w.Write(LEVEL_3, "%s:\t%s\n", name, quantity.String())
+	}
+
+	if len(resources.Requests) > 0 {
+		w.Write(LEVEL_2, "Requests:\n")
+	}
+	for _, name := range SortedResourceNames(resources.Requests) {
+		quantity := resources.Requests[name]
+		w.Write(LEVEL_3, "%s:\t%s\n", name, quantity.String())
+	}
+}
+
+func describeContainerState(status api.ContainerStatus, w PrefixWriter) {
+	describeStatus("State", status.State, w)
+	if status.LastTerminationState.Terminated != nil {
+		describeStatus("Last State", status.LastTerminationState, w)
+	}
+	w.Write(LEVEL_2, "Ready:\t%v\n", printBool(status.Ready))
+	w.Write(LEVEL_2, "Restart Count:\t%d\n", status.RestartCount)
+}
+
+func describeContainerProbe(container api.Container, w PrefixWriter) {
+	if container.LivenessProbe != nil {
+		probe := DescribeProbe(container.LivenessProbe)
+		w.Write(LEVEL_2, "Liveness:\t%s\n", probe)
+	}
+	if container.ReadinessProbe != nil {
+		probe := DescribeProbe(container.ReadinessProbe)
+		w.Write(LEVEL_2, "Readiness:\t%s\n", probe)
+	}
+}
+
+func describeContainerVolumes(container api.Container, w PrefixWriter) {
+	// Show volumeMounts
+	none := ""
+	if len(container.VolumeMounts) == 0 {
+		none = "\t<none>"
+	}
+	w.Write(LEVEL_2, "Mounts:%s\n", none)
+	sort.Sort(SortableVolumeMounts(container.VolumeMounts))
+	for _, mount := range container.VolumeMounts {
+		flags := []string{}
+		switch {
+		case mount.ReadOnly:
+			flags = append(flags, "ro")
+		case !mount.ReadOnly:
+			flags = append(flags, "rw")
+		case len(mount.SubPath) > 0:
+			flags = append(flags, fmt.Sprintf("path=%q", mount.SubPath))
+		}
+		w.Write(LEVEL_3, "%s from %s (%s)\n", mount.MountPath, mount.Name, strings.Join(flags, ","))
+	}
+	// Show volumeDevices if exists
+	if len(container.VolumeDevices) > 0 {
+		w.Write(LEVEL_2, "Devices:%s\n", none)
+		sort.Sort(SortableVolumeDevices(container.VolumeDevices))
+		for _, device := range container.VolumeDevices {
+			w.Write(LEVEL_3, "%s from %s\n", device.DevicePath, device.Name)
+		}
+	}
+}
+
+func describeContainerEnvVars(container api.Container, resolverFn EnvVarResolverFunc, w PrefixWriter) {
+	none := ""
+	if len(container.Env) == 0 {
+		none = "\t<none>"
+	}
+	w.Write(LEVEL_2, "Environment:%s\n", none)
+
+	for _, e := range container.Env {
+		if e.ValueFrom == nil {
+			w.Write(LEVEL_3, "%s:\t%s\n", e.Name, e.Value)
+			continue
+		}
+
+		switch {
+		case e.ValueFrom.FieldRef != nil:
+			var valueFrom string
+			if resolverFn != nil {
+				valueFrom = resolverFn(e)
+			}
+			w.Write(LEVEL_3, "%s:\t%s (%s:%s)\n", e.Name, valueFrom, e.ValueFrom.FieldRef.APIVersion, e.ValueFrom.FieldRef.FieldPath)
+		case e.ValueFrom.ResourceFieldRef != nil:
+			valueFrom, err := resourcehelper.ExtractContainerResourceValue(e.ValueFrom.ResourceFieldRef, &container)
+			if err != nil {
+				valueFrom = ""
+			}
+			resource := e.ValueFrom.ResourceFieldRef.Resource
+			if valueFrom == "0" && (resource == "limits.cpu" || resource == "limits.memory") {
+				valueFrom = "node allocatable"
+			}
+			w.Write(LEVEL_3, "%s:\t%s (%s)\n", e.Name, valueFrom, resource)
+		case e.ValueFrom.SecretKeyRef != nil:
+			optional := e.ValueFrom.SecretKeyRef.Optional != nil && *e.ValueFrom.SecretKeyRef.Optional
+			w.Write(LEVEL_3, "%s:\t<set to the key '%s' in secret '%s'>\tOptional: %t\n", e.Name, e.ValueFrom.SecretKeyRef.Key, e.ValueFrom.SecretKeyRef.Name, optional)
+		case e.ValueFrom.ConfigMapKeyRef != nil:
+			optional := e.ValueFrom.ConfigMapKeyRef.Optional != nil && *e.ValueFrom.ConfigMapKeyRef.Optional
+			w.Write(LEVEL_3, "%s:\t<set to the key '%s' of config map '%s'>\tOptional: %t\n", e.Name, e.ValueFrom.ConfigMapKeyRef.Key, e.ValueFrom.ConfigMapKeyRef.Name, optional)
+		}
+	}
+}
+
+func describeContainerEnvFrom(container api.Container, resolverFn EnvVarResolverFunc, w PrefixWriter) {
+	none := ""
+	if len(container.EnvFrom) == 0 {
+		none = "\t<none>"
+	}
+	w.Write(LEVEL_2, "Environment Variables from:%s\n", none)
+
+	for _, e := range container.EnvFrom {
+		from := ""
+		name := ""
+		optional := false
+		if e.ConfigMapRef != nil {
+			from = "ConfigMap"
+			name = e.ConfigMapRef.Name
+			optional = e.ConfigMapRef.Optional != nil && *e.ConfigMapRef.Optional
+		} else if e.SecretRef != nil {
+			from = "Secret"
+			name = e.SecretRef.Name
+			optional = e.SecretRef.Optional != nil && *e.SecretRef.Optional
+		}
+		if len(e.Prefix) == 0 {
+			w.Write(LEVEL_3, "%s\t%s\tOptional: %t\n", name, from, optional)
+		} else {
+			w.Write(LEVEL_3, "%s\t%s with prefix '%s'\tOptional: %t\n", name, from, e.Prefix, optional)
+		}
+	}
+}
+
+// DescribeProbe is exported for consumers in other API groups that have probes
+func DescribeProbe(probe *api.Probe) string {
+	attrs := fmt.Sprintf("delay=%ds timeout=%ds period=%ds #success=%d #failure=%d", probe.InitialDelaySeconds, probe.TimeoutSeconds, probe.PeriodSeconds, probe.SuccessThreshold, probe.FailureThreshold)
+	switch {
+	case probe.Exec != nil:
+		return fmt.Sprintf("exec %v %s", probe.Exec.Command, attrs)
+	case probe.HTTPGet != nil:
+		url := &url.URL{}
+		url.Scheme = strings.ToLower(string(probe.HTTPGet.Scheme))
+		if len(probe.HTTPGet.Port.String()) > 0 {
+			url.Host = net.JoinHostPort(probe.HTTPGet.Host, probe.HTTPGet.Port.String())
+		} else {
+			url.Host = probe.HTTPGet.Host
+		}
+		url.Path = probe.HTTPGet.Path
+		return fmt.Sprintf("http-get %s %s", url.String(), attrs)
+	case probe.TCPSocket != nil:
+		return fmt.Sprintf("tcp-socket %s:%s %s", probe.TCPSocket.Host, probe.TCPSocket.Port.String(), attrs)
+	}
+	return fmt.Sprintf("unknown %s", attrs)
+}
+
+type EnvVarResolverFunc func(e api.EnvVar) string
+
+// EnvValueFrom is exported for use by describers in other packages
+func EnvValueRetriever(pod *api.Pod) EnvVarResolverFunc {
+	return func(e api.EnvVar) string {
+		internalFieldPath, _, err := legacyscheme.Scheme.ConvertFieldLabel(e.ValueFrom.FieldRef.APIVersion, "Pod", e.ValueFrom.FieldRef.FieldPath, "")
+		if err != nil {
+			return "" // pod validation should catch this on create
+		}
+
+		valueFrom, err := fieldpath.ExtractFieldPathAsString(pod, internalFieldPath)
+		if err != nil {
+			return "" // pod validation should catch this on create
+		}
+
+		return valueFrom
+	}
+}
+
+func describeStatus(stateName string, state api.ContainerState, w PrefixWriter) {
+	switch {
+	case state.Running != nil:
+		w.Write(LEVEL_2, "%s:\tRunning\n", stateName)
+		w.Write(LEVEL_3, "Started:\t%v\n", state.Running.StartedAt.Time.Format(time.RFC1123Z))
+	case state.Waiting != nil:
+		w.Write(LEVEL_2, "%s:\tWaiting\n", stateName)
+		if state.Waiting.Reason != "" {
+			w.Write(LEVEL_3, "Reason:\t%s\n", state.Waiting.Reason)
+		}
+	case state.Terminated != nil:
+		w.Write(LEVEL_2, "%s:\tTerminated\n", stateName)
+		if state.Terminated.Reason != "" {
+			w.Write(LEVEL_3, "Reason:\t%s\n", state.Terminated.Reason)
+		}
+		if state.Terminated.Message != "" {
+			w.Write(LEVEL_3, "Message:\t%s\n", state.Terminated.Message)
+		}
+		w.Write(LEVEL_3, "Exit Code:\t%d\n", state.Terminated.ExitCode)
+		if state.Terminated.Signal > 0 {
+			w.Write(LEVEL_3, "Signal:\t%d\n", state.Terminated.Signal)
+		}
+		w.Write(LEVEL_3, "Started:\t%s\n", state.Terminated.StartedAt.Time.Format(time.RFC1123Z))
+		w.Write(LEVEL_3, "Finished:\t%s\n", state.Terminated.FinishedAt.Time.Format(time.RFC1123Z))
+	default:
+		w.Write(LEVEL_2, "%s:\tWaiting\n", stateName)
+	}
+}
+
+func describeVolumeClaimTemplates(templates []api.PersistentVolumeClaim, w PrefixWriter) {
+	if len(templates) == 0 {
+		w.Write(LEVEL_0, "Volume Claims:\t<none>\n")
+		return
+	}
+	w.Write(LEVEL_0, "Volume Claims:\n")
+	for _, pvc := range templates {
+		w.Write(LEVEL_1, "Name:\t%s\n", pvc.Name)
+		w.Write(LEVEL_1, "StorageClass:\t%s\n", helper.GetPersistentVolumeClaimClass(&pvc))
+		printLabelsMultilineWithIndent(w, "  ", "Labels", "\t", pvc.Labels, sets.NewString())
+		printLabelsMultilineWithIndent(w, "  ", "Annotations", "\t", pvc.Annotations, sets.NewString())
+		if capacity, ok := pvc.Spec.Resources.Requests[api.ResourceStorage]; ok {
+			w.Write(LEVEL_1, "Capacity:\t%s\n", capacity.String())
+		} else {
+			w.Write(LEVEL_1, "Capacity:\t%s\n", "<default>")
+		}
+		w.Write(LEVEL_1, "Access Modes:\t%s\n", pvc.Spec.AccessModes)
+	}
+}
+
+func printBoolPtr(value *bool) string {
+	if value != nil {
+		return printBool(*value)
+	}
+
+	return "<unset>"
+}
+
+func printBool(value bool) string {
+	if value {
+		return "True"
+	}
+
+	return "False"
+}
+
+// ReplicationControllerDescriber generates information about a replication controller
+// and the pods it has created.
+type ReplicationControllerDescriber struct {
+	clientset.Interface
+}
+
+func (d *ReplicationControllerDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	rc := d.Core().ReplicationControllers(namespace)
+	pc := d.Core().Pods(namespace)
+
+	controller, err := rc.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	running, waiting, succeeded, failed, err := getPodStatusForController(pc, labels.SelectorFromSet(controller.Spec.Selector), controller.UID)
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, controller)
+	}
+
+	return describeReplicationController(controller, events, running, waiting, succeeded, failed)
+}
+
+func describeReplicationController(controller *api.ReplicationController, events *api.EventList, running, waiting, succeeded, failed int) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", controller.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", controller.Namespace)
+		w.Write(LEVEL_0, "Selector:\t%s\n", labels.FormatLabels(controller.Spec.Selector))
+		printLabelsMultiline(w, "Labels", controller.Labels)
+		printAnnotationsMultiline(w, "Annotations", controller.Annotations)
+		w.Write(LEVEL_0, "Replicas:\t%d current / %d desired\n", controller.Status.Replicas, controller.Spec.Replicas)
+		w.Write(LEVEL_0, "Pods Status:\t%d Running / %d Waiting / %d Succeeded / %d Failed\n", running, waiting, succeeded, failed)
+		DescribePodTemplate(controller.Spec.Template, w)
+		if len(controller.Status.Conditions) > 0 {
+			w.Write(LEVEL_0, "Conditions:\n  Type\tStatus\tReason\n")
+			w.Write(LEVEL_1, "----\t------\t------\n")
+			for _, c := range controller.Status.Conditions {
+				w.Write(LEVEL_1, "%v \t%v\t%v\n", c.Type, c.Status, c.Reason)
+			}
+		}
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+func DescribePodTemplate(template *api.PodTemplateSpec, w PrefixWriter) {
+	w.Write(LEVEL_0, "Pod Template:\n")
+	if template == nil {
+		w.Write(LEVEL_1, "<unset>")
+		return
+	}
+	printLabelsMultiline(w, "  Labels", template.Labels)
+	if len(template.Annotations) > 0 {
+		printAnnotationsMultiline(w, "  Annotations", template.Annotations)
+	}
+	if len(template.Spec.ServiceAccountName) > 0 {
+		w.Write(LEVEL_1, "Service Account:\t%s\n", template.Spec.ServiceAccountName)
+	}
+	if len(template.Spec.InitContainers) > 0 {
+		describeContainers("Init Containers", template.Spec.InitContainers, nil, nil, w, "  ")
+	}
+	describeContainers("Containers", template.Spec.Containers, nil, nil, w, "  ")
+	describeVolumes(template.Spec.Volumes, w, "  ")
+}
+
+// ReplicaSetDescriber generates information about a ReplicaSet and the pods it has created.
+type ReplicaSetDescriber struct {
+	clientset.Interface
+}
+
+func (d *ReplicaSetDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	rsc := d.Extensions().ReplicaSets(namespace)
+	pc := d.Core().Pods(namespace)
+
+	rs, err := rsc.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	selector, err := metav1.LabelSelectorAsSelector(rs.Spec.Selector)
+	if err != nil {
+		return "", err
+	}
+
+	running, waiting, succeeded, failed, getPodErr := getPodStatusForController(pc, selector, rs.UID)
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, rs)
+	}
+
+	return describeReplicaSet(rs, events, running, waiting, succeeded, failed, getPodErr)
+}
+
+func describeReplicaSet(rs *extensions.ReplicaSet, events *api.EventList, running, waiting, succeeded, failed int, getPodErr error) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", rs.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", rs.Namespace)
+		w.Write(LEVEL_0, "Selector:\t%s\n", metav1.FormatLabelSelector(rs.Spec.Selector))
+		printLabelsMultiline(w, "Labels", rs.Labels)
+		printAnnotationsMultiline(w, "Annotations", rs.Annotations)
+		if controlledBy := printController(rs); len(controlledBy) > 0 {
+			w.Write(LEVEL_0, "Controlled By:\t%s\n", controlledBy)
+		}
+		w.Write(LEVEL_0, "Replicas:\t%d current / %d desired\n", rs.Status.Replicas, rs.Spec.Replicas)
+		w.Write(LEVEL_0, "Pods Status:\t")
+		if getPodErr != nil {
+			w.Write(LEVEL_0, "error in fetching pods: %s\n", getPodErr)
+		} else {
+			w.Write(LEVEL_0, "%d Running / %d Waiting / %d Succeeded / %d Failed\n", running, waiting, succeeded, failed)
+		}
+		DescribePodTemplate(&rs.Spec.Template, w)
+		if len(rs.Status.Conditions) > 0 {
+			w.Write(LEVEL_0, "Conditions:\n  Type\tStatus\tReason\n")
+			w.Write(LEVEL_1, "----\t------\t------\n")
+			for _, c := range rs.Status.Conditions {
+				w.Write(LEVEL_1, "%v \t%v\t%v\n", c.Type, c.Status, c.Reason)
+			}
+		}
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+// JobDescriber generates information about a job and the pods it has created.
+type JobDescriber struct {
+	clientset.Interface
+}
+
+func (d *JobDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	job, err := d.Batch().Jobs(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, job)
+	}
+
+	return describeJob(job, events)
+}
+
+func describeJob(job *batch.Job, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", job.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", job.Namespace)
+		selector, _ := metav1.LabelSelectorAsSelector(job.Spec.Selector)
+		w.Write(LEVEL_0, "Selector:\t%s\n", selector)
+		printLabelsMultiline(w, "Labels", job.Labels)
+		printAnnotationsMultiline(w, "Annotations", job.Annotations)
+		if controlledBy := printController(job); len(controlledBy) > 0 {
+			w.Write(LEVEL_0, "Controlled By:\t%s\n", controlledBy)
+		}
+		w.Write(LEVEL_0, "Parallelism:\t%d\n", *job.Spec.Parallelism)
+		if job.Spec.Completions != nil {
+			w.Write(LEVEL_0, "Completions:\t%d\n", *job.Spec.Completions)
+		} else {
+			w.Write(LEVEL_0, "Completions:\t<unset>\n")
+		}
+		if job.Status.StartTime != nil {
+			w.Write(LEVEL_0, "Start Time:\t%s\n", job.Status.StartTime.Time.Format(time.RFC1123Z))
+		}
+		if job.Spec.ActiveDeadlineSeconds != nil {
+			w.Write(LEVEL_0, "Active Deadline Seconds:\t%ds\n", *job.Spec.ActiveDeadlineSeconds)
+		}
+		w.Write(LEVEL_0, "Pods Statuses:\t%d Running / %d Succeeded / %d Failed\n", job.Status.Active, job.Status.Succeeded, job.Status.Failed)
+		DescribePodTemplate(&job.Spec.Template, w)
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+// CronJobDescriber generates information about a cron job and the jobs it has created.
+type CronJobDescriber struct {
+	clientset.Interface
+	external externalclient.Interface
+}
+
+func (d *CronJobDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	cronJob, err := d.external.BatchV1beta1().CronJobs(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, cronJob)
+	}
+
+	internalCronJob := &batch.CronJob{}
+	if err := legacyscheme.Scheme.Convert(cronJob, internalCronJob, nil); err != nil {
+		return "", err
+	}
+
+	return describeCronJob(internalCronJob, events)
+}
+
+func describeCronJob(cronJob *batch.CronJob, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", cronJob.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", cronJob.Namespace)
+		printLabelsMultiline(w, "Labels", cronJob.Labels)
+		printAnnotationsMultiline(w, "Annotations", cronJob.Annotations)
+		w.Write(LEVEL_0, "Schedule:\t%s\n", cronJob.Spec.Schedule)
+		w.Write(LEVEL_0, "Concurrency Policy:\t%s\n", cronJob.Spec.ConcurrencyPolicy)
+		w.Write(LEVEL_0, "Suspend:\t%s\n", printBoolPtr(cronJob.Spec.Suspend))
+		if cronJob.Spec.StartingDeadlineSeconds != nil {
+			w.Write(LEVEL_0, "Starting Deadline Seconds:\t%ds\n", *cronJob.Spec.StartingDeadlineSeconds)
+		} else {
+			w.Write(LEVEL_0, "Starting Deadline Seconds:\t<unset>\n")
+		}
+		describeJobTemplate(cronJob.Spec.JobTemplate, w)
+		if cronJob.Status.LastScheduleTime != nil {
+			w.Write(LEVEL_0, "Last Schedule Time:\t%s\n", cronJob.Status.LastScheduleTime.Time.Format(time.RFC1123Z))
+		} else {
+			w.Write(LEVEL_0, "Last Schedule Time:\t<unset>\n")
+		}
+		printActiveJobs(w, "Active Jobs", cronJob.Status.Active)
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+func describeJobTemplate(jobTemplate batch.JobTemplateSpec, w PrefixWriter) {
+	if jobTemplate.Spec.Selector != nil {
+		selector, _ := metav1.LabelSelectorAsSelector(jobTemplate.Spec.Selector)
+		w.Write(LEVEL_0, "Selector:\t%s\n", selector)
+	} else {
+		w.Write(LEVEL_0, "Selector:\t<unset>\n")
+	}
+	if jobTemplate.Spec.Parallelism != nil {
+		w.Write(LEVEL_0, "Parallelism:\t%d\n", *jobTemplate.Spec.Parallelism)
+	} else {
+		w.Write(LEVEL_0, "Parallelism:\t<unset>\n")
+	}
+	if jobTemplate.Spec.Completions != nil {
+		w.Write(LEVEL_0, "Completions:\t%d\n", *jobTemplate.Spec.Completions)
+	} else {
+		w.Write(LEVEL_0, "Completions:\t<unset>\n")
+	}
+	if jobTemplate.Spec.ActiveDeadlineSeconds != nil {
+		w.Write(LEVEL_0, "Active Deadline Seconds:\t%ds\n", *jobTemplate.Spec.ActiveDeadlineSeconds)
+	}
+	DescribePodTemplate(&jobTemplate.Spec.Template, w)
+}
+
+func printActiveJobs(w PrefixWriter, title string, jobs []api.ObjectReference) {
+	w.Write(LEVEL_0, "%s:\t", title)
+	if len(jobs) == 0 {
+		w.WriteLine("<none>")
+		return
+	}
+
+	for i, job := range jobs {
+		if i != 0 {
+			w.Write(LEVEL_0, ", ")
+		}
+		w.Write(LEVEL_0, "%s", job.Name)
+	}
+	w.WriteLine("")
+}
+
+// DaemonSetDescriber generates information about a daemon set and the pods it has created.
+type DaemonSetDescriber struct {
+	clientset.Interface
+}
+
+func (d *DaemonSetDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	dc := d.Extensions().DaemonSets(namespace)
+	pc := d.Core().Pods(namespace)
+
+	daemon, err := dc.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	selector, err := metav1.LabelSelectorAsSelector(daemon.Spec.Selector)
+	if err != nil {
+		return "", err
+	}
+	running, waiting, succeeded, failed, err := getPodStatusForController(pc, selector, daemon.UID)
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, daemon)
+	}
+
+	return describeDaemonSet(daemon, events, running, waiting, succeeded, failed)
+}
+
+func describeDaemonSet(daemon *extensions.DaemonSet, events *api.EventList, running, waiting, succeeded, failed int) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", daemon.Name)
+		selector, err := metav1.LabelSelectorAsSelector(daemon.Spec.Selector)
+		if err != nil {
+			// this shouldn't happen if LabelSelector passed validation
+			return err
+		}
+		w.Write(LEVEL_0, "Selector:\t%s\n", selector)
+		w.Write(LEVEL_0, "Node-Selector:\t%s\n", labels.FormatLabels(daemon.Spec.Template.Spec.NodeSelector))
+		printLabelsMultiline(w, "Labels", daemon.Labels)
+		printAnnotationsMultiline(w, "Annotations", daemon.Annotations)
+		w.Write(LEVEL_0, "Desired Number of Nodes Scheduled: %d\n", daemon.Status.DesiredNumberScheduled)
+		w.Write(LEVEL_0, "Current Number of Nodes Scheduled: %d\n", daemon.Status.CurrentNumberScheduled)
+		w.Write(LEVEL_0, "Number of Nodes Scheduled with Up-to-date Pods: %d\n", daemon.Status.UpdatedNumberScheduled)
+		w.Write(LEVEL_0, "Number of Nodes Scheduled with Available Pods: %d\n", daemon.Status.NumberAvailable)
+		w.Write(LEVEL_0, "Number of Nodes Misscheduled: %d\n", daemon.Status.NumberMisscheduled)
+		w.Write(LEVEL_0, "Pods Status:\t%d Running / %d Waiting / %d Succeeded / %d Failed\n", running, waiting, succeeded, failed)
+		DescribePodTemplate(&daemon.Spec.Template, w)
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+// SecretDescriber generates information about a secret
+type SecretDescriber struct {
+	clientset.Interface
+}
+
+func (d *SecretDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	c := d.Core().Secrets(namespace)
+
+	secret, err := c.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	return describeSecret(secret)
+}
+
+func describeSecret(secret *api.Secret) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", secret.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", secret.Namespace)
+		printLabelsMultiline(w, "Labels", secret.Labels)
+		skipAnnotations := sets.NewString(api.LastAppliedConfigAnnotation)
+		printAnnotationsMultilineWithFilter(w, "Annotations", secret.Annotations, skipAnnotations)
+
+		w.Write(LEVEL_0, "\nType:\t%s\n", secret.Type)
+
+		w.Write(LEVEL_0, "\nData\n====\n")
+		for k, v := range secret.Data {
+			switch {
+			case k == api.ServiceAccountTokenKey && secret.Type == api.SecretTypeServiceAccountToken:
+				w.Write(LEVEL_0, "%s:\t%s\n", k, string(v))
+			default:
+				w.Write(LEVEL_0, "%s:\t%d bytes\n", k, len(v))
+			}
+		}
+
+		return nil
+	})
+}
+
+type IngressDescriber struct {
+	clientset.Interface
+}
+
+func (i *IngressDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	c := i.Extensions().Ingresses(namespace)
+	ing, err := c.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+	return i.describeIngress(ing, describerSettings)
+}
+
+func (i *IngressDescriber) describeBackend(ns string, backend *extensions.IngressBackend) string {
+	endpoints, _ := i.Core().Endpoints(ns).Get(backend.ServiceName, metav1.GetOptions{})
+	service, _ := i.Core().Services(ns).Get(backend.ServiceName, metav1.GetOptions{})
+	spName := ""
+	for i := range service.Spec.Ports {
+		sp := &service.Spec.Ports[i]
+		switch backend.ServicePort.Type {
+		case intstr.String:
+			if backend.ServicePort.StrVal == sp.Name {
+				spName = sp.Name
+			}
+		case intstr.Int:
+			if int32(backend.ServicePort.IntVal) == sp.Port {
+				spName = sp.Name
+			}
+		}
+	}
+	return formatEndpoints(endpoints, sets.NewString(spName))
+}
+
+func (i *IngressDescriber) describeIngress(ing *extensions.Ingress, describerSettings printers.DescriberSettings) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%v\n", ing.Name)
+		w.Write(LEVEL_0, "Namespace:\t%v\n", ing.Namespace)
+		w.Write(LEVEL_0, "Address:\t%v\n", loadBalancerStatusStringer(ing.Status.LoadBalancer, true))
+		def := ing.Spec.Backend
+		ns := ing.Namespace
+		if def == nil {
+			// Ingresses that don't specify a default backend inherit the
+			// default backend in the kube-system namespace.
+			def = &extensions.IngressBackend{
+				ServiceName: "default-http-backend",
+				ServicePort: intstr.IntOrString{Type: intstr.Int, IntVal: 80},
+			}
+			ns = metav1.NamespaceSystem
+		}
+		w.Write(LEVEL_0, "Default backend:\t%s (%s)\n", backendStringer(def), i.describeBackend(ns, def))
+		if len(ing.Spec.TLS) != 0 {
+			describeIngressTLS(w, ing.Spec.TLS)
+		}
+		w.Write(LEVEL_0, "Rules:\n  Host\tPath\tBackends\n")
+		w.Write(LEVEL_1, "----\t----\t--------\n")
+		count := 0
+		for _, rules := range ing.Spec.Rules {
+			if rules.HTTP == nil {
+				continue
+			}
+			count++
+			host := rules.Host
+			if len(host) == 0 {
+				host = "*"
+			}
+			w.Write(LEVEL_1, "%s\t\n", host)
+			for _, path := range rules.HTTP.Paths {
+				w.Write(LEVEL_2, "\t%s \t%s (%s)\n", path.Path, backendStringer(&path.Backend), i.describeBackend(ns, &path.Backend))
+			}
+		}
+		if count == 0 {
+			w.Write(LEVEL_1, "%s\t%s \t%s (%s)\n", "*", "*", backendStringer(def), i.describeBackend(ns, def))
+		}
+		describeIngressAnnotations(w, ing.Annotations)
+
+		if describerSettings.ShowEvents {
+			events, _ := i.Core().Events(ing.Namespace).Search(legacyscheme.Scheme, ing)
+			if events != nil {
+				DescribeEvents(events, w)
+			}
+		}
+		return nil
+	})
+}
+
+func describeIngressTLS(w PrefixWriter, ingTLS []extensions.IngressTLS) {
+	w.Write(LEVEL_0, "TLS:\n")
+	for _, t := range ingTLS {
+		if t.SecretName == "" {
+			w.Write(LEVEL_1, "SNI routes %v\n", strings.Join(t.Hosts, ","))
+		} else {
+			w.Write(LEVEL_1, "%v terminates %v\n", t.SecretName, strings.Join(t.Hosts, ","))
+		}
+	}
+	return
+}
+
+// TODO: Move from annotations into Ingress status.
+func describeIngressAnnotations(w PrefixWriter, annotations map[string]string) {
+	w.Write(LEVEL_0, "Annotations:\n")
+	for k, v := range annotations {
+		w.Write(LEVEL_1, "%v:\t%s\n", k, v)
+	}
+	return
+}
+
+// ServiceDescriber generates information about a service.
+type ServiceDescriber struct {
+	clientset.Interface
+}
+
+func (d *ServiceDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	c := d.Core().Services(namespace)
+
+	service, err := c.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	endpoints, _ := d.Core().Endpoints(namespace).Get(name, metav1.GetOptions{})
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, service)
+	}
+	return describeService(service, endpoints, events)
+}
+
+func buildIngressString(ingress []api.LoadBalancerIngress) string {
+	var buffer bytes.Buffer
+
+	for i := range ingress {
+		if i != 0 {
+			buffer.WriteString(", ")
+		}
+		if ingress[i].IP != "" {
+			buffer.WriteString(ingress[i].IP)
+		} else {
+			buffer.WriteString(ingress[i].Hostname)
+		}
+	}
+	return buffer.String()
+}
+
+func describeService(service *api.Service, endpoints *api.Endpoints, events *api.EventList) (string, error) {
+	if endpoints == nil {
+		endpoints = &api.Endpoints{}
+	}
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", service.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", service.Namespace)
+		printLabelsMultiline(w, "Labels", service.Labels)
+		printAnnotationsMultiline(w, "Annotations", service.Annotations)
+		w.Write(LEVEL_0, "Selector:\t%s\n", labels.FormatLabels(service.Spec.Selector))
+		w.Write(LEVEL_0, "Type:\t%s\n", service.Spec.Type)
+		w.Write(LEVEL_0, "IP:\t%s\n", service.Spec.ClusterIP)
+		if len(service.Spec.ExternalIPs) > 0 {
+			w.Write(LEVEL_0, "External IPs:\t%v\n", strings.Join(service.Spec.ExternalIPs, ","))
+		}
+		if service.Spec.LoadBalancerIP != "" {
+			w.Write(LEVEL_0, "IP:\t%s\n", service.Spec.LoadBalancerIP)
+		}
+		if service.Spec.ExternalName != "" {
+			w.Write(LEVEL_0, "External Name:\t%s\n", service.Spec.ExternalName)
+		}
+		if len(service.Status.LoadBalancer.Ingress) > 0 {
+			list := buildIngressString(service.Status.LoadBalancer.Ingress)
+			w.Write(LEVEL_0, "LoadBalancer Ingress:\t%s\n", list)
+		}
+		for i := range service.Spec.Ports {
+			sp := &service.Spec.Ports[i]
+
+			name := sp.Name
+			if name == "" {
+				name = "<unset>"
+			}
+			w.Write(LEVEL_0, "Port:\t%s\t%d/%s\n", name, sp.Port, sp.Protocol)
+			if sp.TargetPort.Type == intstr.Type(intstr.Int) {
+				w.Write(LEVEL_0, "TargetPort:\t%d/%s\n", sp.TargetPort.IntVal, sp.Protocol)
+			} else {
+				w.Write(LEVEL_0, "TargetPort:\t%s/%s\n", sp.TargetPort.StrVal, sp.Protocol)
+			}
+			if sp.NodePort != 0 {
+				w.Write(LEVEL_0, "NodePort:\t%s\t%d/%s\n", name, sp.NodePort, sp.Protocol)
+			}
+			w.Write(LEVEL_0, "Endpoints:\t%s\n", formatEndpoints(endpoints, sets.NewString(sp.Name)))
+		}
+		w.Write(LEVEL_0, "Session Affinity:\t%s\n", service.Spec.SessionAffinity)
+		if service.Spec.ExternalTrafficPolicy != "" {
+			w.Write(LEVEL_0, "External Traffic Policy:\t%s\n", service.Spec.ExternalTrafficPolicy)
+		}
+		if service.Spec.HealthCheckNodePort != 0 {
+			w.Write(LEVEL_0, "HealthCheck NodePort:\t%d\n", service.Spec.HealthCheckNodePort)
+		}
+		if len(service.Spec.LoadBalancerSourceRanges) > 0 {
+			w.Write(LEVEL_0, "LoadBalancer Source Ranges:\t%v\n", strings.Join(service.Spec.LoadBalancerSourceRanges, ","))
+		}
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+// EndpointsDescriber generates information about an Endpoint.
+type EndpointsDescriber struct {
+	clientset.Interface
+}
+
+func (d *EndpointsDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	c := d.Core().Endpoints(namespace)
+
+	ep, err := c.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, ep)
+	}
+
+	return describeEndpoints(ep, events)
+}
+
+func describeEndpoints(ep *api.Endpoints, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", ep.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", ep.Namespace)
+		printLabelsMultiline(w, "Labels", ep.Labels)
+		printAnnotationsMultiline(w, "Annotations", ep.Annotations)
+
+		w.Write(LEVEL_0, "Subsets:\n")
+		for i := range ep.Subsets {
+			subset := &ep.Subsets[i]
+
+			addresses := make([]string, 0, len(subset.Addresses))
+			for _, addr := range subset.Addresses {
+				addresses = append(addresses, addr.IP)
+			}
+			addressesString := strings.Join(addresses, ",")
+			if len(addressesString) == 0 {
+				addressesString = "<none>"
+			}
+			w.Write(LEVEL_1, "Addresses:\t%s\n", addressesString)
+
+			notReadyAddresses := make([]string, 0, len(subset.NotReadyAddresses))
+			for _, addr := range subset.NotReadyAddresses {
+				notReadyAddresses = append(notReadyAddresses, addr.IP)
+			}
+			notReadyAddressesString := strings.Join(notReadyAddresses, ",")
+			if len(notReadyAddressesString) == 0 {
+				notReadyAddressesString = "<none>"
+			}
+			w.Write(LEVEL_1, "NotReadyAddresses:\t%s\n", notReadyAddressesString)
+
+			if len(subset.Ports) > 0 {
+				w.Write(LEVEL_1, "Ports:\n")
+				w.Write(LEVEL_2, "Name\tPort\tProtocol\n")
+				w.Write(LEVEL_2, "----\t----\t--------\n")
+				for _, port := range subset.Ports {
+					name := port.Name
+					if len(name) == 0 {
+						name = "<unset>"
+					}
+					w.Write(LEVEL_2, "%s\t%d\t%s\n", name, port.Port, port.Protocol)
+				}
+			}
+			w.Write(LEVEL_0, "\n")
+		}
+
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+// ServiceAccountDescriber generates information about a service.
+type ServiceAccountDescriber struct {
+	clientset.Interface
+}
+
+func (d *ServiceAccountDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	c := d.Core().ServiceAccounts(namespace)
+
+	serviceAccount, err := c.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	tokens := []api.Secret{}
+
+	// missingSecrets is the set of all secrets present in the
+	// serviceAccount but not present in the set of existing secrets.
+	missingSecrets := sets.NewString()
+	secrets, err := d.Core().Secrets(namespace).List(metav1.ListOptions{})
+
+	// errors are tolerated here in order to describe the serviceAccount with all
+	// of the secrets that it references, even if those secrets cannot be fetched.
+	if err == nil {
+		// existingSecrets is the set of all secrets remaining on a
+		// service account that are not present in the "tokens" slice.
+		existingSecrets := sets.NewString()
+
+		for _, s := range secrets.Items {
+			if s.Type == api.SecretTypeServiceAccountToken {
+				name, _ := s.Annotations[api.ServiceAccountNameKey]
+				uid, _ := s.Annotations[api.ServiceAccountUIDKey]
+				if name == serviceAccount.Name && uid == string(serviceAccount.UID) {
+					tokens = append(tokens, s)
+				}
+			}
+			existingSecrets.Insert(s.Name)
+		}
+
+		for _, s := range serviceAccount.Secrets {
+			if !existingSecrets.Has(s.Name) {
+				missingSecrets.Insert(s.Name)
+			}
+		}
+		for _, s := range serviceAccount.ImagePullSecrets {
+			if !existingSecrets.Has(s.Name) {
+				missingSecrets.Insert(s.Name)
+			}
+		}
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.Core().Events(namespace).Search(legacyscheme.Scheme, serviceAccount)
+	}
+
+	return describeServiceAccount(serviceAccount, tokens, missingSecrets, events)
+}
+
+func describeServiceAccount(serviceAccount *api.ServiceAccount, tokens []api.Secret, missingSecrets sets.String, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", serviceAccount.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", serviceAccount.Namespace)
+		printLabelsMultiline(w, "Labels", serviceAccount.Labels)
+		printAnnotationsMultiline(w, "Annotations", serviceAccount.Annotations)
+
+		var (
+			emptyHeader = "                   "
+			pullHeader  = "Image pull secrets:"
+			mountHeader = "Mountable secrets: "
+			tokenHeader = "Tokens:            "
+
+			pullSecretNames  = []string{}
+			mountSecretNames = []string{}
+			tokenSecretNames = []string{}
+		)
+
+		for _, s := range serviceAccount.ImagePullSecrets {
+			pullSecretNames = append(pullSecretNames, s.Name)
+		}
+		for _, s := range serviceAccount.Secrets {
+			mountSecretNames = append(mountSecretNames, s.Name)
+		}
+		for _, s := range tokens {
+			tokenSecretNames = append(tokenSecretNames, s.Name)
+		}
+
+		types := map[string][]string{
+			pullHeader:  pullSecretNames,
+			mountHeader: mountSecretNames,
+			tokenHeader: tokenSecretNames,
+		}
+		for _, header := range sets.StringKeySet(types).List() {
+			names := types[header]
+			if len(names) == 0 {
+				w.Write(LEVEL_0, "%s\t<none>\n", header)
+			} else {
+				prefix := header
+				for _, name := range names {
+					if missingSecrets.Has(name) {
+						w.Write(LEVEL_0, "%s\t%s (not found)\n", prefix, name)
+					} else {
+						w.Write(LEVEL_0, "%s\t%s\n", prefix, name)
+					}
+					prefix = emptyHeader
+				}
+			}
+		}
+
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+// RoleDescriber generates information about a node.
+type RoleDescriber struct {
+	externalclient.Interface
+}
+
+func (d *RoleDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	role, err := d.Rbac().Roles(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	breakdownRules := []rbacv1.PolicyRule{}
+	for _, rule := range role.Rules {
+		breakdownRules = append(breakdownRules, validation.BreakdownRule(rule)...)
+	}
+
+	compactRules, err := validation.CompactRules(breakdownRules)
+	if err != nil {
+		return "", err
+	}
+	sort.Stable(rbacv1helpers.SortableRuleSlice(compactRules))
+
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", role.Name)
+		printLabelsMultiline(w, "Labels", role.Labels)
+		printAnnotationsMultiline(w, "Annotations", role.Annotations)
+
+		w.Write(LEVEL_0, "PolicyRule:\n")
+		w.Write(LEVEL_1, "Resources\tNon-Resource URLs\tResource Names\tVerbs\n")
+		w.Write(LEVEL_1, "---------\t-----------------\t--------------\t-----\n")
+		for _, r := range compactRules {
+			w.Write(LEVEL_1, "%s\t%v\t%v\t%v\n", combineResourceGroup(r.Resources, r.APIGroups), r.NonResourceURLs, r.ResourceNames, r.Verbs)
+		}
+
+		return nil
+	})
+}
+
+// ClusterRoleDescriber generates information about a node.
+type ClusterRoleDescriber struct {
+	externalclient.Interface
+}
+
+func (d *ClusterRoleDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	role, err := d.Rbac().ClusterRoles().Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	breakdownRules := []rbacv1.PolicyRule{}
+	for _, rule := range role.Rules {
+		breakdownRules = append(breakdownRules, validation.BreakdownRule(rule)...)
+	}
+
+	compactRules, err := validation.CompactRules(breakdownRules)
+	if err != nil {
+		return "", err
+	}
+	sort.Stable(rbacv1helpers.SortableRuleSlice(compactRules))
+
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", role.Name)
+		printLabelsMultiline(w, "Labels", role.Labels)
+		printAnnotationsMultiline(w, "Annotations", role.Annotations)
+
+		w.Write(LEVEL_0, "PolicyRule:\n")
+		w.Write(LEVEL_1, "Resources\tNon-Resource URLs\tResource Names\tVerbs\n")
+		w.Write(LEVEL_1, "---------\t-----------------\t--------------\t-----\n")
+		for _, r := range compactRules {
+			w.Write(LEVEL_1, "%s\t%v\t%v\t%v\n", combineResourceGroup(r.Resources, r.APIGroups), r.NonResourceURLs, r.ResourceNames, r.Verbs)
+		}
+
+		return nil
+	})
+}
+
+func combineResourceGroup(resource, group []string) string {
+	if len(resource) == 0 {
+		return ""
+	}
+	parts := strings.SplitN(resource[0], "/", 2)
+	combine := parts[0]
+
+	if len(group) > 0 && group[0] != "" {
+		combine = combine + "." + group[0]
+	}
+
+	if len(parts) == 2 {
+		combine = combine + "/" + parts[1]
+	}
+	return combine
+}
+
+// RoleBindingDescriber generates information about a node.
+type RoleBindingDescriber struct {
+	externalclient.Interface
+}
+
+func (d *RoleBindingDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	binding, err := d.Rbac().RoleBindings(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", binding.Name)
+		printLabelsMultiline(w, "Labels", binding.Labels)
+		printAnnotationsMultiline(w, "Annotations", binding.Annotations)
+
+		w.Write(LEVEL_0, "Role:\n")
+		w.Write(LEVEL_1, "Kind:\t%s\n", binding.RoleRef.Kind)
+		w.Write(LEVEL_1, "Name:\t%s\n", binding.RoleRef.Name)
+
+		w.Write(LEVEL_0, "Subjects:\n")
+		w.Write(LEVEL_1, "Kind\tName\tNamespace\n")
+		w.Write(LEVEL_1, "----\t----\t---------\n")
+		for _, s := range binding.Subjects {
+			w.Write(LEVEL_1, "%s\t%s\t%s\n", s.Kind, s.Name, s.Namespace)
+		}
+
+		return nil
+	})
+}
+
+// ClusterRoleBindingDescriber generates information about a node.
+type ClusterRoleBindingDescriber struct {
+	externalclient.Interface
+}
+
+func (d *ClusterRoleBindingDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	binding, err := d.Rbac().ClusterRoleBindings().Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", binding.Name)
+		printLabelsMultiline(w, "Labels", binding.Labels)
+		printAnnotationsMultiline(w, "Annotations", binding.Annotations)
+
+		w.Write(LEVEL_0, "Role:\n")
+		w.Write(LEVEL_1, "Kind:\t%s\n", binding.RoleRef.Kind)
+		w.Write(LEVEL_1, "Name:\t%s\n", binding.RoleRef.Name)
+
+		w.Write(LEVEL_0, "Subjects:\n")
+		w.Write(LEVEL_1, "Kind\tName\tNamespace\n")
+		w.Write(LEVEL_1, "----\t----\t---------\n")
+		for _, s := range binding.Subjects {
+			w.Write(LEVEL_1, "%s\t%s\t%s\n", s.Kind, s.Name, s.Namespace)
+		}
+
+		return nil
+	})
+}
+
+// NodeDescriber generates information about a node.
+type NodeDescriber struct {
+	clientset.Interface
+}
+
+func (d *NodeDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	mc := d.Core().Nodes()
+	node, err := mc.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	fieldSelector, err := fields.ParseSelector("spec.nodeName=" + name + ",status.phase!=" + string(api.PodSucceeded) + ",status.phase!=" + string(api.PodFailed))
+	if err != nil {
+		return "", err
+	}
+	// in a policy aware setting, users may have access to a node, but not all pods
+	// in that case, we note that the user does not have access to the pods
+	canViewPods := true
+	nodeNonTerminatedPodsList, err := d.Core().Pods(namespace).List(metav1.ListOptions{FieldSelector: fieldSelector.String()})
+	if err != nil {
+		if !errors.IsForbidden(err) {
+			return "", err
+		}
+		canViewPods = false
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		if ref, err := ref.GetReference(legacyscheme.Scheme, node); err != nil {
+			glog.Errorf("Unable to construct reference to '%#v': %v", node, err)
+		} else {
+			// TODO: We haven't decided the namespace for Node object yet.
+			ref.UID = types.UID(ref.Name)
+			events, _ = d.Core().Events("").Search(legacyscheme.Scheme, ref)
+		}
+	}
+
+	return describeNode(node, nodeNonTerminatedPodsList, events, canViewPods)
+}
+
+func describeNode(node *api.Node, nodeNonTerminatedPodsList *api.PodList, events *api.EventList, canViewPods bool) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", node.Name)
+		if roles := findNodeRoles(node); len(roles) > 0 {
+			w.Write(LEVEL_0, "Roles:\t%s\n", strings.Join(roles, ","))
+		} else {
+			w.Write(LEVEL_0, "Roles:\t%s\n", "<none>")
+		}
+		printLabelsMultiline(w, "Labels", node.Labels)
+		printAnnotationsMultiline(w, "Annotations", node.Annotations)
+		w.Write(LEVEL_0, "CreationTimestamp:\t%s\n", node.CreationTimestamp.Time.Format(time.RFC1123Z))
+		printNodeTaintsMultiline(w, "Taints", node.Spec.Taints)
+		w.Write(LEVEL_0, "Unschedulable:\t%v\n", node.Spec.Unschedulable)
+		if len(node.Status.Conditions) > 0 {
+			w.Write(LEVEL_0, "Conditions:\n  Type\tStatus\tLastHeartbeatTime\tLastTransitionTime\tReason\tMessage\n")
+			w.Write(LEVEL_1, "----\t------\t-----------------\t------------------\t------\t-------\n")
+			for _, c := range node.Status.Conditions {
+				w.Write(LEVEL_1, "%v \t%v \t%s \t%s \t%v \t%v\n",
+					c.Type,
+					c.Status,
+					c.LastHeartbeatTime.Time.Format(time.RFC1123Z),
+					c.LastTransitionTime.Time.Format(time.RFC1123Z),
+					c.Reason,
+					c.Message)
+			}
+		}
+
+		w.Write(LEVEL_0, "Addresses:\n")
+		for _, address := range node.Status.Addresses {
+			w.Write(LEVEL_1, "%s:\t%s\n", address.Type, address.Address)
+		}
+
+		printResourceList := func(resourceList api.ResourceList) {
+			resources := make([]api.ResourceName, 0, len(resourceList))
+			for resource := range resourceList {
+				resources = append(resources, resource)
+			}
+			sort.Sort(SortableResourceNames(resources))
+			for _, resource := range resources {
+				value := resourceList[resource]
+				w.Write(LEVEL_0, " %s:\t%s\n", resource, value.String())
+			}
+		}
+
+		if len(node.Status.Capacity) > 0 {
+			w.Write(LEVEL_0, "Capacity:\n")
+			printResourceList(node.Status.Capacity)
+		}
+		if len(node.Status.Allocatable) > 0 {
+			w.Write(LEVEL_0, "Allocatable:\n")
+			printResourceList(node.Status.Allocatable)
+		}
+
+		w.Write(LEVEL_0, "System Info:\n")
+		w.Write(LEVEL_0, " Machine ID:\t%s\n", node.Status.NodeInfo.MachineID)
+		w.Write(LEVEL_0, " System UUID:\t%s\n", node.Status.NodeInfo.SystemUUID)
+		w.Write(LEVEL_0, " Boot ID:\t%s\n", node.Status.NodeInfo.BootID)
+		w.Write(LEVEL_0, " Kernel Version:\t%s\n", node.Status.NodeInfo.KernelVersion)
+		w.Write(LEVEL_0, " OS Image:\t%s\n", node.Status.NodeInfo.OSImage)
+		w.Write(LEVEL_0, " Operating System:\t%s\n", node.Status.NodeInfo.OperatingSystem)
+		w.Write(LEVEL_0, " Architecture:\t%s\n", node.Status.NodeInfo.Architecture)
+		w.Write(LEVEL_0, " Container Runtime Version:\t%s\n", node.Status.NodeInfo.ContainerRuntimeVersion)
+		w.Write(LEVEL_0, " Kubelet Version:\t%s\n", node.Status.NodeInfo.KubeletVersion)
+		w.Write(LEVEL_0, " Kube-Proxy Version:\t%s\n", node.Status.NodeInfo.KubeProxyVersion)
+
+		if len(node.Spec.PodCIDR) > 0 {
+			w.Write(LEVEL_0, "PodCIDR:\t%s\n", node.Spec.PodCIDR)
+		}
+		if len(node.Spec.ProviderID) > 0 {
+			w.Write(LEVEL_0, "ProviderID:\t%s\n", node.Spec.ProviderID)
+		}
+		if canViewPods && nodeNonTerminatedPodsList != nil {
+			describeNodeResource(nodeNonTerminatedPodsList, node, w)
+		} else {
+			w.Write(LEVEL_0, "Pods:\tnot authorized\n")
+		}
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+		return nil
+	})
+}
+
+type StatefulSetDescriber struct {
+	client clientset.Interface
+}
+
+func (p *StatefulSetDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	ps, err := p.client.Apps().StatefulSets(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+	pc := p.client.Core().Pods(namespace)
+
+	selector, err := metav1.LabelSelectorAsSelector(ps.Spec.Selector)
+	if err != nil {
+		return "", err
+	}
+
+	running, waiting, succeeded, failed, err := getPodStatusForController(pc, selector, ps.UID)
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = p.client.Core().Events(namespace).Search(legacyscheme.Scheme, ps)
+	}
+
+	return describeStatefulSet(ps, selector, events, running, waiting, succeeded, failed)
+}
+
+func describeStatefulSet(ps *apps.StatefulSet, selector labels.Selector, events *api.EventList, running, waiting, succeeded, failed int) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", ps.ObjectMeta.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", ps.ObjectMeta.Namespace)
+		w.Write(LEVEL_0, "CreationTimestamp:\t%s\n", ps.CreationTimestamp.Time.Format(time.RFC1123Z))
+		w.Write(LEVEL_0, "Selector:\t%s\n", selector)
+		printLabelsMultiline(w, "Labels", ps.Labels)
+		printAnnotationsMultiline(w, "Annotations", ps.Annotations)
+		w.Write(LEVEL_0, "Replicas:\t%d desired | %d total\n", ps.Spec.Replicas, ps.Status.Replicas)
+		w.Write(LEVEL_0, "Update Strategy:\t%s\n", ps.Spec.UpdateStrategy.Type)
+		if ps.Spec.UpdateStrategy.RollingUpdate != nil {
+			ru := ps.Spec.UpdateStrategy.RollingUpdate
+			if ru.Partition != 0 {
+				w.Write(LEVEL_1, "Partition:\t%d\n", ru.Partition)
+			}
+		}
+
+		w.Write(LEVEL_0, "Pods Status:\t%d Running / %d Waiting / %d Succeeded / %d Failed\n", running, waiting, succeeded, failed)
+		DescribePodTemplate(&ps.Spec.Template, w)
+		describeVolumeClaimTemplates(ps.Spec.VolumeClaimTemplates, w)
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+type CertificateSigningRequestDescriber struct {
+	client clientset.Interface
+}
+
+func (p *CertificateSigningRequestDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	csr, err := p.client.Certificates().CertificateSigningRequests().Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	cr, err := certificates.ParseCSR(csr)
+	if err != nil {
+		return "", fmt.Errorf("Error parsing CSR: %v", err)
+	}
+	status, err := extractCSRStatus(csr)
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = p.client.Core().Events(namespace).Search(legacyscheme.Scheme, csr)
+	}
+
+	return describeCertificateSigningRequest(csr, cr, status, events)
+}
+
+func describeCertificateSigningRequest(csr *certificates.CertificateSigningRequest, cr *x509.CertificateRequest, status string, events *api.EventList) (string, error) {
+	printListHelper := func(w PrefixWriter, prefix, name string, values []string) {
+		if len(values) == 0 {
+			return
+		}
+		w.Write(LEVEL_0, prefix+name+":\t")
+		w.Write(LEVEL_0, strings.Join(values, "\n"+prefix+"\t"))
+		w.Write(LEVEL_0, "\n")
+	}
+
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", csr.Name)
+		w.Write(LEVEL_0, "Labels:\t%s\n", labels.FormatLabels(csr.Labels))
+		w.Write(LEVEL_0, "Annotations:\t%s\n", labels.FormatLabels(csr.Annotations))
+		w.Write(LEVEL_0, "CreationTimestamp:\t%s\n", csr.CreationTimestamp.Time.Format(time.RFC1123Z))
+		w.Write(LEVEL_0, "Requesting User:\t%s\n", csr.Spec.Username)
+		w.Write(LEVEL_0, "Status:\t%s\n", status)
+
+		w.Write(LEVEL_0, "Subject:\n")
+		w.Write(LEVEL_0, "\tCommon Name:\t%s\n", cr.Subject.CommonName)
+		w.Write(LEVEL_0, "\tSerial Number:\t%s\n", cr.Subject.SerialNumber)
+		printListHelper(w, "\t", "Organization", cr.Subject.Organization)
+		printListHelper(w, "\t", "Organizational Unit", cr.Subject.OrganizationalUnit)
+		printListHelper(w, "\t", "Country", cr.Subject.Country)
+		printListHelper(w, "\t", "Locality", cr.Subject.Locality)
+		printListHelper(w, "\t", "Province", cr.Subject.Province)
+		printListHelper(w, "\t", "StreetAddress", cr.Subject.StreetAddress)
+		printListHelper(w, "\t", "PostalCode", cr.Subject.PostalCode)
+
+		if len(cr.DNSNames)+len(cr.EmailAddresses)+len(cr.IPAddresses) > 0 {
+			w.Write(LEVEL_0, "Subject Alternative Names:\n")
+			printListHelper(w, "\t", "DNS Names", cr.DNSNames)
+			printListHelper(w, "\t", "Email Addresses", cr.EmailAddresses)
+			var ipaddrs []string
+			for _, ipaddr := range cr.IPAddresses {
+				ipaddrs = append(ipaddrs, ipaddr.String())
+			}
+			printListHelper(w, "\t", "IP Addresses", ipaddrs)
+		}
+
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+// HorizontalPodAutoscalerDescriber generates information about a horizontal pod autoscaler.
+type HorizontalPodAutoscalerDescriber struct {
+	client clientset.Interface
+}
+
+func (d *HorizontalPodAutoscalerDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	hpa, err := d.client.Autoscaling().HorizontalPodAutoscalers(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = d.client.Core().Events(namespace).Search(legacyscheme.Scheme, hpa)
+	}
+
+	return describeHorizontalPodAutoscaler(hpa, events, d)
+}
+
+func describeHorizontalPodAutoscaler(hpa *autoscaling.HorizontalPodAutoscaler, events *api.EventList, d *HorizontalPodAutoscalerDescriber) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", hpa.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", hpa.Namespace)
+		printLabelsMultiline(w, "Labels", hpa.Labels)
+		printAnnotationsMultiline(w, "Annotations", hpa.Annotations)
+		w.Write(LEVEL_0, "CreationTimestamp:\t%s\n", hpa.CreationTimestamp.Time.Format(time.RFC1123Z))
+		w.Write(LEVEL_0, "Reference:\t%s/%s\n",
+			hpa.Spec.ScaleTargetRef.Kind,
+			hpa.Spec.ScaleTargetRef.Name)
+		w.Write(LEVEL_0, "Metrics:\t( current / target )\n")
+		for i, metric := range hpa.Spec.Metrics {
+			switch metric.Type {
+			case autoscaling.ExternalMetricSourceType:
+				if metric.External.TargetAverageValue != nil {
+					current := "<unknown>"
+					if len(hpa.Status.CurrentMetrics) > i && hpa.Status.CurrentMetrics[i].External != nil &&
+						hpa.Status.CurrentMetrics[i].External.CurrentAverageValue != nil {
+						current = hpa.Status.CurrentMetrics[i].External.CurrentAverageValue.String()
+					}
+					w.Write(LEVEL_1, "%q (target average value):\t%s / %s\n", metric.External.MetricName, current, metric.External.TargetAverageValue.String())
+				} else {
+					current := "<unknown>"
+					if len(hpa.Status.CurrentMetrics) > i && hpa.Status.CurrentMetrics[i].External != nil {
+						current = hpa.Status.CurrentMetrics[i].External.CurrentValue.String()
+					}
+					w.Write(LEVEL_1, "%q (target value):\t%s / %s\n", metric.External.MetricName, current, metric.External.TargetValue.String())
+
+				}
+			case autoscaling.PodsMetricSourceType:
+				current := "<unknown>"
+				if len(hpa.Status.CurrentMetrics) > i && hpa.Status.CurrentMetrics[i].Pods != nil {
+					current = hpa.Status.CurrentMetrics[i].Pods.CurrentAverageValue.String()
+				}
+				w.Write(LEVEL_1, "%q on pods:\t%s / %s\n", metric.Pods.MetricName, current, metric.Pods.TargetAverageValue.String())
+			case autoscaling.ObjectMetricSourceType:
+				current := "<unknown>"
+				if len(hpa.Status.CurrentMetrics) > i && hpa.Status.CurrentMetrics[i].Object != nil {
+					current = hpa.Status.CurrentMetrics[i].Object.CurrentValue.String()
+				}
+				w.Write(LEVEL_1, "%q on %s/%s:\t%s / %s\n", metric.Object.MetricName, metric.Object.Target.Kind, metric.Object.Target.Name, current, metric.Object.TargetValue.String())
+			case autoscaling.ResourceMetricSourceType:
+				w.Write(LEVEL_1, "resource %s on pods", string(metric.Resource.Name))
+				if metric.Resource.TargetAverageValue != nil {
+					current := "<unknown>"
+					if len(hpa.Status.CurrentMetrics) > i && hpa.Status.CurrentMetrics[i].Resource != nil {
+						current = hpa.Status.CurrentMetrics[i].Resource.CurrentAverageValue.String()
+					}
+					w.Write(LEVEL_0, ":\t%s / %s\n", current, metric.Resource.TargetAverageValue.String())
+				} else {
+					current := "<unknown>"
+					if len(hpa.Status.CurrentMetrics) > i && hpa.Status.CurrentMetrics[i].Resource != nil && hpa.Status.CurrentMetrics[i].Resource.CurrentAverageUtilization != nil {
+						current = fmt.Sprintf("%d%% (%s)", *hpa.Status.CurrentMetrics[i].Resource.CurrentAverageUtilization, hpa.Status.CurrentMetrics[i].Resource.CurrentAverageValue.String())
+					}
+
+					target := "<auto>"
+					if metric.Resource.TargetAverageUtilization != nil {
+						target = fmt.Sprintf("%d%%", *metric.Resource.TargetAverageUtilization)
+					}
+					w.Write(LEVEL_1, "(as a percentage of request):\t%s / %s\n", current, target)
+				}
+			default:
+				w.Write(LEVEL_1, "<unknown metric type %q>", string(metric.Type))
+			}
+		}
+		minReplicas := "<unset>"
+		if hpa.Spec.MinReplicas != nil {
+			minReplicas = fmt.Sprintf("%d", *hpa.Spec.MinReplicas)
+		}
+		w.Write(LEVEL_0, "Min replicas:\t%s\n", minReplicas)
+		w.Write(LEVEL_0, "Max replicas:\t%d\n", hpa.Spec.MaxReplicas)
+		w.Write(LEVEL_0, "%s pods:\t", hpa.Spec.ScaleTargetRef.Kind)
+		w.Write(LEVEL_0, "%d current / %d desired\n", hpa.Status.CurrentReplicas, hpa.Status.DesiredReplicas)
+
+		if len(hpa.Status.Conditions) > 0 {
+			w.Write(LEVEL_0, "Conditions:\n")
+			w.Write(LEVEL_1, "Type\tStatus\tReason\tMessage\n")
+			w.Write(LEVEL_1, "----\t------\t------\t-------\n")
+			for _, c := range hpa.Status.Conditions {
+				w.Write(LEVEL_1, "%v\t%v\t%v\t%v\n", c.Type, c.Status, c.Reason, c.Message)
+			}
+		}
+
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+func describeNodeResource(nodeNonTerminatedPodsList *api.PodList, node *api.Node, w PrefixWriter) {
+	w.Write(LEVEL_0, "Non-terminated Pods:\t(%d in total)\n", len(nodeNonTerminatedPodsList.Items))
+	w.Write(LEVEL_1, "Namespace\tName\t\tCPU Requests\tCPU Limits\tMemory Requests\tMemory Limits\n")
+	w.Write(LEVEL_1, "---------\t----\t\t------------\t----------\t---------------\t-------------\n")
+	allocatable := node.Status.Capacity
+	if len(node.Status.Allocatable) > 0 {
+		allocatable = node.Status.Allocatable
+	}
+
+	for _, pod := range nodeNonTerminatedPodsList.Items {
+		req, limit := resourcehelper.PodRequestsAndLimits(&pod)
+		cpuReq, cpuLimit, memoryReq, memoryLimit := req[api.ResourceCPU], limit[api.ResourceCPU], req[api.ResourceMemory], limit[api.ResourceMemory]
+		fractionCpuReq := float64(cpuReq.MilliValue()) / float64(allocatable.Cpu().MilliValue()) * 100
+		fractionCpuLimit := float64(cpuLimit.MilliValue()) / float64(allocatable.Cpu().MilliValue()) * 100
+		fractionMemoryReq := float64(memoryReq.Value()) / float64(allocatable.Memory().Value()) * 100
+		fractionMemoryLimit := float64(memoryLimit.Value()) / float64(allocatable.Memory().Value()) * 100
+		w.Write(LEVEL_1, "%s\t%s\t\t%s (%d%%)\t%s (%d%%)\t%s (%d%%)\t%s (%d%%)\n", pod.Namespace, pod.Name,
+			cpuReq.String(), int64(fractionCpuReq), cpuLimit.String(), int64(fractionCpuLimit),
+			memoryReq.String(), int64(fractionMemoryReq), memoryLimit.String(), int64(fractionMemoryLimit))
+	}
+
+	w.Write(LEVEL_0, "Allocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n")
+	w.Write(LEVEL_1, "Resource\tRequests\tLimits\n")
+	w.Write(LEVEL_1, "--------\t--------\t------\n")
+	reqs, limits := getPodsTotalRequestsAndLimits(nodeNonTerminatedPodsList)
+	cpuReqs, cpuLimits, memoryReqs, memoryLimits := reqs[api.ResourceCPU], limits[api.ResourceCPU], reqs[api.ResourceMemory], limits[api.ResourceMemory]
+	fractionCpuReqs := float64(0)
+	fractionCpuLimits := float64(0)
+	if allocatable.Cpu().MilliValue() != 0 {
+		fractionCpuReqs = float64(cpuReqs.MilliValue()) / float64(allocatable.Cpu().MilliValue()) * 100
+		fractionCpuLimits = float64(cpuLimits.MilliValue()) / float64(allocatable.Cpu().MilliValue()) * 100
+	}
+	fractionMemoryReqs := float64(0)
+	fractionMemoryLimits := float64(0)
+	if allocatable.Memory().Value() != 0 {
+		fractionMemoryReqs = float64(memoryReqs.Value()) / float64(allocatable.Memory().Value()) * 100
+		fractionMemoryLimits = float64(memoryLimits.Value()) / float64(allocatable.Memory().Value()) * 100
+	}
+	w.Write(LEVEL_1, "%s\t%s (%d%%)\t%s (%d%%)\n",
+		api.ResourceCPU, cpuReqs.String(), int64(fractionCpuReqs), cpuLimits.String(), int64(fractionCpuLimits))
+	w.Write(LEVEL_1, "%s\t%s (%d%%)\t%s (%d%%)\n",
+		api.ResourceMemory, memoryReqs.String(), int64(fractionMemoryReqs), memoryLimits.String(), int64(fractionMemoryLimits))
+	extResources := make([]string, 0, len(allocatable))
+	for resource := range allocatable {
+		if !helper.IsStandardContainerResourceName(string(resource)) && resource != api.ResourcePods {
+			extResources = append(extResources, string(resource))
+		}
+	}
+	sort.Strings(extResources)
+	for _, ext := range extResources {
+		extRequests, extLimits := reqs[api.ResourceName(ext)], limits[api.ResourceName(ext)]
+		w.Write(LEVEL_1, "%s\t%s\t%s\n", ext, extRequests.String(), extLimits.String())
+	}
+}
+
+func getPodsTotalRequestsAndLimits(podList *api.PodList) (reqs map[api.ResourceName]resource.Quantity, limits map[api.ResourceName]resource.Quantity) {
+	reqs, limits = map[api.ResourceName]resource.Quantity{}, map[api.ResourceName]resource.Quantity{}
+	for _, pod := range podList.Items {
+		podReqs, podLimits := resourcehelper.PodRequestsAndLimits(&pod)
+		for podReqName, podReqValue := range podReqs {
+			if value, ok := reqs[podReqName]; !ok {
+				reqs[podReqName] = *podReqValue.Copy()
+			} else {
+				value.Add(podReqValue)
+				reqs[podReqName] = value
+			}
+		}
+		for podLimitName, podLimitValue := range podLimits {
+			if value, ok := limits[podLimitName]; !ok {
+				limits[podLimitName] = *podLimitValue.Copy()
+			} else {
+				value.Add(podLimitValue)
+				limits[podLimitName] = value
+			}
+		}
+	}
+	return
+}
+
+func DescribeEvents(el *api.EventList, w PrefixWriter) {
+	if len(el.Items) == 0 {
+		w.Write(LEVEL_0, "Events:\t<none>\n")
+		return
+	}
+	w.Flush()
+	sort.Sort(events.SortableEvents(el.Items))
+	w.Write(LEVEL_0, "Events:\n  Type\tReason\tAge\tFrom\tMessage\n")
+	w.Write(LEVEL_1, "----\t------\t----\t----\t-------\n")
+	for _, e := range el.Items {
+		var interval string
+		if e.Count > 1 {
+			interval = fmt.Sprintf("%s (x%d over %s)", translateTimestamp(e.LastTimestamp), e.Count, translateTimestamp(e.FirstTimestamp))
+		} else {
+			interval = translateTimestamp(e.FirstTimestamp)
+		}
+		w.Write(LEVEL_1, "%v\t%v\t%s\t%v\t%v\n",
+			e.Type,
+			e.Reason,
+			interval,
+			formatEventSource(e.Source),
+			strings.TrimSpace(e.Message),
+		)
+	}
+}
+
+// DeploymentDescriber generates information about a deployment.
+type DeploymentDescriber struct {
+	clientset.Interface
+	external externalclient.Interface
+}
+
+func (dd *DeploymentDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	d, err := dd.external.AppsV1().Deployments(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+	selector, err := metav1.LabelSelectorAsSelector(d.Spec.Selector)
+	if err != nil {
+		return "", err
+	}
+	internalDeployment := &extensions.Deployment{}
+	if err := legacyscheme.Scheme.Convert(d, internalDeployment, extensions.SchemeGroupVersion); err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = dd.Core().Events(namespace).Search(legacyscheme.Scheme, d)
+	}
+
+	return describeDeployment(d, selector, internalDeployment, events, dd)
+}
+
+func describeDeployment(d *appsv1.Deployment, selector labels.Selector, internalDeployment *extensions.Deployment, events *api.EventList, dd *DeploymentDescriber) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", d.ObjectMeta.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", d.ObjectMeta.Namespace)
+		w.Write(LEVEL_0, "CreationTimestamp:\t%s\n", d.CreationTimestamp.Time.Format(time.RFC1123Z))
+		printLabelsMultiline(w, "Labels", d.Labels)
+		printAnnotationsMultiline(w, "Annotations", d.Annotations)
+		w.Write(LEVEL_0, "Selector:\t%s\n", selector)
+		w.Write(LEVEL_0, "Replicas:\t%d desired | %d updated | %d total | %d available | %d unavailable\n", *(d.Spec.Replicas), d.Status.UpdatedReplicas, d.Status.Replicas, d.Status.AvailableReplicas, d.Status.UnavailableReplicas)
+		w.Write(LEVEL_0, "StrategyType:\t%s\n", d.Spec.Strategy.Type)
+		w.Write(LEVEL_0, "MinReadySeconds:\t%d\n", d.Spec.MinReadySeconds)
+		if d.Spec.Strategy.RollingUpdate != nil {
+			ru := d.Spec.Strategy.RollingUpdate
+			w.Write(LEVEL_0, "RollingUpdateStrategy:\t%s max unavailable, %s max surge\n", ru.MaxUnavailable.String(), ru.MaxSurge.String())
+		}
+		DescribePodTemplate(&internalDeployment.Spec.Template, w)
+		if len(d.Status.Conditions) > 0 {
+			w.Write(LEVEL_0, "Conditions:\n  Type\tStatus\tReason\n")
+			w.Write(LEVEL_1, "----\t------\t------\n")
+			for _, c := range d.Status.Conditions {
+				w.Write(LEVEL_1, "%v \t%v\t%v\n", c.Type, c.Status, c.Reason)
+			}
+		}
+		oldRSs, _, newRS, err := deploymentutil.GetAllReplicaSets(d, dd.external.AppsV1())
+		if err == nil {
+			w.Write(LEVEL_0, "OldReplicaSets:\t%s\n", printReplicaSetsByLabels(oldRSs))
+			var newRSs []*appsv1.ReplicaSet
+			if newRS != nil {
+				newRSs = append(newRSs, newRS)
+			}
+			w.Write(LEVEL_0, "NewReplicaSet:\t%s\n", printReplicaSetsByLabels(newRSs))
+		}
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+func printReplicaSetsByLabels(matchingRSs []*appsv1.ReplicaSet) string {
+	// Format the matching ReplicaSets into strings.
+	rsStrings := make([]string, 0, len(matchingRSs))
+	for _, rs := range matchingRSs {
+		rsStrings = append(rsStrings, fmt.Sprintf("%s (%d/%d replicas created)", rs.Name, rs.Status.Replicas, *rs.Spec.Replicas))
+	}
+
+	list := strings.Join(rsStrings, ", ")
+	if list == "" {
+		return "<none>"
+	}
+	return list
+}
+
+func getPodStatusForController(c coreclient.PodInterface, selector labels.Selector, uid types.UID) (running, waiting, succeeded, failed int, err error) {
+	options := metav1.ListOptions{LabelSelector: selector.String()}
+	rcPods, err := c.List(options)
+	if err != nil {
+		return
+	}
+	for _, pod := range rcPods.Items {
+		controllerRef := metav1.GetControllerOf(&pod)
+		// Skip pods that are orphans or owned by other controllers.
+		if controllerRef == nil || controllerRef.UID != uid {
+			continue
+		}
+		switch pod.Status.Phase {
+		case api.PodRunning:
+			running++
+		case api.PodPending:
+			waiting++
+		case api.PodSucceeded:
+			succeeded++
+		case api.PodFailed:
+			failed++
+		}
+	}
+	return
+}
+
+// ConfigMapDescriber generates information about a ConfigMap
+type ConfigMapDescriber struct {
+	clientset.Interface
+}
+
+func (d *ConfigMapDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	c := d.Core().ConfigMaps(namespace)
+
+	configMap, err := c.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", configMap.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", configMap.Namespace)
+		printLabelsMultiline(w, "Labels", configMap.Labels)
+		printAnnotationsMultiline(w, "Annotations", configMap.Annotations)
+
+		w.Write(LEVEL_0, "\nData\n====\n")
+		for k, v := range configMap.Data {
+			w.Write(LEVEL_0, "%s:\n----\n", k)
+			w.Write(LEVEL_0, "%s\n", string(v))
+		}
+		if describerSettings.ShowEvents {
+			events, err := d.Core().Events(namespace).Search(legacyscheme.Scheme, configMap)
+			if err != nil {
+				return err
+			}
+			if events != nil {
+				DescribeEvents(events, w)
+			}
+		}
+		return nil
+	})
+}
+
+// NetworkPolicyDescriber generates information about a networking.NetworkPolicy
+type NetworkPolicyDescriber struct {
+	clientset.Interface
+}
+
+func (d *NetworkPolicyDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	c := d.Networking().NetworkPolicies(namespace)
+
+	networkPolicy, err := c.Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	return describeNetworkPolicy(networkPolicy)
+}
+
+func describeNetworkPolicy(networkPolicy *networking.NetworkPolicy) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", networkPolicy.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", networkPolicy.Namespace)
+		w.Write(LEVEL_0, "Created on:\t%s\n", networkPolicy.CreationTimestamp)
+		printLabelsMultiline(w, "Labels", networkPolicy.Labels)
+		printAnnotationsMultiline(w, "Annotations", networkPolicy.Annotations)
+		describeNetworkPolicySpec(networkPolicy.Spec, w)
+		return nil
+	})
+}
+
+func describeNetworkPolicySpec(nps networking.NetworkPolicySpec, w PrefixWriter) {
+	w.Write(LEVEL_0, "Spec:\n")
+	w.Write(LEVEL_1, "PodSelector: ")
+	if len(nps.PodSelector.MatchLabels) == 0 && len(nps.PodSelector.MatchExpressions) == 0 {
+		w.Write(LEVEL_2, "<none> (Allowing the specific traffic to all pods in this namespace)\n")
+	} else {
+		w.Write(LEVEL_2, "%s\n", metav1.FormatLabelSelector(&nps.PodSelector))
+	}
+	w.Write(LEVEL_1, "Allowing ingress traffic:\n")
+	printNetworkPolicySpecIngressFrom(nps.Ingress, "    ", w)
+	w.Write(LEVEL_1, "Allowing egress traffic:\n")
+	printNetworkPolicySpecEgressTo(nps.Egress, "    ", w)
+	w.Write(LEVEL_1, "Policy Types: %v\n", policyTypesToString(nps.PolicyTypes))
+}
+
+func printNetworkPolicySpecIngressFrom(npirs []networking.NetworkPolicyIngressRule, initialIndent string, w PrefixWriter) {
+	if len(npirs) == 0 {
+		w.Write(LEVEL_0, "%s%s\n", initialIndent, "<none> (Selected pods are isolated for ingress connectivity)")
+		return
+	}
+	for i, npir := range npirs {
+		if len(npir.Ports) == 0 {
+			w.Write(LEVEL_0, "%s%s\n", initialIndent, "To Port: <any> (traffic allowed to all ports)")
+		} else {
+			for _, port := range npir.Ports {
+				var proto api.Protocol
+				if port.Protocol != nil {
+					proto = *port.Protocol
+				} else {
+					proto = api.ProtocolTCP
+				}
+				w.Write(LEVEL_0, "%s%s: %s/%s\n", initialIndent, "To Port", port.Port, proto)
+			}
+		}
+		if len(npir.From) == 0 {
+			w.Write(LEVEL_0, "%s%s\n", initialIndent, "From: <any> (traffic not restricted by source)")
+		} else {
+			for _, from := range npir.From {
+				w.Write(LEVEL_0, "%s%s\n", initialIndent, "From:")
+				if from.PodSelector != nil && from.NamespaceSelector != nil {
+					w.Write(LEVEL_1, "%s%s: %s\n", initialIndent, "NamespaceSelector", metav1.FormatLabelSelector(from.NamespaceSelector))
+					w.Write(LEVEL_1, "%s%s: %s\n", initialIndent, "PodSelector", metav1.FormatLabelSelector(from.PodSelector))
+				} else if from.PodSelector != nil {
+					w.Write(LEVEL_1, "%s%s: %s\n", initialIndent, "PodSelector", metav1.FormatLabelSelector(from.PodSelector))
+				} else if from.NamespaceSelector != nil {
+					w.Write(LEVEL_1, "%s%s: %s\n", initialIndent, "NamespaceSelector", metav1.FormatLabelSelector(from.NamespaceSelector))
+				} else if from.IPBlock != nil {
+					w.Write(LEVEL_1, "%sIPBlock:\n", initialIndent)
+					w.Write(LEVEL_2, "%sCIDR: %s\n", initialIndent, from.IPBlock.CIDR)
+					w.Write(LEVEL_2, "%sExcept: %v\n", initialIndent, strings.Join(from.IPBlock.Except, ", "))
+				}
+			}
+		}
+		if i != len(npirs)-1 {
+			w.Write(LEVEL_0, "%s%s\n", initialIndent, "----------")
+		}
+	}
+}
+
+func printNetworkPolicySpecEgressTo(npers []networking.NetworkPolicyEgressRule, initialIndent string, w PrefixWriter) {
+	if len(npers) == 0 {
+		w.Write(LEVEL_0, "%s%s\n", initialIndent, "<none> (Selected pods are isolated for egress connectivity)")
+		return
+	}
+	for i, nper := range npers {
+		if len(nper.Ports) == 0 {
+			w.Write(LEVEL_0, "%s%s\n", initialIndent, "To Port: <any> (traffic allowed to all ports)")
+		} else {
+			for _, port := range nper.Ports {
+				var proto api.Protocol
+				if port.Protocol != nil {
+					proto = *port.Protocol
+				} else {
+					proto = api.ProtocolTCP
+				}
+				w.Write(LEVEL_0, "%s%s: %s/%s\n", initialIndent, "To Port", port.Port, proto)
+			}
+		}
+		if len(nper.To) == 0 {
+			w.Write(LEVEL_0, "%s%s\n", initialIndent, "To: <any> (traffic not restricted by source)")
+		} else {
+			for _, to := range nper.To {
+				w.Write(LEVEL_0, "%s%s\n", initialIndent, "To:")
+				if to.PodSelector != nil && to.NamespaceSelector != nil {
+					w.Write(LEVEL_1, "%s%s: %s\n", initialIndent, "NamespaceSelector", metav1.FormatLabelSelector(to.NamespaceSelector))
+					w.Write(LEVEL_1, "%s%s: %s\n", initialIndent, "PodSelector", metav1.FormatLabelSelector(to.PodSelector))
+				} else if to.PodSelector != nil {
+					w.Write(LEVEL_1, "%s%s: %s\n", initialIndent, "PodSelector", metav1.FormatLabelSelector(to.PodSelector))
+				} else if to.NamespaceSelector != nil {
+					w.Write(LEVEL_1, "%s%s: %s\n", initialIndent, "NamespaceSelector", metav1.FormatLabelSelector(to.NamespaceSelector))
+				} else if to.IPBlock != nil {
+					w.Write(LEVEL_1, "%sIPBlock:\n", initialIndent)
+					w.Write(LEVEL_2, "%sCIDR: %s\n", initialIndent, to.IPBlock.CIDR)
+					w.Write(LEVEL_2, "%sExcept: %v\n", initialIndent, strings.Join(to.IPBlock.Except, ", "))
+				}
+			}
+		}
+		if i != len(npers)-1 {
+			w.Write(LEVEL_0, "%s%s\n", initialIndent, "----------")
+		}
+	}
+}
+
+type StorageClassDescriber struct {
+	clientset.Interface
+}
+
+func (s *StorageClassDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	sc, err := s.Storage().StorageClasses().Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = s.Core().Events(namespace).Search(legacyscheme.Scheme, sc)
+	}
+
+	return describeStorageClass(sc, events)
+}
+
+func describeStorageClass(sc *storage.StorageClass, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", sc.Name)
+		w.Write(LEVEL_0, "IsDefaultClass:\t%s\n", storageutil.IsDefaultAnnotationText(sc.ObjectMeta))
+		w.Write(LEVEL_0, "Annotations:\t%s\n", labels.FormatLabels(sc.Annotations))
+		w.Write(LEVEL_0, "Provisioner:\t%s\n", sc.Provisioner)
+		w.Write(LEVEL_0, "Parameters:\t%s\n", labels.FormatLabels(sc.Parameters))
+		w.Write(LEVEL_0, "AllowVolumeExpansion:\t%s\n", printBoolPtr(sc.AllowVolumeExpansion))
+		if len(sc.MountOptions) == 0 {
+			w.Write(LEVEL_0, "MountOptions:\t<none>\n")
+		} else {
+			w.Write(LEVEL_0, "MountOptions:\n")
+			for _, option := range sc.MountOptions {
+				w.Write(LEVEL_1, "%s\n", option)
+			}
+		}
+		if sc.ReclaimPolicy != nil {
+			w.Write(LEVEL_0, "ReclaimPolicy:\t%s\n", *sc.ReclaimPolicy)
+		}
+		if sc.VolumeBindingMode != nil {
+			w.Write(LEVEL_0, "VolumeBindingMode:\t%s\n", *sc.VolumeBindingMode)
+		}
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+type PodDisruptionBudgetDescriber struct {
+	clientset.Interface
+}
+
+func (p *PodDisruptionBudgetDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	pdb, err := p.Policy().PodDisruptionBudgets(namespace).Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = p.Core().Events(namespace).Search(legacyscheme.Scheme, pdb)
+	}
+
+	return describePodDisruptionBudget(pdb, events)
+}
+
+func describePodDisruptionBudget(pdb *policy.PodDisruptionBudget, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", pdb.Name)
+		w.Write(LEVEL_0, "Namespace:\t%s\n", pdb.Namespace)
+
+		if pdb.Spec.MinAvailable != nil {
+			w.Write(LEVEL_0, "Min available:\t%s\n", pdb.Spec.MinAvailable.String())
+		} else if pdb.Spec.MaxUnavailable != nil {
+			w.Write(LEVEL_0, "Max unavailable:\t%s\n", pdb.Spec.MaxUnavailable.String())
+		}
+
+		if pdb.Spec.Selector != nil {
+			w.Write(LEVEL_0, "Selector:\t%s\n", metav1.FormatLabelSelector(pdb.Spec.Selector))
+		} else {
+			w.Write(LEVEL_0, "Selector:\t<unset>\n")
+		}
+		w.Write(LEVEL_0, "Status:\n")
+		w.Write(LEVEL_2, "Allowed disruptions:\t%d\n", pdb.Status.PodDisruptionsAllowed)
+		w.Write(LEVEL_2, "Current:\t%d\n", pdb.Status.CurrentHealthy)
+		w.Write(LEVEL_2, "Desired:\t%d\n", pdb.Status.DesiredHealthy)
+		w.Write(LEVEL_2, "Total:\t%d\n", pdb.Status.ExpectedPods)
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+// PriorityClassDescriber generates information about a PriorityClass.
+type PriorityClassDescriber struct {
+	clientset.Interface
+}
+
+func (s *PriorityClassDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	pc, err := s.Scheduling().PriorityClasses().Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	var events *api.EventList
+	if describerSettings.ShowEvents {
+		events, _ = s.Core().Events(namespace).Search(legacyscheme.Scheme, pc)
+	}
+
+	return describePriorityClass(pc, events)
+}
+
+func describePriorityClass(pc *scheduling.PriorityClass, events *api.EventList) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", pc.Name)
+		w.Write(LEVEL_0, "Value:\t%v\n", pc.Value)
+		w.Write(LEVEL_0, "GlobalDefault:\t%v\n", pc.GlobalDefault)
+		w.Write(LEVEL_0, "Description:\t%s\n", pc.Description)
+
+		w.Write(LEVEL_0, "Annotations:\t%s\n", labels.FormatLabels(pc.Annotations))
+		if events != nil {
+			DescribeEvents(events, w)
+		}
+
+		return nil
+	})
+}
+
+// PodSecurityPolicyDescriber generates information about a PodSecurityPolicy.
+type PodSecurityPolicyDescriber struct {
+	clientset.Interface
+}
+
+func (d *PodSecurityPolicyDescriber) Describe(namespace, name string, describerSettings printers.DescriberSettings) (string, error) {
+	psp, err := d.Policy().PodSecurityPolicies().Get(name, metav1.GetOptions{})
+	if err != nil {
+		return "", err
+	}
+
+	return describePodSecurityPolicy(psp)
+}
+
+func describePodSecurityPolicy(psp *policy.PodSecurityPolicy) (string, error) {
+	return tabbedString(func(out io.Writer) error {
+		w := NewPrefixWriter(out)
+		w.Write(LEVEL_0, "Name:\t%s\n", psp.Name)
+
+		w.Write(LEVEL_0, "\nSettings:\n")
+
+		w.Write(LEVEL_1, "Allow Privileged:\t%t\n", psp.Spec.Privileged)
+		w.Write(LEVEL_1, "Allow Privilege Escalation:\t%v\n", psp.Spec.AllowPrivilegeEscalation)
+		w.Write(LEVEL_1, "Default Add Capabilities:\t%v\n", capsToString(psp.Spec.DefaultAddCapabilities))
+		w.Write(LEVEL_1, "Required Drop Capabilities:\t%s\n", capsToString(psp.Spec.RequiredDropCapabilities))
+		w.Write(LEVEL_1, "Allowed Capabilities:\t%s\n", capsToString(psp.Spec.AllowedCapabilities))
+		w.Write(LEVEL_1, "Allowed Volume Types:\t%s\n", fsTypeToString(psp.Spec.Volumes))
+
+		if len(psp.Spec.AllowedFlexVolumes) > 0 {
+			w.Write(LEVEL_1, "Allowed FlexVolume Types:\t%s\n", flexVolumesToString(psp.Spec.AllowedFlexVolumes))
+		}
+		w.Write(LEVEL_1, "Allow Host Network:\t%t\n", psp.Spec.HostNetwork)
+		w.Write(LEVEL_1, "Allow Host Ports:\t%s\n", hostPortRangeToString(psp.Spec.HostPorts))
+		w.Write(LEVEL_1, "Allow Host PID:\t%t\n", psp.Spec.HostPID)
+		w.Write(LEVEL_1, "Allow Host IPC:\t%t\n", psp.Spec.HostIPC)
+		w.Write(LEVEL_1, "Read Only Root Filesystem:\t%v\n", psp.Spec.ReadOnlyRootFilesystem)
+
+		w.Write(LEVEL_1, "SELinux Context Strategy: %s\t\n", string(psp.Spec.SELinux.Rule))
+		var user, role, seLinuxType, level string
+		if psp.Spec.SELinux.SELinuxOptions != nil {
+			user = psp.Spec.SELinux.SELinuxOptions.User
+			role = psp.Spec.SELinux.SELinuxOptions.Role
+			seLinuxType = psp.Spec.SELinux.SELinuxOptions.Type
+			level = psp.Spec.SELinux.SELinuxOptions.Level
+		}
+		w.Write(LEVEL_2, "User:\t%s\n", stringOrNone(user))
+		w.Write(LEVEL_2, "Role:\t%s\n", stringOrNone(role))
+		w.Write(LEVEL_2, "Type:\t%s\n", stringOrNone(seLinuxType))
+		w.Write(LEVEL_2, "Level:\t%s\n", stringOrNone(level))
+
+		w.Write(LEVEL_1, "Run As User Strategy: %s\t\n", string(psp.Spec.RunAsUser.Rule))
+		w.Write(LEVEL_2, "Ranges:\t%s\n", idRangeToString(psp.Spec.RunAsUser.Ranges))
+
+		w.Write(LEVEL_1, "FSGroup Strategy: %s\t\n", string(psp.Spec.FSGroup.Rule))
+		w.Write(LEVEL_2, "Ranges:\t%s\n", idRangeToString(psp.Spec.FSGroup.Ranges))
+
+		w.Write(LEVEL_1, "Supplemental Groups Strategy: %s\t\n", string(psp.Spec.SupplementalGroups.Rule))
+		w.Write(LEVEL_2, "Ranges:\t%s\n", idRangeToString(psp.Spec.SupplementalGroups.Ranges))
+
+		return nil
+	})
+}
+
+func stringOrNone(s string) string {
+	return stringOrDefaultValue(s, "<none>")
+}
+
+func stringOrDefaultValue(s, defaultValue string) string {
+	if len(s) > 0 {
+		return s
+	}
+	return defaultValue
+}
+
+func fsTypeToString(volumes []policy.FSType) string {
+	strVolumes := []string{}
+	for _, v := range volumes {
+		strVolumes = append(strVolumes, string(v))
+	}
+	return stringOrNone(strings.Join(strVolumes, ","))
+}
+
+func flexVolumesToString(flexVolumes []policy.AllowedFlexVolume) string {
+	volumes := []string{}
+	for _, flexVolume := range flexVolumes {
+		volumes = append(volumes, "driver="+flexVolume.Driver)
+	}
+	return stringOrDefaultValue(strings.Join(volumes, ","), "<all>")
+}
+
+func hostPortRangeToString(ranges []policy.HostPortRange) string {
+	formattedString := ""
+	if ranges != nil {
+		strRanges := []string{}
+		for _, r := range ranges {
+			strRanges = append(strRanges, fmt.Sprintf("%d-%d", r.Min, r.Max))
+		}
+		formattedString = strings.Join(strRanges, ",")
+	}
+	return stringOrNone(formattedString)
+}
+
+func idRangeToString(ranges []policy.IDRange) string {
+	formattedString := ""
+	if ranges != nil {
+		strRanges := []string{}
+		for _, r := range ranges {
+			strRanges = append(strRanges, fmt.Sprintf("%d-%d", r.Min, r.Max))
+		}
+		formattedString = strings.Join(strRanges, ",")
+	}
+	return stringOrNone(formattedString)
+}
+
+func capsToString(caps []api.Capability) string {
+	formattedString := ""
+	if caps != nil {
+		strCaps := []string{}
+		for _, c := range caps {
+			strCaps = append(strCaps, string(c))
+		}
+		formattedString = strings.Join(strCaps, ",")
+	}
+	return stringOrNone(formattedString)
+}
+
+func policyTypesToString(pts []networking.PolicyType) string {
+	formattedString := ""
+	if pts != nil {
+		strPts := []string{}
+		for _, p := range pts {
+			strPts = append(strPts, string(p))
+		}
+		formattedString = strings.Join(strPts, ", ")
+	}
+	return stringOrNone(formattedString)
+}
+
+// newErrNoDescriber creates a new ErrNoDescriber with the names of the provided types.
+func newErrNoDescriber(types ...reflect.Type) error {
+	names := make([]string, 0, len(types))
+	for _, t := range types {
+		names = append(names, t.String())
+	}
+	return printers.ErrNoDescriber{Types: names}
+}
+
+// Describers implements ObjectDescriber against functions registered via Add. Those functions can
+// be strongly typed. Types are exactly matched (no conversion or assignable checks).
+type Describers struct {
+	searchFns map[reflect.Type][]typeFunc
+}
+
+// DescribeObject implements ObjectDescriber and will attempt to print the provided object to a string,
+// if at least one describer function has been registered with the exact types passed, or if any
+// describer can print the exact object in its first argument (the remainder will be provided empty
+// values). If no function registered with Add can satisfy the passed objects, an ErrNoDescriber will
+// be returned
+// TODO: reorder and partial match extra.
+func (d *Describers) DescribeObject(exact interface{}, extra ...interface{}) (string, error) {
+	exactType := reflect.TypeOf(exact)
+	fns, ok := d.searchFns[exactType]
+	if !ok {
+		return "", newErrNoDescriber(exactType)
+	}
+	if len(extra) == 0 {
+		for _, typeFn := range fns {
+			if len(typeFn.Extra) == 0 {
+				return typeFn.Describe(exact, extra...)
+			}
+		}
+		typeFn := fns[0]
+		for _, t := range typeFn.Extra {
+			v := reflect.New(t).Elem()
+			extra = append(extra, v.Interface())
+		}
+		return fns[0].Describe(exact, extra...)
+	}
+
+	types := make([]reflect.Type, 0, len(extra))
+	for _, obj := range extra {
+		types = append(types, reflect.TypeOf(obj))
+	}
+	for _, typeFn := range fns {
+		if typeFn.Matches(types) {
+			return typeFn.Describe(exact, extra...)
+		}
+	}
+	return "", newErrNoDescriber(append([]reflect.Type{exactType}, types...)...)
+}
+
+// Add adds one or more describer functions to the printers.Describer. The passed function must
+// match the signature:
+//
+//     func(...) (string, error)
+//
+// Any number of arguments may be provided.
+func (d *Describers) Add(fns ...interface{}) error {
+	for _, fn := range fns {
+		fv := reflect.ValueOf(fn)
+		ft := fv.Type()
+		if ft.Kind() != reflect.Func {
+			return fmt.Errorf("expected func, got: %v", ft)
+		}
+		numIn := ft.NumIn()
+		if numIn == 0 {
+			return fmt.Errorf("expected at least one 'in' params, got: %v", ft)
+		}
+		if ft.NumOut() != 2 {
+			return fmt.Errorf("expected two 'out' params - (string, error), got: %v", ft)
+		}
+		types := make([]reflect.Type, 0, numIn)
+		for i := 0; i < numIn; i++ {
+			types = append(types, ft.In(i))
+		}
+		if ft.Out(0) != reflect.TypeOf(string("")) {
+			return fmt.Errorf("expected string return, got: %v", ft)
+		}
+		var forErrorType error
+		// This convolution is necessary, otherwise TypeOf picks up on the fact
+		// that forErrorType is nil.
+		errorType := reflect.TypeOf(&forErrorType).Elem()
+		if ft.Out(1) != errorType {
+			return fmt.Errorf("expected error return, got: %v", ft)
+		}
+
+		exact := types[0]
+		extra := types[1:]
+		if d.searchFns == nil {
+			d.searchFns = make(map[reflect.Type][]typeFunc)
+		}
+		fns := d.searchFns[exact]
+		fn := typeFunc{Extra: extra, Fn: fv}
+		fns = append(fns, fn)
+		d.searchFns[exact] = fns
+	}
+	return nil
+}
+
+// typeFunc holds information about a describer function and the types it accepts
+type typeFunc struct {
+	Extra []reflect.Type
+	Fn    reflect.Value
+}
+
+// Matches returns true when the passed types exactly match the Extra list.
+func (fn typeFunc) Matches(types []reflect.Type) bool {
+	if len(fn.Extra) != len(types) {
+		return false
+	}
+	// reorder the items in array types and fn.Extra
+	// convert the type into string and sort them, check if they are matched
+	varMap := make(map[reflect.Type]bool)
+	for i := range fn.Extra {
+		varMap[fn.Extra[i]] = true
+	}
+	for i := range types {
+		if _, found := varMap[types[i]]; !found {
+			return false
+		}
+	}
+	return true
+}
+
+// Describe invokes the nested function with the exact number of arguments.
+func (fn typeFunc) Describe(exact interface{}, extra ...interface{}) (string, error) {
+	values := []reflect.Value{reflect.ValueOf(exact)}
+	for _, obj := range extra {
+		values = append(values, reflect.ValueOf(obj))
+	}
+	out := fn.Fn.Call(values)
+	s := out[0].Interface().(string)
+	var err error
+	if !out[1].IsNil() {
+		err = out[1].Interface().(error)
+	}
+	return s, err
+}
+
+// printLabelsMultiline prints multiple labels with a proper alignment.
+func printLabelsMultiline(w PrefixWriter, title string, labels map[string]string) {
+	printLabelsMultilineWithIndent(w, "", title, "\t", labels, sets.NewString())
+}
+
+// printLabelsMultiline prints multiple labels with a user-defined alignment.
+func printLabelsMultilineWithIndent(w PrefixWriter, initialIndent, title, innerIndent string, labels map[string]string, skip sets.String) {
+	w.Write(LEVEL_0, "%s%s:%s", initialIndent, title, innerIndent)
+
+	if labels == nil || len(labels) == 0 {
+		w.WriteLine("<none>")
+		return
+	}
+
+	// to print labels in the sorted order
+	keys := make([]string, 0, len(labels))
+	for key := range labels {
+		if skip.Has(key) {
+			continue
+		}
+		keys = append(keys, key)
+	}
+	if len(keys) == 0 {
+		w.WriteLine("<none>")
+		return
+	}
+	sort.Strings(keys)
+
+	for i, key := range keys {
+		if i != 0 {
+			w.Write(LEVEL_0, "%s", initialIndent)
+			w.Write(LEVEL_0, "%s", innerIndent)
+		}
+		w.Write(LEVEL_0, "%s=%s\n", key, labels[key])
+		i++
+	}
+}
+
+// printTaintsMultiline prints multiple taints with a proper alignment.
+func printNodeTaintsMultiline(w PrefixWriter, title string, taints []api.Taint) {
+	printTaintsMultilineWithIndent(w, "", title, "\t", taints)
+}
+
+// printTaintsMultilineWithIndent prints multiple taints with a user-defined alignment.
+func printTaintsMultilineWithIndent(w PrefixWriter, initialIndent, title, innerIndent string, taints []api.Taint) {
+	w.Write(LEVEL_0, "%s%s:%s", initialIndent, title, innerIndent)
+
+	if taints == nil || len(taints) == 0 {
+		w.WriteLine("<none>")
+		return
+	}
+
+	// to print taints in the sorted order
+	sort.Slice(taints, func(i, j int) bool {
+		cmpKey := func(taint api.Taint) string {
+			return string(taint.Effect) + "," + taint.Key
+		}
+		return cmpKey(taints[i]) < cmpKey(taints[j])
+	})
+
+	for i, taint := range taints {
+		if i != 0 {
+			w.Write(LEVEL_0, "%s", initialIndent)
+			w.Write(LEVEL_0, "%s", innerIndent)
+		}
+		w.Write(LEVEL_0, "%s\n", taint.ToString())
+	}
+}
+
+// printPodTolerationsMultiline prints multiple tolerations with a proper alignment.
+func printPodTolerationsMultiline(w PrefixWriter, title string, tolerations []api.Toleration) {
+	printTolerationsMultilineWithIndent(w, "", title, "\t", tolerations)
+}
+
+// printTolerationsMultilineWithIndent prints multiple tolerations with a user-defined alignment.
+func printTolerationsMultilineWithIndent(w PrefixWriter, initialIndent, title, innerIndent string, tolerations []api.Toleration) {
+	w.Write(LEVEL_0, "%s%s:%s", initialIndent, title, innerIndent)
+
+	if tolerations == nil || len(tolerations) == 0 {
+		w.WriteLine("<none>")
+		return
+	}
+
+	// to print tolerations in the sorted order
+	sort.Slice(tolerations, func(i, j int) bool {
+		return tolerations[i].Key < tolerations[j].Key
+	})
+
+	for i, toleration := range tolerations {
+		if i != 0 {
+			w.Write(LEVEL_0, "%s", initialIndent)
+			w.Write(LEVEL_0, "%s", innerIndent)
+		}
+		w.Write(LEVEL_0, "%s", toleration.Key)
+		if len(toleration.Value) != 0 {
+			w.Write(LEVEL_0, "=%s", toleration.Value)
+		}
+		if len(toleration.Effect) != 0 {
+			w.Write(LEVEL_0, ":%s", toleration.Effect)
+		}
+		if toleration.TolerationSeconds != nil {
+			w.Write(LEVEL_0, " for %ds", *toleration.TolerationSeconds)
+		}
+		w.Write(LEVEL_0, "\n")
+	}
+}
+
+type flusher interface {
+	Flush()
+}
+
+func tabbedString(f func(io.Writer) error) (string, error) {
+	out := new(tabwriter.Writer)
+	buf := &bytes.Buffer{}
+	out.Init(buf, 0, 8, 2, ' ', 0)
+
+	err := f(out)
+	if err != nil {
+		return "", err
+	}
+
+	out.Flush()
+	str := string(buf.String())
+	return str, nil
+}
+
+type SortableResourceNames []api.ResourceName
+
+func (list SortableResourceNames) Len() int {
+	return len(list)
+}
+
+func (list SortableResourceNames) Swap(i, j int) {
+	list[i], list[j] = list[j], list[i]
+}
+
+func (list SortableResourceNames) Less(i, j int) bool {
+	return list[i] < list[j]
+}
+
+// SortedResourceNames returns the sorted resource names of a resource list.
+func SortedResourceNames(list api.ResourceList) []api.ResourceName {
+	resources := make([]api.ResourceName, 0, len(list))
+	for res := range list {
+		resources = append(resources, res)
+	}
+	sort.Sort(SortableResourceNames(resources))
+	return resources
+}
+
+type SortableResourceQuotas []api.ResourceQuota
+
+func (list SortableResourceQuotas) Len() int {
+	return len(list)
+}
+
+func (list SortableResourceQuotas) Swap(i, j int) {
+	list[i], list[j] = list[j], list[i]
+}
+
+func (list SortableResourceQuotas) Less(i, j int) bool {
+	return list[i].Name < list[j].Name
+}
+
+type SortableVolumeMounts []api.VolumeMount
+
+func (list SortableVolumeMounts) Len() int {
+	return len(list)
+}
+
+func (list SortableVolumeMounts) Swap(i, j int) {
+	list[i], list[j] = list[j], list[i]
+}
+
+func (list SortableVolumeMounts) Less(i, j int) bool {
+	return list[i].MountPath < list[j].MountPath
+}
+
+type SortableVolumeDevices []api.VolumeDevice
+
+func (list SortableVolumeDevices) Len() int {
+	return len(list)
+}
+
+func (list SortableVolumeDevices) Swap(i, j int) {
+	list[i], list[j] = list[j], list[i]
+}
+
+func (list SortableVolumeDevices) Less(i, j int) bool {
+	return list[i].DevicePath < list[j].DevicePath
+}
+
+var maxAnnotationLen = 200
+
+// printAnnotationsMultilineWithFilter prints filtered multiple annotations with a proper alignment.
+func printAnnotationsMultilineWithFilter(w PrefixWriter, title string, annotations map[string]string, skip sets.String) {
+	printAnnotationsMultilineWithIndent(w, "", title, "\t", annotations, skip)
+}
+
+// printAnnotationsMultiline prints multiple annotations with a proper alignment.
+func printAnnotationsMultiline(w PrefixWriter, title string, annotations map[string]string) {
+	printAnnotationsMultilineWithIndent(w, "", title, "\t", annotations, sets.NewString())
+}
+
+// printAnnotationsMultilineWithIndent prints multiple annotations with a user-defined alignment.
+// If annotation string is too long, we omit chars more than 200 length.
+func printAnnotationsMultilineWithIndent(w PrefixWriter, initialIndent, title, innerIndent string, annotations map[string]string, skip sets.String) {
+
+	w.Write(LEVEL_0, "%s%s:%s", initialIndent, title, innerIndent)
+
+	if len(annotations) == 0 {
+		w.WriteLine("<none>")
+		return
+	}
+
+	// to print labels in the sorted order
+	keys := make([]string, 0, len(annotations))
+	for key := range annotations {
+		if skip.Has(key) {
+			continue
+		}
+		keys = append(keys, key)
+	}
+	if len(annotations) == 0 {
+		w.WriteLine("<none>")
+		return
+	}
+	sort.Strings(keys)
+
+	for i, key := range keys {
+		if i != 0 {
+			w.Write(LEVEL_0, initialIndent)
+			w.Write(LEVEL_0, innerIndent)
+		}
+		line := fmt.Sprintf("%s=%s", key, annotations[key])
+		if len(line) > maxAnnotationLen {
+			w.Write(LEVEL_0, "%s...\n", line[:maxAnnotationLen])
+		} else {
+			w.Write(LEVEL_0, "%s\n", line)
+		}
+		i++
+	}
+}
diff --git a/pkg/security/podsecuritypolicy/util/util.go b/pkg/security/podsecuritypolicy/util/util.go
index c0a25da175..8e965032d4 100644
--- a/pkg/security/podsecuritypolicy/util/util.go
+++ b/pkg/security/podsecuritypolicy/util/util.go
@@ -20,9 +20,9 @@ import (
 	"fmt"
 	"strings"
 
-	policy "k8s.io/api/policy/v1beta1"
 	"k8s.io/apimachinery/pkg/util/sets"
 	api "k8s.io/kubernetes/pkg/apis/core"
+	"k8s.io/kubernetes/pkg/apis/policy"
 )
 
 const (
@@ -68,6 +68,7 @@ func GetAllFSTypesAsSet() sets.String {
 		string(policy.PortworxVolume),
 		string(policy.ScaleIO),
 		string(policy.CSI),
+		string(policy.CascadeDisk),
 	)
 	return fstypes
 }
@@ -129,6 +130,8 @@ func GetVolumeFSType(v api.Volume) (policy.FSType, error) {
 		return policy.PortworxVolume, nil
 	case v.ScaleIO != nil:
 		return policy.ScaleIO, nil
+	case v.CascadeDisk != nil:
+		return policy.CascadeDisk, nil
 	}
 
 	return "", fmt.Errorf("unknown volume type for volume: %#v", v)
diff --git a/pkg/volume/cascade_disk/BUILD b/pkg/volume/cascade_disk/BUILD
new file mode 100644
index 0000000000..3386612450
--- /dev/null
+++ b/pkg/volume/cascade_disk/BUILD
@@ -0,0 +1,43 @@
+package(default_visibility = ["//visibility:public"])
+
+load(
+    "@io_bazel_rules_go//go:def.bzl",
+    "go_library",
+    "go_test",
+)
+
+go_library(
+    name = "go_default_library",
+    srcs = [
+        "attacher.go",
+        "cascade_disk.go",
+        "cascade_util.go",
+    ],
+    deps = [
+        "//pkg/cloudprovider:go_default_library",
+        "//pkg/cloudprovider/providers/cascade:go_default_library",
+        "//pkg/util/mount:go_default_library",
+        "//pkg/util/strings:go_default_library",
+        "//pkg/volume:go_default_library",
+        "//pkg/volume/util:go_default_library",
+        "//pkg/volume/util/volumehelper:go_default_library",
+        "//vendor/github.com/golang/glog:go_default_library",
+        "//vendor/k8s.io/api/core/v1:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/api/resource:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/apis/meta/v1:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/types:go_default_library",
+    ],
+)
+
+filegroup(
+    name = "package-srcs",
+    srcs = glob(["**"]),
+    tags = ["automanaged"],
+    visibility = ["//visibility:private"],
+)
+
+filegroup(
+    name = "all-srcs",
+    srcs = [":package-srcs"],
+    tags = ["automanaged"],
+)
diff --git a/pkg/volume/cascade_disk/OWNERS b/pkg/volume/cascade_disk/OWNERS
new file mode 100644
index 0000000000..c3a4ed77dc
--- /dev/null
+++ b/pkg/volume/cascade_disk/OWNERS
@@ -0,0 +1,2 @@
+maintainers:
+- ashokc
diff --git a/pkg/volume/cascade_disk/attacher.go b/pkg/volume/cascade_disk/attacher.go
new file mode 100644
index 0000000000..c19c37c965
--- /dev/null
+++ b/pkg/volume/cascade_disk/attacher.go
@@ -0,0 +1,264 @@
+package cascade_disk
+
+import (
+	"fmt"
+	"os"
+	"path"
+	"time"
+
+	"github.com/golang/glog"
+	"k8s.io/api/core/v1"
+	"k8s.io/apimachinery/pkg/types"
+	"k8s.io/kubernetes/pkg/cloudprovider/providers/cascade"
+	"k8s.io/kubernetes/pkg/util/mount"
+	"k8s.io/kubernetes/pkg/volume"
+	volumeutil "k8s.io/kubernetes/pkg/volume/util"
+)
+
+type cascadeDiskAttacher struct {
+	host         volume.VolumeHost
+	cascadeDisks cascade.Disks
+}
+
+var _ volume.Attacher = &cascadeDiskAttacher{}
+var _ volume.AttachableVolumePlugin = &cascadeDiskPlugin{}
+
+func (plugin *cascadeDiskPlugin) NewAttacher() (volume.Attacher, error) {
+	cascadeCloud, err := getCloudProvider(plugin.host.GetCloudProvider())
+	if err != nil {
+		glog.Errorf("Cascade attacher: NewAttacher failed to get cloud provider")
+		return nil, err
+	}
+
+	return &cascadeDiskAttacher{
+		host:         plugin.host,
+		cascadeDisks: cascadeCloud,
+	}, nil
+}
+
+// Attach attaches the volume specified by the given spec to the given host. On success, returns the device path where
+// the device was attached on the node.
+func (attacher *cascadeDiskAttacher) Attach(spec *volume.Spec, nodeName types.NodeName) (string, error) {
+	hostName := string(nodeName)
+	volumeSource, _, err := getVolumeSource(spec)
+	if err != nil {
+		glog.Errorf("Cascade attacher: Attach failed to get volume source")
+		return "", err
+	}
+
+	// cascadeDisks.AttachDisk checks if disk is already attached to the node. So we don't have to do that separately
+	// here.
+	glog.V(4).Infof("Cascade: Attach disk called for host %s", hostName)
+	devicePath, err := attacher.cascadeDisks.AttachDisk(volumeSource.DiskID, nodeName)
+	if err != nil {
+		glog.Errorf("Error attaching volume %q to node %q: %+v", volumeSource.DiskID, nodeName, err)
+		return "", err
+	}
+	return devicePath, nil
+}
+
+// VolumesAreAttached verifies whether the volumes specified in the spec are attached to the specified node.
+func (attacher *cascadeDiskAttacher) VolumesAreAttached(specs []*volume.Spec,
+	nodeName types.NodeName) (map[*volume.Spec]bool, error) {
+	volumesAttachedCheck := make(map[*volume.Spec]bool)
+	volumeSpecMap := make(map[string]*volume.Spec)
+	diskIDList := []string{}
+	for _, spec := range specs {
+		volumeSource, _, err := getVolumeSource(spec)
+		if err != nil {
+			glog.Errorf("Error getting volume (%q) source : %v", spec.Name(), err)
+			continue
+		}
+
+		diskIDList = append(diskIDList, volumeSource.DiskID)
+		volumesAttachedCheck[spec] = true
+		volumeSpecMap[volumeSource.DiskID] = spec
+	}
+	attachedResult, err := attacher.cascadeDisks.DisksAreAttached(diskIDList, nodeName)
+	if err != nil {
+		glog.Errorf(
+			"Error checking if volumes (%v) are attached to current node (%q). err=%v",
+			diskIDList, nodeName, err)
+		return volumesAttachedCheck, err
+	}
+
+	for diskID, attached := range attachedResult {
+		if !attached {
+			spec := volumeSpecMap[diskID]
+			volumesAttachedCheck[spec] = false
+			glog.V(2).Infof("VolumesAreAttached: check volume %q (specName: %q) is no longer attached",
+				diskID, spec.Name())
+		}
+	}
+	return volumesAttachedCheck, nil
+}
+
+// WaitForAttach waits until the devicePath returned by the Attach call is available.
+func (attacher *cascadeDiskAttacher) WaitForAttach(spec *volume.Spec, devicePath string, _ *v1.Pod,
+	timeout time.Duration) (string, error) {
+	volumeSource, _, err := getVolumeSource(spec)
+	if err != nil {
+		glog.Errorf("Cascade attacher: WaitForAttach failed to get volume source")
+		return "", err
+	}
+
+	if devicePath == "" {
+		return "", fmt.Errorf("WaitForAttach failed for disk %s: devicePath is empty.", volumeSource.DiskID)
+	}
+
+	ticker := time.NewTicker(checkSleepDuration)
+	defer ticker.Stop()
+
+	timer := time.NewTimer(timeout)
+	defer timer.Stop()
+
+	for {
+		select {
+		case <-ticker.C:
+			glog.V(4).Infof("Checking disk %s is attached", volumeSource.DiskID)
+			devicePath := getDiskByIdPath(devicePath)
+			checkPath, err := verifyDevicePath(devicePath)
+			if err != nil {
+				// Log error, if any, and continue checking periodically. See issue #11321
+				glog.Warningf("Cascade attacher: WaitForAttach with devicePath %s Checking PD %s Error verify "+
+					"path", devicePath, volumeSource.DiskID)
+			} else if checkPath != "" {
+				// A device path has successfully been created for the disk
+				glog.V(4).Infof("Successfully found attached disk %s.", volumeSource.DiskID)
+				return checkPath, nil
+			}
+		case <-timer.C:
+			return "", fmt.Errorf("Could not find attached disk %s. Timeout waiting for mount paths to be "+
+				"created.", volumeSource.DiskID)
+		}
+	}
+}
+
+// GetDeviceMountPath returns a path where the device should point which should be bind mounted for individual volumes.
+func (attacher *cascadeDiskAttacher) GetDeviceMountPath(spec *volume.Spec) (string, error) {
+	volumeSource, _, err := getVolumeSource(spec)
+	if err != nil {
+		glog.Errorf("Cascade attacher: GetDeviceMountPath failed to get volume source")
+		return "", err
+	}
+
+	return makeGlobalPDPath(attacher.host, volumeSource.DiskID), nil
+}
+
+// GetMountDeviceRefs finds all other references to the device referenced by deviceMountPath; returns a list of paths.
+func (plugin *cascadeDiskPlugin) GetDeviceMountRefs(deviceMountPath string) ([]string, error) {
+	mounter := plugin.host.GetMounter(plugin.GetPluginName())
+	return mount.GetMountRefs(mounter, deviceMountPath)
+}
+
+// MountDevice mounts device to global mount point.
+func (attacher *cascadeDiskAttacher) MountDevice(spec *volume.Spec, devicePath string, deviceMountPath string) error {
+	mounter := attacher.host.GetMounter(cascadeDiskPluginName)
+	notMnt, err := mounter.IsLikelyNotMountPoint(deviceMountPath)
+	if err != nil {
+		if os.IsNotExist(err) {
+			if err := os.MkdirAll(deviceMountPath, 0750); err != nil {
+				glog.Errorf("Failed to create directory at %#v. err: %s", deviceMountPath, err)
+				return err
+			}
+			notMnt = true
+		} else {
+			return err
+		}
+	}
+
+	volumeSource, _, err := getVolumeSource(spec)
+	if err != nil {
+		glog.Errorf("Cascade attacher: MountDevice failed to get volume source. err: %s", err)
+		return err
+	}
+
+	options := []string{}
+
+	if notMnt {
+		diskMounter := volumeutil.NewSafeFormatAndMountFromHost(cascadeDiskPluginName, attacher.host)
+		mountOptions := volumeutil.MountOptionFromSpec(spec)
+		err = diskMounter.FormatAndMount(devicePath, deviceMountPath, volumeSource.FSType, mountOptions)
+		if err != nil {
+			os.Remove(deviceMountPath)
+			return err
+		}
+		glog.V(4).Infof("formatting spec %v devicePath %v deviceMountPath %v fs %v with options %+v",
+			spec.Name(), devicePath, deviceMountPath, volumeSource.FSType, options)
+	}
+	return nil
+}
+
+type cascadeDiskDetacher struct {
+	mounter      mount.Interface
+	cascadeDisks cascade.Disks
+}
+
+var _ volume.Detacher = &cascadeDiskDetacher{}
+
+// NewDetacher returns the detacher associated with the Cascade volume plugin.
+func (plugin *cascadeDiskPlugin) NewDetacher() (volume.Detacher, error) {
+	cascadeCloud, err := getCloudProvider(plugin.host.GetCloudProvider())
+	if err != nil {
+		glog.Errorf("Cascade attacher: NewDetacher failed to get cloud provider. err: %s", err)
+		return nil, err
+	}
+
+	return &cascadeDiskDetacher{
+		mounter:      plugin.host.GetMounter(plugin.GetPluginName()),
+		cascadeDisks: cascadeCloud,
+	}, nil
+}
+
+// Detach detaches the given device from the given host.
+func (detacher *cascadeDiskDetacher) Detach(deviceMountPath string, nodeName types.NodeName) error {
+	hostName := string(nodeName)
+	diskID := path.Base(deviceMountPath)
+	attached, err := detacher.cascadeDisks.DiskIsAttached(diskID, nodeName)
+	if err != nil {
+		// Log error and continue with detach
+		glog.Errorf(
+			"Error checking if persistent disk (%q) is already attached to current node (%q). "+
+				"Will continue and try detach anyway. err=%v", diskID, hostName, err)
+	}
+
+	if err == nil && !attached {
+		// Volume is already detached from node.
+		glog.V(4).Infof("detach operation was successful. persistent disk %q is already detached "+
+			"from node %q.", diskID, hostName)
+		return nil
+	}
+
+	if err := detacher.cascadeDisks.DetachDisk(diskID, nodeName); err != nil {
+		glog.Errorf("Error detaching volume %q: %v", diskID, err)
+		return err
+	}
+	return nil
+}
+
+// WaitForDetach waits for the devicePath to become unavailable.
+func (detacher *cascadeDiskDetacher) WaitForDetach(devicePath string, timeout time.Duration) error {
+	ticker := time.NewTicker(checkSleepDuration)
+	defer ticker.Stop()
+	timer := time.NewTimer(timeout)
+	defer timer.Stop()
+
+	for {
+		select {
+		case <-ticker.C:
+			glog.V(4).Infof("Checking device %q is detached.", devicePath)
+			if pathExists, err := volumeutil.PathExists(devicePath); err != nil {
+				return fmt.Errorf("Error checking if device path exists: %v", err)
+			} else if !pathExists {
+				return nil
+			}
+		case <-timer.C:
+			return fmt.Errorf("Timeout reached; Device %v is still attached", devicePath)
+		}
+	}
+}
+
+// UnmountDevice unmounts the disk specified by the device mount path.
+func (detacher *cascadeDiskDetacher) UnmountDevice(deviceMountPath string) error {
+	return volumeutil.UnmountPath(deviceMountPath, detacher.mounter)
+}
diff --git a/pkg/volume/cascade_disk/azure_disk_util.go b/pkg/volume/cascade_disk/azure_disk_util.go
new file mode 100644
index 0000000000..7f9812f767
--- /dev/null
+++ b/pkg/volume/cascade_disk/azure_disk_util.go
@@ -0,0 +1,135 @@
+package cascade_disk
+
+import (
+	"io/ioutil"
+	"os"
+	"path"
+	"strconv"
+	"strings"
+
+	"github.com/golang/glog"
+)
+
+const (
+	environmentFilePath = "/etc/kubernetes/environment"
+	diskPath            = "/dev/disk/cloud/"
+	sysPath             = "/sys/bus/scsi/devices"
+	lunIndex            = 3
+	maxOsScsiHostNo     = 3
+	vendor              = "vendor"
+	msftVendor          = "MSFT"
+	model               = "model"
+	vhdModel            = "VIRTUAL DISK"
+	block               = "block"
+)
+
+func findAzureVolume(lun int) (device string, err error) {
+	azureDisks := listAzureDiskPath()
+	return findDiskByLunWithConstraint(lun, azureDisks)
+}
+
+// List all the devices that are used by azure.
+// All these devices are the symbolic link under /dev/disk/cloud/
+// eg. azure_resource -> ../../sdb
+func listAzureDiskPath() []string {
+	var azureDiskList []string
+	if dirs, err := ioutil.ReadDir(diskPath); err == nil {
+		for _, f := range dirs {
+			name := f.Name()
+			diskPath := diskPath + name
+			if link, linkErr := os.Readlink(diskPath); linkErr == nil {
+				sd := link[(strings.LastIndex(link, "/") + 1):]
+				azureDiskList = append(azureDiskList, sd)
+			}
+		}
+	}
+	glog.V(12).Infof("Azure sys disks paths: %v", azureDiskList)
+	return azureDiskList
+}
+
+// Azure attach/detach APIs return the disk model that does not have disk
+// device path name (eg. /dev/sde) instead it gives the lun number of the disk
+// getting attached/detached.
+// This function maps that lun number to device path name of the
+// device mounted to "current" node.
+// Refrence : https://github.com/kubernetes/kubernetes/blob/master/pkg/volume/azure_dd/azure_common_linux.go#L69
+//            https://docs.microsoft.com/en-us/azure/virtual-machines/linux/troubleshoot-device-names-problems
+func findDiskByLunWithConstraint(lun int, azureDisks []string) (string, error) {
+	var err error
+	if dirs, err := ioutil.ReadDir(sysPath); err == nil {
+		for _, f := range dirs {
+			name := f.Name()
+			// look for path like /sys/bus/scsi/devices/3:0:0:1
+			arr := strings.Split(name, ":")
+			if len(arr) < 4 {
+				continue
+			}
+			if len(azureDisks) == 0 {
+				glog.V(4).Infof("/dev/disk/cloud is not populated, now try to parse %v directly", name)
+				target, err := strconv.Atoi(arr[0])
+				if err != nil {
+					glog.Errorf("failed to parse target from %v (%v), err %v", arr[0], name, err)
+					continue
+				}
+				// as observed, targets 0-3 are used by OS disks. Skip them
+				if target <= maxOsScsiHostNo {
+					continue
+				}
+			}
+
+			// extract LUN from the path.
+			// LUN is the last index of the array, i.e. 1 in /sys/bus/scsi/devices/3:0:0:1
+			l, err := strconv.Atoi(arr[lunIndex])
+			if err != nil {
+				// unknown path format, continue to read the next one
+				glog.V(4).Infof("azure disk - failed to parse lun from %v (%v), err %v", arr[lunIndex], name, err)
+				continue
+			}
+			if lun == l {
+				// find the matching LUN
+				// read vendor and model to ensure it is a VHD disk
+				vendorPath := path.Join(sysPath, name, vendor)
+				vendorBytes, err := ioutil.ReadFile(vendorPath)
+				if err != nil {
+					glog.Errorf("failed to read device vendor, err: %v", err)
+					continue
+				}
+				vendor := strings.TrimSpace(string(vendorBytes))
+				if strings.ToUpper(vendor) != msftVendor {
+					glog.V(4).Infof("vendor doesn't match VHD, got %s", vendor)
+					continue
+				}
+
+				modelPath := path.Join(sysPath, name, model)
+				modelBytes, err := ioutil.ReadFile(modelPath)
+				if err != nil {
+					glog.Errorf("failed to read device model, err: %v", err)
+					continue
+				}
+				model := strings.TrimSpace(string(modelBytes))
+				if strings.ToUpper(model) != vhdModel {
+					glog.V(4).Infof("model doesn't match VHD, got %s", model)
+					continue
+				}
+
+				// find a disk, validate name
+				dir := path.Join(sysPath, name, block)
+				if dev, err := ioutil.ReadDir(dir); err == nil {
+					found := false
+					devName := dev[0].Name()
+					for _, diskName := range azureDisks {
+						glog.V(12).Infof("azureDisk - validating disk %q with sys disk %q", devName, diskName)
+						if devName == diskName {
+							found = true
+							break
+						}
+					}
+					if !found {
+						return "/dev/" + devName, nil
+					}
+				}
+			}
+		}
+	}
+	return "", err
+}
diff --git a/pkg/volume/cascade_disk/cascade_disk.go b/pkg/volume/cascade_disk/cascade_disk.go
new file mode 100644
index 0000000000..b7d3fd774b
--- /dev/null
+++ b/pkg/volume/cascade_disk/cascade_disk.go
@@ -0,0 +1,399 @@
+package cascade_disk
+
+import (
+	"fmt"
+	"os"
+	"path"
+
+	"github.com/golang/glog"
+	"k8s.io/api/core/v1"
+	"k8s.io/apimachinery/pkg/api/resource"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/types"
+	"k8s.io/kubernetes/pkg/util/mount"
+	utilstrings "k8s.io/kubernetes/pkg/util/strings"
+	"k8s.io/kubernetes/pkg/volume"
+	"k8s.io/kubernetes/pkg/volume/util"
+)
+
+// This is the primary entrypoint for volume plugins.
+func ProbeVolumePlugins() []volume.VolumePlugin {
+	return []volume.VolumePlugin{&cascadeDiskPlugin{}}
+}
+
+type cascadeDiskPlugin struct {
+	host volume.VolumeHost
+}
+
+var _ volume.VolumePlugin = &cascadeDiskPlugin{}
+var _ volume.PersistentVolumePlugin = &cascadeDiskPlugin{}
+var _ volume.DeletableVolumePlugin = &cascadeDiskPlugin{}
+var _ volume.ProvisionableVolumePlugin = &cascadeDiskPlugin{}
+
+const (
+	cascadeDiskPluginName = "kubernetes.io/vke-disk"
+)
+
+// Init initializes the Cascade volume plugin.
+func (plugin *cascadeDiskPlugin) Init(host volume.VolumeHost) error {
+	plugin.host = host
+	return nil
+}
+
+// GetPluginName returns the name of the Cascade volume plugin.
+func (plugin *cascadeDiskPlugin) GetPluginName() string {
+	return cascadeDiskPluginName
+}
+
+// GetVolumeName returns the name of the volume which is the diskID in our case.
+func (plugin *cascadeDiskPlugin) GetVolumeName(spec *volume.Spec) (string, error) {
+	volumeSource, _, err := getVolumeSource(spec)
+	if err != nil {
+		glog.Errorf("Cascade volume plugin: GetVolumeName failed to get volume source")
+		return "", err
+	}
+
+	return volumeSource.DiskID, nil
+}
+
+// CanSupport specifies whether the Cascade volume plguin can support the specific resource type.
+// Cascade plugin only supports the persistent volume and volume resource which has the Cascade disk annotation.
+func (plugin *cascadeDiskPlugin) CanSupport(spec *volume.Spec) bool {
+	return (spec.PersistentVolume != nil && spec.PersistentVolume.Spec.CascadeDisk != nil) ||
+		(spec.Volume != nil && spec.Volume.CascadeDisk != nil)
+}
+
+// RequiresRemount specifies whether remount is required for the disk.
+func (plugin *cascadeDiskPlugin) RequiresRemount() bool {
+	return false
+}
+
+// SupportsMountOption specifies whether the Cascade volume plugin supports the mount operation.
+func (plugin *cascadeDiskPlugin) SupportsMountOption() bool {
+	return true
+}
+
+// SupportsBulkVolumeVerification specifies whether bulk volume verification is supported.
+func (plugin *cascadeDiskPlugin) SupportsBulkVolumeVerification() bool {
+	return false
+}
+
+// NewMounter returns the mounter associated with the Cascade volume plugin.
+func (plugin *cascadeDiskPlugin) NewMounter(spec *volume.Spec, pod *v1.Pod,
+	_ volume.VolumeOptions) (volume.Mounter, error) {
+	return plugin.newMounterInternal(spec, pod.UID, &CascadeDiskUtil{}, plugin.host.GetMounter(plugin.GetPluginName()))
+}
+
+// NewUnmounter returns the unmounter associated with the Cascade volume plugin.
+func (plugin *cascadeDiskPlugin) NewUnmounter(volName string, podUID types.UID) (volume.Unmounter, error) {
+	return plugin.newUnmounterInternal(volName, podUID, &CascadeDiskUtil{},
+		plugin.host.GetMounter(plugin.GetPluginName()))
+}
+
+func (plugin *cascadeDiskPlugin) newMounterInternal(spec *volume.Spec, podUID types.UID, manager diskManager,
+	mounter mount.Interface) (volume.Mounter, error) {
+	volumeSource, _, err := getVolumeSource(spec)
+	if err != nil {
+		glog.Errorf("Cascade volume plugin: newMounterInternal failed to get volume source")
+		return nil, err
+	}
+
+	diskID := volumeSource.DiskID
+	fsType := volumeSource.FSType
+
+	return &cascadeDiskMounter{
+		cascadeDisk: &cascadeDisk{
+			podUID:  podUID,
+			volName: spec.Name(),
+			diskID:  diskID,
+			manager: manager,
+			mounter: mounter,
+			plugin:  plugin,
+		},
+		fsType:      fsType,
+		diskMounter: util.NewSafeFormatAndMountFromHost(plugin.GetPluginName(), plugin.host)}, nil
+}
+
+func (plugin *cascadeDiskPlugin) newUnmounterInternal(volName string, podUID types.UID, manager diskManager,
+	mounter mount.Interface) (volume.Unmounter, error) {
+	return &cascadeDiskUnmounter{
+		&cascadeDisk{
+			podUID:  podUID,
+			volName: volName,
+			manager: manager,
+			mounter: mounter,
+			plugin:  plugin,
+		}}, nil
+}
+
+// ConstructVolumeSpec constructs a Cascade volume spec based on the name and mount path.
+func (plugin *cascadeDiskPlugin) ConstructVolumeSpec(volumeSpecName, mountPath string) (*volume.Spec, error) {
+	mounter := plugin.host.GetMounter(plugin.GetPluginName())
+	pluginDir := plugin.host.GetPluginDir(plugin.GetPluginName())
+	diskID, err := mounter.GetDeviceNameFromMount(mountPath, pluginDir)
+	if err != nil {
+		return nil, err
+	}
+
+	cascadeDisk := &v1.Volume{
+		Name: volumeSpecName,
+		VolumeSource: v1.VolumeSource{
+			CascadeDisk: &v1.CascadeDiskVolumeSource{
+				DiskID: diskID,
+			},
+		},
+	}
+	return volume.NewSpecFromVolume(cascadeDisk), nil
+}
+
+// Abstract interface to disk operations.
+type diskManager interface {
+	// Creates a volume
+	CreateVolume(provisioner *cascadeDiskProvisioner) (diskID string, volumeSizeGB int, labels map[string]string, fstype string, err error)
+	// Deletes a volume
+	DeleteVolume(deleter *cascadeDiskDeleter) error
+}
+
+// cascadeDisk volumes are disk resources attached to the kubelet's host machine and exposed to the pod.
+type cascadeDisk struct {
+	volName string
+	podUID  types.UID
+	diskID  string
+	fsType  string
+	manager diskManager
+	mounter mount.Interface
+	plugin  *cascadeDiskPlugin
+	volume.MetricsNil
+}
+
+var _ volume.Mounter = &cascadeDiskMounter{}
+
+type cascadeDiskMounter struct {
+	*cascadeDisk
+	fsType      string
+	diskMounter *mount.SafeFormatAndMount
+}
+
+// GetAttributes returns the attributes associated with a Cascade disk.
+func (b *cascadeDiskMounter) GetAttributes() volume.Attributes {
+	return volume.Attributes{
+		SupportsSELinux: true,
+	}
+}
+
+// CanMount checks prior to mount operations to verify that the required components (binaries, etc.) to mount the
+// volume are available on the underlying node. If not, it returns an error.
+func (b *cascadeDiskMounter) CanMount() error {
+	return nil
+}
+
+// SetUp attaches the disk and bind mounts to the volume path.
+func (b *cascadeDiskMounter) SetUp(fsGroup *int64) error {
+	return b.SetUpAt(b.GetPath(), fsGroup)
+}
+
+// SetUpAt attaches the disk and bind mounts to the volume path.
+func (b *cascadeDiskMounter) SetUpAt(dir string, fsGroup *int64) error {
+	glog.V(4).Infof("Cascade Persistent Disk setup %s to %s", b.diskID, dir)
+
+	// TODO: handle failed mounts here.
+	notmnt, err := b.mounter.IsLikelyNotMountPoint(dir)
+	if err != nil && !os.IsNotExist(err) {
+		glog.Errorf("cannot validate mount point: %s %v", dir, err)
+		return err
+	}
+	if !notmnt {
+		return nil
+	}
+
+	if err := os.MkdirAll(dir, 0750); err != nil {
+		glog.Errorf("mkdir failed on disk %s (%v)", dir, err)
+		return err
+	}
+
+	options := []string{"bind"}
+
+	// Perform a bind mount to the full path to allow duplicate mounts of the same PD.
+	globalPDPath := makeGlobalPDPath(b.plugin.host, b.diskID)
+	glog.V(4).Infof("attempting to mount %s", dir)
+
+	err = b.mounter.Mount(globalPDPath, dir, "", options)
+	if err != nil {
+		notmnt, mntErr := b.mounter.IsLikelyNotMountPoint(dir)
+		if mntErr != nil {
+			glog.Errorf("IsLikelyNotMountPoint check failed: %v", mntErr)
+			return err
+		}
+		if !notmnt {
+			if mntErr = b.mounter.Unmount(dir); mntErr != nil {
+				glog.Errorf("Failed to unmount: %v", mntErr)
+				return err
+			}
+			notmnt, mntErr := b.mounter.IsLikelyNotMountPoint(dir)
+			if mntErr != nil {
+				glog.Errorf("IsLikelyNotMountPoint check failed: %v", mntErr)
+				return err
+			}
+			if !notmnt {
+				glog.Errorf("%s is still mounted, despite call to unmount().  Will try again next sync loop.",
+					b.GetPath())
+				return err
+			}
+		}
+		os.Remove(dir)
+		glog.Errorf("Mount of disk %s failed: %v", dir, err)
+		return err
+	}
+	volume.SetVolumeOwnership(b, fsGroup)
+
+	return nil
+}
+
+var _ volume.Unmounter = &cascadeDiskUnmounter{}
+
+type cascadeDiskUnmounter struct {
+	*cascadeDisk
+}
+
+// TearDown unmounts the bind mount, and detaches the disk only if the disk resource was the last reference to that
+// disk on the kubelet.
+func (c *cascadeDiskUnmounter) TearDown() error {
+	return c.TearDownAt(c.GetPath())
+}
+
+// TearDownAt unmounts the bind mount, and detaches the disk only if the disk resource was the last reference to that
+// disk on the kubelet.
+func (c *cascadeDiskUnmounter) TearDownAt(dir string) error {
+	return util.UnmountPath(dir, c.mounter)
+}
+
+func makeGlobalPDPath(host volume.VolumeHost, diskID string) string {
+	return path.Join(host.GetPluginDir(cascadeDiskPluginName), mount.MountsInGlobalPDPath, diskID)
+}
+
+func (cd *cascadeDisk) GetPath() string {
+	name := cascadeDiskPluginName
+	return cd.plugin.host.GetPodVolumeDir(cd.podUID, utilstrings.EscapeQualifiedNameForDisk(name), cd.volName)
+}
+
+func (plugin *cascadeDiskPlugin) GetAccessModes() []v1.PersistentVolumeAccessMode {
+	return []v1.PersistentVolumeAccessMode{
+		v1.ReadWriteOnce,
+	}
+}
+
+type cascadeDiskDeleter struct {
+	*cascadeDisk
+}
+
+var _ volume.Deleter = &cascadeDiskDeleter{}
+
+// NewDeleter returns the deleter associated with the Cascade volume plugin.
+func (plugin *cascadeDiskPlugin) NewDeleter(spec *volume.Spec) (volume.Deleter, error) {
+	return plugin.newDeleterInternal(spec, &CascadeDiskUtil{})
+}
+
+func (plugin *cascadeDiskPlugin) newDeleterInternal(spec *volume.Spec, manager diskManager) (volume.Deleter, error) {
+	if spec.PersistentVolume != nil && spec.PersistentVolume.Spec.CascadeDisk == nil {
+		return nil, fmt.Errorf("spec.PersistentVolumeSource.CascadeDisk is nil")
+	}
+	return &cascadeDiskDeleter{
+		&cascadeDisk{
+			volName: spec.Name(),
+			diskID:  spec.PersistentVolume.Spec.CascadeDisk.DiskID,
+			manager: manager,
+			plugin:  plugin,
+		}}, nil
+}
+
+func (r *cascadeDiskDeleter) Delete() error {
+	return r.manager.DeleteVolume(r)
+}
+
+type cascadeDiskProvisioner struct {
+	*cascadeDisk
+	options volume.VolumeOptions
+}
+
+var _ volume.Provisioner = &cascadeDiskProvisioner{}
+
+// NewProvisioner returns the provisioner associated with the Cascade volume plugin.
+func (plugin *cascadeDiskPlugin) NewProvisioner(options volume.VolumeOptions) (volume.Provisioner, error) {
+	return plugin.newProvisionerInternal(options, &CascadeDiskUtil{})
+}
+
+func (plugin *cascadeDiskPlugin) newProvisionerInternal(options volume.VolumeOptions,
+	manager diskManager) (volume.Provisioner, error) {
+	return &cascadeDiskProvisioner{
+		cascadeDisk: &cascadeDisk{
+			manager: manager,
+			plugin:  plugin,
+		},
+		options: options,
+	}, nil
+}
+
+// Provision provisions the persistent volume by making a CreateDisk call to Cascade Controller.
+func (p *cascadeDiskProvisioner) Provision(selectedNode *v1.Node, allowedTopologies []v1.TopologySelectorTerm) (*v1.PersistentVolume, error) {
+	if !util.AccessModesContainedInAll(p.plugin.GetAccessModes(), p.options.PVC.Spec.AccessModes) {
+		return nil, fmt.Errorf("invalid AccessModes %v: only AccessModes %v are supported",
+			p.options.PVC.Spec.AccessModes, p.plugin.GetAccessModes())
+	}
+
+	diskID, sizeGB, labels, fstype, err := p.manager.CreateVolume(p)
+	if err != nil {
+		return nil, err
+	}
+
+	if fstype == "" {
+		fstype = "ext4"
+	}
+
+	pv := &v1.PersistentVolume{
+		ObjectMeta: metav1.ObjectMeta{
+			Name:   p.options.PVName,
+			Labels: map[string]string{},
+			Annotations: map[string]string{
+				util.VolumeDynamicallyCreatedByKey: "vke-volume-dynamic-provisioner",
+			},
+		},
+		Spec: v1.PersistentVolumeSpec{
+			PersistentVolumeReclaimPolicy: p.options.PersistentVolumeReclaimPolicy,
+			AccessModes:                   p.options.PVC.Spec.AccessModes,
+			Capacity: v1.ResourceList{
+				v1.ResourceName(v1.ResourceStorage): resource.MustParse(fmt.Sprintf("%dGi", sizeGB)),
+			},
+			PersistentVolumeSource: v1.PersistentVolumeSource{
+				CascadeDisk: &v1.CascadeDiskVolumeSource{
+					DiskID: diskID,
+					FSType: fstype,
+				},
+			},
+			MountOptions: p.options.MountOptions,
+		},
+	}
+	if len(p.options.PVC.Spec.AccessModes) == 0 {
+		pv.Spec.AccessModes = p.plugin.GetAccessModes()
+	}
+
+	if len(labels) != 0 {
+		if pv.Labels == nil {
+			pv.Labels = make(map[string]string)
+		}
+		for k, v := range labels {
+			pv.Labels[k] = v
+		}
+	}
+
+	return pv, nil
+}
+
+func getVolumeSource(spec *volume.Spec) (*v1.CascadeDiskVolumeSource, bool, error) {
+	if spec.Volume != nil && spec.Volume.CascadeDisk != nil {
+		return spec.Volume.CascadeDisk, spec.ReadOnly, nil
+	} else if spec.PersistentVolume != nil && spec.PersistentVolume.Spec.CascadeDisk != nil {
+		return spec.PersistentVolume.Spec.CascadeDisk, spec.ReadOnly, nil
+	}
+
+	return nil, false, fmt.Errorf("Spec does not reference a Cascade disk type")
+}
diff --git a/pkg/volume/cascade_disk/cascade_util.go b/pkg/volume/cascade_disk/cascade_util.go
new file mode 100644
index 0000000000..5ad0bc9316
--- /dev/null
+++ b/pkg/volume/cascade_disk/cascade_util.go
@@ -0,0 +1,217 @@
+package cascade_disk
+
+import (
+	"fmt"
+	"os"
+	"path/filepath"
+	"strconv"
+	"strings"
+	"time"
+
+	"github.com/golang/glog"
+	"k8s.io/api/core/v1"
+	"k8s.io/kubernetes/pkg/cloudprovider"
+	"k8s.io/kubernetes/pkg/cloudprovider/providers/cascade"
+	"k8s.io/kubernetes/pkg/volume"
+	volumeutil "k8s.io/kubernetes/pkg/volume/util"
+	"bufio"
+)
+
+const (
+	checkSleepDuration = time.Second
+)
+
+type CascadeDiskUtil struct{}
+
+func verifyDevicePath(path string) (string, error) {
+	if pathExists, err := volumeutil.PathExists(path); err != nil {
+		return "", fmt.Errorf("Error checking if path exists: %v", err)
+	} else if pathExists {
+		return path, nil
+	}
+
+	glog.V(4).Infof("verifyDevicePath: path does not exist yet")
+	return "", nil
+}
+
+// Returns path for given VKE disk mount
+func getDiskByIdPath(devicePath string) string {
+	provider, err := getProvider()
+	if err != nil {
+		glog.Warningf("error getting provider name from %s: %v", environmentFilePath, err)
+		return devicePath
+	}
+
+	switch provider {
+	case "azure":
+		// devicePath is an integer then it is lun returned from azure attach disk.
+		if diskLun, err := strconv.Atoi(devicePath); err == nil {
+			azDevicePath, err := findAzureVolume(diskLun)
+			if err != nil {
+				glog.Warningf("error looking for azure volume %q: %v", devicePath, err)
+			} else if azDevicePath != "" {
+				devicePath = azDevicePath
+			}
+		} else {
+			glog.Warningf("The device path for azure expected to be an integer but it is %s. Error : %v", devicePath, err)
+		}
+	default:
+		nvmePath, err := findNvmeVolume(devicePath)
+		if err != nil {
+			glog.Warningf("error looking for nvme volume %q: %v", devicePath, err)
+		} else if nvmePath != "" {
+			devicePath = nvmePath
+		}
+	}
+	return devicePath
+}
+
+// CreateVolume creates a Cascade persistent disk.
+func (util *CascadeDiskUtil) CreateVolume(p *cascadeDiskProvisioner) (string, int, map[string]string, string, error) {
+
+	cloud, err := getCloudProvider(p.plugin.host.GetCloudProvider())
+	if err != nil {
+		glog.Errorf("CreateVolume failed to get cloud provider. Error [%v]", err)
+		return "", 0, nil, "", err
+	}
+
+	capacity := p.options.PVC.Spec.Resources.Requests[v1.ResourceName(v1.ResourceStorage)]
+	volSizeBytes := capacity.Value()
+	// Cascade works with GB, convert to GB with rounding up
+	volSizeGB := int(volumeutil.RoundUpSize(volSizeBytes, 1024*1024*1024))
+	name := volumeutil.GenerateVolumeName(p.options.ClusterName, p.options.PVName, 255)
+	volumeOptions := &cascade.VolumeOptions{
+		CapacityGB: volSizeGB,
+		Tags:       *p.options.CloudTags,
+		Name:       name,
+	}
+	fstype := ""
+	// enabling encryption by default if not provided from within storage class
+	volumeOptions.Encrypted = true
+	for parameter, value := range p.options.Parameters {
+		switch strings.ToLower(parameter) {
+		case "type":
+			volumeOptions.Type = value
+		case "zone":
+			volumeOptions.ZonePresent = true
+			volumeOptions.AvailabilityZone = value
+		case "zones":
+			volumeOptions.ZonesPresent = true
+			volumeOptions.AvailabilityZones = value
+		case "encrypted":
+			volumeOptions.Encrypted, err = strconv.ParseBool(value)
+			if err != nil {
+				glog.Errorf("invalid value %q for encryption of volume plugin %s.", value, p.plugin.GetPluginName())
+				return "", 0, nil, "",
+					fmt.Errorf("invalid encrypted boolean value %q, must be true or false: %v", value, err)
+			}
+		case volume.VolumeParameterFSType:
+			fstype = value
+			glog.V(4).Infof("Setting fstype to %s", fstype)
+		default:
+			glog.Errorf("invalid option %s for volume plugin %s.", parameter,
+				p.plugin.GetPluginName())
+			return "", 0, nil, "",
+				fmt.Errorf("invalid option %s for volume plugin %s.", parameter, p.plugin.GetPluginName())
+		}
+	}
+
+	if volumeOptions.ZonePresent && volumeOptions.ZonesPresent {
+		return "", 0, nil, "", fmt.Errorf("both zone and zones StorageClass parameters must not be used at the same time")
+	}
+
+	diskID, err := cloud.CreateDisk(volumeOptions)
+	if err != nil {
+		glog.Errorf("failed to CreateDisk. Error [%v]", err)
+		return "", 0, nil, "", err
+	}
+
+	labels, err := cloud.GetVolumeLabels(diskID)
+	if err != nil {
+		// We don't really want to leak the volume here...
+		glog.Errorf("error building labels for new volume %q: %v", name, err)
+	}
+
+	glog.V(4).Infof("Successfully created Cascade persistent disk %s", name)
+	return diskID, volSizeGB, labels, fstype, nil
+}
+
+// DeleteVolume deletes a Cascade volume.
+func (util *CascadeDiskUtil) DeleteVolume(disk *cascadeDiskDeleter) error {
+	cloud, err := getCloudProvider(disk.plugin.host.GetCloudProvider())
+	if err != nil {
+		glog.Errorf("DeleteVolume failed to get cloud provider. Error [%v]", err)
+		return err
+	}
+
+	if err = cloud.DeleteDisk(disk.diskID); err != nil {
+		glog.Errorf("failed to DeleteDisk for diskID %s. Error [%v]", disk.diskID, err)
+		return err
+	}
+
+	glog.V(4).Infof("Successfully deleted Cascade persistent disk %s", disk.diskID)
+	return nil
+}
+
+func getCloudProvider(cloud cloudprovider.Interface) (*cascade.CascadeCloud, error) {
+	if cloud == nil {
+		glog.Errorf("Cloud provider not initialized properly")
+		return nil, fmt.Errorf("Cloud provider not initialized properly")
+	}
+
+	cc := cloud.(*cascade.CascadeCloud)
+	if cc == nil {
+		glog.Errorf("Invalid cloud provider: expected Cascade")
+		return nil, fmt.Errorf("Invalid cloud provider: expected Cascade")
+	}
+	return cc, nil
+}
+
+// findNvmeVolume looks for the nvme volume with the specified name
+// It follows the symlink (if it exists) and returns the absolute path to the device
+func findNvmeVolume(findName string) (device string, err error) {
+	stat, err := os.Lstat(findName)
+	if err != nil {
+		if os.IsNotExist(err) {
+			glog.V(6).Infof("nvme path not found %q", findName)
+			return "", nil
+		}
+		return "", fmt.Errorf("error getting stat of %q: %v", findName, err)
+	}
+
+	if stat.Mode()&os.ModeSymlink != os.ModeSymlink {
+		glog.Warningf("nvme file %q found, but was not a symlink", findName)
+		return "", nil
+	}
+
+	// Find the target, resolving to an absolute path
+	// For example, /dev/disk/by-id/nvme-Amazon_Elastic_Block_Store_vol0fab1d5e3f72a5e23 -> ../../nvme2n1
+	resolved, err := filepath.EvalSymlinks(findName)
+	if err != nil {
+		return "", fmt.Errorf("error reading target of symlink %q: %v", findName, err)
+	}
+
+	if !strings.HasPrefix(resolved, "/dev") {
+		return "", fmt.Errorf("resolved symlink for %q was unexpected: %q", findName, resolved)
+	}
+
+	return resolved, nil
+}
+
+func getProvider() (provider string, err error) {
+	file, err := os.Open(environmentFilePath)
+	if err != nil {
+		return "", err
+	}
+	defer file.Close()
+
+	scanner := bufio.NewScanner(file)
+
+	for scanner.Scan() {
+		lineContent := scanner.Text()
+		if strings.Contains(lineContent, "PROVIDER=") {
+			return strings.SplitAfter(lineContent, "=")[1], err
+		}
+	}
+	return "", err
+}
diff --git a/plugin/pkg/admission/storage/persistentvolume/label/admission.go b/plugin/pkg/admission/storage/persistentvolume/label/admission.go
index 4125dd52c3..8c51e38c3d 100644
--- a/plugin/pkg/admission/storage/persistentvolume/label/admission.go
+++ b/plugin/pkg/admission/storage/persistentvolume/label/admission.go
@@ -22,17 +22,16 @@ import (
 	"io"
 	"sync"
 
+	"github.com/golang/glog"
 	"k8s.io/apiserver/pkg/admission"
-	cloudprovider "k8s.io/cloud-provider"
-	"k8s.io/klog"
 	api "k8s.io/kubernetes/pkg/apis/core"
+	"k8s.io/kubernetes/pkg/cloudprovider"
 	"k8s.io/kubernetes/pkg/cloudprovider/providers/aws"
-	"k8s.io/kubernetes/pkg/cloudprovider/providers/azure"
+	"k8s.io/kubernetes/pkg/cloudprovider/providers/cascade"
 	"k8s.io/kubernetes/pkg/cloudprovider/providers/gce"
 	kubeapiserveradmission "k8s.io/kubernetes/pkg/kubeapiserver/admission"
 	kubeletapis "k8s.io/kubernetes/pkg/kubelet/apis"
 	vol "k8s.io/kubernetes/pkg/volume"
-	volumeutil "k8s.io/kubernetes/pkg/volume/util"
 )
 
 const (
@@ -56,8 +55,8 @@ type persistentVolumeLabel struct {
 	mutex            sync.Mutex
 	ebsVolumes       aws.Volumes
 	cloudConfig      []byte
-	gceCloudProvider *gce.Cloud
-	azureProvider    *azure.Cloud
+	gceCloudProvider *gce.GCECloud
+	cascadeDisks     cascade.Disks
 }
 
 var _ admission.MutationInterface = &persistentVolumeLabel{}
@@ -69,9 +68,9 @@ var _ kubeapiserveradmission.WantsCloudConfig = &persistentVolumeLabel{}
 // As a side effect, the cloud provider may block invalid or non-existent volumes.
 func newPersistentVolumeLabel() *persistentVolumeLabel {
 	// DEPRECATED: cloud-controller-manager will now start NewPersistentVolumeLabelController
-	// which does exactly what this admission controller used to do. So once GCE, AWS and AZURE can
+	// which does exactly what this admission controller used to do. So once GCE and AWS can
 	// run externally, we can remove this admission controller.
-	klog.Warning("PersistentVolumeLabel admission controller is deprecated. " +
+	glog.Warning("PersistentVolumeLabel admission controller is deprecated. " +
 		"Please remove this controller from your configuration files and scripts.")
 	return &persistentVolumeLabel{
 		Handler: admission.NewHandler(admission.Create),
@@ -82,19 +81,6 @@ func (l *persistentVolumeLabel) SetCloudConfig(cloudConfig []byte) {
 	l.cloudConfig = cloudConfig
 }
 
-func nodeSelectorRequirementKeysExistInNodeSelectorTerms(reqs []api.NodeSelectorRequirement, terms []api.NodeSelectorTerm) bool {
-	for _, req := range reqs {
-		for _, term := range terms {
-			for _, r := range term.MatchExpressions {
-				if r.Key == req.Key {
-					return true
-				}
-			}
-		}
-	}
-	return false
-}
-
 func (l *persistentVolumeLabel) Admit(a admission.Attributes) (err error) {
 	if a.GetResource().GroupResource() != api.Resource("persistentvolumes") {
 		return nil
@@ -123,15 +109,14 @@ func (l *persistentVolumeLabel) Admit(a admission.Attributes) (err error) {
 		}
 		volumeLabels = labels
 	}
-	if volume.Spec.AzureDisk != nil {
-		labels, err := l.findAzureDiskLabels(volume)
+	if volume.Spec.CascadeDisk != nil {
+		labels, err := l.findCascadeDiskLabels(volume)
 		if err != nil {
-			return admission.NewForbidden(a, fmt.Errorf("error querying AzureDisk volume %s: %v", volume.Spec.AzureDisk.DiskName, err))
+			return admission.NewForbidden(a, fmt.Errorf("error querying Cascade volume %s: %v", volume.Spec.CascadeDisk.DiskID, err))
 		}
 		volumeLabels = labels
 	}
 
-	requirements := make([]api.NodeSelectorRequirement, 0)
 	if len(volumeLabels) != 0 {
 		if volume.Labels == nil {
 			volume.Labels = make(map[string]string)
@@ -141,40 +126,6 @@ func (l *persistentVolumeLabel) Admit(a admission.Attributes) (err error) {
 			// This should be OK because they are in the kubernetes.io namespace
 			// i.e. we own them
 			volume.Labels[k] = v
-
-			// Set NodeSelectorRequirements based on the labels
-			var values []string
-			if k == kubeletapis.LabelZoneFailureDomain {
-				zones, err := volumeutil.LabelZonesToSet(v)
-				if err != nil {
-					return admission.NewForbidden(a, fmt.Errorf("failed to convert label string for Zone: %s to a Set", v))
-				}
-				values = zones.UnsortedList()
-			} else {
-				values = []string{v}
-			}
-			requirements = append(requirements, api.NodeSelectorRequirement{Key: k, Operator: api.NodeSelectorOpIn, Values: values})
-		}
-
-		if volume.Spec.NodeAffinity == nil {
-			volume.Spec.NodeAffinity = new(api.VolumeNodeAffinity)
-		}
-		if volume.Spec.NodeAffinity.Required == nil {
-			volume.Spec.NodeAffinity.Required = new(api.NodeSelector)
-		}
-		if len(volume.Spec.NodeAffinity.Required.NodeSelectorTerms) == 0 {
-			// Need at least one term pre-allocated whose MatchExpressions can be appended to
-			volume.Spec.NodeAffinity.Required.NodeSelectorTerms = make([]api.NodeSelectorTerm, 1)
-		}
-		if nodeSelectorRequirementKeysExistInNodeSelectorTerms(requirements, volume.Spec.NodeAffinity.Required.NodeSelectorTerms) {
-			klog.V(4).Infof("NodeSelectorRequirements for cloud labels %v conflict with existing NodeAffinity %v. Skipping addition of NodeSelectorRequirements for cloud labels.",
-				requirements, volume.Spec.NodeAffinity)
-		} else {
-			for _, req := range requirements {
-				for i := range volume.Spec.NodeAffinity.Required.NodeSelectorTerms {
-					volume.Spec.NodeAffinity.Required.NodeSelectorTerms[i].MatchExpressions = append(volume.Spec.NodeAffinity.Required.NodeSelectorTerms[i].MatchExpressions, req)
-				}
-			}
 		}
 	}
 
@@ -255,7 +206,7 @@ func (l *persistentVolumeLabel) findGCEPDLabels(volume *api.PersistentVolume) (m
 }
 
 // getGCECloudProvider returns the GCE cloud provider, for use for querying volume labels
-func (l *persistentVolumeLabel) getGCECloudProvider() (*gce.Cloud, error) {
+func (l *persistentVolumeLabel) getGCECloudProvider() (*gce.GCECloud, error) {
 	l.mutex.Lock()
 	defer l.mutex.Unlock()
 
@@ -268,7 +219,7 @@ func (l *persistentVolumeLabel) getGCECloudProvider() (*gce.Cloud, error) {
 		if err != nil || cloudProvider == nil {
 			return nil, err
 		}
-		gceCloudProvider, ok := cloudProvider.(*gce.Cloud)
+		gceCloudProvider, ok := cloudProvider.(*gce.GCECloud)
 		if !ok {
 			// GetCloudProvider has gone very wrong
 			return nil, fmt.Errorf("error retrieving GCE cloud provider")
@@ -278,44 +229,47 @@ func (l *persistentVolumeLabel) getGCECloudProvider() (*gce.Cloud, error) {
 	return l.gceCloudProvider, nil
 }
 
-// getAzureCloudProvider returns the Azure cloud provider, for use for querying volume labels
-func (l *persistentVolumeLabel) getAzureCloudProvider() (*azure.Cloud, error) {
+func (l *persistentVolumeLabel) findCascadeDiskLabels(volume *api.PersistentVolume) (map[string]string, error) {
+	// Ignore any volumes that are being provisioned
+	if volume.Spec.CascadeDisk.DiskID == vol.ProvisionedVolumeName {
+		return nil, nil
+	}
+	cascadeDisks, err := l.getCascadeDisks()
+	if err != nil {
+		return nil, err
+	}
+	if cascadeDisks == nil {
+		return nil, fmt.Errorf("unable to build Cascade cloud provider for volumes")
+	}
+
+	labels, err := cascadeDisks.GetVolumeLabels(volume.Spec.CascadeDisk.DiskID)
+	if err != nil {
+		return nil, err
+	}
+
+	return labels, nil
+}
+
+// getCascadeDisks returns the Cascade Disks interface
+func (l *persistentVolumeLabel) getCascadeDisks() (cascade.Disks, error) {
 	l.mutex.Lock()
 	defer l.mutex.Unlock()
 
-	if l.azureProvider == nil {
+	if l.cascadeDisks == nil {
 		var cloudConfigReader io.Reader
 		if len(l.cloudConfig) > 0 {
 			cloudConfigReader = bytes.NewReader(l.cloudConfig)
 		}
-		cloudProvider, err := cloudprovider.GetCloudProvider("azure", cloudConfigReader)
+		cloudProvider, err := cloudprovider.GetCloudProvider("vke", cloudConfigReader)
 		if err != nil || cloudProvider == nil {
 			return nil, err
 		}
-		azureProvider, ok := cloudProvider.(*azure.Cloud)
+		provider, ok := cloudProvider.(*cascade.CascadeCloud)
 		if !ok {
 			// GetCloudProvider has gone very wrong
-			return nil, fmt.Errorf("error retrieving Azure cloud provider")
+			return nil, fmt.Errorf("error retrieving Cascade cloud provider")
 		}
-		l.azureProvider = azureProvider
+		l.cascadeDisks = provider
 	}
-
-	return l.azureProvider, nil
-}
-
-func (l *persistentVolumeLabel) findAzureDiskLabels(volume *api.PersistentVolume) (map[string]string, error) {
-	// Ignore any volumes that are being provisioned
-	if volume.Spec.AzureDisk.DiskName == vol.ProvisionedVolumeName {
-		return nil, nil
-	}
-
-	provider, err := l.getAzureCloudProvider()
-	if err != nil {
-		return nil, err
-	}
-	if provider == nil {
-		return nil, fmt.Errorf("unable to build Azure cloud provider for AzureDisk")
-	}
-
-	return provider.GetAzureDiskLabels(volume.Spec.AzureDisk.DataDiskURI)
+	return l.cascadeDisks, nil
 }
diff --git a/plugin/pkg/admission/vke/BUILD b/plugin/pkg/admission/vke/BUILD
new file mode 100644
index 0000000000..530877a443
--- /dev/null
+++ b/plugin/pkg/admission/vke/BUILD
@@ -0,0 +1,61 @@
+package(default_visibility = ["//visibility:public"])
+
+load(
+    "@io_bazel_rules_go//go:def.bzl",
+    "go_library",
+)
+
+go_library(
+    name = "go_default_library",
+    srcs = ["admission.go"],
+    importpath = "k8s.io/kubernetes/plugin/pkg/admission/vke",
+    deps = [
+        "//pkg/apis/core:go_default_library",
+        "//pkg/apis/extensions:go_default_library",
+        "//pkg/apis/policy/v1beta1:go_default_library",
+        "//pkg/apis/rbac:go_default_library",
+        "//pkg/registry/rbac:go_default_library",
+        "//pkg/security/podsecuritypolicy:go_default_library",
+        "//vendor/github.com/golang/glog:go_default_library",
+        "//vendor/k8s.io/api/policy/v1beta1:go_default_library"
+        "//vendor/k8s.io/apimachinery/pkg/api/equality:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/runtime:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/yaml:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/validation/field:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/apis/meta/v1:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/admission:go_default_library",
+    ],
+)
+
+go_test(
+    name = "go_default_test",
+    srcs = ["admission_test.go"],
+    embed = [":go_default_library"],
+    deps = [
+        "//pkg/apis/core:go_default_library",
+        "//pkg/apis/extensions:go_default_library",
+        "//pkg/apis/rbac:go_default_library",
+        "//pkg/registry/rbac:go_default_library",
+        "//pkg/security/podsecuritypolicy:go_default_library",
+        "//vendor/github.com/golang/glog:go_default_library",
+        "//vendor/github.com/stretchr/testify/assert:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/api/equality:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/yaml:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/util/validation/field:go_default_library",
+        "//vendor/k8s.io/apimachinery/pkg/apis/meta/v1:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/admission:go_default_library",
+    ],
+)
+
+filegroup(
+    name = "package-srcs",
+    srcs = glob(["**"]),
+    tags = ["automanaged"],
+    visibility = ["//visibility:private"],
+)
+
+filegroup(
+    name = "all-srcs",
+    srcs = [":package-srcs"],
+    tags = ["automanaged"],
+)
\ No newline at end of file
diff --git a/plugin/pkg/admission/vke/admission.go b/plugin/pkg/admission/vke/admission.go
new file mode 100644
index 0000000000..1998d1d338
--- /dev/null
+++ b/plugin/pkg/admission/vke/admission.go
@@ -0,0 +1,629 @@
+package vke
+
+import (
+	"fmt"
+	"io"
+	"os"
+	"strings"
+
+	"github.com/golang/glog"
+	"k8s.io/api/policy/v1beta1"
+	apiequality "k8s.io/apimachinery/pkg/api/equality"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/util/validation/field"
+	"k8s.io/apimachinery/pkg/util/yaml"
+	"k8s.io/apiserver/pkg/admission"
+	api "k8s.io/kubernetes/pkg/apis/core"
+	"k8s.io/kubernetes/pkg/apis/policy"
+	policybeta "k8s.io/kubernetes/pkg/apis/policy/v1beta1"
+	"k8s.io/kubernetes/pkg/apis/rbac"
+	rbacregistry "k8s.io/kubernetes/pkg/registry/rbac"
+	"k8s.io/kubernetes/pkg/security/podsecuritypolicy"
+)
+
+const (
+	// PluginName indicates name of admission plugin.
+	PluginName = "VMwareAdmissionController"
+
+	systemNodesGroup         = "system:nodes"
+	systemMastersGroup       = "system:masters"
+	systemWorkerGroup        = "system:worker"
+	privilegedNamespace      = "vke-system"
+	privilegedServiceAccount = "system:serviceaccount:" + privilegedNamespace + ":"
+	reservedPrefix           = "vke"
+	reservedTolerationKey    = "Dedicated"
+	reservedTolerationValue  = "Master"
+	masterNodePrefix         = "master"
+	etcSslCerts              = "/etc/ssl/certs"
+)
+
+// Register registers a plugin.
+func Register(plugins *admission.Plugins) {
+	plugins.Register(PluginName, func(config io.Reader) (admission.Interface, error) {
+		return NewVMwareAdmissionController(config)
+	})
+}
+
+// vmwareAdmissionController is an implementation of admission.Interface.
+// It restricts access to VKE namespace for users and prevents the users from creating privileged pods.
+type vmwareAdmissionController struct {
+	psp             *policy.PodSecurityPolicy
+	strategyFactory podsecuritypolicy.StrategyFactory
+	privilegedGroup string
+	clusterID       string
+}
+
+// vmwareAdmissionControllerConfig holds config data for VMwareAdmissionController.
+type vmwareAdmissionControllerConfig struct {
+	ClusterID             string `yaml:"clusterID"`
+	PrivilegedGroup       string `yaml:"privilegedGroup"`
+	PodSecurityPolicyFile string `yaml:"podSecurityPolicyFile"`
+}
+
+// AdmissionConfig holds config data for admission controllers.
+type AdmissionConfig struct {
+	VMwareAdmissionController vmwareAdmissionControllerConfig `yaml:"vmwareAdmissionController"`
+}
+
+var _ admission.MutationInterface = &vmwareAdmissionController{}
+var _ admission.ValidationInterface = &vmwareAdmissionController{}
+
+// Admit makes an admission decision based on the request attributes.
+// Note: We implement the mutation interface for this admission controller, which means we have the ability to modify
+// the resources. But we do not modify them because we just need to validate the requests to either let them through or
+// block them. We have implemented this mutation interface because we need access to oldObjects during update operations
+// to find out what values are being modified. For node update operation, the old and new objects are always identical
+// in the validation phase (possibly due to some initializer modifying it). So, we are performing this specific
+// vaidation during the mutation phase.
+func (vac *vmwareAdmissionController) Admit(a admission.Attributes) (err error) {
+	if isPrivilegedServiceAccount(a) {
+		return validatePrivilegedServiceAccount(a)
+	}
+
+	return err
+}
+
+// Validate makes an admission decision based on the request attributes.
+func (vac *vmwareAdmissionController) Validate(a admission.Attributes) (err error) {
+	if isPrivilegedUser(vac, a) {
+		return nil
+	}
+
+	if isCertificateFromMaster(a) {
+		return validateCertificateFromMaster(vac, a)
+	}
+
+	if isCertificateFromWorker(a) {
+		return validateCertificateFromWorker(a)
+	}
+
+	if isPrivilegedServiceAccount(a) {
+		return validatePrivilegedServiceAccount(a)
+	}
+
+	if isPrivilegedNamespace(a) {
+		return admission.NewForbidden(a,
+			fmt.Errorf("%s validation failed: cannot modify resources in namespace %s", PluginName, a.GetNamespace()))
+	}
+
+	switch a.GetResource().GroupResource() {
+	case api.Resource("pods"):
+		err = validatePods(vac, a)
+	case api.Resource("nodes"):
+		err = validateNodes(a)
+	case rbac.Resource("clusterroles"):
+		err = validateClusterRoles(a)
+	case rbac.Resource("clusterrolebindings"):
+		err = validateClusterRoleBindings(a)
+	}
+
+	return err
+}
+
+// Handles returns true if this admission controller can handle the given operation
+// where operation can be one of CREATE, UPDATE, DELETE, or CONNECT.
+func (vac *vmwareAdmissionController) Handles(operation admission.Operation) bool {
+	return true
+}
+
+// NewVMwareAdmissionController creates a new VMwareAdmissionController.
+func NewVMwareAdmissionController(configFile io.Reader) (*vmwareAdmissionController, error) {
+	glog.V(2).Infof("%s is enabled", PluginName)
+	if configFile == nil {
+		glog.Warningf("No config specified for %s. Using default configuration", PluginName)
+		return nil, fmt.Errorf("no config file specified for %s", PluginName)
+	}
+
+	var config AdmissionConfig
+	d := yaml.NewYAMLOrJSONDecoder(configFile, 4096)
+	err := d.Decode(&config)
+	if err != nil {
+		return nil, err
+	}
+
+	// Load PSP from file. If it fails, use default.
+	psp := getPSPFromFile(config.VMwareAdmissionController.PodSecurityPolicyFile)
+	if psp == nil {
+		psp = getDefaultPSP()
+	}
+
+	return &vmwareAdmissionController{
+		psp:             psp,
+		strategyFactory: podsecuritypolicy.NewSimpleStrategyFactory(),
+		privilegedGroup: config.VMwareAdmissionController.PrivilegedGroup,
+		clusterID:       config.VMwareAdmissionController.ClusterID,
+	}, nil
+}
+
+func getDefaultPSP() *policy.PodSecurityPolicy {
+	return &policy.PodSecurityPolicy{
+		TypeMeta: metav1.TypeMeta{
+			Kind:       "PodSecurityPolicy",
+			APIVersion: "policy/v1beta1",
+		},
+		Spec: policy.PodSecurityPolicySpec{
+			Privileged:               false,
+			HostNetwork:              false,
+			HostIPC:                  false,
+			HostPID:                  false,
+			AllowPrivilegeEscalation: false,
+			HostPorts: []policy.HostPortRange{
+				{1, 65535},
+			},
+			Volumes: []policy.FSType{
+				"emptyDir",
+				"secret",
+				"downwardAPI",
+				"configMap",
+				"persistentVolumeClaim",
+				"projected",
+				"hostPath",
+			},
+			// We allow /etc/ssl/certs to be mounted in read only mode as a hack to allow Wavefront pods to be deployed.
+			// TODO(ashokc): Once we have support for users to create pods using privileged mode and host path, remove this.
+			AllowedHostPaths: []policy.AllowedHostPath{
+				{
+					PathPrefix: etcSslCerts,
+					ReadOnly:   true,
+				},
+			},
+			FSGroup: policy.FSGroupStrategyOptions{
+				Rule: policy.FSGroupStrategyRunAsAny,
+			},
+			RunAsUser: policy.RunAsUserStrategyOptions{
+				Rule: policy.RunAsUserStrategyRunAsAny,
+			},
+			SELinux: policy.SELinuxStrategyOptions{
+				Rule: policy.SELinuxStrategyRunAsAny,
+			},
+			SupplementalGroups: policy.SupplementalGroupsStrategyOptions{
+				Rule: policy.SupplementalGroupsStrategyRunAsAny,
+			},
+		},
+	}
+}
+
+func getPSPFromFile(pspFile string) *policy.PodSecurityPolicy {
+	pspBeta := v1beta1.PodSecurityPolicy{}
+	pspExtensions := policy.PodSecurityPolicy{}
+
+	if pspFile == "" {
+		glog.V(2).Infof("%s: PSP file not specified, using default PSP", PluginName)
+		return nil
+	}
+
+	pspConfig, err := os.Open(pspFile)
+	if err != nil {
+		glog.V(2).Infof("%s: cannot open PSP file, using default PSP: %v", PluginName, err)
+		return nil
+	}
+
+	// We load the PSP that we read from file into pspBeta because this is the struct to which we can decode yaml to.
+	d := yaml.NewYAMLOrJSONDecoder(pspConfig, 4096)
+	err = d.Decode(&pspBeta)
+	if err != nil {
+		glog.V(2).Infof("%s: cannot decode PSP file, using default PSP: %v", PluginName, err)
+		return nil
+	}
+
+	// We convert pspBeta object into pspExtensions object because this is the one that pod validation uses.
+	err = policybeta.Convert_v1beta1_PodSecurityPolicy_To_policy_PodSecurityPolicy(&pspBeta, &pspExtensions, nil)
+	if err != nil {
+		glog.V(2).Infof("%s: cannot convert v1beta1.PSP to extensions.PSP, using default PSP: %v", PluginName, err)
+		return nil
+	}
+
+	return &pspExtensions
+}
+
+func isPrivilegedUser(vac *vmwareAdmissionController, a admission.Attributes) bool {
+	// If the request comes from a user belonging to a privileged group, then we allow it. Only calls from Cascade
+	// controller will belong to this privileged group.
+	groups := a.GetUserInfo().GetGroups()
+	for _, group := range groups {
+		if group == vac.privilegedGroup {
+			return true
+		}
+	}
+
+	return false
+}
+
+func isCertificateFromMaster(a admission.Attributes) bool {
+	groups := a.GetUserInfo().GetGroups()
+	for _, group := range groups {
+		if group == systemMastersGroup {
+			return true
+		}
+	}
+	return false
+}
+
+func validateCertificateFromMaster(vac *vmwareAdmissionController, a admission.Attributes) (err error) {
+	// kube-controller-manager, kube-scheduler and cloud-init script which creates our pods and other resources can use
+	// the master certificate to create pods in privileged namespace. If the request comes to any other namespace,
+	// we need to make it go through our pod validation. This is needed because a user can create a deployment or
+	// replica set which has a privileged pod. Since our admission controller does not look at deployments or replica
+	// sets, we will allow it. The actual pod inside the deployment or replica set will be created by the
+	// controller-manager and if we allow it to create pods in any namespace, then a user can create a privileged pod
+	// totally bypassing our security checks.
+	if !isPrivilegedNamespace(a) && (a.GetResource().GroupResource() == api.Resource("pods")) {
+		return validatePods(vac, a)
+	}
+
+	// For all other resources, allow.
+	return nil
+}
+
+func isCertificateFromWorker(a admission.Attributes) bool {
+	groups := a.GetUserInfo().GetGroups()
+	for _, group := range groups {
+		if group == systemWorkerGroup {
+			return true
+		}
+	}
+	return false
+}
+
+func isCreatingPodsThroughControllerManager(resource string) bool {
+	// If the resource is one of the following, it means the controller manager will create a pod for them and not the
+	// user directly. So, we need to identify these cases and block them in certain scenarios.
+	if resource == "deployments" ||
+		resource == "replicasets" ||
+		resource == "replicationcontrollers" ||
+		resource == "statefulsets" ||
+		resource == "daemonsets" ||
+		resource == "jobs" ||
+		resource == "cronjobs" {
+		return true
+	}
+	return false
+}
+
+func validateCertificateFromWorker(a admission.Attributes) error {
+	// Block exec operations into pods for workers. This is needed to block someone from using Kubelet's certificate to
+	// exec into privileged pods running on the master. Other operations with the node certificate like modifying master
+	// node, creating pods on master node, etc. are blocked by the node restriction admission controller.
+	resource := a.GetResource().GroupResource()
+	if resource == api.Resource("pods") && a.GetOperation() == admission.Connect {
+		return admission.NewForbidden(a,
+			fmt.Errorf("%s validation failed: cannot modify pods in namespace %s", PluginName, a.GetNamespace()))
+	}
+
+	// Block creation of pods indirectly by going through the controller manager.
+	if isCreatingPodsThroughControllerManager(resource.Resource) {
+		return admission.NewForbidden(a,
+			fmt.Errorf("%s validation failed: cannot modify %s in namespace %s", PluginName, resource.Resource, a.GetNamespace()))
+	}
+
+	return nil
+}
+
+func isPrivilegedNamespace(a admission.Attributes) bool {
+	// If the namespace mentioned in the resource is privileged, return true. We will hit this for calls made to all
+	// resources in this namespace and during delete and update operation on the namespace itself.
+	if a.GetNamespace() == privilegedNamespace {
+		return true
+	}
+
+	// If the resource is a namespace and if its name matched the privileged namespace, return true. We will hit this
+	// during creation of the namespace.
+	if a.GetResource().GroupResource() == api.Resource("namespaces") {
+		if namespace, ok := a.GetObject().(*api.Namespace); ok {
+			if namespace.Name == privilegedNamespace {
+				return true
+			}
+		}
+	}
+
+	return false
+}
+
+func isPrivilegedServiceAccount(a admission.Attributes) bool {
+	user := a.GetUserInfo().GetName()
+	return strings.HasPrefix(user, privilegedServiceAccount)
+}
+
+func validatePrivilegedServiceAccount(a admission.Attributes) error {
+	// If the privileged service account performs any operation on the pods resource like create, update or connect,
+	// we block it. This is needed so that we can block exec access into privileged pods running on the master. Also,
+	// privileged service account does not need to perform these operations. So, just to be extra cautious we also block
+	// off create and update pods.
+	resource := a.GetResource().GroupResource()
+	if resource == api.Resource("pods") {
+		// Allow Delete operation on pods
+		if a.GetOperation() == admission.Delete {
+			return nil
+		}
+		// Allow subresources other than exec on pods
+		if len(a.GetSubresource()) != 0 && a.GetSubresource() != "exec" {
+			return nil
+		}
+		// Block all other operations
+		if a.GetOperation() == admission.Create || a.GetOperation() == admission.Update || a.GetOperation() == admission.Connect {
+			return admission.NewForbidden(a,
+				fmt.Errorf("%s validation failed: cannot modify pods in namespace %s", PluginName, a.GetNamespace()))
+		}
+	}
+
+	// If the privileged service account tries to update taints on the master node, we block. We need to do this so that
+	// a user cannot use a privileged service account to untaint the node and run pods on a master.
+	if resource == api.Resource("nodes") {
+		if a.GetOperation() == admission.Update && strings.HasPrefix(a.GetName(), masterNodePrefix) {
+			node, ok := a.GetObject().(*api.Node)
+			if !ok {
+				return admission.NewForbidden(a,
+					fmt.Errorf("%s validation failed: unexpected type %T", PluginName, a.GetObject()))
+			}
+			oldNode, ok := a.GetOldObject().(*api.Node)
+			if !ok {
+				return admission.NewForbidden(a,
+					fmt.Errorf("%s validation failed: unexpected type %T", PluginName, a.GetOldObject()))
+			}
+
+			if !apiequality.Semantic.DeepEqual(node.Spec.Taints, oldNode.Spec.Taints) {
+				return admission.NewForbidden(a,
+					fmt.Errorf("%s validation failed: cannot modify taints on a node", PluginName))
+			}
+		}
+	}
+
+	// Block creation of pods indirectly by going through the controller manager.
+	if isCreatingPodsThroughControllerManager(resource.Resource) {
+		return admission.NewForbidden(a,
+			fmt.Errorf("%s validation failed: cannot modify %s in namespace %s", PluginName, resource.Resource, a.GetNamespace()))
+	}
+
+	return nil
+}
+
+func validateNodes(a admission.Attributes) error {
+	// If it is a connect operation on the sub resource, allow it. Sub resources of nodes are nodes/nodename/proxy and
+	// nodes/nodename/status. Prometheus needs read access to nodes/nodename/proxy/metrics. To support that and other
+	// pods which might need read access to node metrics, we need to allow this. But the VKE authorizer blocks off any
+	// access to perform exec, attach or run on the proxy resource on a master which will prevent the users from getting
+	// access to the privileged pods on master.
+	if a.GetOperation() == admission.Connect && len(a.GetSubresource()) != 0 {
+		return nil
+	}
+
+	// If the operation is Delete, fail. Deleting a node is not something that is useful to the user. Also, by deleting
+	// a node, they can potentially make their cluster useless.
+	if a.GetOperation() == admission.Delete {
+		return admission.NewForbidden(a, fmt.Errorf("%s validation failed: cannot delete nodes", PluginName))
+	}
+
+	// If the operation is on a master node, fail. We do not want to allow the users to modify labels and taints on the
+	// master node because it can compromise the security of the cluster.
+	if strings.HasPrefix(a.GetName(), masterNodePrefix) {
+		return admission.NewForbidden(a, fmt.Errorf("%s validation failed: cannot modify master nodes", PluginName))
+	}
+
+	return nil
+}
+
+func validateClusterRoles(a admission.Attributes) error {
+	// If the name in the request is not empty and has the reserved prefix, then fail. We will hit this during delete
+	// and update operations on the cluster roles. If it does not have the reserved prefix, allow it. If the name is
+	// empty then proceed to read it from the object in the request.
+	if a.GetName() != "" {
+		return checkReservedPrefix(a.GetName(), a)
+	}
+
+	clusterRole, ok := a.GetObject().(*rbac.ClusterRole)
+	// If we cannot get the cluster role binding object, fail.
+	if !ok {
+		return admission.NewForbidden(a,
+			fmt.Errorf("%s validation failed: unexpected type %T", PluginName, a.GetObject()))
+	}
+	// If we get the object and the name has the reserved prefix, fail. We will hit this when someone tries to create a
+	// cluster role with the reserved prefix.
+	return checkReservedPrefix(clusterRole.Name, a)
+}
+
+func validateClusterRoleBindings(a admission.Attributes) error {
+	// If the name in the request is not empty and has the reserved prefix, then fail. We will hit this during delete
+	// and update operations on the cluster role bindings. If it does not have the reserved prefix, allow it. If the
+	// name is empty then proceed to read it from the object in the request.
+	if a.GetName() != "" {
+		return checkReservedPrefix(a.GetName(), a)
+	}
+
+	clusterRoleBinding, ok := a.GetObject().(*rbac.ClusterRoleBinding)
+	// If we cannot get the cluster role binding object, fail.
+	if !ok {
+		return admission.NewForbidden(a,
+			fmt.Errorf("%s validation failed: unexpected type %T", PluginName, a.GetObject()))
+	}
+	// If we get the object and the name has the reserved prefix, fail. We will hit this when someone tries to create a
+	// cluster role binding with the reserved prefix.
+	return checkReservedPrefix(clusterRoleBinding.Name, a)
+}
+
+func validatePods(vac *vmwareAdmissionController, a admission.Attributes) error {
+	// If the request is acting on a sub resource of a pod then allow it. This request is not directly coming to a pod,
+	// but to a sub-resource like pods/foo/status. So, this does not have to be blocked.
+	if len(a.GetSubresource()) != 0 {
+		return nil
+	}
+
+	// If it is a Connect or Delete operation, allow it. We restrict access to connect to any pods in the vke-system
+	// namespace. So it is OK to allow this.
+	if a.GetOperation() == admission.Connect || a.GetOperation() == admission.Delete {
+		return nil
+	}
+
+	// If we cannot get the pod object, fail.
+	if _, ok := a.GetObject().(*api.Pod); !ok {
+		return admission.NewForbidden(a,
+			fmt.Errorf("%s validation failed: unexpected type %T", PluginName, a.GetObject()))
+	}
+
+	// If this is an update, see if we are only updating the ownerRef/finalizers.  Garbage collection does this
+	// and we should allow it in general, since you had the power to update and the power to delete.
+	// The worst that happens is that you delete something, but you aren't controlling the privileged object itself
+	if a.GetOperation() == admission.Update &&
+		rbacregistry.IsOnlyMutatingGCFields(a.GetObject(), a.GetOldObject(), apiequality.Semantic) {
+		return nil
+	}
+
+	errs := field.ErrorList{}
+	originalPod := a.GetObject().(*api.Pod)
+
+	// Generate a copy of the pod object because we are not allowed to mutate the pod object.
+	pod := originalPod.DeepCopy()
+
+	provider, err := podsecuritypolicy.NewSimpleProvider(vac.psp, pod.Namespace, vac.strategyFactory)
+	if err != nil {
+		return admission.NewForbidden(a, fmt.Errorf("%s validation failed: %v", PluginName, err))
+	}
+
+	// Set default security context for the pod. This fills in the defaults for the security context values that are not
+	// provided. This is needed to validate the security context correctly.
+	err = provider.DefaultPodSecurityContext(pod)
+	if err != nil {
+		errs = append(errs, field.Invalid(field.NewPath("spec", "securityContext"),
+			pod.Spec.SecurityContext, err.Error()))
+	}
+
+	// Validate the pod.
+	errs = append(errs, provider.ValidatePod(pod, field.NewPath("spec", "securityContext"))...)
+
+	// Validate the pod's tolerations.
+	fieldErr := validatePodToleration(pod)
+	if fieldErr != nil {
+		errs = append(errs, fieldErr)
+	}
+
+	// Validate the initContainers that are part of the pod.
+	for i := range pod.Spec.InitContainers {
+		err := provider.DefaultContainerSecurityContext(pod, &pod.Spec.InitContainers[i])
+		if err != nil {
+			errs = append(errs, field.Invalid(field.NewPath("spec", "initContainers").Index(i).
+				Child("securityContext"), "", err.Error()))
+			continue
+		}
+		errs = append(errs, provider.ValidateContainerSecurityContext(pod, &pod.Spec.InitContainers[i],
+			field.NewPath("spec", "initContainers").Index(i).Child("securityContext"))...)
+	}
+
+	// Validate the containers that are part of the pod.
+	for i := range pod.Spec.Containers {
+		err := provider.DefaultContainerSecurityContext(pod, &pod.Spec.Containers[i])
+		if err != nil {
+			errs = append(errs, field.Invalid(field.NewPath("spec", "containers").Index(i).
+				Child("securityContext"), "", err.Error()))
+			continue
+		}
+		errs = append(errs, provider.ValidateContainerSecurityContext(pod, &pod.Spec.Containers[i],
+			field.NewPath("spec", "containers").Index(i).Child("securityContext"))...)
+	}
+
+	// Validate that /etc/ssl/certs if mounted using hostPath volume mount is readOnly.
+	fieldErr = validateEtcSslCertsHostPath(pod)
+	if fieldErr != nil {
+		errs = append(errs, fieldErr)
+	}
+
+	if len(errs) > 0 {
+		return admission.NewForbidden(a,
+			fmt.Errorf("%s validation failed: %v", PluginName, errs))
+	}
+
+	return nil
+}
+
+func validatePodToleration(pod *api.Pod) *field.Error {
+	// Master nodes are tainted with "Dedicated=Master:NoSchedule". Only vke-system pods are allowed to tolerate
+	// this taint and to run on master nodes. A user's pod will be rejected if its spec has toleration for this taint.
+	for _, t := range pod.Spec.Tolerations {
+		reject := false
+
+		if t.Key == reservedTolerationKey && t.Value == reservedTolerationValue {
+			// Reject pod that has the reserved toleration "Dedicated=Master"
+			reject = true
+		} else if t.Operator == api.TolerationOpExists && (t.Key == reservedTolerationKey || t.Key == "") {
+			// Reject pod that has wildcard toleration matching the reserved toleration
+			reject = true
+		}
+
+		if reject {
+			return field.Invalid(field.NewPath("spec", "toleration"), fmt.Sprintf("%+v", t),
+				fmt.Sprintf("%s validation failed: should not tolerate master node taint", PluginName))
+		}
+	}
+	return nil
+}
+
+// Validate that /etc/ssl/certs if mounted using hostPath volume mount is readOnly. If not, fail.
+// This is a hack that is needed to get Wavefront pods to work.
+// TODO(ashokc): Once we have support for users to create pods using privileged mode and host path, remove this.
+func validateEtcSslCertsHostPath(pod *api.Pod) *field.Error {
+	// Get volumes which mount /etc/ssl/certs and put them in a map.
+	volumes := map[string]struct{}{}
+	for _, vol := range pod.Spec.Volumes {
+		if vol.HostPath != nil && strings.HasPrefix(vol.HostPath.Path, etcSslCerts) {
+			volumes[vol.Name] = struct{}{}
+		}
+	}
+
+	// For every initContainer, get all volumeMounts and verify if it matches any of the volumes in the volumes map.
+	// If yes, then check if they are read only. If not, return an error.
+	err := checkVolumeReadOnly(pod.Spec.InitContainers, volumes, "initContainers")
+	if err != nil {
+		return err
+	}
+
+	// For every container, get all volumeMounts and verify if it matches any of the volumes in the volumes map.
+	// If yes, then check if they are read only. If not, return an error.
+	err = checkVolumeReadOnly(pod.Spec.Containers, volumes, "containers")
+	if err != nil {
+		return err
+	}
+
+	return nil
+}
+
+// Checks if the container has a volumeMount belonging to the volumes map. If yes, it has to be read only. If not,
+// return error.
+func checkVolumeReadOnly(containers []api.Container, volumes map[string]struct{}, containerType string) *field.Error {
+	for i, container := range containers {
+		for _, vol := range container.VolumeMounts {
+			if _, ok := volumes[vol.Name]; ok {
+				if !vol.ReadOnly {
+					return field.Invalid(field.NewPath("spec", containerType).Index(i).Child("volumeMounts"),
+						fmt.Sprintf("%+v", vol), fmt.Sprintf("%s has to be mount as readOnly", etcSslCerts))
+				}
+			}
+		}
+	}
+	return nil
+}
+
+func checkReservedPrefix(resourceName string, a admission.Attributes) error {
+	if strings.HasPrefix(resourceName, reservedPrefix) {
+		return admission.NewForbidden(a,
+			fmt.Errorf("%s validation failed: cannot modify resources with prefix %s", PluginName, reservedPrefix))
+	}
+	return nil
+}
diff --git a/plugin/pkg/admission/vke/admission_test.go b/plugin/pkg/admission/vke/admission_test.go
new file mode 100644
index 0000000000..689a22dfa4
--- /dev/null
+++ b/plugin/pkg/admission/vke/admission_test.go
@@ -0,0 +1,960 @@
+package vke
+
+import (
+	"fmt"
+	"os"
+	"strings"
+	"testing"
+
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/runtime"
+	kadmission "k8s.io/apiserver/pkg/admission"
+	kapi "k8s.io/kubernetes/pkg/apis/core"
+	"k8s.io/kubernetes/pkg/apis/rbac"
+	"k8s.io/kubernetes/staging/src/k8s.io/apiserver/pkg/authentication/user"
+)
+
+const (
+	testServiceAccountsGroup = "system.test\\cascade-controller-service-accounts"
+	clusterID                = "cluster-id"
+	defaultConfigFileFormat  = `
+vmwareAdmissionController:
+  privilegedGroup: %s
+  podSecurityPolicyFile: %s
+  clusterID: %s
+`
+	pspFileName   = "/tmp/psp.yaml"
+	pspConfigFile = `
+apiVersion: extensions/v1beta1
+kind: PodSecurityPolicy
+metadata:
+  name: vmware-pod-security-policy-restricted
+spec:
+  privileged: true
+  fsGroup:
+    rule: RunAsAny
+  runAsUser:
+    rule: RunAsAny
+  seLinux:
+    rule: RunAsAny
+  supplementalGroups:
+    rule: RunAsAny
+  volumes:
+  - 'emptyDir'
+  - 'secret'
+  - 'downwardAPI'
+  - 'configMap'
+  - 'persistentVolumeClaim'
+  - 'projected'
+  - 'hostPath'
+  hostPID: false
+  hostIPC: false
+  hostNetwork: true
+  hostPorts:
+  - min: 1
+    max: 65536
+`
+)
+
+func TestAdmitPrivileged(t *testing.T) {
+	tests := map[string]struct {
+		operation          kadmission.Operation
+		pod                *kapi.Pod
+		name               string
+		userInfo           user.Info
+		shouldPassValidate bool
+	}{
+		"create pod with Privileged=nil allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with Privileged=false allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withPrivileged(false).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with Privileged=true denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withPrivileged(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with multiple containers, one has Privileged=true denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withPrivileged(true).withInitContainer().withContainer().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"update pod with Privileged=true denied": {
+			operation:          kadmission.Update,
+			pod:                newTestPodBuilder().withPrivileged(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with HostNetwork=true denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostNetwork(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with HostIPC=true denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostIPC(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with HostPID=true denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostPID(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with HostPort allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostPort().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with HostVolume denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostVolume("/", false).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with HostVolume /etc/ssl/certs in read-only mode allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostVolume("/etc/ssl/certs", true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with HostVolume /etc/ssl/certs in read-write mode denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostVolume("/etc/ssl/certs", false).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with CascadeDisk allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withCascadeDisk().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with HostVolume and CascadeDisk denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostVolume("/", false).withCascadeDisk().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"connect pod allowed": {
+			operation:          kadmission.Connect,
+			pod:                newTestPodBuilder().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"delete pod allowed": {
+			operation:          kadmission.Delete,
+			pod:                nil,
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+	}
+
+	for k, v := range tests {
+		testPodValidation(k, v.operation, v.pod, v.name, v.userInfo, v.shouldPassValidate, t)
+	}
+}
+
+func TestAdmitPrivilegedWithCustomPSP(t *testing.T) {
+	tests := map[string]struct {
+		operation          kadmission.Operation
+		pod                *kapi.Pod
+		name               string
+		userInfo           user.Info
+		shouldPassValidate bool
+	}{
+		"create pod with Privileged=nil allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with Privileged=false allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withPrivileged(false).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with Privileged=true allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withPrivileged(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with multiple containers, one has Privileged=true allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withPrivileged(true).withInitContainer().withContainer().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"update pod with Privileged=true allowed": {
+			operation:          kadmission.Update,
+			pod:                newTestPodBuilder().withPrivileged(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with HostNetwork=true allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostNetwork(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with HostIPC=true denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostIPC(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with HostPID=true denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostPID(true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with HostPort allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostPort().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with HostVolume allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostVolume("/", false).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with HostVolume /etc/ssl/certs in read-only mode allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostVolume("/etc/ssl/certs", true).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with HostVolume /etc/ssl/certs in read-write mode denied": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostVolume("/etc/ssl/certs", false).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"create pod with CascadeDisk allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withCascadeDisk().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"create pod with HostVolume and CascadeDisk allowed": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withHostVolume("/", false).withCascadeDisk().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"connect pod allowed": {
+			operation:          kadmission.Connect,
+			pod:                newTestPodBuilder().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"delete pod allowed": {
+			operation:          kadmission.Delete,
+			pod:                nil,
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+	}
+
+	// Setup custom PSP file.
+	file, err := os.Create(pspFileName)
+	if err != nil {
+		t.Errorf("TestAdmitPrivilegedWithCustomPSP: failed to open custom PSP file %v", err)
+		return
+	}
+	_, err = file.WriteString(pspConfigFile)
+	if err != nil {
+		t.Errorf("TestAdmitPrivilegedWithCustomPSP: failed to write to custom PSP file %v", err)
+		return
+	}
+
+	for k, v := range tests {
+		testPodValidation(k, v.operation, v.pod, v.name, v.userInfo, v.shouldPassValidate, t)
+	}
+
+	// Delete custom PSP file.
+	err = os.Remove(pspFileName)
+	if err != nil {
+		t.Errorf("TestAdmitPrivilegedWithCustomPSP: failed to delete custom PSP file %v", err)
+	}
+}
+
+func TestPrivilegedNamespace(t *testing.T) {
+	tests := map[string]struct {
+		operation          kadmission.Operation
+		pod                *kapi.Pod
+		name               string
+		userInfo           user.Info
+		shouldPassValidate bool
+	}{
+		"denied: regular lightwave user creates pod in vke-system namespace": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user cannot escalate privilege using service account": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).withServiceAccount(privilegedServiceAccount + "default").build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular service account creates pod in vke-system namespace": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().withName("system:serviceaccount:kube-system:default").build(),
+			shouldPassValidate: false,
+		},
+		"allowed: privileged service account deletes a pod in privileged namespace": {
+			operation:          kadmission.Delete,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().withName(privilegedServiceAccount + "default").build(),
+			shouldPassValidate: true,
+		},
+		"denied: privileged service account creates a pod in privileged namespace": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().withName(privilegedServiceAccount + "default").build(),
+			shouldPassValidate: false,
+		},
+		"denied: privileged service account execs into a pod in privileged namespace": {
+			operation:          kadmission.Connect,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().withName(privilegedServiceAccount + "default").build(),
+			shouldPassValidate: false,
+		},
+		"denied: privileged service account updates a pod in privileged namespace": {
+			operation:          kadmission.Update,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().withName(privilegedServiceAccount + "default").build(),
+			shouldPassValidate: false,
+		},
+		"allowed: regular user creates pod in other namespace": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withNamespace("default").build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"allowed: Cascade Controller Service Account creates pod in vke-system namespace": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().withGroup(testServiceAccountsGroup).build(),
+			shouldPassValidate: true,
+		},
+		"allowed: systemMasters group creates pod in vke-system namespace": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().withGroup(systemMastersGroup).build(),
+			shouldPassValidate: true,
+		},
+		"denied: regular lightwave group does not grant privileged access": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().withGroup("test1\\group1").build(),
+			shouldPassValidate: false,
+		},
+		"allowed: if user has multiple groups, any privileged group can grant privileged access": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withNamespace(privilegedNamespace).build(),
+			userInfo:           newTestUserBuilder().withGroup("test1\\group1").withGroup(testServiceAccountsGroup).build(),
+			shouldPassValidate: true,
+		},
+		"denied: worker kubelet exec into pod": {
+			operation:          kadmission.Connect,
+			pod:                newTestPodBuilder().build(),
+			userInfo:           newTestUserBuilder().withGroup("system:worker").build(),
+			shouldPassValidate: false,
+		},
+	}
+	for k, v := range tests {
+		testPodValidation(k, v.operation, v.pod, v.name, v.userInfo, v.shouldPassValidate, t)
+	}
+}
+
+func TestToleration(t *testing.T) {
+	tests := map[string]struct {
+		operation          kadmission.Operation
+		pod                *kapi.Pod
+		name               string
+		userInfo           user.Info
+		shouldPassValidate bool
+	}{
+		"allowed: create pod with no toleration": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"allowed: create pod with normal toleration key": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withToleration("mykey", reservedTolerationValue, kapi.TolerationOpEqual, kapi.TaintEffectNoSchedule).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"allowed: create pod with normal toleration value": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withToleration(reservedTolerationKey, "myval", kapi.TolerationOpEqual, kapi.TaintEffectNoSchedule).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"denied: create pod with reserved toleration": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withToleration(reservedTolerationKey, reservedTolerationValue, kapi.TolerationOpEqual, kapi.TaintEffectNoSchedule).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: create pod with wildcard toleration": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withToleration("", "", kapi.TolerationOpExists, "").build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: create pod with value wildcard toleration": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withToleration(reservedTolerationKey, "", kapi.TolerationOpExists, kapi.TaintEffectNoSchedule).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"allowed: create pod with value wildcard and normal key": {
+			operation:          kadmission.Create,
+			pod:                newTestPodBuilder().withToleration("mykey", "", kapi.TolerationOpExists, kapi.TaintEffectNoSchedule).build(),
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+	}
+
+	for k, v := range tests {
+		testPodValidation(k, v.operation, v.pod, v.name, v.userInfo, v.shouldPassValidate, t)
+	}
+}
+
+func TestClusterLevelResources(t *testing.T) {
+	tests := map[string]struct {
+		operation          kadmission.Operation
+		resource           string
+		subresource        string
+		name               string
+		namespace          string
+		userInfo           user.Info
+		object             runtime.Object
+		oldObject          runtime.Object
+		shouldPassValidate bool
+	}{
+		"denied: regular lightwave user update configmaps in vke-system namespace": {
+			operation:          kadmission.Update,
+			resource:           "configmaps",
+			namespace:          privilegedNamespace,
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user delete daemonsets in vke-system namespace": {
+			operation:          kadmission.Delete,
+			resource:           "daemonsets",
+			namespace:          privilegedNamespace,
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user create deployments in vke-system namespace": {
+			operation:          kadmission.Create,
+			resource:           "deployments",
+			namespace:          privilegedNamespace,
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user create rolebindings in vke-system namespace": {
+			operation:          kadmission.Create,
+			resource:           "rolebindings",
+			namespace:          privilegedNamespace,
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"allowed: regular lightwave user create rolebindings in other namespace": {
+			operation:          kadmission.Create,
+			resource:           "rolebindings",
+			namespace:          "default",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"allowed: regular lightwave user create clusterroles": {
+			operation:          kadmission.Create,
+			resource:           "clusterroles",
+			name:               "cluster-role",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"denied: regular lightwave user create clusterroles with vke: prefix": {
+			operation:          kadmission.Create,
+			resource:           "clusterroles",
+			name:               "vke:clusterrole",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user delete clusterroles with vke: prefix": {
+			operation:          kadmission.Delete,
+			resource:           "clusterroles",
+			name:               "vke:clusterrole",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"allowed: systemMasters group update clusterroles with vke: prefix": {
+			operation:          kadmission.Update,
+			resource:           "clusterroles",
+			name:               "vke:clusterrole",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().withGroup(systemMastersGroup).build(),
+			shouldPassValidate: true,
+		},
+		"allowed: regular lightwave user create clusterrolebindings": {
+			operation:          kadmission.Create,
+			resource:           "clusterrolebindings",
+			name:               "cluster-role-binding",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"denied: regular lightwave user create clusterrolebindings with vke: prefix": {
+			operation:          kadmission.Create,
+			resource:           "clusterrolebindings",
+			name:               "vke:clusterrolebinding",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user update clusterrolebindings with vke: prefix": {
+			operation:          kadmission.Delete,
+			resource:           "clusterrolebindings",
+			name:               "vke:clusterrolebinding",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"allowed: systemMastersGroup update clusterrolebindings with vke: prefix": {
+			operation:          kadmission.Update,
+			resource:           "clusterrolebindings",
+			name:               "vke:clusterrolebinding",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().withGroup(systemMastersGroup).build(),
+			shouldPassValidate: true,
+		},
+		"allowed: regular lightwave user update worker nodes": {
+			operation:          kadmission.Update,
+			resource:           "nodes",
+			name:               "worker-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"allowed: regular lightwave user get worker nodes proxy subresource": {
+			operation:          kadmission.Connect,
+			resource:           "nodes",
+			subresource:        "proxy",
+			name:               "worker-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"allowed: regular lightwave user patch worker nodes proxy subresource": {
+			operation:          kadmission.Update,
+			resource:           "nodes",
+			subresource:        "proxy",
+			name:               "worker-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"allowed: regular lightwave user create worker nodes proxy subresource": {
+			operation:          kadmission.Create,
+			resource:           "nodes",
+			subresource:        "proxy",
+			name:               "worker-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"allowed: regular lightwave user get master nodes proxy subresource": {
+			operation:          kadmission.Connect,
+			resource:           "nodes",
+			subresource:        "proxy",
+			name:               "master-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: true,
+		},
+		"denied: regular lightwave user patch master nodes proxy subresource": {
+			operation:          kadmission.Update,
+			resource:           "nodes",
+			subresource:        "proxy",
+			name:               "master-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user create master nodes proxy subresource": {
+			operation:          kadmission.Create,
+			resource:           "nodes",
+			subresource:        "proxy",
+			name:               "master-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user update master nodes": {
+			operation:          kadmission.Update,
+			resource:           "nodes",
+			name:               "master-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user delete master nodes": {
+			operation:          kadmission.Delete,
+			resource:           "nodes",
+			name:               "master-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"denied: regular lightwave user delete worker nodes": {
+			operation:          kadmission.Delete,
+			resource:           "nodes",
+			name:               "worker-guid",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().build(),
+			shouldPassValidate: false,
+		},
+		"allowed: systemMasters group update nodes": {
+			operation:          kadmission.Update,
+			resource:           "nodes",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().withGroup(systemMastersGroup).build(),
+			shouldPassValidate: true,
+		},
+		"allowed: kubelet update node": {
+			operation:          kadmission.Update,
+			resource:           "nodes",
+			namespace:          "",
+			userInfo:           newTestUserBuilder().withGroup(systemNodesGroup).build(),
+			shouldPassValidate: true,
+		},
+		"allowed: privileged service account update worker node taint": {
+			operation:          kadmission.Update,
+			resource:           "nodes",
+			namespace:          "",
+			name:               "worker-guid",
+			oldObject:          newTestNodeBuilder().build(),
+			object:             newTestNodeBuilder().withTaint(nil).build(),
+			userInfo:           newTestUserBuilder().withName(privilegedServiceAccount + "default").build(),
+			shouldPassValidate: true,
+		},
+		"denied: privileged service account update master node taint": {
+			operation:          kadmission.Update,
+			resource:           "nodes",
+			namespace:          "",
+			name:               "master-guid",
+			oldObject:          newTestNodeBuilder().build(),
+			object:             newTestNodeBuilder().withTaint(nil).build(),
+			userInfo:           newTestUserBuilder().withName(privilegedServiceAccount + "default").build(),
+			shouldPassValidate: false,
+		},
+		"denied: privileged service account create a deployment": {
+			operation:          kadmission.Create,
+			resource:           "deployments",
+			namespace:          "vke-system",
+			userInfo:           newTestUserBuilder().withName(privilegedServiceAccount + "default").build(),
+			shouldPassValidate: false,
+		},
+		"denied: worker kubelet create a deployment": {
+			operation:          kadmission.Create,
+			resource:           "deployments",
+			namespace:          "vke-system",
+			userInfo:           newTestUserBuilder().withGroup(systemWorkerGroup).build(),
+			shouldPassValidate: false,
+		},
+	}
+	for k, v := range tests {
+		testResourceValidation(k, v.operation, v.resource, v.subresource, v.name, v.namespace, v.userInfo, v.object,
+			v.oldObject, v.shouldPassValidate, t)
+	}
+}
+
+func testPodValidation(testCaseName string, op kadmission.Operation, pod *kapi.Pod, name string, userInfo user.Info,
+	shouldPassValidate bool, t *testing.T) {
+
+	defaultConfigFile := fmt.Sprintf(defaultConfigFileFormat, testServiceAccountsGroup, pspFileName, clusterID)
+	configFile := strings.NewReader(defaultConfigFile)
+	plugin, err := NewVMwareAdmissionController(configFile)
+	if err != nil {
+		t.Errorf("%s: failed to create admission controller %v", testCaseName, err)
+	}
+
+	namespace := "default"
+	if pod != nil {
+		namespace = pod.Namespace
+	}
+
+	attrs := kadmission.NewAttributesRecord(pod, nil, kapi.Kind("Pod").WithVersion("version"),
+		namespace, name, kapi.Resource("pods").WithVersion("version"), "", op, userInfo)
+
+	err = plugin.Validate(attrs)
+	if shouldPassValidate && err != nil {
+		t.Errorf("%s: expected no errors on Validate but received %v", testCaseName, err)
+	} else if !shouldPassValidate && err == nil {
+		t.Errorf("%s: expected errors on Validate but received none", testCaseName)
+	}
+}
+
+func testResourceValidation(testCaseName string, op kadmission.Operation, resource, subresource, name, namespace string,
+	userInfo user.Info, object runtime.Object, oldObject runtime.Object, shouldPassValidate bool, t *testing.T) {
+
+	defaultConfigFile := fmt.Sprintf(defaultConfigFileFormat, testServiceAccountsGroup, pspFileName, clusterID)
+	configFile := strings.NewReader(defaultConfigFile)
+	plugin, err := NewVMwareAdmissionController(configFile)
+	if err != nil {
+		t.Errorf("%s: failed to create admission controller %v", testCaseName, err)
+	}
+
+	groupResource := kapi.Resource(resource).WithVersion("version")
+	if resource == "clusterroles" || resource == "clusterrolebindings" {
+		groupResource = rbac.Resource(resource).WithVersion("version")
+	}
+
+	attrs := kadmission.NewAttributesRecord(object, oldObject, kapi.Kind("kind").WithVersion("version"),
+		namespace, name, groupResource, subresource, op, userInfo)
+
+	err = plugin.Validate(attrs)
+	if shouldPassValidate && err != nil {
+		t.Errorf("%s: expected no errors on Validate but received %v", testCaseName, err)
+	} else if !shouldPassValidate && err == nil {
+		t.Errorf("%s: expected errors on Validate but received none", testCaseName)
+	}
+}
+
+// testPodBuilder
+type testPodBuilder struct {
+	pod kapi.Pod
+}
+
+func newTestPodBuilder() *testPodBuilder {
+	builder := new(testPodBuilder)
+	return builder.init()
+}
+
+func (p *testPodBuilder) init() *testPodBuilder {
+	p.pod = kapi.Pod{
+		ObjectMeta: metav1.ObjectMeta{
+			Name:        "pod",
+			Namespace:   "namespace",
+			Annotations: map[string]string{},
+		},
+		Spec: kapi.PodSpec{
+			ServiceAccountName: "default",
+			SecurityContext:    &kapi.PodSecurityContext{},
+			Containers: []kapi.Container{
+				{
+					Name:            "test-container-1",
+					SecurityContext: &kapi.SecurityContext{},
+				},
+			},
+		},
+	}
+	return p
+}
+
+func (p *testPodBuilder) build() *kapi.Pod {
+	return &p.pod
+}
+
+func (p *testPodBuilder) withNamespace(namespace string) *testPodBuilder {
+	p.pod.ObjectMeta.Namespace = namespace
+	return p
+}
+
+func (p *testPodBuilder) withServiceAccount(sa string) *testPodBuilder {
+	p.pod.Spec.ServiceAccountName = sa
+	return p
+}
+
+func (p *testPodBuilder) withPrivileged(v bool) *testPodBuilder {
+	p.pod.Spec.Containers[0].SecurityContext.Privileged = &v
+	return p
+}
+
+func (p *testPodBuilder) withHostNetwork(v bool) *testPodBuilder {
+	p.pod.Spec.SecurityContext.HostNetwork = v
+	return p
+}
+
+func (p *testPodBuilder) withHostIPC(v bool) *testPodBuilder {
+	p.pod.Spec.SecurityContext.HostIPC = v
+	return p
+}
+
+func (p *testPodBuilder) withHostPID(v bool) *testPodBuilder {
+	p.pod.Spec.SecurityContext.HostPID = v
+	return p
+}
+
+func (p *testPodBuilder) withHostPort() *testPodBuilder {
+	containerPorts := []kapi.ContainerPort{
+		{
+			HostPort:      3000,
+			ContainerPort: 80,
+		},
+	}
+
+	p.pod.Spec.Containers[0].Ports = containerPorts
+	return p
+}
+
+func (p *testPodBuilder) withHostVolume(hostPath string, readOnly bool) *testPodBuilder {
+	volume := kapi.Volume{
+		Name: "host",
+		VolumeSource: kapi.VolumeSource{
+			HostPath: &kapi.HostPathVolumeSource{
+				Path: hostPath,
+			},
+		},
+	}
+	volumeMount := kapi.VolumeMount{Name: "host", MountPath: "/data", ReadOnly: readOnly}
+
+	p.pod.Spec.Volumes = append(p.pod.Spec.Volumes, volume)
+	p.pod.Spec.Containers[0].VolumeMounts = append(p.pod.Spec.Containers[0].VolumeMounts, volumeMount)
+	return p
+}
+
+func (p *testPodBuilder) withCascadeDisk() *testPodBuilder {
+	volume := kapi.Volume{
+		Name: "cascadeDisk",
+		VolumeSource: kapi.VolumeSource{
+			PersistentVolumeClaim: &kapi.PersistentVolumeClaimVolumeSource{
+				ClaimName: "00000000-0000-0000-0000-000000000001",
+				ReadOnly:  false,
+			},
+		},
+	}
+	device := kapi.VolumeDevice{Name: "cascadeDisk", DevicePath: "/cascadeDisk"}
+
+	p.pod.Spec.Volumes = append(p.pod.Spec.Volumes, volume)
+	p.pod.Spec.Containers[0].VolumeDevices = append(p.pod.Spec.Containers[0].VolumeDevices, device)
+	return p
+}
+
+func (p *testPodBuilder) withContainer() *testPodBuilder {
+	container := kapi.Container{
+		Name:            "test-container-2",
+		SecurityContext: &kapi.SecurityContext{},
+	}
+
+	p.pod.Spec.Containers = append(p.pod.Spec.Containers, container)
+	return p
+}
+
+func (p *testPodBuilder) withInitContainer() *testPodBuilder {
+	container := kapi.Container{
+		Name:            "test-init-container",
+		SecurityContext: &kapi.SecurityContext{},
+	}
+
+	p.pod.Spec.Containers = append(p.pod.Spec.Containers, container)
+	return p
+}
+
+func (p *testPodBuilder) withToleration(key, value string, operator kapi.TolerationOperator, effect kapi.TaintEffect) *testPodBuilder {
+	p.pod.Spec.Tolerations = append(p.pod.Spec.Tolerations, kapi.Toleration{
+		Key:      key,
+		Value:    value,
+		Operator: operator,
+		Effect:   effect,
+	})
+	return p
+}
+
+// testUserBuilder
+type testUserBuilder struct {
+	user *user.DefaultInfo
+}
+
+func newTestUserBuilder() *testUserBuilder {
+	builder := new(testUserBuilder)
+	return builder.init()
+}
+
+func (p *testUserBuilder) init() *testUserBuilder {
+	p.user = &user.DefaultInfo{
+		Name:   "https://lightwave.cascade-cloud.com/openidconnect/00000000-0000-0000-0000-000000000001#joe@vmware.com",
+		UID:    "10001",
+		Groups: []string{},
+	}
+	return p
+}
+
+func (p *testUserBuilder) build() *user.DefaultInfo {
+	return p.user
+}
+
+func (p *testUserBuilder) withName(name string) *testUserBuilder {
+	p.user.Name = name
+	return p
+}
+
+func (p *testUserBuilder) withGroup(group string) *testUserBuilder {
+	p.user.Groups = append(p.user.Groups, group)
+	return p
+}
+
+// testNodeBuilder
+type testNodeBuilder struct {
+	node kapi.Node
+}
+
+func newTestNodeBuilder() *testNodeBuilder {
+	builder := new(testNodeBuilder)
+	return builder.init()
+}
+
+func (n *testNodeBuilder) init() *testNodeBuilder {
+	n.node = kapi.Node{
+		ObjectMeta: metav1.ObjectMeta{
+			Name:        "node",
+			Namespace:   "",
+			Annotations: nil,
+		},
+		Spec: kapi.NodeSpec{
+			Taints: []kapi.Taint{
+				{
+					"Dedicated", "Master", "NoSchedule", nil,
+				},
+			},
+		},
+	}
+	return n
+}
+
+func (n *testNodeBuilder) build() *kapi.Node {
+	return &n.node
+}
+
+func (n *testNodeBuilder) withTaint(taints []kapi.Taint) *testNodeBuilder {
+	n.node.Spec.Taints = taints
+	return n
+}
diff --git a/plugin/pkg/auth/authorizer/vke/BUILD b/plugin/pkg/auth/authorizer/vke/BUILD
new file mode 100644
index 0000000000..4b984f14ec
--- /dev/null
+++ b/plugin/pkg/auth/authorizer/vke/BUILD
@@ -0,0 +1,40 @@
+package(default_visibility = ["//visibility:public"])
+
+load(
+    "@io_bazel_rules_go//go:def.bzl",
+    "go_library",
+)
+
+go_test(
+    name = "go_default_test",
+    srcs = ["vke_authorizer_test.go"],
+    embed = [":go_default_library"],
+    deps = [
+        "//vendor/k8s.io/apiserver/pkg/authentication/user:go_default_library",
+        "//vendor/k8s.io/apiserver/pkg/authorization/authorizer:go_default_library",
+    ],
+)
+
+go_library(
+    name = "go_default_library",
+    srcs = [
+        "vke_authorizer.go",
+    ],
+    importpath = "k8s.io/kubernetes/plugin/pkg/auth/authorizer/vke",
+    deps = [
+        "//vendor/k8s.io/apiserver/pkg/authorization/authorizer:go_default_library",
+    ],
+)
+
+filegroup(
+    name = "package-srcs",
+    srcs = glob(["**"]),
+    tags = ["automanaged"],
+    visibility = ["//visibility:private"],
+)
+
+filegroup(
+    name = "all-srcs",
+    srcs = [":package-srcs"],
+    tags = ["automanaged"],
+)
diff --git a/plugin/pkg/auth/authorizer/vke/OWNERS b/plugin/pkg/auth/authorizer/vke/OWNERS
new file mode 100644
index 0000000000..c3a4ed77dc
--- /dev/null
+++ b/plugin/pkg/auth/authorizer/vke/OWNERS
@@ -0,0 +1,2 @@
+maintainers:
+- ashokc
diff --git a/plugin/pkg/auth/authorizer/vke/vke_authorizer.go b/plugin/pkg/auth/authorizer/vke/vke_authorizer.go
new file mode 100644
index 0000000000..6d7f9ae2b8
--- /dev/null
+++ b/plugin/pkg/auth/authorizer/vke/vke_authorizer.go
@@ -0,0 +1,125 @@
+package vke
+
+import (
+	"bufio"
+	"fmt"
+	"os"
+	"strings"
+
+	"github.com/golang/glog"
+	"k8s.io/apiserver/pkg/authorization/authorizer"
+)
+
+const (
+	systemClusterPrefix = "system:clusterID:"
+	systemNodePrefix    = "system:node:"
+	systemWorkerGroup   = "system:worker"
+	masterPrefix        = "master-"
+)
+
+
+// VKEAuthorizer authorizes requests which comes from nodes using certificates.
+// If a request is from a node which is not a part of the cluster, reject.
+type VKEAuthorizer struct {
+	clusterID string
+}
+
+// NewAuthorizer returns a new node authorizer
+func NewAuthorizer() (authorizer.Authorizer, error) {
+	file, err := os.Open("/etc/kubernetes/cc_cloud.config")
+	if err != nil {
+		return nil, err
+	}
+	defer file.Close()
+
+	scanner := bufio.NewScanner(file)
+
+	for scanner.Scan() {
+		lineContent := scanner.Text()
+		if strings.Contains(lineContent, "clusterID = ") {
+			clusterID := strings.SplitAfter(lineContent, "= ")[1]
+			return &VKEAuthorizer{clusterID: clusterID}, nil
+		}
+	}
+
+	return nil, fmt.Errorf("Cluster ID cannot be parsed from config file successfully")
+}
+
+// Authorize authorizes requests based on the VKE authorizer.
+func (v *VKEAuthorizer) Authorize(attrs authorizer.Attributes) (authorizer.Decision, string, error) {
+	// If the request comes from a non cluster node, then deny.
+	if isNonClusterNode(attrs, v.clusterID) {
+		glog.V(2).Infof("VKE authorizer: DENY the request because it is from a different cluster")
+		return authorizer.DecisionDeny, "", nil
+	}
+
+	// If a worker node name does not have the node prefix, then deny. This is needed for the request to go through node
+	// authorizer and node restriction admission controller. If it is not set, then a user can bypass node authorizer
+	// and the node restriction admission controller and modify the master node.
+	if isWorkerWithoutNodeNameRestriction(attrs) {
+		glog.V(2).Infof("VKE authorizer: DENY the request because the node name restriction is not met")
+		return authorizer.DecisionDeny, "", nil
+	}
+
+	// If it is a proxy request to the master node to exec, run or attach to a container, then deny.
+	if isProxyRequestToMasterNode(attrs) {
+		glog.V(2).Infof("VKE authorizer: DENY the request because it tried to execute commands on master pods")
+		return authorizer.DecisionDeny, "", nil
+	}
+
+	return authorizer.DecisionNoOpinion, "", nil
+}
+
+// isNonClusterNode verifies that the request is not from a node which does not belong to this cluster. This is needed
+// to prevent cross cluster attacks where a user can use the kubelet certificate of one cluster to access the resources
+// in another cluster. The reason we have this check is because, when a certificate is presented for authentication,
+// Kubernetes just verifies that the certificate is signed by the CA that the cluster trusts. Since, in our case, the CA
+// is same for all clusters, authentication with certificate is not enough. So, we make sure that the request is not
+// from another cluster. Lightwave will make sure that any certificates generated on a worker will always have the
+// "system:clusterID:<id>" group. This way, we can just check the cluster ID in the group and reject if it is not the
+// same as this cluster's ID.
+func isNonClusterNode(attrs authorizer.Attributes, clusterID string) bool {
+	groups := attrs.GetUser().GetGroups()
+	for _, group := range groups {
+		if strings.HasPrefix(group, systemClusterPrefix) {
+			groupParts := strings.Split(group, ":")
+			if clusterID != "" && groupParts[len(groupParts)-1] != clusterID {
+				return true
+			}
+		}
+	}
+
+	return false
+}
+
+// isWorkerWithoutNodeNameRestriction verifies that the certificate presented by the worker nodes also have the
+// appropriate name "system:node:<hostname>". We need to validate this because it is possible for a user to generate
+// certificates with CN other than "system:node:<hostname>". This is because lightwave does group validation and that
+// the CNs can be one of system:node:<hostname>, kubernetes-master and etcd. When that happens, that certificate will be
+// able to bypass the NodeRestriction admission controller which will allow access to modify master node and create pods
+// on master. To prevent that from happening, we need to verify that if a request comes from a worker node, then it has
+// to have the expected name so that NodeRestriction admission controller is enforced.
+func isWorkerWithoutNodeNameRestriction(attrs authorizer.Attributes) bool {
+	groups := attrs.GetUser().GetGroups()
+	name := attrs.GetUser().GetName()
+	for _, group := range groups {
+		if group == systemWorkerGroup && !strings.HasPrefix(name, systemNodePrefix) {
+			return true
+		}
+	}
+	return false
+}
+
+// isProxyRequestToMasterNode checks if the request is made to exec, run or attach to a container on the master node. We
+// need this check because we do not want to allow a user to exec into a privileged pod on the master node.
+func isProxyRequestToMasterNode(attrs authorizer.Attributes) bool {
+	if attrs.GetResource() == "nodes" && strings.HasPrefix(attrs.GetName(), masterPrefix) {
+		if strings.Contains(attrs.GetPath(), "proxy/run") ||
+			strings.Contains(attrs.GetPath(), "proxy/exec") ||
+			strings.Contains(attrs.GetPath(), "proxy/attach") {
+			return true
+		}
+	}
+	return false
+}
+
diff --git a/plugin/pkg/auth/authorizer/vke/vke_authorizer_test.go b/plugin/pkg/auth/authorizer/vke/vke_authorizer_test.go
new file mode 100644
index 0000000000..6aba9ecec9
--- /dev/null
+++ b/plugin/pkg/auth/authorizer/vke/vke_authorizer_test.go
@@ -0,0 +1,230 @@
+package vke
+
+import (
+	"testing"
+
+	"k8s.io/apiserver/pkg/authentication/user"
+	"k8s.io/apiserver/pkg/authorization/authorizer"
+)
+
+const (
+	masterProxyAttachPath = "/api/v1/nodes/master-0/proxy/attach/vke-system/pod-name/container-name"
+	masterProxyExecPath   = "/api/v1/nodes/master-0/proxy/exec/vke-system/pod-name/container-name"
+	masterProxyRunPath    = "/api/v1/nodes/master-0/proxy/run/vke-system/pod-name/container-name"
+	workerProxyAttachPath = "/api/v1/nodes/worker-0/proxy/attach/vke-system/pod-name/container-name"
+	workerProxyExecPath   = "/api/v1/nodes/worker-0/proxy/exec/vke-system/pod-name/container-name"
+	workerProxyRunPath    = "/api/v1/nodes/worker-0/proxy/run/vke-system/pod-name/container-name"
+)
+
+func TestAuthorizer(t *testing.T) {
+	authz := &VKEAuthorizer{clusterID: "cluster-id"}
+
+	clusterNode := &user.DefaultInfo{Name: "system:node:worker-0", Groups: []string{"system:nodes", "system:clusterID:cluster-id", "system:worker"}}
+	crossClusterNode := &user.DefaultInfo{Name: "system:node:worker-0", Groups: []string{"system:nodes", "system:clusterID:invalid", "system:worker"}}
+	invalidWorker := &user.DefaultInfo{Name: "worker-0", Groups: []string{"system:nodes", "system:clusterID:cluster-id", "system:worker"}}
+
+	tests := []struct {
+		name   string
+		attrs  authorizer.AttributesRecord
+		expect authorizer.Decision
+	}{
+		// Do not deny requests from a normal cluster node user.
+		{
+			name:   "allowed: cluster node get pod",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "get", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: cluster node list pod",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "list", Resource: "pods", Namespace: "ns"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: cluster node create pod",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "create", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: cluster node update pod",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "update", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: cluster node delete pod",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "delete", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: cluster node get node",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "get", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: cluster node list nodes",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "list", Resource: "nodes"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: cluster node create nodes",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "create", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: cluster node update nodes",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "update", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: cluster node delete nodes",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "delete", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionNoOpinion,
+		},
+
+		// Deny requests from another cluster node.
+		{
+			name:   "denied: cross cluster node get pod",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "get", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: cross cluster node list pod",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "list", Resource: "pods", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: cross cluster node create pod",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "create", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: cross cluster node update pod",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "update", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: cross cluster node delete pod",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "delete", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: cross cluster node get node",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "get", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: cross cluster node list nodes",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "list", Resource: "nodes"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: cross cluster node create nodes",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "create", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: cross cluster node update nodes",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "update", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: cross cluster node delete nodes",
+			attrs:  authorizer.AttributesRecord{User: crossClusterNode, ResourceRequest: true, Verb: "delete", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionDeny,
+		},
+
+		// Deny requests from invalid node.
+		{
+			name:   "denied: invalid worker get pod",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "get", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: invalid worker list pod",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "list", Resource: "pods", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: invalid worker create pod",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "create", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: invalid worker update pod",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "update", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: invalid worker delete pod",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "delete", Resource: "pods", Name: "pod", Namespace: "ns"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: invalid worker get node",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "get", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: invalid worker list nodes",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "list", Resource: "nodes"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: invalid worker create nodes",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "create", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: invalid worker update nodes",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "update", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: invalid worker delete nodes",
+			attrs:  authorizer.AttributesRecord{User: invalidWorker, ResourceRequest: true, Verb: "delete", Resource: "nodes", Name: "node"},
+			expect: authorizer.DecisionDeny,
+		},
+
+		// Deny exec, run and attach operation on master nodes using proxy resource.
+		{
+			name:   "denied: attach using proxy resource on master",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "create", Resource: "nodes", Name: "master-0", Path: masterProxyAttachPath},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: exec using proxy resource on master",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "create", Resource: "nodes", Name: "master-0", Path: masterProxyExecPath},
+			expect: authorizer.DecisionDeny,
+		},
+		{
+			name:   "denied: run using proxy resource on master",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "create", Resource: "nodes", Name: "master-0", Path: masterProxyRunPath},
+			expect: authorizer.DecisionDeny,
+		},
+
+		// Do not deny exec, run and attach operation on worker nodes using proxy resource.
+		{
+			name:   "allowed: attach using proxy resource on worker",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "create", Resource: "nodes", Name: "worker-0", Path: workerProxyAttachPath},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: exec using proxy resource on worker",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "create", Resource: "nodes", Name: "worker-0", Path: workerProxyExecPath},
+			expect: authorizer.DecisionNoOpinion,
+		},
+		{
+			name:   "allowed: run using proxy resource on worker",
+			attrs:  authorizer.AttributesRecord{User: clusterNode, ResourceRequest: true, Verb: "create", Resource: "nodes", Name: "worker-0", Path: workerProxyRunPath},
+			expect: authorizer.DecisionNoOpinion,
+		},
+	}
+
+	for _, tc := range tests {
+		t.Run(tc.name, func(t *testing.T) {
+			decision, _, _ := authz.Authorize(tc.attrs)
+			if decision != tc.expect {
+				t.Errorf("expected %v, got %v", tc.expect, decision)
+			}
+		})
+	}
+}
diff --git a/staging/src/k8s.io/api/core/v1/generated.pb.go b/staging/src/k8s.io/api/core/v1/generated.pb.go
index 05cc6d6284..f27250e2d9 100644
--- a/staging/src/k8s.io/api/core/v1/generated.pb.go
+++ b/staging/src/k8s.io/api/core/v1/generated.pb.go
@@ -14,8 +14,9 @@ See the License for the specific language governing permissions and
 limitations under the License.
 */
 
-// Code generated by protoc-gen-gogo. DO NOT EDIT.
+// Code generated by protoc-gen-gogo.
 // source: k8s.io/kubernetes/vendor/k8s.io/api/core/v1/generated.proto
+// DO NOT EDIT!
 
 /*
 	Package v1 is a generated protocol buffer package.
@@ -34,6 +35,7 @@ limitations under the License.
 		Binding
 		CSIPersistentVolumeSource
 		Capabilities
+		CascadeDiskVolumeSource
 		CephFSPersistentVolumeSource
 		CephFSVolumeSource
 		CinderPersistentVolumeSource
@@ -81,7 +83,6 @@ limitations under the License.
 		FlockerVolumeSource
 		GCEPersistentDiskVolumeSource
 		GitRepoVolumeSource
-		GlusterfsPersistentVolumeSource
 		GlusterfsVolumeSource
 		HTTPGetAction
 		HTTPHeader
@@ -211,7 +212,6 @@ limitations under the License.
 		Toleration
 		TopologySelectorLabelRequirement
 		TopologySelectorTerm
-		TypedLocalObjectReference
 		Volume
 		VolumeDevice
 		VolumeMount
@@ -297,213 +297,213 @@ func (m *Capabilities) Reset()                    { *m = Capabilities{} }
 func (*Capabilities) ProtoMessage()               {}
 func (*Capabilities) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{9} }
 
+func (m *CascadeDiskVolumeSource) Reset()      { *m = CascadeDiskVolumeSource{} }
+func (*CascadeDiskVolumeSource) ProtoMessage() {}
+func (*CascadeDiskVolumeSource) Descriptor() ([]byte, []int) {
+	return fileDescriptorGenerated, []int{10}
+}
+
 func (m *CephFSPersistentVolumeSource) Reset()      { *m = CephFSPersistentVolumeSource{} }
 func (*CephFSPersistentVolumeSource) ProtoMessage() {}
 func (*CephFSPersistentVolumeSource) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{10}
+	return fileDescriptorGenerated, []int{11}
 }
 
 func (m *CephFSVolumeSource) Reset()                    { *m = CephFSVolumeSource{} }
 func (*CephFSVolumeSource) ProtoMessage()               {}
-func (*CephFSVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{11} }
+func (*CephFSVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{12} }
 
 func (m *CinderPersistentVolumeSource) Reset()      { *m = CinderPersistentVolumeSource{} }
 func (*CinderPersistentVolumeSource) ProtoMessage() {}
 func (*CinderPersistentVolumeSource) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{12}
+	return fileDescriptorGenerated, []int{13}
 }
 
 func (m *CinderVolumeSource) Reset()                    { *m = CinderVolumeSource{} }
 func (*CinderVolumeSource) ProtoMessage()               {}
-func (*CinderVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{13} }
+func (*CinderVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{14} }
 
 func (m *ClientIPConfig) Reset()                    { *m = ClientIPConfig{} }
 func (*ClientIPConfig) ProtoMessage()               {}
-func (*ClientIPConfig) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{14} }
+func (*ClientIPConfig) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{15} }
 
 func (m *ComponentCondition) Reset()                    { *m = ComponentCondition{} }
 func (*ComponentCondition) ProtoMessage()               {}
-func (*ComponentCondition) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{15} }
+func (*ComponentCondition) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{16} }
 
 func (m *ComponentStatus) Reset()                    { *m = ComponentStatus{} }
 func (*ComponentStatus) ProtoMessage()               {}
-func (*ComponentStatus) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{16} }
+func (*ComponentStatus) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{17} }
 
 func (m *ComponentStatusList) Reset()                    { *m = ComponentStatusList{} }
 func (*ComponentStatusList) ProtoMessage()               {}
-func (*ComponentStatusList) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{17} }
+func (*ComponentStatusList) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{18} }
 
 func (m *ConfigMap) Reset()                    { *m = ConfigMap{} }
 func (*ConfigMap) ProtoMessage()               {}
-func (*ConfigMap) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{18} }
+func (*ConfigMap) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{19} }
 
 func (m *ConfigMapEnvSource) Reset()                    { *m = ConfigMapEnvSource{} }
 func (*ConfigMapEnvSource) ProtoMessage()               {}
-func (*ConfigMapEnvSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{19} }
+func (*ConfigMapEnvSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{20} }
 
 func (m *ConfigMapKeySelector) Reset()                    { *m = ConfigMapKeySelector{} }
 func (*ConfigMapKeySelector) ProtoMessage()               {}
-func (*ConfigMapKeySelector) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{20} }
+func (*ConfigMapKeySelector) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{21} }
 
 func (m *ConfigMapList) Reset()                    { *m = ConfigMapList{} }
 func (*ConfigMapList) ProtoMessage()               {}
-func (*ConfigMapList) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{21} }
+func (*ConfigMapList) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{22} }
 
 func (m *ConfigMapNodeConfigSource) Reset()      { *m = ConfigMapNodeConfigSource{} }
 func (*ConfigMapNodeConfigSource) ProtoMessage() {}
 func (*ConfigMapNodeConfigSource) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{22}
+	return fileDescriptorGenerated, []int{23}
 }
 
 func (m *ConfigMapProjection) Reset()                    { *m = ConfigMapProjection{} }
 func (*ConfigMapProjection) ProtoMessage()               {}
-func (*ConfigMapProjection) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{23} }
+func (*ConfigMapProjection) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{24} }
 
 func (m *ConfigMapVolumeSource) Reset()                    { *m = ConfigMapVolumeSource{} }
 func (*ConfigMapVolumeSource) ProtoMessage()               {}
-func (*ConfigMapVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{24} }
+func (*ConfigMapVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{25} }
 
 func (m *Container) Reset()                    { *m = Container{} }
 func (*Container) ProtoMessage()               {}
-func (*Container) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{25} }
+func (*Container) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{26} }
 
 func (m *ContainerImage) Reset()                    { *m = ContainerImage{} }
 func (*ContainerImage) ProtoMessage()               {}
-func (*ContainerImage) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{26} }
+func (*ContainerImage) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{27} }
 
 func (m *ContainerPort) Reset()                    { *m = ContainerPort{} }
 func (*ContainerPort) ProtoMessage()               {}
-func (*ContainerPort) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{27} }
+func (*ContainerPort) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{28} }
 
 func (m *ContainerState) Reset()                    { *m = ContainerState{} }
 func (*ContainerState) ProtoMessage()               {}
-func (*ContainerState) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{28} }
+func (*ContainerState) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{29} }
 
 func (m *ContainerStateRunning) Reset()                    { *m = ContainerStateRunning{} }
 func (*ContainerStateRunning) ProtoMessage()               {}
-func (*ContainerStateRunning) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{29} }
+func (*ContainerStateRunning) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{30} }
 
 func (m *ContainerStateTerminated) Reset()      { *m = ContainerStateTerminated{} }
 func (*ContainerStateTerminated) ProtoMessage() {}
 func (*ContainerStateTerminated) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{30}
+	return fileDescriptorGenerated, []int{31}
 }
 
 func (m *ContainerStateWaiting) Reset()                    { *m = ContainerStateWaiting{} }
 func (*ContainerStateWaiting) ProtoMessage()               {}
-func (*ContainerStateWaiting) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{31} }
+func (*ContainerStateWaiting) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{32} }
 
 func (m *ContainerStatus) Reset()                    { *m = ContainerStatus{} }
 func (*ContainerStatus) ProtoMessage()               {}
-func (*ContainerStatus) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{32} }
+func (*ContainerStatus) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{33} }
 
 func (m *DaemonEndpoint) Reset()                    { *m = DaemonEndpoint{} }
 func (*DaemonEndpoint) ProtoMessage()               {}
-func (*DaemonEndpoint) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{33} }
+func (*DaemonEndpoint) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{34} }
 
 func (m *DownwardAPIProjection) Reset()                    { *m = DownwardAPIProjection{} }
 func (*DownwardAPIProjection) ProtoMessage()               {}
-func (*DownwardAPIProjection) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{34} }
+func (*DownwardAPIProjection) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{35} }
 
 func (m *DownwardAPIVolumeFile) Reset()                    { *m = DownwardAPIVolumeFile{} }
 func (*DownwardAPIVolumeFile) ProtoMessage()               {}
-func (*DownwardAPIVolumeFile) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{35} }
+func (*DownwardAPIVolumeFile) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{36} }
 
 func (m *DownwardAPIVolumeSource) Reset()      { *m = DownwardAPIVolumeSource{} }
 func (*DownwardAPIVolumeSource) ProtoMessage() {}
 func (*DownwardAPIVolumeSource) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{36}
+	return fileDescriptorGenerated, []int{37}
 }
 
 func (m *EmptyDirVolumeSource) Reset()                    { *m = EmptyDirVolumeSource{} }
 func (*EmptyDirVolumeSource) ProtoMessage()               {}
-func (*EmptyDirVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{37} }
+func (*EmptyDirVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{38} }
 
 func (m *EndpointAddress) Reset()                    { *m = EndpointAddress{} }
 func (*EndpointAddress) ProtoMessage()               {}
-func (*EndpointAddress) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{38} }
+func (*EndpointAddress) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{39} }
 
 func (m *EndpointPort) Reset()                    { *m = EndpointPort{} }
 func (*EndpointPort) ProtoMessage()               {}
-func (*EndpointPort) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{39} }
+func (*EndpointPort) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{40} }
 
 func (m *EndpointSubset) Reset()                    { *m = EndpointSubset{} }
 func (*EndpointSubset) ProtoMessage()               {}
-func (*EndpointSubset) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{40} }
+func (*EndpointSubset) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{41} }
 
 func (m *Endpoints) Reset()                    { *m = Endpoints{} }
 func (*Endpoints) ProtoMessage()               {}
-func (*Endpoints) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{41} }
+func (*Endpoints) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{42} }
 
 func (m *EndpointsList) Reset()                    { *m = EndpointsList{} }
 func (*EndpointsList) ProtoMessage()               {}
-func (*EndpointsList) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{42} }
+func (*EndpointsList) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{43} }
 
 func (m *EnvFromSource) Reset()                    { *m = EnvFromSource{} }
 func (*EnvFromSource) ProtoMessage()               {}
-func (*EnvFromSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{43} }
+func (*EnvFromSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{44} }
 
 func (m *EnvVar) Reset()                    { *m = EnvVar{} }
 func (*EnvVar) ProtoMessage()               {}
-func (*EnvVar) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{44} }
+func (*EnvVar) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{45} }
 
 func (m *EnvVarSource) Reset()                    { *m = EnvVarSource{} }
 func (*EnvVarSource) ProtoMessage()               {}
-func (*EnvVarSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{45} }
+func (*EnvVarSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{46} }
 
 func (m *Event) Reset()                    { *m = Event{} }
 func (*Event) ProtoMessage()               {}
-func (*Event) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{46} }
+func (*Event) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{47} }
 
 func (m *EventList) Reset()                    { *m = EventList{} }
 func (*EventList) ProtoMessage()               {}
-func (*EventList) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{47} }
+func (*EventList) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{48} }
 
 func (m *EventSeries) Reset()                    { *m = EventSeries{} }
 func (*EventSeries) ProtoMessage()               {}
-func (*EventSeries) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{48} }
+func (*EventSeries) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{49} }
 
 func (m *EventSource) Reset()                    { *m = EventSource{} }
 func (*EventSource) ProtoMessage()               {}
-func (*EventSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{49} }
+func (*EventSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{50} }
 
 func (m *ExecAction) Reset()                    { *m = ExecAction{} }
 func (*ExecAction) ProtoMessage()               {}
-func (*ExecAction) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{50} }
+func (*ExecAction) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{51} }
 
 func (m *FCVolumeSource) Reset()                    { *m = FCVolumeSource{} }
 func (*FCVolumeSource) ProtoMessage()               {}
-func (*FCVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{51} }
+func (*FCVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{52} }
 
 func (m *FlexPersistentVolumeSource) Reset()      { *m = FlexPersistentVolumeSource{} }
 func (*FlexPersistentVolumeSource) ProtoMessage() {}
 func (*FlexPersistentVolumeSource) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{52}
+	return fileDescriptorGenerated, []int{53}
 }
 
 func (m *FlexVolumeSource) Reset()                    { *m = FlexVolumeSource{} }
 func (*FlexVolumeSource) ProtoMessage()               {}
-func (*FlexVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{53} }
+func (*FlexVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{54} }
 
 func (m *FlockerVolumeSource) Reset()                    { *m = FlockerVolumeSource{} }
 func (*FlockerVolumeSource) ProtoMessage()               {}
-func (*FlockerVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{54} }
+func (*FlockerVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{55} }
 
 func (m *GCEPersistentDiskVolumeSource) Reset()      { *m = GCEPersistentDiskVolumeSource{} }
 func (*GCEPersistentDiskVolumeSource) ProtoMessage() {}
 func (*GCEPersistentDiskVolumeSource) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{55}
+	return fileDescriptorGenerated, []int{56}
 }
 
 func (m *GitRepoVolumeSource) Reset()                    { *m = GitRepoVolumeSource{} }
 func (*GitRepoVolumeSource) ProtoMessage()               {}
-func (*GitRepoVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{56} }
-
-func (m *GlusterfsPersistentVolumeSource) Reset()      { *m = GlusterfsPersistentVolumeSource{} }
-func (*GlusterfsPersistentVolumeSource) ProtoMessage() {}
-func (*GlusterfsPersistentVolumeSource) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{57}
-}
+func (*GitRepoVolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{57} }
 
 func (m *GlusterfsVolumeSource) Reset()                    { *m = GlusterfsVolumeSource{} }
 func (*GlusterfsVolumeSource) ProtoMessage()               {}
@@ -1063,46 +1063,40 @@ func (m *TopologySelectorTerm) Reset()                    { *m = TopologySelecto
 func (*TopologySelectorTerm) ProtoMessage()               {}
 func (*TopologySelectorTerm) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{186} }
 
-func (m *TypedLocalObjectReference) Reset()      { *m = TypedLocalObjectReference{} }
-func (*TypedLocalObjectReference) ProtoMessage() {}
-func (*TypedLocalObjectReference) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{187}
-}
-
 func (m *Volume) Reset()                    { *m = Volume{} }
 func (*Volume) ProtoMessage()               {}
-func (*Volume) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{188} }
+func (*Volume) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{187} }
 
 func (m *VolumeDevice) Reset()                    { *m = VolumeDevice{} }
 func (*VolumeDevice) ProtoMessage()               {}
-func (*VolumeDevice) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{189} }
+func (*VolumeDevice) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{188} }
 
 func (m *VolumeMount) Reset()                    { *m = VolumeMount{} }
 func (*VolumeMount) ProtoMessage()               {}
-func (*VolumeMount) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{190} }
+func (*VolumeMount) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{189} }
 
 func (m *VolumeNodeAffinity) Reset()                    { *m = VolumeNodeAffinity{} }
 func (*VolumeNodeAffinity) ProtoMessage()               {}
-func (*VolumeNodeAffinity) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{191} }
+func (*VolumeNodeAffinity) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{190} }
 
 func (m *VolumeProjection) Reset()                    { *m = VolumeProjection{} }
 func (*VolumeProjection) ProtoMessage()               {}
-func (*VolumeProjection) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{192} }
+func (*VolumeProjection) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{191} }
 
 func (m *VolumeSource) Reset()                    { *m = VolumeSource{} }
 func (*VolumeSource) ProtoMessage()               {}
-func (*VolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{193} }
+func (*VolumeSource) Descriptor() ([]byte, []int) { return fileDescriptorGenerated, []int{192} }
 
 func (m *VsphereVirtualDiskVolumeSource) Reset()      { *m = VsphereVirtualDiskVolumeSource{} }
 func (*VsphereVirtualDiskVolumeSource) ProtoMessage() {}
 func (*VsphereVirtualDiskVolumeSource) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{194}
+	return fileDescriptorGenerated, []int{193}
 }
 
 func (m *WeightedPodAffinityTerm) Reset()      { *m = WeightedPodAffinityTerm{} }
 func (*WeightedPodAffinityTerm) ProtoMessage() {}
 func (*WeightedPodAffinityTerm) Descriptor() ([]byte, []int) {
-	return fileDescriptorGenerated, []int{195}
+	return fileDescriptorGenerated, []int{194}
 }
 
 func init() {
@@ -1116,6 +1110,7 @@ func init() {
 	proto.RegisterType((*Binding)(nil), "k8s.io.api.core.v1.Binding")
 	proto.RegisterType((*CSIPersistentVolumeSource)(nil), "k8s.io.api.core.v1.CSIPersistentVolumeSource")
 	proto.RegisterType((*Capabilities)(nil), "k8s.io.api.core.v1.Capabilities")
+	proto.RegisterType((*CascadeDiskVolumeSource)(nil), "k8s.io.api.core.v1.CascadeDiskVolumeSource")
 	proto.RegisterType((*CephFSPersistentVolumeSource)(nil), "k8s.io.api.core.v1.CephFSPersistentVolumeSource")
 	proto.RegisterType((*CephFSVolumeSource)(nil), "k8s.io.api.core.v1.CephFSVolumeSource")
 	proto.RegisterType((*CinderPersistentVolumeSource)(nil), "k8s.io.api.core.v1.CinderPersistentVolumeSource")
@@ -1163,7 +1158,6 @@ func init() {
 	proto.RegisterType((*FlockerVolumeSource)(nil), "k8s.io.api.core.v1.FlockerVolumeSource")
 	proto.RegisterType((*GCEPersistentDiskVolumeSource)(nil), "k8s.io.api.core.v1.GCEPersistentDiskVolumeSource")
 	proto.RegisterType((*GitRepoVolumeSource)(nil), "k8s.io.api.core.v1.GitRepoVolumeSource")
-	proto.RegisterType((*GlusterfsPersistentVolumeSource)(nil), "k8s.io.api.core.v1.GlusterfsPersistentVolumeSource")
 	proto.RegisterType((*GlusterfsVolumeSource)(nil), "k8s.io.api.core.v1.GlusterfsVolumeSource")
 	proto.RegisterType((*HTTPGetAction)(nil), "k8s.io.api.core.v1.HTTPGetAction")
 	proto.RegisterType((*HTTPHeader)(nil), "k8s.io.api.core.v1.HTTPHeader")
@@ -1293,7 +1287,6 @@ func init() {
 	proto.RegisterType((*Toleration)(nil), "k8s.io.api.core.v1.Toleration")
 	proto.RegisterType((*TopologySelectorLabelRequirement)(nil), "k8s.io.api.core.v1.TopologySelectorLabelRequirement")
 	proto.RegisterType((*TopologySelectorTerm)(nil), "k8s.io.api.core.v1.TopologySelectorTerm")
-	proto.RegisterType((*TypedLocalObjectReference)(nil), "k8s.io.api.core.v1.TypedLocalObjectReference")
 	proto.RegisterType((*Volume)(nil), "k8s.io.api.core.v1.Volume")
 	proto.RegisterType((*VolumeDevice)(nil), "k8s.io.api.core.v1.VolumeDevice")
 	proto.RegisterType((*VolumeMount)(nil), "k8s.io.api.core.v1.VolumeMount")
@@ -1744,6 +1737,32 @@ func (m *Capabilities) MarshalTo(dAtA []byte) (int, error) {
 	return i, nil
 }
 
+func (m *CascadeDiskVolumeSource) Marshal() (dAtA []byte, err error) {
+	size := m.Size()
+	dAtA = make([]byte, size)
+	n, err := m.MarshalTo(dAtA)
+	if err != nil {
+		return nil, err
+	}
+	return dAtA[:n], nil
+}
+
+func (m *CascadeDiskVolumeSource) MarshalTo(dAtA []byte) (int, error) {
+	var i int
+	_ = i
+	var l int
+	_ = l
+	dAtA[i] = 0xa
+	i++
+	i = encodeVarintGenerated(dAtA, i, uint64(len(m.DiskID)))
+	i += copy(dAtA[i:], m.DiskID)
+	dAtA[i] = 0x12
+	i++
+	i = encodeVarintGenerated(dAtA, i, uint64(len(m.FSType)))
+	i += copy(dAtA[i:], m.FSType)
+	return i, nil
+}
+
 func (m *CephFSPersistentVolumeSource) Marshal() (dAtA []byte, err error) {
 	size := m.Size()
 	dAtA = make([]byte, size)
@@ -3956,46 +3975,6 @@ func (m *GitRepoVolumeSource) MarshalTo(dAtA []byte) (int, error) {
 	return i, nil
 }
 
-func (m *GlusterfsPersistentVolumeSource) Marshal() (dAtA []byte, err error) {
-	size := m.Size()
-	dAtA = make([]byte, size)
-	n, err := m.MarshalTo(dAtA)
-	if err != nil {
-		return nil, err
-	}
-	return dAtA[:n], nil
-}
-
-func (m *GlusterfsPersistentVolumeSource) MarshalTo(dAtA []byte) (int, error) {
-	var i int
-	_ = i
-	var l int
-	_ = l
-	dAtA[i] = 0xa
-	i++
-	i = encodeVarintGenerated(dAtA, i, uint64(len(m.EndpointsName)))
-	i += copy(dAtA[i:], m.EndpointsName)
-	dAtA[i] = 0x12
-	i++
-	i = encodeVarintGenerated(dAtA, i, uint64(len(m.Path)))
-	i += copy(dAtA[i:], m.Path)
-	dAtA[i] = 0x18
-	i++
-	if m.ReadOnly {
-		dAtA[i] = 1
-	} else {
-		dAtA[i] = 0
-	}
-	i++
-	if m.EndpointsNamespace != nil {
-		dAtA[i] = 0x22
-		i++
-		i = encodeVarintGenerated(dAtA, i, uint64(len(*m.EndpointsNamespace)))
-		i += copy(dAtA[i:], *m.EndpointsNamespace)
-	}
-	return i, nil
-}
-
 func (m *GlusterfsVolumeSource) Marshal() (dAtA []byte, err error) {
 	size := m.Size()
 	dAtA = make([]byte, size)
@@ -4886,12 +4865,6 @@ func (m *LocalVolumeSource) MarshalTo(dAtA []byte) (int, error) {
 	i++
 	i = encodeVarintGenerated(dAtA, i, uint64(len(m.Path)))
 	i += copy(dAtA[i:], m.Path)
-	if m.FSType != nil {
-		dAtA[i] = 0x12
-		i++
-		i = encodeVarintGenerated(dAtA, i, uint64(len(*m.FSType)))
-		i += copy(dAtA[i:], *m.FSType)
-	}
 	return i, nil
 }
 
@@ -6149,16 +6122,6 @@ func (m *PersistentVolumeClaimSpec) MarshalTo(dAtA []byte) (int, error) {
 		i = encodeVarintGenerated(dAtA, i, uint64(len(*m.VolumeMode)))
 		i += copy(dAtA[i:], *m.VolumeMode)
 	}
-	if m.DataSource != nil {
-		dAtA[i] = 0x3a
-		i++
-		i = encodeVarintGenerated(dAtA, i, uint64(m.DataSource.Size()))
-		n110, err := m.DataSource.MarshalTo(dAtA[i:])
-		if err != nil {
-			return 0, err
-		}
-		i += n110
-	}
 	return i, nil
 }
 
@@ -6220,11 +6183,11 @@ func (m *PersistentVolumeClaimStatus) MarshalTo(dAtA []byte) (int, error) {
 			dAtA[i] = 0x12
 			i++
 			i = encodeVarintGenerated(dAtA, i, uint64((&v).Size()))
-			n111, err := (&v).MarshalTo(dAtA[i:])
+			n110, err := (&v).MarshalTo(dAtA[i:])
 			if err != nil {
 				return 0, err
 			}
-			i += n111
+			i += n110
 		}
 	}
 	if len(m.Conditions) > 0 {
@@ -6290,11 +6253,11 @@ func (m *PersistentVolumeList) MarshalTo(dAtA []byte) (int, error) {
 	dAtA[i] = 0xa
 	i++
 	i = encodeVarintGenerated(dAtA, i, uint64(m.ListMeta.Size()))
-	n112, err := m.ListMeta.MarshalTo(dAtA[i:])
+	n111, err := m.ListMeta.MarshalTo(dAtA[i:])
 	if err != nil {
 		return 0, err
 	}
-	i += n112
+	i += n111
 	if len(m.Items) > 0 {
 		for _, msg := range m.Items {
 			dAtA[i] = 0x12
@@ -6329,163 +6292,163 @@ func (m *PersistentVolumeSource) MarshalTo(dAtA []byte) (int, error) {
 		dAtA[i] = 0xa
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.GCEPersistentDisk.Size()))
-		n113, err := m.GCEPersistentDisk.MarshalTo(dAtA[i:])
+		n112, err := m.GCEPersistentDisk.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n113
+		i += n112
 	}
 	if m.AWSElasticBlockStore != nil {
 		dAtA[i] = 0x12
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.AWSElasticBlockStore.Size()))
-		n114, err := m.AWSElasticBlockStore.MarshalTo(dAtA[i:])
+		n113, err := m.AWSElasticBlockStore.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n114
+		i += n113
 	}
 	if m.HostPath != nil {
 		dAtA[i] = 0x1a
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.HostPath.Size()))
-		n115, err := m.HostPath.MarshalTo(dAtA[i:])
+		n114, err := m.HostPath.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n115
+		i += n114
 	}
 	if m.Glusterfs != nil {
 		dAtA[i] = 0x22
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.Glusterfs.Size()))
-		n116, err := m.Glusterfs.MarshalTo(dAtA[i:])
+		n115, err := m.Glusterfs.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n116
+		i += n115
 	}
 	if m.NFS != nil {
 		dAtA[i] = 0x2a
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.NFS.Size()))
-		n117, err := m.NFS.MarshalTo(dAtA[i:])
+		n116, err := m.NFS.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n117
+		i += n116
 	}
 	if m.RBD != nil {
 		dAtA[i] = 0x32
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.RBD.Size()))
-		n118, err := m.RBD.MarshalTo(dAtA[i:])
+		n117, err := m.RBD.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n118
+		i += n117
 	}
 	if m.ISCSI != nil {
 		dAtA[i] = 0x3a
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.ISCSI.Size()))
-		n119, err := m.ISCSI.MarshalTo(dAtA[i:])
+		n118, err := m.ISCSI.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n119
+		i += n118
 	}
 	if m.Cinder != nil {
 		dAtA[i] = 0x42
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.Cinder.Size()))
-		n120, err := m.Cinder.MarshalTo(dAtA[i:])
+		n119, err := m.Cinder.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n120
+		i += n119
 	}
 	if m.CephFS != nil {
 		dAtA[i] = 0x4a
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.CephFS.Size()))
-		n121, err := m.CephFS.MarshalTo(dAtA[i:])
+		n120, err := m.CephFS.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n121
+		i += n120
 	}
 	if m.FC != nil {
 		dAtA[i] = 0x52
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.FC.Size()))
-		n122, err := m.FC.MarshalTo(dAtA[i:])
+		n121, err := m.FC.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n122
+		i += n121
 	}
 	if m.Flocker != nil {
 		dAtA[i] = 0x5a
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.Flocker.Size()))
-		n123, err := m.Flocker.MarshalTo(dAtA[i:])
+		n122, err := m.Flocker.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n123
+		i += n122
 	}
 	if m.FlexVolume != nil {
 		dAtA[i] = 0x62
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.FlexVolume.Size()))
-		n124, err := m.FlexVolume.MarshalTo(dAtA[i:])
+		n123, err := m.FlexVolume.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n124
+		i += n123
 	}
 	if m.AzureFile != nil {
 		dAtA[i] = 0x6a
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.AzureFile.Size()))
-		n125, err := m.AzureFile.MarshalTo(dAtA[i:])
+		n124, err := m.AzureFile.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n125
+		i += n124
 	}
 	if m.VsphereVolume != nil {
 		dAtA[i] = 0x72
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.VsphereVolume.Size()))
-		n126, err := m.VsphereVolume.MarshalTo(dAtA[i:])
+		n125, err := m.VsphereVolume.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n126
+		i += n125
 	}
 	if m.Quobyte != nil {
 		dAtA[i] = 0x7a
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.Quobyte.Size()))
-		n127, err := m.Quobyte.MarshalTo(dAtA[i:])
+		n126, err := m.Quobyte.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n127
+		i += n126
 	}
-	if m.AzureDisk != nil {
+	if m.CascadeDisk != nil {
 		dAtA[i] = 0x82
 		i++
 		dAtA[i] = 0x1
 		i++
-		i = encodeVarintGenerated(dAtA, i, uint64(m.AzureDisk.Size()))
-		n128, err := m.AzureDisk.MarshalTo(dAtA[i:])
+		i = encodeVarintGenerated(dAtA, i, uint64(m.CascadeDisk.Size()))
+		n127, err := m.CascadeDisk.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n128
+		i += n127
 	}
 	if m.PhotonPersistentDisk != nil {
 		dAtA[i] = 0x8a
@@ -6493,11 +6456,11 @@ func (m *PersistentVolumeSource) MarshalTo(dAtA []byte) (int, error) {
 		dAtA[i] = 0x1
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.PhotonPersistentDisk.Size()))
-		n129, err := m.PhotonPersistentDisk.MarshalTo(dAtA[i:])
+		n128, err := m.PhotonPersistentDisk.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n129
+		i += n128
 	}
 	if m.PortworxVolume != nil {
 		dAtA[i] = 0x92
@@ -6505,11 +6468,11 @@ func (m *PersistentVolumeSource) MarshalTo(dAtA []byte) (int, error) {
 		dAtA[i] = 0x1
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.PortworxVolume.Size()))
-		n130, err := m.PortworxVolume.MarshalTo(dAtA[i:])
+		n129, err := m.PortworxVolume.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n130
+		i += n129
 	}
 	if m.ScaleIO != nil {
 		dAtA[i] = 0x9a
@@ -6517,11 +6480,11 @@ func (m *PersistentVolumeSource) MarshalTo(dAtA []byte) (int, error) {
 		dAtA[i] = 0x1
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.ScaleIO.Size()))
-		n131, err := m.ScaleIO.MarshalTo(dAtA[i:])
+		n130, err := m.ScaleIO.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n131
+		i += n130
 	}
 	if m.Local != nil {
 		dAtA[i] = 0xa2
@@ -6529,11 +6492,11 @@ func (m *PersistentVolumeSource) MarshalTo(dAtA []byte) (int, error) {
 		dAtA[i] = 0x1
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.Local.Size()))
-		n132, err := m.Local.MarshalTo(dAtA[i:])
+		n131, err := m.Local.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n132
+		i += n131
 	}
 	if m.StorageOS != nil {
 		dAtA[i] = 0xaa
@@ -6541,11 +6504,11 @@ func (m *PersistentVolumeSource) MarshalTo(dAtA []byte) (int, error) {
 		dAtA[i] = 0x1
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.StorageOS.Size()))
-		n133, err := m.StorageOS.MarshalTo(dAtA[i:])
+		n132, err := m.StorageOS.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
-		i += n133
+		i += n132
 	}
 	if m.CSI != nil {
 		dAtA[i] = 0xb2
@@ -6553,7 +6516,19 @@ func (m *PersistentVolumeSource) MarshalTo(dAtA []byte) (int, error) {
 		dAtA[i] = 0x1
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(m.CSI.Size()))
-		n134, err := m.CSI.MarshalTo(dAtA[i:])
+		n133, err := m.CSI.MarshalTo(dAtA[i:])
+		if err != nil {
+			return 0, err
+		}
+		i += n133
+	}
+	if m.AzureDisk != nil {
+		dAtA[i] = 0xba
+		i++
+		dAtA[i] = 0x1
+		i++
+		i = encodeVarintGenerated(dAtA, i, uint64(m.AzureDisk.Size()))
+		n134, err := m.AzureDisk.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
@@ -7723,26 +7698,6 @@ func (m *PodSpec) MarshalTo(dAtA []byte) (int, error) {
 			i += n
 		}
 	}
-	if m.RuntimeClassName != nil {
-		dAtA[i] = 0xea
-		i++
-		dAtA[i] = 0x1
-		i++
-		i = encodeVarintGenerated(dAtA, i, uint64(len(*m.RuntimeClassName)))
-		i += copy(dAtA[i:], *m.RuntimeClassName)
-	}
-	if m.EnableServiceLinks != nil {
-		dAtA[i] = 0xf0
-		i++
-		dAtA[i] = 0x1
-		i++
-		if *m.EnableServiceLinks {
-			dAtA[i] = 1
-		} else {
-			dAtA[i] = 0
-		}
-		i++
-	}
 	return i, nil
 }
 
@@ -9627,12 +9582,6 @@ func (m *SecurityContext) MarshalTo(dAtA []byte) (int, error) {
 		i++
 		i = encodeVarintGenerated(dAtA, i, uint64(*m.RunAsGroup))
 	}
-	if m.ProcMount != nil {
-		dAtA[i] = 0x4a
-		i++
-		i = encodeVarintGenerated(dAtA, i, uint64(len(*m.ProcMount)))
-		i += copy(dAtA[i:], *m.ProcMount)
-	}
 	return i, nil
 }
 
@@ -10412,38 +10361,6 @@ func (m *TopologySelectorTerm) MarshalTo(dAtA []byte) (int, error) {
 	return i, nil
 }
 
-func (m *TypedLocalObjectReference) Marshal() (dAtA []byte, err error) {
-	size := m.Size()
-	dAtA = make([]byte, size)
-	n, err := m.MarshalTo(dAtA)
-	if err != nil {
-		return nil, err
-	}
-	return dAtA[:n], nil
-}
-
-func (m *TypedLocalObjectReference) MarshalTo(dAtA []byte) (int, error) {
-	var i int
-	_ = i
-	var l int
-	_ = l
-	if m.APIGroup != nil {
-		dAtA[i] = 0xa
-		i++
-		i = encodeVarintGenerated(dAtA, i, uint64(len(*m.APIGroup)))
-		i += copy(dAtA[i:], *m.APIGroup)
-	}
-	dAtA[i] = 0x12
-	i++
-	i = encodeVarintGenerated(dAtA, i, uint64(len(m.Kind)))
-	i += copy(dAtA[i:], m.Kind)
-	dAtA[i] = 0x1a
-	i++
-	i = encodeVarintGenerated(dAtA, i, uint64(len(m.Name)))
-	i += copy(dAtA[i:], m.Name)
-	return i, nil
-}
-
 func (m *Volume) Marshal() (dAtA []byte, err error) {
 	size := m.Size()
 	dAtA = make([]byte, size)
@@ -10867,13 +10784,13 @@ func (m *VolumeSource) MarshalTo(dAtA []byte) (int, error) {
 		}
 		i += n234
 	}
-	if m.AzureDisk != nil {
+	if m.CascadeDisk != nil {
 		dAtA[i] = 0xb2
 		i++
 		dAtA[i] = 0x1
 		i++
-		i = encodeVarintGenerated(dAtA, i, uint64(m.AzureDisk.Size()))
-		n235, err := m.AzureDisk.MarshalTo(dAtA[i:])
+		i = encodeVarintGenerated(dAtA, i, uint64(m.CascadeDisk.Size()))
+		n235, err := m.CascadeDisk.MarshalTo(dAtA[i:])
 		if err != nil {
 			return 0, err
 		}
@@ -10939,6 +10856,18 @@ func (m *VolumeSource) MarshalTo(dAtA []byte) (int, error) {
 		}
 		i += n240
 	}
+	if m.AzureDisk != nil {
+		dAtA[i] = 0xe2
+		i++
+		dAtA[i] = 0x1
+		i++
+		i = encodeVarintGenerated(dAtA, i, uint64(m.AzureDisk.Size()))
+		n241, err := m.AzureDisk.MarshalTo(dAtA[i:])
+		if err != nil {
+			return 0, err
+		}
+		i += n241
+	}
 	return i, nil
 }
 
@@ -10997,14 +10926,32 @@ func (m *WeightedPodAffinityTerm) MarshalTo(dAtA []byte) (int, error) {
 	dAtA[i] = 0x12
 	i++
 	i = encodeVarintGenerated(dAtA, i, uint64(m.PodAffinityTerm.Size()))
-	n241, err := m.PodAffinityTerm.MarshalTo(dAtA[i:])
+	n242, err := m.PodAffinityTerm.MarshalTo(dAtA[i:])
 	if err != nil {
 		return 0, err
 	}
-	i += n241
+	i += n242
 	return i, nil
 }
 
+func encodeFixed64Generated(dAtA []byte, offset int, v uint64) int {
+	dAtA[offset] = uint8(v)
+	dAtA[offset+1] = uint8(v >> 8)
+	dAtA[offset+2] = uint8(v >> 16)
+	dAtA[offset+3] = uint8(v >> 24)
+	dAtA[offset+4] = uint8(v >> 32)
+	dAtA[offset+5] = uint8(v >> 40)
+	dAtA[offset+6] = uint8(v >> 48)
+	dAtA[offset+7] = uint8(v >> 56)
+	return offset + 8
+}
+func encodeFixed32Generated(dAtA []byte, offset int, v uint32) int {
+	dAtA[offset] = uint8(v)
+	dAtA[offset+1] = uint8(v >> 8)
+	dAtA[offset+2] = uint8(v >> 16)
+	dAtA[offset+3] = uint8(v >> 24)
+	return offset + 4
+}
 func encodeVarintGenerated(dAtA []byte, offset int, v uint64) int {
 	for v >= 1<<7 {
 		dAtA[offset] = uint8(v&0x7f | 0x80)
@@ -11178,6 +11125,16 @@ func (m *Capabilities) Size() (n int) {
 	return n
 }
 
+func (m *CascadeDiskVolumeSource) Size() (n int) {
+	var l int
+	_ = l
+	l = len(m.DiskID)
+	n += 1 + l + sovGenerated(uint64(l))
+	l = len(m.FSType)
+	n += 1 + l + sovGenerated(uint64(l))
+	return n
+}
+
 func (m *CephFSPersistentVolumeSource) Size() (n int) {
 	var l int
 	_ = l
@@ -11994,21 +11951,6 @@ func (m *GitRepoVolumeSource) Size() (n int) {
 	return n
 }
 
-func (m *GlusterfsPersistentVolumeSource) Size() (n int) {
-	var l int
-	_ = l
-	l = len(m.EndpointsName)
-	n += 1 + l + sovGenerated(uint64(l))
-	l = len(m.Path)
-	n += 1 + l + sovGenerated(uint64(l))
-	n += 2
-	if m.EndpointsNamespace != nil {
-		l = len(*m.EndpointsNamespace)
-		n += 1 + l + sovGenerated(uint64(l))
-	}
-	return n
-}
-
 func (m *GlusterfsVolumeSource) Size() (n int) {
 	var l int
 	_ = l
@@ -12323,10 +12265,6 @@ func (m *LocalVolumeSource) Size() (n int) {
 	_ = l
 	l = len(m.Path)
 	n += 1 + l + sovGenerated(uint64(l))
-	if m.FSType != nil {
-		l = len(*m.FSType)
-		n += 1 + l + sovGenerated(uint64(l))
-	}
 	return n
 }
 
@@ -12788,10 +12726,6 @@ func (m *PersistentVolumeClaimSpec) Size() (n int) {
 		l = len(*m.VolumeMode)
 		n += 1 + l + sovGenerated(uint64(l))
 	}
-	if m.DataSource != nil {
-		l = m.DataSource.Size()
-		n += 1 + l + sovGenerated(uint64(l))
-	}
 	return n
 }
 
@@ -12910,8 +12844,8 @@ func (m *PersistentVolumeSource) Size() (n int) {
 		l = m.Quobyte.Size()
 		n += 1 + l + sovGenerated(uint64(l))
 	}
-	if m.AzureDisk != nil {
-		l = m.AzureDisk.Size()
+	if m.CascadeDisk != nil {
+		l = m.CascadeDisk.Size()
 		n += 2 + l + sovGenerated(uint64(l))
 	}
 	if m.PhotonPersistentDisk != nil {
@@ -12938,6 +12872,10 @@ func (m *PersistentVolumeSource) Size() (n int) {
 		l = m.CSI.Size()
 		n += 2 + l + sovGenerated(uint64(l))
 	}
+	if m.AzureDisk != nil {
+		l = m.AzureDisk.Size()
+		n += 2 + l + sovGenerated(uint64(l))
+	}
 	return n
 }
 
@@ -13367,13 +13305,6 @@ func (m *PodSpec) Size() (n int) {
 			n += 2 + l + sovGenerated(uint64(l))
 		}
 	}
-	if m.RuntimeClassName != nil {
-		l = len(*m.RuntimeClassName)
-		n += 2 + l + sovGenerated(uint64(l))
-	}
-	if m.EnableServiceLinks != nil {
-		n += 3
-	}
 	return n
 }
 
@@ -14048,10 +13979,6 @@ func (m *SecurityContext) Size() (n int) {
 	if m.RunAsGroup != nil {
 		n += 1 + sovGenerated(uint64(*m.RunAsGroup))
 	}
-	if m.ProcMount != nil {
-		l = len(*m.ProcMount)
-		n += 1 + l + sovGenerated(uint64(l))
-	}
 	return n
 }
 
@@ -14342,20 +14269,6 @@ func (m *TopologySelectorTerm) Size() (n int) {
 	return n
 }
 
-func (m *TypedLocalObjectReference) Size() (n int) {
-	var l int
-	_ = l
-	if m.APIGroup != nil {
-		l = len(*m.APIGroup)
-		n += 1 + l + sovGenerated(uint64(l))
-	}
-	l = len(m.Kind)
-	n += 1 + l + sovGenerated(uint64(l))
-	l = len(m.Name)
-	n += 1 + l + sovGenerated(uint64(l))
-	return n
-}
-
 func (m *Volume) Size() (n int) {
 	var l int
 	_ = l
@@ -14512,8 +14425,8 @@ func (m *VolumeSource) Size() (n int) {
 		l = m.Quobyte.Size()
 		n += 2 + l + sovGenerated(uint64(l))
 	}
-	if m.AzureDisk != nil {
-		l = m.AzureDisk.Size()
+	if m.CascadeDisk != nil {
+		l = m.CascadeDisk.Size()
 		n += 2 + l + sovGenerated(uint64(l))
 	}
 	if m.PhotonPersistentDisk != nil {
@@ -14536,6 +14449,10 @@ func (m *VolumeSource) Size() (n int) {
 		l = m.StorageOS.Size()
 		n += 2 + l + sovGenerated(uint64(l))
 	}
+	if m.AzureDisk != nil {
+		l = m.AzureDisk.Size()
+		n += 2 + l + sovGenerated(uint64(l))
+	}
 	return n
 }
 
@@ -14710,6 +14627,17 @@ func (this *Capabilities) String() string {
 	}, "")
 	return s
 }
+func (this *CascadeDiskVolumeSource) String() string {
+	if this == nil {
+		return "nil"
+	}
+	s := strings.Join([]string{`&CascadeDiskVolumeSource{`,
+		`DiskID:` + fmt.Sprintf("%v", this.DiskID) + `,`,
+		`FSType:` + fmt.Sprintf("%v", this.FSType) + `,`,
+		`}`,
+	}, "")
+	return s
+}
 func (this *CephFSPersistentVolumeSource) String() string {
 	if this == nil {
 		return "nil"
@@ -15354,19 +15282,6 @@ func (this *GitRepoVolumeSource) String() string {
 	}, "")
 	return s
 }
-func (this *GlusterfsPersistentVolumeSource) String() string {
-	if this == nil {
-		return "nil"
-	}
-	s := strings.Join([]string{`&GlusterfsPersistentVolumeSource{`,
-		`EndpointsName:` + fmt.Sprintf("%v", this.EndpointsName) + `,`,
-		`Path:` + fmt.Sprintf("%v", this.Path) + `,`,
-		`ReadOnly:` + fmt.Sprintf("%v", this.ReadOnly) + `,`,
-		`EndpointsNamespace:` + valueToStringGenerated(this.EndpointsNamespace) + `,`,
-		`}`,
-	}, "")
-	return s
-}
 func (this *GlusterfsVolumeSource) String() string {
 	if this == nil {
 		return "nil"
@@ -15646,7 +15561,6 @@ func (this *LocalVolumeSource) String() string {
 	}
 	s := strings.Join([]string{`&LocalVolumeSource{`,
 		`Path:` + fmt.Sprintf("%v", this.Path) + `,`,
-		`FSType:` + valueToStringGenerated(this.FSType) + `,`,
 		`}`,
 	}, "")
 	return s
@@ -16024,7 +15938,6 @@ func (this *PersistentVolumeClaimSpec) String() string {
 		`Selector:` + strings.Replace(fmt.Sprintf("%v", this.Selector), "LabelSelector", "k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector", 1) + `,`,
 		`StorageClassName:` + valueToStringGenerated(this.StorageClassName) + `,`,
 		`VolumeMode:` + valueToStringGenerated(this.VolumeMode) + `,`,
-		`DataSource:` + strings.Replace(fmt.Sprintf("%v", this.DataSource), "TypedLocalObjectReference", "TypedLocalObjectReference", 1) + `,`,
 		`}`,
 	}, "")
 	return s
@@ -16082,7 +15995,7 @@ func (this *PersistentVolumeSource) String() string {
 		`GCEPersistentDisk:` + strings.Replace(fmt.Sprintf("%v", this.GCEPersistentDisk), "GCEPersistentDiskVolumeSource", "GCEPersistentDiskVolumeSource", 1) + `,`,
 		`AWSElasticBlockStore:` + strings.Replace(fmt.Sprintf("%v", this.AWSElasticBlockStore), "AWSElasticBlockStoreVolumeSource", "AWSElasticBlockStoreVolumeSource", 1) + `,`,
 		`HostPath:` + strings.Replace(fmt.Sprintf("%v", this.HostPath), "HostPathVolumeSource", "HostPathVolumeSource", 1) + `,`,
-		`Glusterfs:` + strings.Replace(fmt.Sprintf("%v", this.Glusterfs), "GlusterfsPersistentVolumeSource", "GlusterfsPersistentVolumeSource", 1) + `,`,
+		`Glusterfs:` + strings.Replace(fmt.Sprintf("%v", this.Glusterfs), "GlusterfsVolumeSource", "GlusterfsVolumeSource", 1) + `,`,
 		`NFS:` + strings.Replace(fmt.Sprintf("%v", this.NFS), "NFSVolumeSource", "NFSVolumeSource", 1) + `,`,
 		`RBD:` + strings.Replace(fmt.Sprintf("%v", this.RBD), "RBDPersistentVolumeSource", "RBDPersistentVolumeSource", 1) + `,`,
 		`ISCSI:` + strings.Replace(fmt.Sprintf("%v", this.ISCSI), "ISCSIPersistentVolumeSource", "ISCSIPersistentVolumeSource", 1) + `,`,
@@ -16094,13 +16007,14 @@ func (this *PersistentVolumeSource) String() string {
 		`AzureFile:` + strings.Replace(fmt.Sprintf("%v", this.AzureFile), "AzureFilePersistentVolumeSource", "AzureFilePersistentVolumeSource", 1) + `,`,
 		`VsphereVolume:` + strings.Replace(fmt.Sprintf("%v", this.VsphereVolume), "VsphereVirtualDiskVolumeSource", "VsphereVirtualDiskVolumeSource", 1) + `,`,
 		`Quobyte:` + strings.Replace(fmt.Sprintf("%v", this.Quobyte), "QuobyteVolumeSource", "QuobyteVolumeSource", 1) + `,`,
-		`AzureDisk:` + strings.Replace(fmt.Sprintf("%v", this.AzureDisk), "AzureDiskVolumeSource", "AzureDiskVolumeSource", 1) + `,`,
+		`CascadeDisk:` + strings.Replace(fmt.Sprintf("%v", this.CascadeDisk), "CascadeDiskVolumeSource", "CascadeDiskVolumeSource", 1) + `,`,
 		`PhotonPersistentDisk:` + strings.Replace(fmt.Sprintf("%v", this.PhotonPersistentDisk), "PhotonPersistentDiskVolumeSource", "PhotonPersistentDiskVolumeSource", 1) + `,`,
 		`PortworxVolume:` + strings.Replace(fmt.Sprintf("%v", this.PortworxVolume), "PortworxVolumeSource", "PortworxVolumeSource", 1) + `,`,
 		`ScaleIO:` + strings.Replace(fmt.Sprintf("%v", this.ScaleIO), "ScaleIOPersistentVolumeSource", "ScaleIOPersistentVolumeSource", 1) + `,`,
 		`Local:` + strings.Replace(fmt.Sprintf("%v", this.Local), "LocalVolumeSource", "LocalVolumeSource", 1) + `,`,
 		`StorageOS:` + strings.Replace(fmt.Sprintf("%v", this.StorageOS), "StorageOSPersistentVolumeSource", "StorageOSPersistentVolumeSource", 1) + `,`,
 		`CSI:` + strings.Replace(fmt.Sprintf("%v", this.CSI), "CSIPersistentVolumeSource", "CSIPersistentVolumeSource", 1) + `,`,
+		`AzureDisk:` + strings.Replace(fmt.Sprintf("%v", this.AzureDisk), "AzureDiskVolumeSource", "AzureDiskVolumeSource", 1) + `,`,
 		`}`,
 	}, "")
 	return s
@@ -16396,8 +16310,6 @@ func (this *PodSpec) String() string {
 		`DNSConfig:` + strings.Replace(fmt.Sprintf("%v", this.DNSConfig), "PodDNSConfig", "PodDNSConfig", 1) + `,`,
 		`ShareProcessNamespace:` + valueToStringGenerated(this.ShareProcessNamespace) + `,`,
 		`ReadinessGates:` + strings.Replace(strings.Replace(fmt.Sprintf("%v", this.ReadinessGates), "PodReadinessGate", "PodReadinessGate", 1), `&`, ``, 1) + `,`,
-		`RuntimeClassName:` + valueToStringGenerated(this.RuntimeClassName) + `,`,
-		`EnableServiceLinks:` + valueToStringGenerated(this.EnableServiceLinks) + `,`,
 		`}`,
 	}, "")
 	return s
@@ -16981,7 +16893,6 @@ func (this *SecurityContext) String() string {
 		`ReadOnlyRootFilesystem:` + valueToStringGenerated(this.ReadOnlyRootFilesystem) + `,`,
 		`AllowPrivilegeEscalation:` + valueToStringGenerated(this.AllowPrivilegeEscalation) + `,`,
 		`RunAsGroup:` + valueToStringGenerated(this.RunAsGroup) + `,`,
-		`ProcMount:` + valueToStringGenerated(this.ProcMount) + `,`,
 		`}`,
 	}, "")
 	return s
@@ -17229,18 +17140,6 @@ func (this *TopologySelectorTerm) String() string {
 	}, "")
 	return s
 }
-func (this *TypedLocalObjectReference) String() string {
-	if this == nil {
-		return "nil"
-	}
-	s := strings.Join([]string{`&TypedLocalObjectReference{`,
-		`APIGroup:` + valueToStringGenerated(this.APIGroup) + `,`,
-		`Kind:` + fmt.Sprintf("%v", this.Kind) + `,`,
-		`Name:` + fmt.Sprintf("%v", this.Name) + `,`,
-		`}`,
-	}, "")
-	return s
-}
 func (this *Volume) String() string {
 	if this == nil {
 		return "nil"
@@ -17326,12 +17225,13 @@ func (this *VolumeSource) String() string {
 		`ConfigMap:` + strings.Replace(fmt.Sprintf("%v", this.ConfigMap), "ConfigMapVolumeSource", "ConfigMapVolumeSource", 1) + `,`,
 		`VsphereVolume:` + strings.Replace(fmt.Sprintf("%v", this.VsphereVolume), "VsphereVirtualDiskVolumeSource", "VsphereVirtualDiskVolumeSource", 1) + `,`,
 		`Quobyte:` + strings.Replace(fmt.Sprintf("%v", this.Quobyte), "QuobyteVolumeSource", "QuobyteVolumeSource", 1) + `,`,
-		`AzureDisk:` + strings.Replace(fmt.Sprintf("%v", this.AzureDisk), "AzureDiskVolumeSource", "AzureDiskVolumeSource", 1) + `,`,
+		`CascadeDisk:` + strings.Replace(fmt.Sprintf("%v", this.CascadeDisk), "CascadeDiskVolumeSource", "CascadeDiskVolumeSource", 1) + `,`,
 		`PhotonPersistentDisk:` + strings.Replace(fmt.Sprintf("%v", this.PhotonPersistentDisk), "PhotonPersistentDiskVolumeSource", "PhotonPersistentDiskVolumeSource", 1) + `,`,
 		`PortworxVolume:` + strings.Replace(fmt.Sprintf("%v", this.PortworxVolume), "PortworxVolumeSource", "PortworxVolumeSource", 1) + `,`,
 		`ScaleIO:` + strings.Replace(fmt.Sprintf("%v", this.ScaleIO), "ScaleIOVolumeSource", "ScaleIOVolumeSource", 1) + `,`,
 		`Projected:` + strings.Replace(fmt.Sprintf("%v", this.Projected), "ProjectedVolumeSource", "ProjectedVolumeSource", 1) + `,`,
 		`StorageOS:` + strings.Replace(fmt.Sprintf("%v", this.StorageOS), "StorageOSVolumeSource", "StorageOSVolumeSource", 1) + `,`,
+		`AzureDisk:` + strings.Replace(fmt.Sprintf("%v", this.AzureDisk), "AzureDiskVolumeSource", "AzureDiskVolumeSource", 1) + `,`,
 		`}`,
 	}, "")
 	return s
@@ -18630,14 +18530,51 @@ func (m *CSIPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.VolumeAttributes == nil {
 				m.VolumeAttributes = make(map[string]string)
 			}
-			var mapkey string
-			var mapvalue string
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -18647,80 +18584,41 @@ func (m *CSIPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var stringLenmapvalue uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapvalue |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapvalue := int(stringLenmapvalue)
-					if intStringLenmapvalue < 0 {
-						return ErrInvalidLengthGenerated
+				var stringLenmapvalue uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
-					if postStringIndexmapvalue > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
-					iNdEx = postStringIndexmapvalue
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					stringLenmapvalue |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				intStringLenmapvalue := int(stringLenmapvalue)
+				if intStringLenmapvalue < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postStringIndexmapvalue := iNdEx + intStringLenmapvalue
+				if postStringIndexmapvalue > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := string(dAtA[iNdEx:postStringIndexmapvalue])
+				iNdEx = postStringIndexmapvalue
+				m.VolumeAttributes[mapkey] = mapvalue
+			} else {
+				var mapvalue string
+				m.VolumeAttributes[mapkey] = mapvalue
 			}
-			m.VolumeAttributes[mapkey] = mapvalue
 			iNdEx = postIndex
 		case 6:
 			if wireType != 2 {
@@ -18950,6 +18848,114 @@ func (m *Capabilities) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
+func (m *CascadeDiskVolumeSource) Unmarshal(dAtA []byte) error {
+	l := len(dAtA)
+	iNdEx := 0
+	for iNdEx < l {
+		preIndex := iNdEx
+		var wire uint64
+		for shift := uint(0); ; shift += 7 {
+			if shift >= 64 {
+				return ErrIntOverflowGenerated
+			}
+			if iNdEx >= l {
+				return io.ErrUnexpectedEOF
+			}
+			b := dAtA[iNdEx]
+			iNdEx++
+			wire |= (uint64(b) & 0x7F) << shift
+			if b < 0x80 {
+				break
+			}
+		}
+		fieldNum := int32(wire >> 3)
+		wireType := int(wire & 0x7)
+		if wireType == 4 {
+			return fmt.Errorf("proto: CascadeDiskVolumeSource: wiretype end group for non-group")
+		}
+		if fieldNum <= 0 {
+			return fmt.Errorf("proto: CascadeDiskVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
+		}
+		switch fieldNum {
+		case 1:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field DiskID", wireType)
+			}
+			var stringLen uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLen |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLen := int(stringLen)
+			if intStringLen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + intStringLen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			m.DiskID = string(dAtA[iNdEx:postIndex])
+			iNdEx = postIndex
+		case 2:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field FSType", wireType)
+			}
+			var stringLen uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLen |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLen := int(stringLen)
+			if intStringLen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + intStringLen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			m.FSType = string(dAtA[iNdEx:postIndex])
+			iNdEx = postIndex
+		default:
+			iNdEx = preIndex
+			skippy, err := skipGenerated(dAtA[iNdEx:])
+			if err != nil {
+				return err
+			}
+			if skippy < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			if (iNdEx + skippy) > l {
+				return io.ErrUnexpectedEOF
+			}
+			iNdEx += skippy
+		}
+	}
+
+	if iNdEx > l {
+		return io.ErrUnexpectedEOF
+	}
+	return nil
+}
 func (m *CephFSPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
@@ -20253,14 +20259,51 @@ func (m *ConfigMap) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Data == nil {
 				m.Data = make(map[string]string)
 			}
-			var mapkey string
-			var mapvalue string
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -20270,80 +20313,41 @@ func (m *ConfigMap) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var stringLenmapvalue uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapvalue |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapvalue := int(stringLenmapvalue)
-					if intStringLenmapvalue < 0 {
-						return ErrInvalidLengthGenerated
+				var stringLenmapvalue uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
-					if postStringIndexmapvalue > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
-					iNdEx = postStringIndexmapvalue
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					stringLenmapvalue |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				intStringLenmapvalue := int(stringLenmapvalue)
+				if intStringLenmapvalue < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postStringIndexmapvalue := iNdEx + intStringLenmapvalue
+				if postStringIndexmapvalue > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := string(dAtA[iNdEx:postStringIndexmapvalue])
+				iNdEx = postStringIndexmapvalue
+				m.Data[mapkey] = mapvalue
+			} else {
+				var mapvalue string
+				m.Data[mapkey] = mapvalue
 			}
-			m.Data[mapkey] = mapvalue
 			iNdEx = postIndex
 		case 3:
 			if wireType != 2 {
@@ -20371,14 +20375,51 @@ func (m *ConfigMap) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.BinaryData == nil {
 				m.BinaryData = make(map[string][]byte)
 			}
-			var mapkey string
-			mapvalue := []byte{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -20388,81 +20429,42 @@ func (m *ConfigMap) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapbyteLen uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapbyteLen |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intMapbyteLen := int(mapbyteLen)
-					if intMapbyteLen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapbyteLen uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postbytesIndex := iNdEx + intMapbyteLen
-					if postbytesIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = make([]byte, mapbyteLen)
-					copy(mapvalue, dAtA[iNdEx:postbytesIndex])
-					iNdEx = postbytesIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapbyteLen |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				intMapbyteLen := int(mapbyteLen)
+				if intMapbyteLen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postbytesIndex := iNdEx + intMapbyteLen
+				if postbytesIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := make([]byte, mapbyteLen)
+				copy(mapvalue, dAtA[iNdEx:postbytesIndex])
+				iNdEx = postbytesIndex
+				m.BinaryData[mapkey] = mapvalue
+			} else {
+				var mapvalue []byte
+				m.BinaryData[mapkey] = mapvalue
 			}
-			m.BinaryData[mapkey] = mapvalue
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -25992,14 +25994,51 @@ func (m *FlexPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Options == nil {
 				m.Options = make(map[string]string)
 			}
-			var mapkey string
-			var mapvalue string
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -26009,80 +26048,41 @@ func (m *FlexPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var stringLenmapvalue uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapvalue |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapvalue := int(stringLenmapvalue)
-					if intStringLenmapvalue < 0 {
-						return ErrInvalidLengthGenerated
+				var stringLenmapvalue uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
-					if postStringIndexmapvalue > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
-					iNdEx = postStringIndexmapvalue
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					stringLenmapvalue |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				intStringLenmapvalue := int(stringLenmapvalue)
+				if intStringLenmapvalue < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postStringIndexmapvalue := iNdEx + intStringLenmapvalue
+				if postStringIndexmapvalue > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := string(dAtA[iNdEx:postStringIndexmapvalue])
+				iNdEx = postStringIndexmapvalue
+				m.Options[mapkey] = mapvalue
+			} else {
+				var mapvalue string
+				m.Options[mapkey] = mapvalue
 			}
-			m.Options[mapkey] = mapvalue
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -26271,14 +26271,51 @@ func (m *FlexVolumeSource) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Options == nil {
 				m.Options = make(map[string]string)
 			}
-			var mapkey string
-			var mapvalue string
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -26288,80 +26325,41 @@ func (m *FlexVolumeSource) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var stringLenmapvalue uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapvalue |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapvalue := int(stringLenmapvalue)
-					if intStringLenmapvalue < 0 {
-						return ErrInvalidLengthGenerated
+				var stringLenmapvalue uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
-					if postStringIndexmapvalue > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
-					iNdEx = postStringIndexmapvalue
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					stringLenmapvalue |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				intStringLenmapvalue := int(stringLenmapvalue)
+				if intStringLenmapvalue < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postStringIndexmapvalue := iNdEx + intStringLenmapvalue
+				if postStringIndexmapvalue > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := string(dAtA[iNdEx:postStringIndexmapvalue])
+				iNdEx = postStringIndexmapvalue
+				m.Options[mapkey] = mapvalue
+			} else {
+				var mapvalue string
+				m.Options[mapkey] = mapvalue
 			}
-			m.Options[mapkey] = mapvalue
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -26776,7 +26774,7 @@ func (m *GitRepoVolumeSource) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *GlusterfsPersistentVolumeSource) Unmarshal(dAtA []byte) error {
+func (m *GlusterfsVolumeSource) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -26799,10 +26797,10 @@ func (m *GlusterfsPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: GlusterfsPersistentVolumeSource: wiretype end group for non-group")
+			return fmt.Errorf("proto: GlusterfsVolumeSource: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: GlusterfsPersistentVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: GlusterfsVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
@@ -26883,36 +26881,6 @@ func (m *GlusterfsPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 				}
 			}
 			m.ReadOnly = bool(v != 0)
-		case 4:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field EndpointsNamespace", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			s := string(dAtA[iNdEx:postIndex])
-			m.EndpointsNamespace = &s
-			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
 			skippy, err := skipGenerated(dAtA[iNdEx:])
@@ -26934,135 +26902,7 @@ func (m *GlusterfsPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *GlusterfsVolumeSource) Unmarshal(dAtA []byte) error {
-	l := len(dAtA)
-	iNdEx := 0
-	for iNdEx < l {
-		preIndex := iNdEx
-		var wire uint64
-		for shift := uint(0); ; shift += 7 {
-			if shift >= 64 {
-				return ErrIntOverflowGenerated
-			}
-			if iNdEx >= l {
-				return io.ErrUnexpectedEOF
-			}
-			b := dAtA[iNdEx]
-			iNdEx++
-			wire |= (uint64(b) & 0x7F) << shift
-			if b < 0x80 {
-				break
-			}
-		}
-		fieldNum := int32(wire >> 3)
-		wireType := int(wire & 0x7)
-		if wireType == 4 {
-			return fmt.Errorf("proto: GlusterfsVolumeSource: wiretype end group for non-group")
-		}
-		if fieldNum <= 0 {
-			return fmt.Errorf("proto: GlusterfsVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
-		}
-		switch fieldNum {
-		case 1:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field EndpointsName", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.EndpointsName = string(dAtA[iNdEx:postIndex])
-			iNdEx = postIndex
-		case 2:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Path", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.Path = string(dAtA[iNdEx:postIndex])
-			iNdEx = postIndex
-		case 3:
-			if wireType != 0 {
-				return fmt.Errorf("proto: wrong wireType = %d for field ReadOnly", wireType)
-			}
-			var v int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				v |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			m.ReadOnly = bool(v != 0)
-		default:
-			iNdEx = preIndex
-			skippy, err := skipGenerated(dAtA[iNdEx:])
-			if err != nil {
-				return err
-			}
-			if skippy < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			if (iNdEx + skippy) > l {
-				return io.ErrUnexpectedEOF
-			}
-			iNdEx += skippy
-		}
-	}
-
-	if iNdEx > l {
-		return io.ErrUnexpectedEOF
-	}
-	return nil
-}
-func (m *HTTPGetAction) Unmarshal(dAtA []byte) error {
+func (m *HTTPGetAction) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -28846,108 +28686,22 @@ func (m *LimitRangeItem) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			if m.Max == nil {
-				m.Max = make(ResourceList)
-			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
-				for shift := uint(0); ; shift += 7 {
-					if shift >= 64 {
-						return ErrIntOverflowGenerated
-					}
-					if iNdEx >= l {
-						return io.ErrUnexpectedEOF
-					}
-					b := dAtA[iNdEx]
-					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
-					if b < 0x80 {
-						break
-					}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if postmsgIndex > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
-					}
-					iNdEx += skippy
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
 				}
 			}
-			m.Max[ResourceName(mapkey)] = *mapvalue
-			iNdEx = postIndex
-		case 3:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Min", wireType)
-			}
-			var msglen int
+			var stringLenmapkey uint64
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -28957,26 +28711,26 @@ func (m *LimitRangeItem) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			if msglen < 0 {
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
 				return ErrInvalidLengthGenerated
 			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
 				return io.ErrUnexpectedEOF
 			}
-			if m.Min == nil {
-				m.Min = make(ResourceList)
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
+			if m.Max == nil {
+				m.Max = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -28986,89 +28740,50 @@ func (m *LimitRangeItem) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Max[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Max[ResourceName(mapkey)] = mapvalue
 			}
-			m.Min[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
-		case 4:
+		case 3:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Default", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Min", wireType)
 			}
 			var msglen int
 			for shift := uint(0); ; shift += 7 {
@@ -29092,14 +28807,51 @@ func (m *LimitRangeItem) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			if m.Default == nil {
-				m.Default = make(ResourceList)
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
+			if m.Min == nil {
+				m.Min = make(ResourceList)
+			}
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -29109,85 +28861,167 @@ func (m *LimitRangeItem) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Min[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Min[ResourceName(mapkey)] = mapvalue
+			}
+			iNdEx = postIndex
+		case 4:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Default", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
+			if m.Default == nil {
+				m.Default = make(ResourceList)
+			}
+			if iNdEx < postIndex {
+				var valuekey uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
+					b := dAtA[iNdEx]
+					iNdEx++
+					valuekey |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
+				}
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if (iNdEx + skippy) > postIndex {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					iNdEx += skippy
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
+					}
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Default[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Default[ResourceName(mapkey)] = mapvalue
 			}
-			m.Default[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		case 5:
 			if wireType != 2 {
@@ -29215,14 +29049,51 @@ func (m *LimitRangeItem) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.DefaultRequest == nil {
 				m.DefaultRequest = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -29232,85 +29103,46 @@ func (m *LimitRangeItem) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.DefaultRequest[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.DefaultRequest[ResourceName(mapkey)] = mapvalue
 			}
-			m.DefaultRequest[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		case 6:
 			if wireType != 2 {
@@ -29338,14 +29170,51 @@ func (m *LimitRangeItem) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.MaxLimitRequestRatio == nil {
 				m.MaxLimitRequestRatio = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -29355,85 +29224,46 @@ func (m *LimitRangeItem) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.MaxLimitRequestRatio[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.MaxLimitRequestRatio[ResourceName(mapkey)] = mapvalue
 			}
-			m.MaxLimitRequestRatio[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -29890,98 +29720,17 @@ func (m *LoadBalancerStatus) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: LoadBalancerStatus: wiretype end group for non-group")
-		}
-		if fieldNum <= 0 {
-			return fmt.Errorf("proto: LoadBalancerStatus: illegal tag %d (wire type %d)", fieldNum, wire)
-		}
-		switch fieldNum {
-		case 1:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Ingress", wireType)
-			}
-			var msglen int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			if msglen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.Ingress = append(m.Ingress, LoadBalancerIngress{})
-			if err := m.Ingress[len(m.Ingress)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
-			iNdEx = postIndex
-		default:
-			iNdEx = preIndex
-			skippy, err := skipGenerated(dAtA[iNdEx:])
-			if err != nil {
-				return err
-			}
-			if skippy < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			if (iNdEx + skippy) > l {
-				return io.ErrUnexpectedEOF
-			}
-			iNdEx += skippy
-		}
-	}
-
-	if iNdEx > l {
-		return io.ErrUnexpectedEOF
-	}
-	return nil
-}
-func (m *LocalObjectReference) Unmarshal(dAtA []byte) error {
-	l := len(dAtA)
-	iNdEx := 0
-	for iNdEx < l {
-		preIndex := iNdEx
-		var wire uint64
-		for shift := uint(0); ; shift += 7 {
-			if shift >= 64 {
-				return ErrIntOverflowGenerated
-			}
-			if iNdEx >= l {
-				return io.ErrUnexpectedEOF
-			}
-			b := dAtA[iNdEx]
-			iNdEx++
-			wire |= (uint64(b) & 0x7F) << shift
-			if b < 0x80 {
-				break
-			}
-		}
-		fieldNum := int32(wire >> 3)
-		wireType := int(wire & 0x7)
-		if wireType == 4 {
-			return fmt.Errorf("proto: LocalObjectReference: wiretype end group for non-group")
+			return fmt.Errorf("proto: LoadBalancerStatus: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: LocalObjectReference: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: LoadBalancerStatus: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Ingress", wireType)
 			}
-			var stringLen uint64
+			var msglen int
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -29991,20 +29740,22 @@ func (m *LocalObjectReference) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
+				msglen |= (int(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
+			if msglen < 0 {
 				return ErrInvalidLengthGenerated
 			}
-			postIndex := iNdEx + intStringLen
+			postIndex := iNdEx + msglen
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Name = string(dAtA[iNdEx:postIndex])
+			m.Ingress = append(m.Ingress, LoadBalancerIngress{})
+			if err := m.Ingress[len(m.Ingress)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -30027,7 +29778,7 @@ func (m *LocalObjectReference) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *LocalVolumeSource) Unmarshal(dAtA []byte) error {
+func (m *LocalObjectReference) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -30050,15 +29801,15 @@ func (m *LocalVolumeSource) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: LocalVolumeSource: wiretype end group for non-group")
+			return fmt.Errorf("proto: LocalObjectReference: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: LocalVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: LocalObjectReference: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Path", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
 			}
 			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
@@ -30083,11 +29834,61 @@ func (m *LocalVolumeSource) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Path = string(dAtA[iNdEx:postIndex])
+			m.Name = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
-		case 2:
+		default:
+			iNdEx = preIndex
+			skippy, err := skipGenerated(dAtA[iNdEx:])
+			if err != nil {
+				return err
+			}
+			if skippy < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			if (iNdEx + skippy) > l {
+				return io.ErrUnexpectedEOF
+			}
+			iNdEx += skippy
+		}
+	}
+
+	if iNdEx > l {
+		return io.ErrUnexpectedEOF
+	}
+	return nil
+}
+func (m *LocalVolumeSource) Unmarshal(dAtA []byte) error {
+	l := len(dAtA)
+	iNdEx := 0
+	for iNdEx < l {
+		preIndex := iNdEx
+		var wire uint64
+		for shift := uint(0); ; shift += 7 {
+			if shift >= 64 {
+				return ErrIntOverflowGenerated
+			}
+			if iNdEx >= l {
+				return io.ErrUnexpectedEOF
+			}
+			b := dAtA[iNdEx]
+			iNdEx++
+			wire |= (uint64(b) & 0x7F) << shift
+			if b < 0x80 {
+				break
+			}
+		}
+		fieldNum := int32(wire >> 3)
+		wireType := int(wire & 0x7)
+		if wireType == 4 {
+			return fmt.Errorf("proto: LocalVolumeSource: wiretype end group for non-group")
+		}
+		if fieldNum <= 0 {
+			return fmt.Errorf("proto: LocalVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
+		}
+		switch fieldNum {
+		case 1:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field FSType", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Path", wireType)
 			}
 			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
@@ -30112,8 +29913,7 @@ func (m *LocalVolumeSource) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			s := string(dAtA[iNdEx:postIndex])
-			m.FSType = &s
+			m.Path = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -31847,14 +31647,51 @@ func (m *NodeResources) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Capacity == nil {
 				m.Capacity = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -31864,85 +31701,46 @@ func (m *NodeResources) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Capacity[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Capacity[ResourceName(mapkey)] = mapvalue
 			}
-			m.Capacity[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -32571,108 +32369,143 @@ func (m *NodeStatus) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			if m.Capacity == nil {
-				m.Capacity = make(ResourceList)
-			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
-				for shift := uint(0); ; shift += 7 {
-					if shift >= 64 {
-						return ErrIntOverflowGenerated
-					}
-					if iNdEx >= l {
-						return io.ErrUnexpectedEOF
-					}
-					b := dAtA[iNdEx]
-					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
-					if b < 0x80 {
-						break
-					}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
+			if m.Capacity == nil {
+				m.Capacity = make(ResourceList)
+			}
+			if iNdEx < postIndex {
+				var valuekey uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
+					}
+					if iNdEx >= l {
+						return io.ErrUnexpectedEOF
+					}
+					b := dAtA[iNdEx]
+					iNdEx++
+					valuekey |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
+					}
+				}
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
+					}
+					if iNdEx >= l {
+						return io.ErrUnexpectedEOF
+					}
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
+					}
+				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Capacity[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Capacity[ResourceName(mapkey)] = mapvalue
+			}
+			iNdEx = postIndex
+		case 2:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Allocatable", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if postmsgIndex > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
-					}
-					iNdEx += skippy
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
 				}
 			}
-			m.Capacity[ResourceName(mapkey)] = *mapvalue
-			iNdEx = postIndex
-		case 2:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Allocatable", wireType)
-			}
-			var msglen int
+			var stringLenmapkey uint64
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -32682,26 +32515,26 @@ func (m *NodeStatus) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			if msglen < 0 {
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
 				return ErrInvalidLengthGenerated
 			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
 				return io.ErrUnexpectedEOF
 			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Allocatable == nil {
 				m.Allocatable = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -32711,85 +32544,46 @@ func (m *NodeStatus) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Allocatable[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Allocatable[ResourceName(mapkey)] = mapvalue
 			}
-			m.Allocatable[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		case 3:
 			if wireType != 2 {
@@ -34615,39 +34409,6 @@ func (m *PersistentVolumeClaimSpec) Unmarshal(dAtA []byte) error {
 			s := PersistentVolumeMode(dAtA[iNdEx:postIndex])
 			m.VolumeMode = &s
 			iNdEx = postIndex
-		case 7:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field DataSource", wireType)
-			}
-			var msglen int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			if msglen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			if m.DataSource == nil {
-				m.DataSource = &TypedLocalObjectReference{}
-			}
-			if err := m.DataSource.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
-			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
 			skippy, err := skipGenerated(dAtA[iNdEx:])
@@ -34782,14 +34543,51 @@ func (m *PersistentVolumeClaimStatus) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Capacity == nil {
 				m.Capacity = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -34799,85 +34597,46 @@ func (m *PersistentVolumeClaimStatus) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Capacity[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Capacity[ResourceName(mapkey)] = mapvalue
 			}
-			m.Capacity[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		case 4:
 			if wireType != 2 {
@@ -35296,7 +35055,7 @@ func (m *PersistentVolumeSource) Unmarshal(dAtA []byte) error {
 				return io.ErrUnexpectedEOF
 			}
 			if m.Glusterfs == nil {
-				m.Glusterfs = &GlusterfsPersistentVolumeSource{}
+				m.Glusterfs = &GlusterfsVolumeSource{}
 			}
 			if err := m.Glusterfs.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
 				return err
@@ -35667,7 +35426,7 @@ func (m *PersistentVolumeSource) Unmarshal(dAtA []byte) error {
 			iNdEx = postIndex
 		case 16:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field AzureDisk", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field CascadeDisk", wireType)
 			}
 			var msglen int
 			for shift := uint(0); ; shift += 7 {
@@ -35691,10 +35450,10 @@ func (m *PersistentVolumeSource) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			if m.AzureDisk == nil {
-				m.AzureDisk = &AzureDiskVolumeSource{}
+			if m.CascadeDisk == nil {
+				m.CascadeDisk = &CascadeDiskVolumeSource{}
 			}
-			if err := m.AzureDisk.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+			if err := m.CascadeDisk.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
 				return err
 			}
 			iNdEx = postIndex
@@ -35896,6 +35655,39 @@ func (m *PersistentVolumeSource) Unmarshal(dAtA []byte) error {
 				return err
 			}
 			iNdEx = postIndex
+		case 23:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field AzureDisk", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			if m.AzureDisk == nil {
+				m.AzureDisk = &AzureDiskVolumeSource{}
+			}
+			if err := m.AzureDisk.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
+			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
 			skippy, err := skipGenerated(dAtA[iNdEx:])
@@ -35972,14 +35764,51 @@ func (m *PersistentVolumeSpec) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Capacity == nil {
 				m.Capacity = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -35989,85 +35818,46 @@ func (m *PersistentVolumeSpec) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Capacity[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Capacity[ResourceName(mapkey)] = mapvalue
 			}
-			m.Capacity[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		case 2:
 			if wireType != 2 {
@@ -39071,14 +38861,51 @@ func (m *PodSpec) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.NodeSelector == nil {
 				m.NodeSelector = make(map[string]string)
 			}
-			var mapkey string
-			var mapvalue string
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -39088,80 +38915,41 @@ func (m *PodSpec) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var stringLenmapvalue uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapvalue |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapvalue := int(stringLenmapvalue)
-					if intStringLenmapvalue < 0 {
-						return ErrInvalidLengthGenerated
+				var stringLenmapvalue uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
-					if postStringIndexmapvalue > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
-					iNdEx = postStringIndexmapvalue
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					stringLenmapvalue |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				intStringLenmapvalue := int(stringLenmapvalue)
+				if intStringLenmapvalue < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postStringIndexmapvalue := iNdEx + intStringLenmapvalue
+				if postStringIndexmapvalue > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := string(dAtA[iNdEx:postStringIndexmapvalue])
+				iNdEx = postStringIndexmapvalue
+				m.NodeSelector[mapkey] = mapvalue
+			} else {
+				var mapvalue string
+				m.NodeSelector[mapkey] = mapvalue
 			}
-			m.NodeSelector[mapkey] = mapvalue
 			iNdEx = postIndex
 		case 8:
 			if wireType != 2 {
@@ -39742,57 +39530,6 @@ func (m *PodSpec) Unmarshal(dAtA []byte) error {
 				return err
 			}
 			iNdEx = postIndex
-		case 29:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field RuntimeClassName", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			s := string(dAtA[iNdEx:postIndex])
-			m.RuntimeClassName = &s
-			iNdEx = postIndex
-		case 30:
-			if wireType != 0 {
-				return fmt.Errorf("proto: wrong wireType = %d for field EnableServiceLinks", wireType)
-			}
-			var v int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				v |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			b := bool(v != 0)
-			m.EnableServiceLinks = &b
 		default:
 			iNdEx = preIndex
 			skippy, err := skipGenerated(dAtA[iNdEx:])
@@ -42787,14 +42524,51 @@ func (m *ReplicationControllerSpec) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Selector == nil {
 				m.Selector = make(map[string]string)
 			}
-			var mapkey string
-			var mapvalue string
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -42804,80 +42578,41 @@ func (m *ReplicationControllerSpec) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var stringLenmapvalue uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapvalue |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapvalue := int(stringLenmapvalue)
-					if intStringLenmapvalue < 0 {
-						return ErrInvalidLengthGenerated
+				var stringLenmapvalue uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
-					if postStringIndexmapvalue > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
-					iNdEx = postStringIndexmapvalue
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					stringLenmapvalue |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				intStringLenmapvalue := int(stringLenmapvalue)
+				if intStringLenmapvalue < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postStringIndexmapvalue := iNdEx + intStringLenmapvalue
+				if postStringIndexmapvalue > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := string(dAtA[iNdEx:postStringIndexmapvalue])
+				iNdEx = postStringIndexmapvalue
+				m.Selector[mapkey] = mapvalue
+			} else {
+				var mapvalue string
+				m.Selector[mapkey] = mapvalue
 			}
-			m.Selector[mapkey] = mapvalue
 			iNdEx = postIndex
 		case 3:
 			if wireType != 2 {
@@ -43572,14 +43307,51 @@ func (m *ResourceQuotaSpec) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Hard == nil {
 				m.Hard = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -43589,85 +43361,46 @@ func (m *ResourceQuotaSpec) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Hard[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Hard[ResourceName(mapkey)] = mapvalue
 			}
-			m.Hard[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		case 2:
 			if wireType != 2 {
@@ -43807,14 +43540,51 @@ func (m *ResourceQuotaStatus) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Hard == nil {
 				m.Hard = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -43824,85 +43594,46 @@ func (m *ResourceQuotaStatus) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Hard[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Hard[ResourceName(mapkey)] = mapvalue
 			}
-			m.Hard[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		case 2:
 			if wireType != 2 {
@@ -43930,14 +43661,51 @@ func (m *ResourceQuotaStatus) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Used == nil {
 				m.Used = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -43947,85 +43715,46 @@ func (m *ResourceQuotaStatus) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Used[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Used[ResourceName(mapkey)] = mapvalue
 			}
-			m.Used[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -44103,14 +43832,51 @@ func (m *ResourceRequirements) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Limits == nil {
 				m.Limits = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -44120,85 +43886,46 @@ func (m *ResourceRequirements) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Limits[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Limits[ResourceName(mapkey)] = mapvalue
 			}
-			m.Limits[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		case 2:
 			if wireType != 2 {
@@ -44226,14 +43953,51 @@ func (m *ResourceRequirements) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := ResourceName(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Requests == nil {
 				m.Requests = make(ResourceList)
 			}
-			var mapkey ResourceName
-			mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -44243,85 +44007,46 @@ func (m *ResourceRequirements) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = ResourceName(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapmsglen int
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapmsglen |= (int(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postmsgIndex := iNdEx + mapmsglen
-					if mapmsglen < 0 {
-						return ErrInvalidLengthGenerated
+				var mapmsglen int
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					if postmsgIndex > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = &k8s_io_apimachinery_pkg_api_resource.Quantity{}
-					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
-						return err
-					}
-					iNdEx = postmsgIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapmsglen |= (int(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postmsgIndex := iNdEx + mapmsglen
+				if mapmsglen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				if postmsgIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := &k8s_io_apimachinery_pkg_api_resource.Quantity{}
+				if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
+					return err
+				}
+				iNdEx = postmsgIndex
+				m.Requests[ResourceName(mapkey)] = *mapvalue
+			} else {
+				var mapvalue k8s_io_apimachinery_pkg_api_resource.Quantity
+				m.Requests[ResourceName(mapkey)] = mapvalue
 			}
-			m.Requests[ResourceName(mapkey)] = *mapvalue
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -45357,61 +45082,237 @@ func (m *ScopedResourceSelectorRequirement) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Values = append(m.Values, string(dAtA[iNdEx:postIndex]))
+			m.Values = append(m.Values, string(dAtA[iNdEx:postIndex]))
+			iNdEx = postIndex
+		default:
+			iNdEx = preIndex
+			skippy, err := skipGenerated(dAtA[iNdEx:])
+			if err != nil {
+				return err
+			}
+			if skippy < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			if (iNdEx + skippy) > l {
+				return io.ErrUnexpectedEOF
+			}
+			iNdEx += skippy
+		}
+	}
+
+	if iNdEx > l {
+		return io.ErrUnexpectedEOF
+	}
+	return nil
+}
+func (m *Secret) Unmarshal(dAtA []byte) error {
+	l := len(dAtA)
+	iNdEx := 0
+	for iNdEx < l {
+		preIndex := iNdEx
+		var wire uint64
+		for shift := uint(0); ; shift += 7 {
+			if shift >= 64 {
+				return ErrIntOverflowGenerated
+			}
+			if iNdEx >= l {
+				return io.ErrUnexpectedEOF
+			}
+			b := dAtA[iNdEx]
+			iNdEx++
+			wire |= (uint64(b) & 0x7F) << shift
+			if b < 0x80 {
+				break
+			}
+		}
+		fieldNum := int32(wire >> 3)
+		wireType := int(wire & 0x7)
+		if wireType == 4 {
+			return fmt.Errorf("proto: Secret: wiretype end group for non-group")
+		}
+		if fieldNum <= 0 {
+			return fmt.Errorf("proto: Secret: illegal tag %d (wire type %d)", fieldNum, wire)
+		}
+		switch fieldNum {
+		case 1:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field ObjectMeta", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			if err := m.ObjectMeta.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
+			iNdEx = postIndex
+		case 2:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Data", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			var stringLenmapkey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
+				return io.ErrUnexpectedEOF
+			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
+			if m.Data == nil {
+				m.Data = make(map[string][]byte)
+			}
+			if iNdEx < postIndex {
+				var valuekey uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
+					}
+					if iNdEx >= l {
+						return io.ErrUnexpectedEOF
+					}
+					b := dAtA[iNdEx]
+					iNdEx++
+					valuekey |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
+					}
+				}
+				var mapbyteLen uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
+					}
+					if iNdEx >= l {
+						return io.ErrUnexpectedEOF
+					}
+					b := dAtA[iNdEx]
+					iNdEx++
+					mapbyteLen |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
+					}
+				}
+				intMapbyteLen := int(mapbyteLen)
+				if intMapbyteLen < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postbytesIndex := iNdEx + intMapbyteLen
+				if postbytesIndex > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := make([]byte, mapbyteLen)
+				copy(mapvalue, dAtA[iNdEx:postbytesIndex])
+				iNdEx = postbytesIndex
+				m.Data[mapkey] = mapvalue
+			} else {
+				var mapvalue []byte
+				m.Data[mapkey] = mapvalue
+			}
+			iNdEx = postIndex
+		case 3:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
+			}
+			var stringLen uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLen |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLen := int(stringLen)
+			if intStringLen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + intStringLen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			m.Type = SecretType(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
-		default:
-			iNdEx = preIndex
-			skippy, err := skipGenerated(dAtA[iNdEx:])
-			if err != nil {
-				return err
-			}
-			if skippy < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			if (iNdEx + skippy) > l {
-				return io.ErrUnexpectedEOF
-			}
-			iNdEx += skippy
-		}
-	}
-
-	if iNdEx > l {
-		return io.ErrUnexpectedEOF
-	}
-	return nil
-}
-func (m *Secret) Unmarshal(dAtA []byte) error {
-	l := len(dAtA)
-	iNdEx := 0
-	for iNdEx < l {
-		preIndex := iNdEx
-		var wire uint64
-		for shift := uint(0); ; shift += 7 {
-			if shift >= 64 {
-				return ErrIntOverflowGenerated
-			}
-			if iNdEx >= l {
-				return io.ErrUnexpectedEOF
-			}
-			b := dAtA[iNdEx]
-			iNdEx++
-			wire |= (uint64(b) & 0x7F) << shift
-			if b < 0x80 {
-				break
-			}
-		}
-		fieldNum := int32(wire >> 3)
-		wireType := int(wire & 0x7)
-		if wireType == 4 {
-			return fmt.Errorf("proto: Secret: wiretype end group for non-group")
-		}
-		if fieldNum <= 0 {
-			return fmt.Errorf("proto: Secret: illegal tag %d (wire type %d)", fieldNum, wire)
-		}
-		switch fieldNum {
-		case 1:
+		case 4:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field ObjectMeta", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field StringData", wireType)
 			}
 			var msglen int
 			for shift := uint(0); ; shift += 7 {
@@ -45435,15 +45336,7 @@ func (m *Secret) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			if err := m.ObjectMeta.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
-			iNdEx = postIndex
-		case 2:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Data", wireType)
-			}
-			var msglen int
+			var keykey uint64
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -45453,116 +45346,12 @@ func (m *Secret) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
+				keykey |= (uint64(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			if msglen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			if m.Data == nil {
-				m.Data = make(map[string][]byte)
-			}
-			var mapkey string
-			mapvalue := []byte{}
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
-				for shift := uint(0); ; shift += 7 {
-					if shift >= 64 {
-						return ErrIntOverflowGenerated
-					}
-					if iNdEx >= l {
-						return io.ErrUnexpectedEOF
-					}
-					b := dAtA[iNdEx]
-					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
-					if b < 0x80 {
-						break
-					}
-				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var mapbyteLen uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						mapbyteLen |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intMapbyteLen := int(mapbyteLen)
-					if intMapbyteLen < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postbytesIndex := iNdEx + intMapbyteLen
-					if postbytesIndex > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapvalue = make([]byte, mapbyteLen)
-					copy(mapvalue, dAtA[iNdEx:postbytesIndex])
-					iNdEx = postbytesIndex
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
-					}
-					iNdEx += skippy
-				}
-			}
-			m.Data[mapkey] = mapvalue
-			iNdEx = postIndex
-		case 3:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
-			}
-			var stringLen uint64
+			var stringLenmapkey uint64
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -45572,55 +45361,26 @@ func (m *Secret) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.Type = SecretType(dAtA[iNdEx:postIndex])
-			iNdEx = postIndex
-		case 4:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field StringData", wireType)
-			}
-			var msglen int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			if msglen < 0 {
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
 				return ErrInvalidLengthGenerated
 			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
 				return io.ErrUnexpectedEOF
 			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.StringData == nil {
 				m.StringData = make(map[string]string)
 			}
-			var mapkey string
-			var mapvalue string
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -45630,80 +45390,41 @@ func (m *Secret) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var stringLenmapvalue uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapvalue |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapvalue := int(stringLenmapvalue)
-					if intStringLenmapvalue < 0 {
-						return ErrInvalidLengthGenerated
+				var stringLenmapvalue uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
-					if postStringIndexmapvalue > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
-					iNdEx = postStringIndexmapvalue
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					stringLenmapvalue |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				intStringLenmapvalue := int(stringLenmapvalue)
+				if intStringLenmapvalue < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postStringIndexmapvalue := iNdEx + intStringLenmapvalue
+				if postStringIndexmapvalue > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := string(dAtA[iNdEx:postStringIndexmapvalue])
+				iNdEx = postStringIndexmapvalue
+				m.StringData[mapkey] = mapvalue
+			} else {
+				var mapvalue string
+				m.StringData[mapkey] = mapvalue
 			}
-			m.StringData[mapkey] = mapvalue
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -46678,36 +46399,6 @@ func (m *SecurityContext) Unmarshal(dAtA []byte) error {
 				}
 			}
 			m.RunAsGroup = &v
-		case 9:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field ProcMount", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			s := ProcMountType(dAtA[iNdEx:postIndex])
-			m.ProcMount = &s
-			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
 			skippy, err := skipGenerated(dAtA[iNdEx:])
@@ -47772,16 +47463,53 @@ func (m *ServiceSpec) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Ports = append(m.Ports, ServicePort{})
-			if err := m.Ports[len(m.Ports)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
-			iNdEx = postIndex
-		case 2:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Selector", wireType)
+			m.Ports = append(m.Ports, ServicePort{})
+			if err := m.Ports[len(m.Ports)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
+			iNdEx = postIndex
+		case 2:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Selector", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			var keykey uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				keykey |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
 			}
-			var msglen int
+			var stringLenmapkey uint64
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -47791,26 +47519,26 @@ func (m *ServiceSpec) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
+				stringLenmapkey |= (uint64(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			if msglen < 0 {
+			intStringLenmapkey := int(stringLenmapkey)
+			if intStringLenmapkey < 0 {
 				return ErrInvalidLengthGenerated
 			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
+			postStringIndexmapkey := iNdEx + intStringLenmapkey
+			if postStringIndexmapkey > l {
 				return io.ErrUnexpectedEOF
 			}
+			mapkey := string(dAtA[iNdEx:postStringIndexmapkey])
+			iNdEx = postStringIndexmapkey
 			if m.Selector == nil {
 				m.Selector = make(map[string]string)
 			}
-			var mapkey string
-			var mapvalue string
-			for iNdEx < postIndex {
-				entryPreIndex := iNdEx
-				var wire uint64
+			if iNdEx < postIndex {
+				var valuekey uint64
 				for shift := uint(0); ; shift += 7 {
 					if shift >= 64 {
 						return ErrIntOverflowGenerated
@@ -47820,80 +47548,41 @@ func (m *ServiceSpec) Unmarshal(dAtA []byte) error {
 					}
 					b := dAtA[iNdEx]
 					iNdEx++
-					wire |= (uint64(b) & 0x7F) << shift
+					valuekey |= (uint64(b) & 0x7F) << shift
 					if b < 0x80 {
 						break
 					}
 				}
-				fieldNum := int32(wire >> 3)
-				if fieldNum == 1 {
-					var stringLenmapkey uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapkey |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapkey := int(stringLenmapkey)
-					if intStringLenmapkey < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					postStringIndexmapkey := iNdEx + intStringLenmapkey
-					if postStringIndexmapkey > l {
-						return io.ErrUnexpectedEOF
-					}
-					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
-					iNdEx = postStringIndexmapkey
-				} else if fieldNum == 2 {
-					var stringLenmapvalue uint64
-					for shift := uint(0); ; shift += 7 {
-						if shift >= 64 {
-							return ErrIntOverflowGenerated
-						}
-						if iNdEx >= l {
-							return io.ErrUnexpectedEOF
-						}
-						b := dAtA[iNdEx]
-						iNdEx++
-						stringLenmapvalue |= (uint64(b) & 0x7F) << shift
-						if b < 0x80 {
-							break
-						}
-					}
-					intStringLenmapvalue := int(stringLenmapvalue)
-					if intStringLenmapvalue < 0 {
-						return ErrInvalidLengthGenerated
+				var stringLenmapvalue uint64
+				for shift := uint(0); ; shift += 7 {
+					if shift >= 64 {
+						return ErrIntOverflowGenerated
 					}
-					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
-					if postStringIndexmapvalue > l {
+					if iNdEx >= l {
 						return io.ErrUnexpectedEOF
 					}
-					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
-					iNdEx = postStringIndexmapvalue
-				} else {
-					iNdEx = entryPreIndex
-					skippy, err := skipGenerated(dAtA[iNdEx:])
-					if err != nil {
-						return err
-					}
-					if skippy < 0 {
-						return ErrInvalidLengthGenerated
-					}
-					if (iNdEx + skippy) > postIndex {
-						return io.ErrUnexpectedEOF
+					b := dAtA[iNdEx]
+					iNdEx++
+					stringLenmapvalue |= (uint64(b) & 0x7F) << shift
+					if b < 0x80 {
+						break
 					}
-					iNdEx += skippy
 				}
+				intStringLenmapvalue := int(stringLenmapvalue)
+				if intStringLenmapvalue < 0 {
+					return ErrInvalidLengthGenerated
+				}
+				postStringIndexmapvalue := iNdEx + intStringLenmapvalue
+				if postStringIndexmapvalue > l {
+					return io.ErrUnexpectedEOF
+				}
+				mapvalue := string(dAtA[iNdEx:postStringIndexmapvalue])
+				iNdEx = postStringIndexmapvalue
+				m.Selector[mapkey] = mapvalue
+			} else {
+				var mapvalue string
+				m.Selector[mapkey] = mapvalue
 			}
-			m.Selector[mapkey] = mapvalue
 			iNdEx = postIndex
 		case 3:
 			if wireType != 2 {
@@ -48355,200 +48044,10 @@ func (m *SessionAffinityConfig) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			if m.ClientIP == nil {
-				m.ClientIP = &ClientIPConfig{}
-			}
-			if err := m.ClientIP.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
-			iNdEx = postIndex
-		default:
-			iNdEx = preIndex
-			skippy, err := skipGenerated(dAtA[iNdEx:])
-			if err != nil {
-				return err
-			}
-			if skippy < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			if (iNdEx + skippy) > l {
-				return io.ErrUnexpectedEOF
-			}
-			iNdEx += skippy
-		}
-	}
-
-	if iNdEx > l {
-		return io.ErrUnexpectedEOF
-	}
-	return nil
-}
-func (m *StorageOSPersistentVolumeSource) Unmarshal(dAtA []byte) error {
-	l := len(dAtA)
-	iNdEx := 0
-	for iNdEx < l {
-		preIndex := iNdEx
-		var wire uint64
-		for shift := uint(0); ; shift += 7 {
-			if shift >= 64 {
-				return ErrIntOverflowGenerated
-			}
-			if iNdEx >= l {
-				return io.ErrUnexpectedEOF
-			}
-			b := dAtA[iNdEx]
-			iNdEx++
-			wire |= (uint64(b) & 0x7F) << shift
-			if b < 0x80 {
-				break
-			}
-		}
-		fieldNum := int32(wire >> 3)
-		wireType := int(wire & 0x7)
-		if wireType == 4 {
-			return fmt.Errorf("proto: StorageOSPersistentVolumeSource: wiretype end group for non-group")
-		}
-		if fieldNum <= 0 {
-			return fmt.Errorf("proto: StorageOSPersistentVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
-		}
-		switch fieldNum {
-		case 1:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field VolumeName", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.VolumeName = string(dAtA[iNdEx:postIndex])
-			iNdEx = postIndex
-		case 2:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field VolumeNamespace", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.VolumeNamespace = string(dAtA[iNdEx:postIndex])
-			iNdEx = postIndex
-		case 3:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field FSType", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.FSType = string(dAtA[iNdEx:postIndex])
-			iNdEx = postIndex
-		case 4:
-			if wireType != 0 {
-				return fmt.Errorf("proto: wrong wireType = %d for field ReadOnly", wireType)
-			}
-			var v int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				v |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			m.ReadOnly = bool(v != 0)
-		case 5:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field SecretRef", wireType)
-			}
-			var msglen int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			if msglen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			if m.SecretRef == nil {
-				m.SecretRef = &ObjectReference{}
+			if m.ClientIP == nil {
+				m.ClientIP = &ClientIPConfig{}
 			}
-			if err := m.SecretRef.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+			if err := m.ClientIP.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
 				return err
 			}
 			iNdEx = postIndex
@@ -48573,7 +48072,7 @@ func (m *StorageOSPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *StorageOSVolumeSource) Unmarshal(dAtA []byte) error {
+func (m *StorageOSPersistentVolumeSource) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -48596,10 +48095,10 @@ func (m *StorageOSVolumeSource) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: StorageOSVolumeSource: wiretype end group for non-group")
+			return fmt.Errorf("proto: StorageOSPersistentVolumeSource: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: StorageOSVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: StorageOSPersistentVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
@@ -48736,7 +48235,7 @@ func (m *StorageOSVolumeSource) Unmarshal(dAtA []byte) error {
 				return io.ErrUnexpectedEOF
 			}
 			if m.SecretRef == nil {
-				m.SecretRef = &LocalObjectReference{}
+				m.SecretRef = &ObjectReference{}
 			}
 			if err := m.SecretRef.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
 				return err
@@ -48763,7 +48262,7 @@ func (m *StorageOSVolumeSource) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *Sysctl) Unmarshal(dAtA []byte) error {
+func (m *StorageOSVolumeSource) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -48786,15 +48285,15 @@ func (m *Sysctl) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: Sysctl: wiretype end group for non-group")
+			return fmt.Errorf("proto: StorageOSVolumeSource: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: Sysctl: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: StorageOSVolumeSource: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field VolumeName", wireType)
 			}
 			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
@@ -48819,11 +48318,11 @@ func (m *Sysctl) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Name = string(dAtA[iNdEx:postIndex])
+			m.VolumeName = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
 		case 2:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Value", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field VolumeNamespace", wireType)
 			}
 			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
@@ -48848,7 +48347,89 @@ func (m *Sysctl) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Value = string(dAtA[iNdEx:postIndex])
+			m.VolumeNamespace = string(dAtA[iNdEx:postIndex])
+			iNdEx = postIndex
+		case 3:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field FSType", wireType)
+			}
+			var stringLen uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLen |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			intStringLen := int(stringLen)
+			if intStringLen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + intStringLen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			m.FSType = string(dAtA[iNdEx:postIndex])
+			iNdEx = postIndex
+		case 4:
+			if wireType != 0 {
+				return fmt.Errorf("proto: wrong wireType = %d for field ReadOnly", wireType)
+			}
+			var v int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				v |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			m.ReadOnly = bool(v != 0)
+		case 5:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field SecretRef", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			if m.SecretRef == nil {
+				m.SecretRef = &LocalObjectReference{}
+			}
+			if err := m.SecretRef.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -48871,7 +48452,7 @@ func (m *Sysctl) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *TCPSocketAction) Unmarshal(dAtA []byte) error {
+func (m *Sysctl) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -48894,17 +48475,17 @@ func (m *TCPSocketAction) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: TCPSocketAction: wiretype end group for non-group")
+			return fmt.Errorf("proto: Sysctl: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: TCPSocketAction: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: Sysctl: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Port", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
 			}
-			var msglen int
+			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -48914,25 +48495,24 @@ func (m *TCPSocketAction) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
+				stringLen |= (uint64(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			if msglen < 0 {
+			intStringLen := int(stringLen)
+			if intStringLen < 0 {
 				return ErrInvalidLengthGenerated
 			}
-			postIndex := iNdEx + msglen
+			postIndex := iNdEx + intStringLen
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			if err := m.Port.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
+			m.Name = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
 		case 2:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Host", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Value", wireType)
 			}
 			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
@@ -48957,7 +48537,7 @@ func (m *TCPSocketAction) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Host = string(dAtA[iNdEx:postIndex])
+			m.Value = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -48980,7 +48560,7 @@ func (m *TCPSocketAction) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *Taint) Unmarshal(dAtA []byte) error {
+func (m *TCPSocketAction) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -49003,17 +48583,17 @@ func (m *Taint) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: Taint: wiretype end group for non-group")
+			return fmt.Errorf("proto: TCPSocketAction: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: Taint: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: TCPSocketAction: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Port", wireType)
 			}
-			var stringLen uint64
+			var msglen int
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -49023,53 +48603,25 @@ func (m *Taint) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
+				msglen |= (int(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
+			if msglen < 0 {
 				return ErrInvalidLengthGenerated
 			}
-			postIndex := iNdEx + intStringLen
+			postIndex := iNdEx + msglen
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Key = string(dAtA[iNdEx:postIndex])
-			iNdEx = postIndex
-		case 2:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Value", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
+			if err := m.Port.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
 			}
-			m.Value = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
-		case 3:
+		case 2:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Effect", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Host", wireType)
 			}
 			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
@@ -49094,40 +48646,7 @@ func (m *Taint) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Effect = TaintEffect(dAtA[iNdEx:postIndex])
-			iNdEx = postIndex
-		case 4:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field TimeAdded", wireType)
-			}
-			var msglen int
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			if msglen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + msglen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			if m.TimeAdded == nil {
-				m.TimeAdded = &k8s_io_apimachinery_pkg_apis_meta_v1.Time{}
-			}
-			if err := m.TimeAdded.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
+			m.Host = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -49150,7 +48669,7 @@ func (m *Taint) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *Toleration) Unmarshal(dAtA []byte) error {
+func (m *Taint) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -49173,10 +48692,10 @@ func (m *Toleration) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: Toleration: wiretype end group for non-group")
+			return fmt.Errorf("proto: Taint: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: Toleration: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: Taint: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
@@ -49209,35 +48728,6 @@ func (m *Toleration) Unmarshal(dAtA []byte) error {
 			m.Key = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
 		case 2:
-			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Operator", wireType)
-			}
-			var stringLen uint64
-			for shift := uint(0); ; shift += 7 {
-				if shift >= 64 {
-					return ErrIntOverflowGenerated
-				}
-				if iNdEx >= l {
-					return io.ErrUnexpectedEOF
-				}
-				b := dAtA[iNdEx]
-				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
-				if b < 0x80 {
-					break
-				}
-			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
-				return ErrInvalidLengthGenerated
-			}
-			postIndex := iNdEx + intStringLen
-			if postIndex > l {
-				return io.ErrUnexpectedEOF
-			}
-			m.Operator = TolerationOperator(dAtA[iNdEx:postIndex])
-			iNdEx = postIndex
-		case 3:
 			if wireType != 2 {
 				return fmt.Errorf("proto: wrong wireType = %d for field Value", wireType)
 			}
@@ -49266,7 +48756,7 @@ func (m *Toleration) Unmarshal(dAtA []byte) error {
 			}
 			m.Value = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
-		case 4:
+		case 3:
 			if wireType != 2 {
 				return fmt.Errorf("proto: wrong wireType = %d for field Effect", wireType)
 			}
@@ -49295,11 +48785,11 @@ func (m *Toleration) Unmarshal(dAtA []byte) error {
 			}
 			m.Effect = TaintEffect(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
-		case 5:
-			if wireType != 0 {
-				return fmt.Errorf("proto: wrong wireType = %d for field TolerationSeconds", wireType)
+		case 4:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field TimeAdded", wireType)
 			}
-			var v int64
+			var msglen int
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -49309,12 +48799,25 @@ func (m *Toleration) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				v |= (int64(b) & 0x7F) << shift
+				msglen |= (int(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			m.TolerationSeconds = &v
+			if msglen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			if m.TimeAdded == nil {
+				m.TimeAdded = &k8s_io_apimachinery_pkg_apis_meta_v1.Time{}
+			}
+			if err := m.TimeAdded.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
+			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
 			skippy, err := skipGenerated(dAtA[iNdEx:])
@@ -49336,7 +48839,7 @@ func (m *Toleration) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *TopologySelectorLabelRequirement) Unmarshal(dAtA []byte) error {
+func (m *Toleration) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -49359,10 +48862,10 @@ func (m *TopologySelectorLabelRequirement) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: TopologySelectorLabelRequirement: wiretype end group for non-group")
+			return fmt.Errorf("proto: Toleration: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: TopologySelectorLabelRequirement: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: Toleration: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
@@ -49396,7 +48899,7 @@ func (m *TopologySelectorLabelRequirement) Unmarshal(dAtA []byte) error {
 			iNdEx = postIndex
 		case 2:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Values", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Operator", wireType)
 			}
 			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
@@ -49421,63 +48924,42 @@ func (m *TopologySelectorLabelRequirement) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Values = append(m.Values, string(dAtA[iNdEx:postIndex]))
+			m.Operator = TolerationOperator(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
-		default:
-			iNdEx = preIndex
-			skippy, err := skipGenerated(dAtA[iNdEx:])
-			if err != nil {
-				return err
-			}
-			if skippy < 0 {
-				return ErrInvalidLengthGenerated
+		case 3:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field Value", wireType)
 			}
-			if (iNdEx + skippy) > l {
-				return io.ErrUnexpectedEOF
+			var stringLen uint64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				stringLen |= (uint64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
 			}
-			iNdEx += skippy
-		}
-	}
-
-	if iNdEx > l {
-		return io.ErrUnexpectedEOF
-	}
-	return nil
-}
-func (m *TopologySelectorTerm) Unmarshal(dAtA []byte) error {
-	l := len(dAtA)
-	iNdEx := 0
-	for iNdEx < l {
-		preIndex := iNdEx
-		var wire uint64
-		for shift := uint(0); ; shift += 7 {
-			if shift >= 64 {
-				return ErrIntOverflowGenerated
+			intStringLen := int(stringLen)
+			if intStringLen < 0 {
+				return ErrInvalidLengthGenerated
 			}
-			if iNdEx >= l {
+			postIndex := iNdEx + intStringLen
+			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			b := dAtA[iNdEx]
-			iNdEx++
-			wire |= (uint64(b) & 0x7F) << shift
-			if b < 0x80 {
-				break
-			}
-		}
-		fieldNum := int32(wire >> 3)
-		wireType := int(wire & 0x7)
-		if wireType == 4 {
-			return fmt.Errorf("proto: TopologySelectorTerm: wiretype end group for non-group")
-		}
-		if fieldNum <= 0 {
-			return fmt.Errorf("proto: TopologySelectorTerm: illegal tag %d (wire type %d)", fieldNum, wire)
-		}
-		switch fieldNum {
-		case 1:
+			m.Value = string(dAtA[iNdEx:postIndex])
+			iNdEx = postIndex
+		case 4:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field MatchLabelExpressions", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Effect", wireType)
 			}
-			var msglen int
+			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -49487,23 +48969,41 @@ func (m *TopologySelectorTerm) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				msglen |= (int(b) & 0x7F) << shift
+				stringLen |= (uint64(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			if msglen < 0 {
+			intStringLen := int(stringLen)
+			if intStringLen < 0 {
 				return ErrInvalidLengthGenerated
 			}
-			postIndex := iNdEx + msglen
+			postIndex := iNdEx + intStringLen
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.MatchLabelExpressions = append(m.MatchLabelExpressions, TopologySelectorLabelRequirement{})
-			if err := m.MatchLabelExpressions[len(m.MatchLabelExpressions)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
-				return err
-			}
+			m.Effect = TaintEffect(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
+		case 5:
+			if wireType != 0 {
+				return fmt.Errorf("proto: wrong wireType = %d for field TolerationSeconds", wireType)
+			}
+			var v int64
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				v |= (int64(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			m.TolerationSeconds = &v
 		default:
 			iNdEx = preIndex
 			skippy, err := skipGenerated(dAtA[iNdEx:])
@@ -49525,7 +49025,7 @@ func (m *TopologySelectorTerm) Unmarshal(dAtA []byte) error {
 	}
 	return nil
 }
-func (m *TypedLocalObjectReference) Unmarshal(dAtA []byte) error {
+func (m *TopologySelectorLabelRequirement) Unmarshal(dAtA []byte) error {
 	l := len(dAtA)
 	iNdEx := 0
 	for iNdEx < l {
@@ -49548,15 +49048,15 @@ func (m *TypedLocalObjectReference) Unmarshal(dAtA []byte) error {
 		fieldNum := int32(wire >> 3)
 		wireType := int(wire & 0x7)
 		if wireType == 4 {
-			return fmt.Errorf("proto: TypedLocalObjectReference: wiretype end group for non-group")
+			return fmt.Errorf("proto: TopologySelectorLabelRequirement: wiretype end group for non-group")
 		}
 		if fieldNum <= 0 {
-			return fmt.Errorf("proto: TypedLocalObjectReference: illegal tag %d (wire type %d)", fieldNum, wire)
+			return fmt.Errorf("proto: TopologySelectorLabelRequirement: illegal tag %d (wire type %d)", fieldNum, wire)
 		}
 		switch fieldNum {
 		case 1:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field APIGroup", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
 			}
 			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
@@ -49581,12 +49081,11 @@ func (m *TypedLocalObjectReference) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			s := string(dAtA[iNdEx:postIndex])
-			m.APIGroup = &s
+			m.Key = string(dAtA[iNdEx:postIndex])
 			iNdEx = postIndex
 		case 2:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Kind", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field Values", wireType)
 			}
 			var stringLen uint64
 			for shift := uint(0); ; shift += 7 {
@@ -49611,13 +49110,63 @@ func (m *TypedLocalObjectReference) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Kind = string(dAtA[iNdEx:postIndex])
+			m.Values = append(m.Values, string(dAtA[iNdEx:postIndex]))
 			iNdEx = postIndex
-		case 3:
+		default:
+			iNdEx = preIndex
+			skippy, err := skipGenerated(dAtA[iNdEx:])
+			if err != nil {
+				return err
+			}
+			if skippy < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			if (iNdEx + skippy) > l {
+				return io.ErrUnexpectedEOF
+			}
+			iNdEx += skippy
+		}
+	}
+
+	if iNdEx > l {
+		return io.ErrUnexpectedEOF
+	}
+	return nil
+}
+func (m *TopologySelectorTerm) Unmarshal(dAtA []byte) error {
+	l := len(dAtA)
+	iNdEx := 0
+	for iNdEx < l {
+		preIndex := iNdEx
+		var wire uint64
+		for shift := uint(0); ; shift += 7 {
+			if shift >= 64 {
+				return ErrIntOverflowGenerated
+			}
+			if iNdEx >= l {
+				return io.ErrUnexpectedEOF
+			}
+			b := dAtA[iNdEx]
+			iNdEx++
+			wire |= (uint64(b) & 0x7F) << shift
+			if b < 0x80 {
+				break
+			}
+		}
+		fieldNum := int32(wire >> 3)
+		wireType := int(wire & 0x7)
+		if wireType == 4 {
+			return fmt.Errorf("proto: TopologySelectorTerm: wiretype end group for non-group")
+		}
+		if fieldNum <= 0 {
+			return fmt.Errorf("proto: TopologySelectorTerm: illegal tag %d (wire type %d)", fieldNum, wire)
+		}
+		switch fieldNum {
+		case 1:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field MatchLabelExpressions", wireType)
 			}
-			var stringLen uint64
+			var msglen int
 			for shift := uint(0); ; shift += 7 {
 				if shift >= 64 {
 					return ErrIntOverflowGenerated
@@ -49627,20 +49176,22 @@ func (m *TypedLocalObjectReference) Unmarshal(dAtA []byte) error {
 				}
 				b := dAtA[iNdEx]
 				iNdEx++
-				stringLen |= (uint64(b) & 0x7F) << shift
+				msglen |= (int(b) & 0x7F) << shift
 				if b < 0x80 {
 					break
 				}
 			}
-			intStringLen := int(stringLen)
-			if intStringLen < 0 {
+			if msglen < 0 {
 				return ErrInvalidLengthGenerated
 			}
-			postIndex := iNdEx + intStringLen
+			postIndex := iNdEx + msglen
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			m.Name = string(dAtA[iNdEx:postIndex])
+			m.MatchLabelExpressions = append(m.MatchLabelExpressions, TopologySelectorLabelRequirement{})
+			if err := m.MatchLabelExpressions[len(m.MatchLabelExpressions)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
 			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
@@ -51056,7 +50607,7 @@ func (m *VolumeSource) Unmarshal(dAtA []byte) error {
 			iNdEx = postIndex
 		case 22:
 			if wireType != 2 {
-				return fmt.Errorf("proto: wrong wireType = %d for field AzureDisk", wireType)
+				return fmt.Errorf("proto: wrong wireType = %d for field CascadeDisk", wireType)
 			}
 			var msglen int
 			for shift := uint(0); ; shift += 7 {
@@ -51080,10 +50631,10 @@ func (m *VolumeSource) Unmarshal(dAtA []byte) error {
 			if postIndex > l {
 				return io.ErrUnexpectedEOF
 			}
-			if m.AzureDisk == nil {
-				m.AzureDisk = &AzureDiskVolumeSource{}
+			if m.CascadeDisk == nil {
+				m.CascadeDisk = &CascadeDiskVolumeSource{}
 			}
-			if err := m.AzureDisk.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+			if err := m.CascadeDisk.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
 				return err
 			}
 			iNdEx = postIndex
@@ -51252,6 +50803,39 @@ func (m *VolumeSource) Unmarshal(dAtA []byte) error {
 				return err
 			}
 			iNdEx = postIndex
+		case 28:
+			if wireType != 2 {
+				return fmt.Errorf("proto: wrong wireType = %d for field AzureDisk", wireType)
+			}
+			var msglen int
+			for shift := uint(0); ; shift += 7 {
+				if shift >= 64 {
+					return ErrIntOverflowGenerated
+				}
+				if iNdEx >= l {
+					return io.ErrUnexpectedEOF
+				}
+				b := dAtA[iNdEx]
+				iNdEx++
+				msglen |= (int(b) & 0x7F) << shift
+				if b < 0x80 {
+					break
+				}
+			}
+			if msglen < 0 {
+				return ErrInvalidLengthGenerated
+			}
+			postIndex := iNdEx + msglen
+			if postIndex > l {
+				return io.ErrUnexpectedEOF
+			}
+			if m.AzureDisk == nil {
+				m.AzureDisk = &AzureDiskVolumeSource{}
+			}
+			if err := m.AzureDisk.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
+				return err
+			}
+			iNdEx = postIndex
 		default:
 			iNdEx = preIndex
 			skippy, err := skipGenerated(dAtA[iNdEx:])
@@ -51648,808 +51232,802 @@ func init() {
 }
 
 var fileDescriptorGenerated = []byte{
-	// 12835 bytes of a gzipped FileDescriptorProto
-	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xec, 0x7d, 0x6d, 0x70, 0x64, 0x57,
-	0x56, 0xd8, 0xbe, 0xee, 0xd6, 0x47, 0x1f, 0x7d, 0xdf, 0x99, 0xb1, 0x35, 0xb2, 0x67, 0x7a, 0xfc,
-	0xbc, 0x3b, 0x1e, 0xaf, 0x6d, 0xcd, 0x7a, 0x6c, 0xaf, 0xcd, 0xda, 0x6b, 0x90, 0xd4, 0xd2, 0x4c,
-	0x7b, 0x46, 0x9a, 0xf6, 0x6d, 0xcd, 0x78, 0xd7, 0x78, 0x97, 0x7d, 0xea, 0xbe, 0x92, 0x9e, 0xf5,
-	0xf4, 0x5e, 0xfb, 0xbd, 0xd7, 0x9a, 0x91, 0x03, 0x55, 0xc9, 0x12, 0x48, 0x36, 0x50, 0xa9, 0xad,
-	0xb0, 0x95, 0x0f, 0xa0, 0x48, 0x15, 0x21, 0x05, 0x84, 0x24, 0x15, 0x02, 0x01, 0xc2, 0x42, 0x42,
-	0x20, 0x3f, 0xc8, 0x9f, 0x0d, 0x49, 0x55, 0x6a, 0xa9, 0xa2, 0xa2, 0x80, 0x48, 0x25, 0xc5, 0x8f,
-	0x40, 0x2a, 0xe4, 0x47, 0x50, 0xa8, 0x90, 0xba, 0x9f, 0xef, 0xde, 0xd7, 0xef, 0x75, 0xb7, 0xc6,
-	0x1a, 0xd9, 0x50, 0xfb, 0xaf, 0xfb, 0x9e, 0x73, 0xcf, 0xbd, 0xef, 0x7e, 0x9e, 0x73, 0xee, 0xf9,
-	0x80, 0x57, 0x77, 0x5e, 0x89, 0xe6, 0xdd, 0xe0, 0xea, 0x4e, 0x67, 0x83, 0x84, 0x3e, 0x89, 0x49,
-	0x74, 0x75, 0x8f, 0xf8, 0xad, 0x20, 0xbc, 0x2a, 0x00, 0x4e, 0xdb, 0xbd, 0xda, 0x0c, 0x42, 0x72,
-	0x75, 0xef, 0xf9, 0xab, 0x5b, 0xc4, 0x27, 0xa1, 0x13, 0x93, 0xd6, 0x7c, 0x3b, 0x0c, 0xe2, 0x00,
-	0x21, 0x8e, 0x33, 0xef, 0xb4, 0xdd, 0x79, 0x8a, 0x33, 0xbf, 0xf7, 0xfc, 0xdc, 0x73, 0x5b, 0x6e,
-	0xbc, 0xdd, 0xd9, 0x98, 0x6f, 0x06, 0xbb, 0x57, 0xb7, 0x82, 0xad, 0xe0, 0x2a, 0x43, 0xdd, 0xe8,
-	0x6c, 0xb2, 0x7f, 0xec, 0x0f, 0xfb, 0xc5, 0x49, 0xcc, 0xbd, 0x98, 0x34, 0xb3, 0xeb, 0x34, 0xb7,
-	0x5d, 0x9f, 0x84, 0xfb, 0x57, 0xdb, 0x3b, 0x5b, 0xac, 0xdd, 0x90, 0x44, 0x41, 0x27, 0x6c, 0x92,
-	0x74, 0xc3, 0x3d, 0x6b, 0x45, 0x57, 0x77, 0x49, 0xec, 0x64, 0x74, 0x77, 0xee, 0x6a, 0x5e, 0xad,
-	0xb0, 0xe3, 0xc7, 0xee, 0x6e, 0x77, 0x33, 0x9f, 0xee, 0x57, 0x21, 0x6a, 0x6e, 0x93, 0x5d, 0xa7,
-	0xab, 0xde, 0x0b, 0x79, 0xf5, 0x3a, 0xb1, 0xeb, 0x5d, 0x75, 0xfd, 0x38, 0x8a, 0xc3, 0x74, 0x25,
-	0xfb, 0x9b, 0x16, 0x5c, 0x5a, 0x78, 0xab, 0xb1, 0xec, 0x39, 0x51, 0xec, 0x36, 0x17, 0xbd, 0xa0,
-	0xb9, 0xd3, 0x88, 0x83, 0x90, 0xdc, 0x0d, 0xbc, 0xce, 0x2e, 0x69, 0xb0, 0x81, 0x40, 0xcf, 0xc2,
-	0xe8, 0x1e, 0xfb, 0x5f, 0xab, 0xce, 0x5a, 0x97, 0xac, 0x2b, 0xe5, 0xc5, 0xe9, 0xdf, 0x3c, 0xa8,
-	0x7c, 0xec, 0xf0, 0xa0, 0x32, 0x7a, 0x57, 0x94, 0x63, 0x85, 0x81, 0x2e, 0xc3, 0xf0, 0x66, 0xb4,
-	0xbe, 0xdf, 0x26, 0xb3, 0x05, 0x86, 0x3b, 0x29, 0x70, 0x87, 0x57, 0x1a, 0xb4, 0x14, 0x0b, 0x28,
-	0xba, 0x0a, 0xe5, 0xb6, 0x13, 0xc6, 0x6e, 0xec, 0x06, 0xfe, 0x6c, 0xf1, 0x92, 0x75, 0x65, 0x68,
-	0x71, 0x46, 0xa0, 0x96, 0xeb, 0x12, 0x80, 0x13, 0x1c, 0xda, 0x8d, 0x90, 0x38, 0xad, 0xdb, 0xbe,
-	0xb7, 0x3f, 0x5b, 0xba, 0x64, 0x5d, 0x19, 0x4d, 0xba, 0x81, 0x45, 0x39, 0x56, 0x18, 0xf6, 0x0f,
-	0x17, 0x60, 0x74, 0x61, 0x73, 0xd3, 0xf5, 0xdd, 0x78, 0x1f, 0xdd, 0x85, 0x71, 0x3f, 0x68, 0x11,
-	0xf9, 0x9f, 0x7d, 0xc5, 0xd8, 0xb5, 0x4b, 0xf3, 0xdd, 0x4b, 0x69, 0x7e, 0x4d, 0xc3, 0x5b, 0x9c,
-	0x3e, 0x3c, 0xa8, 0x8c, 0xeb, 0x25, 0xd8, 0xa0, 0x83, 0x30, 0x8c, 0xb5, 0x83, 0x96, 0x22, 0x5b,
-	0x60, 0x64, 0x2b, 0x59, 0x64, 0xeb, 0x09, 0xda, 0xe2, 0xd4, 0xe1, 0x41, 0x65, 0x4c, 0x2b, 0xc0,
-	0x3a, 0x11, 0xb4, 0x01, 0x53, 0xf4, 0xaf, 0x1f, 0xbb, 0x8a, 0x6e, 0x91, 0xd1, 0x7d, 0x32, 0x8f,
-	0xae, 0x86, 0xba, 0x78, 0xe6, 0xf0, 0xa0, 0x32, 0x95, 0x2a, 0xc4, 0x69, 0x82, 0xf6, 0xfb, 0x30,
-	0xb9, 0x10, 0xc7, 0x4e, 0x73, 0x9b, 0xb4, 0xf8, 0x0c, 0xa2, 0x17, 0xa1, 0xe4, 0x3b, 0xbb, 0x44,
-	0xcc, 0xef, 0x25, 0x31, 0xb0, 0xa5, 0x35, 0x67, 0x97, 0x1c, 0x1d, 0x54, 0xa6, 0xef, 0xf8, 0xee,
-	0x7b, 0x1d, 0xb1, 0x2a, 0x68, 0x19, 0x66, 0xd8, 0xe8, 0x1a, 0x40, 0x8b, 0xec, 0xb9, 0x4d, 0x52,
-	0x77, 0xe2, 0x6d, 0x31, 0xdf, 0x48, 0xd4, 0x85, 0xaa, 0x82, 0x60, 0x0d, 0xcb, 0xbe, 0x0f, 0xe5,
-	0x85, 0xbd, 0xc0, 0x6d, 0xd5, 0x83, 0x56, 0x84, 0x76, 0x60, 0xaa, 0x1d, 0x92, 0x4d, 0x12, 0xaa,
-	0xa2, 0x59, 0xeb, 0x52, 0xf1, 0xca, 0xd8, 0xb5, 0x2b, 0x99, 0x1f, 0x6b, 0xa2, 0x2e, 0xfb, 0x71,
-	0xb8, 0xbf, 0xf8, 0xa8, 0x68, 0x6f, 0x2a, 0x05, 0xc5, 0x69, 0xca, 0xf6, 0xbf, 0x2d, 0xc0, 0xb9,
-	0x85, 0xf7, 0x3b, 0x21, 0xa9, 0xba, 0xd1, 0x4e, 0x7a, 0x85, 0xb7, 0xdc, 0x68, 0x67, 0x2d, 0x19,
-	0x01, 0xb5, 0xb4, 0xaa, 0xa2, 0x1c, 0x2b, 0x0c, 0xf4, 0x1c, 0x8c, 0xd0, 0xdf, 0x77, 0x70, 0x4d,
-	0x7c, 0xf2, 0x19, 0x81, 0x3c, 0x56, 0x75, 0x62, 0xa7, 0xca, 0x41, 0x58, 0xe2, 0xa0, 0x55, 0x18,
-	0x6b, 0xb2, 0x0d, 0xb9, 0xb5, 0x1a, 0xb4, 0x08, 0x9b, 0xcc, 0xf2, 0xe2, 0x33, 0x14, 0x7d, 0x29,
-	0x29, 0x3e, 0x3a, 0xa8, 0xcc, 0xf2, 0xbe, 0x09, 0x12, 0x1a, 0x0c, 0xeb, 0xf5, 0x91, 0xad, 0xf6,
-	0x57, 0x89, 0x51, 0x82, 0x8c, 0xbd, 0x75, 0x45, 0xdb, 0x2a, 0x43, 0x6c, 0xab, 0x8c, 0x67, 0x6f,
-	0x13, 0xf4, 0x3c, 0x94, 0x76, 0x5c, 0xbf, 0x35, 0x3b, 0xcc, 0x68, 0x5d, 0xa0, 0x73, 0x7e, 0xd3,
-	0xf5, 0x5b, 0x47, 0x07, 0x95, 0x19, 0xa3, 0x3b, 0xb4, 0x10, 0x33, 0x54, 0xfb, 0x8f, 0x2d, 0xa8,
-	0x30, 0xd8, 0x8a, 0xeb, 0x91, 0x3a, 0x09, 0x23, 0x37, 0x8a, 0x89, 0x1f, 0x1b, 0x03, 0x7a, 0x0d,
-	0x20, 0x22, 0xcd, 0x90, 0xc4, 0xda, 0x90, 0xaa, 0x85, 0xd1, 0x50, 0x10, 0xac, 0x61, 0xd1, 0x03,
-	0x21, 0xda, 0x76, 0x42, 0xb6, 0xbe, 0xc4, 0xc0, 0xaa, 0x03, 0xa1, 0x21, 0x01, 0x38, 0xc1, 0x31,
-	0x0e, 0x84, 0x62, 0xbf, 0x03, 0x01, 0x7d, 0x16, 0xa6, 0x92, 0xc6, 0xa2, 0xb6, 0xd3, 0x94, 0x03,
-	0xc8, 0xb6, 0x4c, 0xc3, 0x04, 0xe1, 0x34, 0xae, 0xfd, 0x8f, 0x2c, 0xb1, 0x78, 0xe8, 0x57, 0x7f,
-	0xc4, 0xbf, 0xd5, 0xfe, 0x25, 0x0b, 0x46, 0x16, 0x5d, 0xbf, 0xe5, 0xfa, 0x5b, 0xe8, 0x4b, 0x30,
-	0x4a, 0xef, 0xa6, 0x96, 0x13, 0x3b, 0xe2, 0xdc, 0xfb, 0x94, 0xb6, 0xb7, 0xd4, 0x55, 0x31, 0xdf,
-	0xde, 0xd9, 0xa2, 0x05, 0xd1, 0x3c, 0xc5, 0xa6, 0xbb, 0xed, 0xf6, 0xc6, 0xbb, 0xa4, 0x19, 0xaf,
-	0x92, 0xd8, 0x49, 0x3e, 0x27, 0x29, 0xc3, 0x8a, 0x2a, 0xba, 0x09, 0xc3, 0xb1, 0x13, 0x6e, 0x91,
-	0x58, 0x1c, 0x80, 0x99, 0x07, 0x15, 0xaf, 0x89, 0xe9, 0x8e, 0x24, 0x7e, 0x93, 0x24, 0xd7, 0xc2,
-	0x3a, 0xab, 0x8a, 0x05, 0x09, 0xfb, 0x6f, 0x0c, 0xc3, 0xf9, 0xa5, 0x46, 0x2d, 0x67, 0x5d, 0x5d,
-	0x86, 0xe1, 0x56, 0xe8, 0xee, 0x91, 0x50, 0x8c, 0xb3, 0xa2, 0x52, 0x65, 0xa5, 0x58, 0x40, 0xd1,
-	0x2b, 0x30, 0xce, 0x2f, 0xa4, 0x1b, 0x8e, 0xdf, 0xf2, 0xe4, 0x10, 0x9f, 0x15, 0xd8, 0xe3, 0x77,
-	0x35, 0x18, 0x36, 0x30, 0x8f, 0xb9, 0xa8, 0x2e, 0xa7, 0x36, 0x63, 0xde, 0x65, 0xf7, 0x15, 0x0b,
-	0xa6, 0x79, 0x33, 0x0b, 0x71, 0x1c, 0xba, 0x1b, 0x9d, 0x98, 0x44, 0xb3, 0x43, 0xec, 0xa4, 0x5b,
-	0xca, 0x1a, 0xad, 0xdc, 0x11, 0x98, 0xbf, 0x9b, 0xa2, 0xc2, 0x0f, 0xc1, 0x59, 0xd1, 0xee, 0x74,
-	0x1a, 0x8c, 0xbb, 0x9a, 0x45, 0xdf, 0x6b, 0xc1, 0x5c, 0x33, 0xf0, 0xe3, 0x30, 0xf0, 0x3c, 0x12,
-	0xd6, 0x3b, 0x1b, 0x9e, 0x1b, 0x6d, 0xf3, 0x75, 0x8a, 0xc9, 0x26, 0x3b, 0x09, 0x72, 0xe6, 0x50,
-	0x21, 0x89, 0x39, 0xbc, 0x78, 0x78, 0x50, 0x99, 0x5b, 0xca, 0x25, 0x85, 0x7b, 0x34, 0x83, 0x76,
-	0x00, 0xd1, 0xab, 0xb4, 0x11, 0x3b, 0x5b, 0x24, 0x69, 0x7c, 0x64, 0xf0, 0xc6, 0x1f, 0x39, 0x3c,
-	0xa8, 0xa0, 0xb5, 0x2e, 0x12, 0x38, 0x83, 0x2c, 0x7a, 0x0f, 0xce, 0xd2, 0xd2, 0xae, 0x6f, 0x1d,
-	0x1d, 0xbc, 0xb9, 0xd9, 0xc3, 0x83, 0xca, 0xd9, 0xb5, 0x0c, 0x22, 0x38, 0x93, 0xf4, 0xdc, 0x12,
-	0x9c, 0xcb, 0x9c, 0x2a, 0x34, 0x0d, 0xc5, 0x1d, 0xc2, 0x59, 0x90, 0x32, 0xa6, 0x3f, 0xd1, 0x59,
-	0x18, 0xda, 0x73, 0xbc, 0x8e, 0x58, 0xa5, 0x98, 0xff, 0xf9, 0x4c, 0xe1, 0x15, 0xcb, 0x6e, 0xc2,
-	0xf8, 0x92, 0xd3, 0x76, 0x36, 0x5c, 0xcf, 0x8d, 0x5d, 0x12, 0xa1, 0xa7, 0xa0, 0xe8, 0xb4, 0x5a,
-	0xec, 0x8a, 0x2c, 0x2f, 0x9e, 0x3b, 0x3c, 0xa8, 0x14, 0x17, 0x5a, 0xf4, 0xac, 0x06, 0x85, 0xb5,
-	0x8f, 0x29, 0x06, 0xfa, 0x24, 0x94, 0x5a, 0x61, 0xd0, 0x9e, 0x2d, 0x30, 0x4c, 0x3a, 0x54, 0xa5,
-	0x6a, 0x18, 0xb4, 0x53, 0xa8, 0x0c, 0xc7, 0xfe, 0xb5, 0x02, 0x3c, 0xbe, 0x44, 0xda, 0xdb, 0x2b,
-	0x8d, 0x9c, 0x4d, 0x77, 0x05, 0x46, 0x77, 0x03, 0xdf, 0x8d, 0x83, 0x30, 0x12, 0x4d, 0xb3, 0xdb,
-	0x64, 0x55, 0x94, 0x61, 0x05, 0x45, 0x97, 0xa0, 0xd4, 0x4e, 0x38, 0x81, 0x71, 0xc9, 0x45, 0x30,
-	0x1e, 0x80, 0x41, 0x28, 0x46, 0x27, 0x22, 0xa1, 0xb8, 0x05, 0x15, 0xc6, 0x9d, 0x88, 0x84, 0x98,
-	0x41, 0x92, 0xe3, 0x94, 0x1e, 0xb4, 0x62, 0x5b, 0xa5, 0x8e, 0x53, 0x0a, 0xc1, 0x1a, 0x16, 0xaa,
-	0x43, 0x39, 0x52, 0x93, 0x3a, 0x34, 0xf8, 0xa4, 0x4e, 0xb0, 0xf3, 0x56, 0xcd, 0x64, 0x42, 0xc4,
-	0x38, 0x06, 0x86, 0xfb, 0x9e, 0xb7, 0x5f, 0x2f, 0x00, 0xe2, 0x43, 0xf8, 0xe7, 0x6c, 0xe0, 0xee,
-	0x74, 0x0f, 0x5c, 0x26, 0xe7, 0x75, 0x2b, 0x68, 0x3a, 0x5e, 0xfa, 0x08, 0x3f, 0xa9, 0xd1, 0xfb,
-	0xdf, 0x16, 0x3c, 0xbe, 0xe4, 0xfa, 0x2d, 0x12, 0xe6, 0x2c, 0xc0, 0x87, 0x23, 0x80, 0x1c, 0xef,
-	0xa4, 0x37, 0x96, 0x58, 0xe9, 0x04, 0x96, 0x98, 0xfd, 0x47, 0x16, 0x20, 0xfe, 0xd9, 0x1f, 0xb9,
-	0x8f, 0xbd, 0xd3, 0xfd, 0xb1, 0x27, 0xb0, 0x2c, 0xec, 0x5b, 0x30, 0xb9, 0xe4, 0xb9, 0xc4, 0x8f,
-	0x6b, 0xf5, 0xa5, 0xc0, 0xdf, 0x74, 0xb7, 0xd0, 0x67, 0x60, 0x92, 0xca, 0xb4, 0x41, 0x27, 0x6e,
-	0x90, 0x66, 0xe0, 0x33, 0xf6, 0x9f, 0x4a, 0x82, 0xe8, 0xf0, 0xa0, 0x32, 0xb9, 0x6e, 0x40, 0x70,
-	0x0a, 0xd3, 0xfe, 0x1d, 0x3a, 0x7e, 0xc1, 0x6e, 0x3b, 0xf0, 0x89, 0x1f, 0x2f, 0x05, 0x7e, 0x8b,
-	0x8b, 0x89, 0x9f, 0x81, 0x52, 0x4c, 0xc7, 0x83, 0x8f, 0xdd, 0x65, 0xb9, 0x51, 0xe8, 0x28, 0x1c,
-	0x1d, 0x54, 0x1e, 0xe9, 0xae, 0xc1, 0xc6, 0x89, 0xd5, 0x41, 0xdf, 0x06, 0xc3, 0x51, 0xec, 0xc4,
-	0x9d, 0x48, 0x8c, 0xe6, 0x13, 0x72, 0x34, 0x1b, 0xac, 0xf4, 0xe8, 0xa0, 0x32, 0xa5, 0xaa, 0xf1,
-	0x22, 0x2c, 0x2a, 0xa0, 0xa7, 0x61, 0x64, 0x97, 0x44, 0x91, 0xb3, 0x25, 0x39, 0xfc, 0x29, 0x51,
-	0x77, 0x64, 0x95, 0x17, 0x63, 0x09, 0x47, 0x4f, 0xc2, 0x10, 0x09, 0xc3, 0x20, 0x14, 0x7b, 0x74,
-	0x42, 0x20, 0x0e, 0x2d, 0xd3, 0x42, 0xcc, 0x61, 0xf6, 0xbf, 0xb7, 0x60, 0x4a, 0xf5, 0x95, 0xb7,
-	0x75, 0x0a, 0xac, 0xdc, 0xdb, 0x00, 0x4d, 0xf9, 0x81, 0x11, 0xbb, 0x3d, 0xc6, 0xae, 0x5d, 0xce,
-	0x64, 0x50, 0xba, 0x86, 0x31, 0xa1, 0xac, 0x8a, 0x22, 0xac, 0x51, 0xb3, 0x7f, 0xd5, 0x82, 0x33,
-	0xa9, 0x2f, 0xba, 0xe5, 0x46, 0x31, 0x7a, 0xa7, 0xeb, 0xab, 0xe6, 0x07, 0xfb, 0x2a, 0x5a, 0x9b,
-	0x7d, 0x93, 0x5a, 0xca, 0xb2, 0x44, 0xfb, 0xa2, 0x1b, 0x30, 0xe4, 0xc6, 0x64, 0x57, 0x7e, 0xcc,
-	0x93, 0x3d, 0x3f, 0x86, 0xf7, 0x2a, 0x99, 0x91, 0x1a, 0xad, 0x89, 0x39, 0x01, 0xfb, 0x87, 0x8a,
-	0x50, 0xe6, 0xcb, 0x76, 0xd5, 0x69, 0x9f, 0xc2, 0x5c, 0xd4, 0xa0, 0xc4, 0xa8, 0xf3, 0x8e, 0x3f,
-	0x95, 0xdd, 0x71, 0xd1, 0x9d, 0x79, 0x2a, 0xa7, 0x71, 0x56, 0x50, 0x5d, 0x0d, 0xb4, 0x08, 0x33,
-	0x12, 0xc8, 0x01, 0xd8, 0x70, 0x7d, 0x27, 0xdc, 0xa7, 0x65, 0xb3, 0x45, 0x46, 0xf0, 0xb9, 0xde,
-	0x04, 0x17, 0x15, 0x3e, 0x27, 0xab, 0xfa, 0x9a, 0x00, 0xb0, 0x46, 0x74, 0xee, 0x65, 0x28, 0x2b,
-	0xe4, 0xe3, 0xf0, 0x38, 0x73, 0x9f, 0x85, 0xa9, 0x54, 0x5b, 0xfd, 0xaa, 0x8f, 0xeb, 0x2c, 0xd2,
-	0x2f, 0xb3, 0x53, 0x40, 0xf4, 0x7a, 0xd9, 0xdf, 0x13, 0xa7, 0xe8, 0xfb, 0x70, 0xd6, 0xcb, 0x38,
-	0x9c, 0xc4, 0x54, 0x0d, 0x7e, 0x98, 0x3d, 0x2e, 0x3e, 0xfb, 0x6c, 0x16, 0x14, 0x67, 0xb6, 0x41,
-	0xaf, 0xfd, 0xa0, 0x4d, 0xd7, 0xbc, 0xe3, 0xb1, 0xfe, 0x0a, 0xe9, 0xfb, 0xb6, 0x28, 0xc3, 0x0a,
-	0x4a, 0x8f, 0xb0, 0xb3, 0xaa, 0xf3, 0x37, 0xc9, 0x7e, 0x83, 0x78, 0xa4, 0x19, 0x07, 0xe1, 0x87,
-	0xda, 0xfd, 0x0b, 0x7c, 0xf4, 0xf9, 0x09, 0x38, 0x26, 0x08, 0x14, 0x6f, 0x92, 0x7d, 0x3e, 0x15,
-	0xfa, 0xd7, 0x15, 0x7b, 0x7e, 0xdd, 0xcf, 0x5a, 0x30, 0xa1, 0xbe, 0xee, 0x14, 0xb6, 0xfa, 0xa2,
-	0xb9, 0xd5, 0x2f, 0xf4, 0x5c, 0xe0, 0x39, 0x9b, 0xfc, 0xeb, 0x05, 0x38, 0xaf, 0x70, 0x28, 0xbb,
-	0xcf, 0xff, 0x88, 0x55, 0x75, 0x15, 0xca, 0xbe, 0xd2, 0x1e, 0x58, 0xa6, 0xd8, 0x9e, 0xe8, 0x0e,
-	0x12, 0x1c, 0xca, 0xb5, 0xf9, 0x89, 0x88, 0x3f, 0xae, 0xab, 0xd5, 0x84, 0x0a, 0x6d, 0x11, 0x8a,
-	0x1d, 0xb7, 0x25, 0xee, 0x8c, 0x4f, 0xc9, 0xd1, 0xbe, 0x53, 0xab, 0x1e, 0x1d, 0x54, 0x9e, 0xc8,
-	0x53, 0xe9, 0xd2, 0xcb, 0x2a, 0x9a, 0xbf, 0x53, 0xab, 0x62, 0x5a, 0x19, 0x2d, 0xc0, 0x94, 0xd4,
-	0x5a, 0xdf, 0xa5, 0x1c, 0x54, 0xe0, 0x8b, 0xab, 0x45, 0xe9, 0xc6, 0xb0, 0x09, 0xc6, 0x69, 0x7c,
-	0x54, 0x85, 0xe9, 0x9d, 0xce, 0x06, 0xf1, 0x48, 0xcc, 0x3f, 0xf8, 0x26, 0xe1, 0x9a, 0xa3, 0x72,
-	0x22, 0x5a, 0xde, 0x4c, 0xc1, 0x71, 0x57, 0x0d, 0xfb, 0xcf, 0xd8, 0x11, 0x2f, 0x46, 0xaf, 0x1e,
-	0x06, 0x74, 0x61, 0x51, 0xea, 0x1f, 0xe6, 0x72, 0x1e, 0x64, 0x55, 0xdc, 0x24, 0xfb, 0xeb, 0x01,
-	0x65, 0xb6, 0xb3, 0x57, 0x85, 0xb1, 0xe6, 0x4b, 0x3d, 0xd7, 0xfc, 0xcf, 0x17, 0xe0, 0x9c, 0x1a,
-	0x01, 0x83, 0xaf, 0xfb, 0xf3, 0x3e, 0x06, 0xcf, 0xc3, 0x58, 0x8b, 0x6c, 0x3a, 0x1d, 0x2f, 0x56,
-	0x6a, 0xcc, 0x21, 0xae, 0xca, 0xae, 0x26, 0xc5, 0x58, 0xc7, 0x39, 0xc6, 0xb0, 0xfd, 0xc4, 0x18,
-	0xbb, 0x5b, 0x63, 0x87, 0xae, 0x71, 0xb5, 0x6b, 0xac, 0xdc, 0x5d, 0xf3, 0x24, 0x0c, 0xb9, 0xbb,
-	0x94, 0xd7, 0x2a, 0x98, 0x2c, 0x54, 0x8d, 0x16, 0x62, 0x0e, 0x43, 0x9f, 0x80, 0x91, 0x66, 0xb0,
-	0xbb, 0xeb, 0xf8, 0x2d, 0x76, 0xe5, 0x95, 0x17, 0xc7, 0x28, 0x3b, 0xb6, 0xc4, 0x8b, 0xb0, 0x84,
-	0xa1, 0xc7, 0xa1, 0xe4, 0x84, 0x5b, 0xd1, 0x6c, 0x89, 0xe1, 0x8c, 0xd2, 0x96, 0x16, 0xc2, 0xad,
-	0x08, 0xb3, 0x52, 0x2a, 0x55, 0xdd, 0x0b, 0xc2, 0x1d, 0xd7, 0xdf, 0xaa, 0xba, 0xa1, 0xd8, 0x12,
-	0xea, 0x2e, 0x7c, 0x4b, 0x41, 0xb0, 0x86, 0x85, 0x56, 0x60, 0xa8, 0x1d, 0x84, 0x71, 0x34, 0x3b,
-	0xcc, 0x86, 0xfb, 0x89, 0x9c, 0x83, 0x88, 0x7f, 0x6d, 0x3d, 0x08, 0xe3, 0xe4, 0x03, 0xe8, 0xbf,
-	0x08, 0xf3, 0xea, 0xe8, 0xdb, 0xa0, 0x48, 0xfc, 0xbd, 0xd9, 0x11, 0x46, 0x65, 0x2e, 0x8b, 0xca,
-	0xb2, 0xbf, 0x77, 0xd7, 0x09, 0x93, 0x53, 0x7a, 0xd9, 0xdf, 0xc3, 0xb4, 0x0e, 0xfa, 0x3c, 0x94,
-	0xe5, 0x16, 0x8f, 0x84, 0x9a, 0x23, 0x73, 0x89, 0xc9, 0x83, 0x01, 0x93, 0xf7, 0x3a, 0x6e, 0x48,
-	0x76, 0x89, 0x1f, 0x47, 0xc9, 0x99, 0x26, 0xa1, 0x11, 0x4e, 0xa8, 0xa1, 0xcf, 0x4b, 0xdd, 0xda,
-	0x6a, 0xd0, 0xf1, 0xe3, 0x68, 0xb6, 0xcc, 0xba, 0x97, 0xf9, 0xea, 0x71, 0x37, 0xc1, 0x4b, 0x2b,
-	0xdf, 0x78, 0x65, 0x6c, 0x90, 0x42, 0x18, 0x26, 0x3c, 0x77, 0x8f, 0xf8, 0x24, 0x8a, 0xea, 0x61,
-	0xb0, 0x41, 0x66, 0x81, 0xf5, 0xfc, 0x7c, 0xf6, 0x63, 0x40, 0xb0, 0x41, 0x16, 0x67, 0x0e, 0x0f,
-	0x2a, 0x13, 0xb7, 0xf4, 0x3a, 0xd8, 0x24, 0x81, 0xee, 0xc0, 0x24, 0x95, 0x6b, 0xdc, 0x84, 0xe8,
-	0x58, 0x3f, 0xa2, 0x4c, 0xfa, 0xc0, 0x46, 0x25, 0x9c, 0x22, 0x82, 0xde, 0x80, 0xb2, 0xe7, 0x6e,
-	0x92, 0xe6, 0x7e, 0xd3, 0x23, 0xb3, 0xe3, 0x8c, 0x62, 0xe6, 0xb6, 0xba, 0x25, 0x91, 0xb8, 0x5c,
-	0xa4, 0xfe, 0xe2, 0xa4, 0x3a, 0xba, 0x0b, 0x8f, 0xc4, 0x24, 0xdc, 0x75, 0x7d, 0x87, 0x6e, 0x07,
-	0x21, 0x2f, 0xb0, 0x27, 0x95, 0x09, 0xb6, 0xde, 0x2e, 0x8a, 0xa1, 0x7b, 0x64, 0x3d, 0x13, 0x0b,
-	0xe7, 0xd4, 0x46, 0xb7, 0x61, 0x8a, 0xed, 0x84, 0x7a, 0xc7, 0xf3, 0xea, 0x81, 0xe7, 0x36, 0xf7,
-	0x67, 0x27, 0x19, 0xc1, 0x4f, 0xc8, 0x7b, 0xa1, 0x66, 0x82, 0x8f, 0x0e, 0x2a, 0x90, 0xfc, 0xc3,
-	0xe9, 0xda, 0x68, 0x83, 0xe9, 0xd0, 0x3b, 0xa1, 0x1b, 0xef, 0xd3, 0xf5, 0x4b, 0xee, 0xc7, 0xb3,
-	0x53, 0x3d, 0x45, 0x61, 0x1d, 0x55, 0x29, 0xda, 0xf5, 0x42, 0x9c, 0x26, 0x48, 0xb7, 0x76, 0x14,
-	0xb7, 0x5c, 0x7f, 0x76, 0x9a, 0x9d, 0x18, 0x6a, 0x67, 0x34, 0x68, 0x21, 0xe6, 0x30, 0xa6, 0x3f,
-	0xa7, 0x3f, 0x6e, 0xd3, 0x13, 0x74, 0x86, 0x21, 0x26, 0xfa, 0x73, 0x09, 0xc0, 0x09, 0x0e, 0x65,
-	0x6a, 0xe2, 0x78, 0x7f, 0x16, 0x31, 0x54, 0xb5, 0x5d, 0xd6, 0xd7, 0x3f, 0x8f, 0x69, 0x39, 0xba,
-	0x05, 0x23, 0xc4, 0xdf, 0x5b, 0x09, 0x83, 0xdd, 0xd9, 0x33, 0xf9, 0x7b, 0x76, 0x99, 0xa3, 0xf0,
-	0x03, 0x3d, 0x11, 0xf0, 0x44, 0x31, 0x96, 0x24, 0xd0, 0x7d, 0x98, 0xcd, 0x98, 0x11, 0x3e, 0x01,
-	0x67, 0xd9, 0x04, 0xbc, 0x26, 0xea, 0xce, 0xae, 0xe7, 0xe0, 0x1d, 0xf5, 0x80, 0xe1, 0x5c, 0xea,
-	0xe8, 0x0b, 0x30, 0xc1, 0x37, 0x14, 0x7f, 0x7c, 0x8b, 0x66, 0xcf, 0xb1, 0xaf, 0xb9, 0x94, 0xbf,
-	0x39, 0x39, 0xe2, 0xe2, 0x39, 0xd1, 0xa1, 0x09, 0xbd, 0x34, 0xc2, 0x26, 0x35, 0x7b, 0x03, 0x26,
-	0xd5, 0xb9, 0xc5, 0x96, 0x0e, 0xaa, 0xc0, 0x10, 0xe3, 0x76, 0x84, 0x7e, 0xab, 0x4c, 0x67, 0x8a,
-	0x71, 0x42, 0x98, 0x97, 0xb3, 0x99, 0x72, 0xdf, 0x27, 0x8b, 0xfb, 0x31, 0xe1, 0x52, 0x75, 0x51,
-	0x9b, 0x29, 0x09, 0xc0, 0x09, 0x8e, 0xfd, 0xff, 0x38, 0xd7, 0x98, 0x1c, 0x8e, 0x03, 0x5c, 0x07,
-	0xcf, 0xc2, 0xe8, 0x76, 0x10, 0xc5, 0x14, 0x9b, 0xb5, 0x31, 0x94, 0xf0, 0x89, 0x37, 0x44, 0x39,
-	0x56, 0x18, 0xe8, 0x55, 0x98, 0x68, 0xea, 0x0d, 0x88, 0xbb, 0x4c, 0x0d, 0x81, 0xd1, 0x3a, 0x36,
-	0x71, 0xd1, 0x2b, 0x30, 0xca, 0x9e, 0xce, 0x9b, 0x81, 0x27, 0x98, 0x2c, 0x79, 0x21, 0x8f, 0xd6,
-	0x45, 0xf9, 0x91, 0xf6, 0x1b, 0x2b, 0x6c, 0x74, 0x19, 0x86, 0x69, 0x17, 0x6a, 0x75, 0x71, 0x8b,
-	0x28, 0x55, 0xcd, 0x0d, 0x56, 0x8a, 0x05, 0xd4, 0xfe, 0x5b, 0x05, 0x6d, 0x94, 0xa9, 0x44, 0x4a,
-	0x50, 0x1d, 0x46, 0xee, 0x39, 0x6e, 0xec, 0xfa, 0x5b, 0x82, 0x5d, 0x78, 0xba, 0xe7, 0x95, 0xc2,
-	0x2a, 0xbd, 0xc5, 0x2b, 0xf0, 0x4b, 0x4f, 0xfc, 0xc1, 0x92, 0x0c, 0xa5, 0x18, 0x76, 0x7c, 0x9f,
-	0x52, 0x2c, 0x0c, 0x4a, 0x11, 0xf3, 0x0a, 0x9c, 0xa2, 0xf8, 0x83, 0x25, 0x19, 0xf4, 0x0e, 0x80,
-	0x5c, 0x96, 0xa4, 0x25, 0x9e, 0xac, 0x9f, 0xed, 0x4f, 0x74, 0x5d, 0xd5, 0x59, 0x9c, 0xa4, 0x57,
-	0x6a, 0xf2, 0x1f, 0x6b, 0xf4, 0xec, 0x98, 0xb1, 0x55, 0xdd, 0x9d, 0x41, 0xdf, 0x49, 0x4f, 0x02,
-	0x27, 0x8c, 0x49, 0x6b, 0x21, 0x16, 0x83, 0xf3, 0xc9, 0xc1, 0x64, 0x8a, 0x75, 0x77, 0x97, 0xe8,
-	0xa7, 0x86, 0x20, 0x82, 0x13, 0x7a, 0xf6, 0x2f, 0x16, 0x61, 0x36, 0xaf, 0xbb, 0x74, 0xd1, 0x91,
-	0xfb, 0x6e, 0xbc, 0x44, 0xb9, 0x21, 0xcb, 0x5c, 0x74, 0xcb, 0xa2, 0x1c, 0x2b, 0x0c, 0x3a, 0xfb,
-	0x91, 0xbb, 0x25, 0x45, 0xc2, 0xa1, 0x64, 0xf6, 0x1b, 0xac, 0x14, 0x0b, 0x28, 0xc5, 0x0b, 0x89,
-	0x13, 0x09, 0x9b, 0x08, 0x6d, 0x95, 0x60, 0x56, 0x8a, 0x05, 0x54, 0xd7, 0x37, 0x95, 0xfa, 0xe8,
-	0x9b, 0x8c, 0x21, 0x1a, 0x3a, 0xd9, 0x21, 0x42, 0x5f, 0x04, 0xd8, 0x74, 0x7d, 0x37, 0xda, 0x66,
-	0xd4, 0x87, 0x8f, 0x4d, 0x5d, 0xf1, 0x52, 0x2b, 0x8a, 0x0a, 0xd6, 0x28, 0xa2, 0x97, 0x60, 0x4c,
-	0x6d, 0xc0, 0x5a, 0x95, 0x3d, 0x10, 0x69, 0x0f, 0xee, 0xc9, 0x69, 0x54, 0xc5, 0x3a, 0x9e, 0xfd,
-	0x6e, 0x7a, 0xbd, 0x88, 0x1d, 0xa0, 0x8d, 0xaf, 0x35, 0xe8, 0xf8, 0x16, 0x7a, 0x8f, 0xaf, 0xfd,
-	0xeb, 0x45, 0x98, 0x32, 0x1a, 0xeb, 0x44, 0x03, 0x9c, 0x59, 0xd7, 0xe9, 0x3d, 0xe7, 0xc4, 0x44,
-	0xec, 0x3f, 0xbb, 0xff, 0x56, 0xd1, 0xef, 0x42, 0xba, 0x03, 0x78, 0x7d, 0xf4, 0x45, 0x28, 0x7b,
-	0x4e, 0xc4, 0x74, 0x57, 0x44, 0xec, 0xbb, 0x41, 0x88, 0x25, 0x72, 0x84, 0x13, 0xc5, 0xda, 0x55,
-	0xc3, 0x69, 0x27, 0x24, 0xe9, 0x85, 0x4c, 0x79, 0x1f, 0x69, 0x74, 0xa3, 0x3a, 0x41, 0x19, 0xa4,
-	0x7d, 0xcc, 0x61, 0xe8, 0x15, 0x18, 0x0f, 0x09, 0x5b, 0x15, 0x4b, 0x94, 0x95, 0x63, 0xcb, 0x6c,
-	0x28, 0xe1, 0xf9, 0xb0, 0x06, 0xc3, 0x06, 0x66, 0xc2, 0xca, 0x0f, 0xf7, 0x60, 0xe5, 0x9f, 0x86,
-	0x11, 0xf6, 0x43, 0xad, 0x00, 0x35, 0x1b, 0x35, 0x5e, 0x8c, 0x25, 0x3c, 0xbd, 0x60, 0x46, 0x07,
-	0x5c, 0x30, 0x9f, 0x84, 0xc9, 0xaa, 0x43, 0x76, 0x03, 0x7f, 0xd9, 0x6f, 0xb5, 0x03, 0xd7, 0x8f,
-	0xd1, 0x2c, 0x94, 0xd8, 0xed, 0xc0, 0xf7, 0x76, 0x89, 0x52, 0xc0, 0x25, 0xca, 0x98, 0xdb, 0x5b,
-	0x70, 0xae, 0x1a, 0xdc, 0xf3, 0xef, 0x39, 0x61, 0x6b, 0xa1, 0x5e, 0xd3, 0xe4, 0xdc, 0x35, 0x29,
-	0x67, 0x71, 0x23, 0x96, 0xcc, 0x33, 0x55, 0xab, 0xc9, 0xef, 0xda, 0x15, 0xd7, 0x23, 0x39, 0xda,
-	0x88, 0xbf, 0x53, 0x30, 0x5a, 0x4a, 0xf0, 0xd5, 0x83, 0x91, 0x95, 0xfb, 0x60, 0xf4, 0x26, 0x8c,
-	0x6e, 0xba, 0xc4, 0x6b, 0x61, 0xb2, 0x29, 0x96, 0xd8, 0x53, 0xf9, 0xef, 0xf2, 0x2b, 0x14, 0x53,
-	0x6a, 0x9f, 0xb8, 0x94, 0xb6, 0x22, 0x2a, 0x63, 0x45, 0x06, 0xed, 0xc0, 0xb4, 0x14, 0x03, 0x24,
-	0x54, 0x2c, 0xb8, 0xa7, 0x7b, 0xc9, 0x16, 0x26, 0xf1, 0xb3, 0x87, 0x07, 0x95, 0x69, 0x9c, 0x22,
-	0x83, 0xbb, 0x08, 0x53, 0xb1, 0x6c, 0x97, 0x1e, 0xad, 0x25, 0x36, 0xfc, 0x4c, 0x2c, 0x63, 0x12,
-	0x26, 0x2b, 0xb5, 0x7f, 0xd4, 0x82, 0x47, 0xbb, 0x46, 0x46, 0x48, 0xda, 0x27, 0x3c, 0x0b, 0x69,
-	0xc9, 0xb7, 0xd0, 0x5f, 0xf2, 0xb5, 0xff, 0xb1, 0x05, 0x67, 0x97, 0x77, 0xdb, 0xf1, 0x7e, 0xd5,
-	0x35, 0x5f, 0x77, 0x5e, 0x86, 0xe1, 0x5d, 0xd2, 0x72, 0x3b, 0xbb, 0x62, 0xe6, 0x2a, 0xf2, 0xf8,
-	0x59, 0x65, 0xa5, 0x47, 0x07, 0x95, 0x89, 0x46, 0x1c, 0x84, 0xce, 0x16, 0xe1, 0x05, 0x58, 0xa0,
-	0xb3, 0x43, 0xdc, 0x7d, 0x9f, 0xdc, 0x72, 0x77, 0x5d, 0x69, 0x67, 0xd1, 0x53, 0x77, 0x36, 0x2f,
-	0x07, 0x74, 0xfe, 0xcd, 0x8e, 0xe3, 0xc7, 0x6e, 0xbc, 0x2f, 0x1e, 0x66, 0x24, 0x11, 0x9c, 0xd0,
-	0xb3, 0xbf, 0x69, 0xc1, 0x94, 0x5c, 0xf7, 0x0b, 0xad, 0x56, 0x48, 0xa2, 0x08, 0xcd, 0x41, 0xc1,
-	0x6d, 0x8b, 0x5e, 0x82, 0xe8, 0x65, 0xa1, 0x56, 0xc7, 0x05, 0xb7, 0x8d, 0xea, 0x50, 0xe6, 0xe6,
-	0x1a, 0xc9, 0xe2, 0x1a, 0xc8, 0xe8, 0x83, 0xf5, 0x60, 0x5d, 0xd6, 0xc4, 0x09, 0x11, 0xc9, 0xc1,
-	0xb1, 0x33, 0xb3, 0x68, 0xbe, 0x7a, 0xdd, 0x10, 0xe5, 0x58, 0x61, 0xa0, 0x2b, 0x30, 0xea, 0x07,
-	0x2d, 0x6e, 0x3d, 0xc3, 0x6f, 0x3f, 0xb6, 0x64, 0xd7, 0x44, 0x19, 0x56, 0x50, 0xfb, 0x07, 0x2d,
-	0x18, 0x97, 0x5f, 0x36, 0x20, 0x33, 0x49, 0xb7, 0x56, 0xc2, 0x48, 0x26, 0x5b, 0x8b, 0x32, 0x83,
-	0x0c, 0x62, 0xf0, 0x80, 0xc5, 0xe3, 0xf0, 0x80, 0xf6, 0x8f, 0x14, 0x60, 0x52, 0x76, 0xa7, 0xd1,
-	0xd9, 0x88, 0x48, 0x8c, 0xd6, 0xa1, 0xec, 0xf0, 0x21, 0x27, 0x72, 0xc5, 0x3e, 0x99, 0x2d, 0x7c,
-	0x18, 0xf3, 0x93, 0x5c, 0xcb, 0x0b, 0xb2, 0x36, 0x4e, 0x08, 0x21, 0x0f, 0x66, 0xfc, 0x20, 0x66,
-	0x47, 0xb4, 0x82, 0xf7, 0x7a, 0x02, 0x49, 0x53, 0x3f, 0x2f, 0xa8, 0xcf, 0xac, 0xa5, 0xa9, 0xe0,
-	0x6e, 0xc2, 0x68, 0x59, 0x2a, 0x3c, 0x8a, 0xf9, 0xe2, 0x86, 0x3e, 0x0b, 0xd9, 0xfa, 0x0e, 0xfb,
-	0x57, 0x2c, 0x28, 0x4b, 0xb4, 0xd3, 0x78, 0xed, 0x5a, 0x85, 0x91, 0x88, 0x4d, 0x82, 0x1c, 0x1a,
-	0xbb, 0x57, 0xc7, 0xf9, 0x7c, 0x25, 0x37, 0x0f, 0xff, 0x1f, 0x61, 0x49, 0x83, 0xe9, 0xbb, 0x55,
-	0xf7, 0x3f, 0x22, 0xfa, 0x6e, 0xd5, 0x9f, 0x9c, 0x1b, 0xe6, 0xbf, 0xb3, 0x3e, 0x6b, 0x62, 0x2d,
-	0x65, 0x90, 0xda, 0x21, 0xd9, 0x74, 0xef, 0xa7, 0x19, 0xa4, 0x3a, 0x2b, 0xc5, 0x02, 0x8a, 0xde,
-	0x81, 0xf1, 0xa6, 0x54, 0x74, 0x26, 0xc7, 0xc0, 0xe5, 0x9e, 0x4a, 0x77, 0xf5, 0x3e, 0xc3, 0x2d,
-	0x6b, 0x97, 0xb4, 0xfa, 0xd8, 0xa0, 0x66, 0x3e, 0xb7, 0x17, 0xfb, 0x3d, 0xb7, 0x27, 0x74, 0xf3,
-	0x1f, 0x9f, 0x7f, 0xcc, 0x82, 0x61, 0xae, 0x2e, 0x1b, 0x4c, 0xbf, 0xa8, 0x3d, 0x57, 0x25, 0x63,
-	0x77, 0x97, 0x16, 0x8a, 0xe7, 0x27, 0xb4, 0x0a, 0x65, 0xf6, 0x83, 0xa9, 0x0d, 0x8a, 0xf9, 0x26,
-	0xc5, 0xbc, 0x55, 0xbd, 0x83, 0x77, 0x65, 0x35, 0x9c, 0x50, 0xb0, 0xbf, 0x56, 0xa4, 0x47, 0x55,
-	0x82, 0x6a, 0xdc, 0xe0, 0xd6, 0xc3, 0xbb, 0xc1, 0x0b, 0x0f, 0xeb, 0x06, 0xdf, 0x82, 0xa9, 0xa6,
-	0xf6, 0xb8, 0x95, 0xcc, 0xe4, 0x95, 0x9e, 0x8b, 0x44, 0x7b, 0x07, 0xe3, 0x2a, 0xa3, 0x25, 0x93,
-	0x08, 0x4e, 0x53, 0x45, 0xdf, 0x09, 0xe3, 0x7c, 0x9e, 0x45, 0x2b, 0xdc, 0x62, 0xe1, 0x13, 0xf9,
-	0xeb, 0x45, 0x6f, 0x82, 0xad, 0xc4, 0x86, 0x56, 0x1d, 0x1b, 0xc4, 0xec, 0x5f, 0x1c, 0x85, 0xa1,
-	0xe5, 0x3d, 0xe2, 0xc7, 0xa7, 0x70, 0x20, 0x35, 0x61, 0xd2, 0xf5, 0xf7, 0x02, 0x6f, 0x8f, 0xb4,
-	0x38, 0xfc, 0x38, 0x97, 0xeb, 0x23, 0x82, 0xf4, 0x64, 0xcd, 0x20, 0x81, 0x53, 0x24, 0x1f, 0x86,
-	0x84, 0x79, 0x1d, 0x86, 0xf9, 0xdc, 0x0b, 0xf1, 0x32, 0x53, 0x19, 0xcc, 0x06, 0x51, 0xec, 0x82,
-	0x44, 0xfa, 0xe5, 0xda, 0x67, 0x51, 0x1d, 0xbd, 0x0b, 0x93, 0x9b, 0x6e, 0x18, 0xc5, 0x54, 0x34,
-	0x8c, 0x62, 0x67, 0xb7, 0xfd, 0x00, 0x12, 0xa5, 0x1a, 0x87, 0x15, 0x83, 0x12, 0x4e, 0x51, 0x46,
-	0x5b, 0x30, 0x41, 0x85, 0x9c, 0xa4, 0xa9, 0x91, 0x63, 0x37, 0xa5, 0x54, 0x46, 0xb7, 0x74, 0x42,
-	0xd8, 0xa4, 0x4b, 0x0f, 0x93, 0x26, 0x13, 0x8a, 0x46, 0x19, 0x47, 0xa1, 0x0e, 0x13, 0x2e, 0x0d,
-	0x71, 0x18, 0x3d, 0x93, 0x98, 0xd9, 0x4a, 0xd9, 0x3c, 0x93, 0x34, 0xe3, 0x94, 0x2f, 0x41, 0x99,
-	0xd0, 0x21, 0xa4, 0x84, 0x85, 0x62, 0xfc, 0xea, 0x60, 0x7d, 0x5d, 0x75, 0x9b, 0x61, 0x60, 0xca,
-	0xf2, 0xcb, 0x92, 0x12, 0x4e, 0x88, 0xa2, 0x25, 0x18, 0x8e, 0x48, 0xe8, 0x92, 0x48, 0xa8, 0xc8,
-	0x7b, 0x4c, 0x23, 0x43, 0xe3, 0xb6, 0xe7, 0xfc, 0x37, 0x16, 0x55, 0xe9, 0xf2, 0x72, 0x98, 0x34,
-	0xc4, 0xb4, 0xe2, 0xda, 0xf2, 0x5a, 0x60, 0xa5, 0x58, 0x40, 0xd1, 0x1b, 0x30, 0x12, 0x12, 0x8f,
-	0x29, 0x8b, 0x26, 0x06, 0x5f, 0xe4, 0x5c, 0xf7, 0xc4, 0xeb, 0x61, 0x49, 0x00, 0xdd, 0x04, 0x14,
-	0x12, 0xca, 0x43, 0xb8, 0xfe, 0x96, 0x32, 0xe6, 0x10, 0xba, 0xee, 0xc7, 0x44, 0xfb, 0x67, 0x70,
-	0x82, 0x21, 0xad, 0x52, 0x71, 0x46, 0x35, 0x74, 0x1d, 0x66, 0x54, 0x69, 0xcd, 0x8f, 0x62, 0xc7,
-	0x6f, 0x12, 0xa6, 0xe6, 0x2e, 0x27, 0x5c, 0x11, 0x4e, 0x23, 0xe0, 0xee, 0x3a, 0xf6, 0x4f, 0x53,
-	0x76, 0x86, 0x8e, 0xd6, 0x29, 0xf0, 0x02, 0xaf, 0x9b, 0xbc, 0xc0, 0xf9, 0xdc, 0x99, 0xcb, 0xe1,
-	0x03, 0x0e, 0x2d, 0x18, 0xd3, 0x66, 0x36, 0x59, 0xb3, 0x56, 0x8f, 0x35, 0xdb, 0x81, 0x69, 0xba,
-	0xd2, 0x6f, 0x6f, 0x44, 0x24, 0xdc, 0x23, 0x2d, 0xb6, 0x30, 0x0b, 0x0f, 0xb6, 0x30, 0xd5, 0x2b,
-	0xf3, 0xad, 0x14, 0x41, 0xdc, 0xd5, 0x04, 0x7a, 0x59, 0x6a, 0x4e, 0x8a, 0x86, 0x91, 0x16, 0xd7,
-	0x8a, 0x1c, 0x1d, 0x54, 0xa6, 0xb5, 0x0f, 0xd1, 0x35, 0x25, 0xf6, 0x97, 0xe4, 0x37, 0xaa, 0xd7,
-	0xfc, 0xa6, 0x5a, 0x2c, 0xa9, 0xd7, 0x7c, 0xb5, 0x1c, 0x70, 0x82, 0x43, 0xf7, 0x28, 0x15, 0x41,
-	0xd2, 0xaf, 0xf9, 0x54, 0x40, 0xc1, 0x0c, 0x62, 0xbf, 0x00, 0xb0, 0x7c, 0x9f, 0x34, 0xf9, 0x52,
-	0xd7, 0x1f, 0x20, 0xad, 0xfc, 0x07, 0x48, 0xfb, 0x3f, 0x5a, 0x30, 0xb9, 0xb2, 0x64, 0x88, 0x89,
-	0xf3, 0x00, 0x5c, 0x36, 0x7a, 0xeb, 0xad, 0x35, 0xa9, 0x5b, 0xe7, 0xea, 0x51, 0x55, 0x8a, 0x35,
-	0x0c, 0x74, 0x1e, 0x8a, 0x5e, 0xc7, 0x17, 0x22, 0xcb, 0xc8, 0xe1, 0x41, 0xa5, 0x78, 0xab, 0xe3,
-	0x63, 0x5a, 0xa6, 0x59, 0x08, 0x16, 0x07, 0xb6, 0x10, 0xec, 0xeb, 0x5e, 0x85, 0x2a, 0x30, 0x74,
-	0xef, 0x9e, 0xdb, 0xe2, 0x46, 0xec, 0x42, 0xef, 0xff, 0xd6, 0x5b, 0xb5, 0x6a, 0x84, 0x79, 0xb9,
-	0xfd, 0xd5, 0x22, 0xcc, 0xad, 0x78, 0xe4, 0xfe, 0x07, 0x34, 0xe4, 0x1f, 0xd4, 0xbe, 0xf1, 0x78,
-	0xfc, 0xe2, 0x71, 0x6d, 0x58, 0xfb, 0x8f, 0xc7, 0x26, 0x8c, 0xf0, 0xc7, 0x6c, 0x69, 0xd6, 0xff,
-	0x6a, 0x56, 0xeb, 0xf9, 0x03, 0x32, 0xcf, 0x1f, 0xc5, 0x85, 0x39, 0xbf, 0xba, 0x69, 0x45, 0x29,
-	0x96, 0xc4, 0xe7, 0x3e, 0x03, 0xe3, 0x3a, 0xe6, 0xb1, 0xac, 0xc9, 0xff, 0x4a, 0x11, 0xa6, 0x69,
-	0x0f, 0x1e, 0xea, 0x44, 0xdc, 0xe9, 0x9e, 0x88, 0x93, 0xb6, 0x28, 0xee, 0x3f, 0x1b, 0xef, 0xa4,
-	0x67, 0xe3, 0xf9, 0xbc, 0xd9, 0x38, 0xed, 0x39, 0xf8, 0x5e, 0x0b, 0xce, 0xac, 0x78, 0x41, 0x73,
-	0x27, 0x65, 0xf5, 0xfb, 0x12, 0x8c, 0xd1, 0x73, 0x3c, 0x32, 0xbc, 0x88, 0x0c, 0xbf, 0x32, 0x01,
-	0xc2, 0x3a, 0x9e, 0x56, 0xed, 0xce, 0x9d, 0x5a, 0x35, 0xcb, 0x1d, 0x4d, 0x80, 0xb0, 0x8e, 0x67,
-	0x7f, 0xc3, 0x82, 0x0b, 0xd7, 0x97, 0x96, 0x93, 0xa5, 0xd8, 0xe5, 0x11, 0x47, 0xa5, 0xc0, 0x96,
-	0xd6, 0x95, 0x44, 0x0a, 0xac, 0xb2, 0x5e, 0x08, 0xe8, 0x47, 0xc5, 0xdb, 0xf3, 0xa7, 0x2c, 0x38,
-	0x73, 0xdd, 0x8d, 0xe9, 0xb5, 0x9c, 0xf6, 0xcd, 0xa2, 0xf7, 0x72, 0xe4, 0xc6, 0x41, 0xb8, 0x9f,
-	0xf6, 0xcd, 0xc2, 0x0a, 0x82, 0x35, 0x2c, 0xde, 0xf2, 0x9e, 0xcb, 0xcc, 0xa8, 0x0a, 0xa6, 0x2a,
-	0x0a, 0x8b, 0x72, 0xac, 0x30, 0xe8, 0x87, 0xb5, 0xdc, 0x90, 0x89, 0x12, 0xfb, 0xe2, 0x84, 0x55,
-	0x1f, 0x56, 0x95, 0x00, 0x9c, 0xe0, 0xd8, 0x7f, 0x68, 0x41, 0xe5, 0xba, 0xd7, 0x89, 0x62, 0x12,
-	0x6e, 0x46, 0x39, 0xa7, 0xe3, 0x0b, 0x50, 0x26, 0x52, 0x70, 0x17, 0xbd, 0x56, 0xac, 0xa6, 0x92,
-	0xe8, 0xb9, 0x8b, 0x98, 0xc2, 0x1b, 0xc0, 0x87, 0xe0, 0x78, 0x46, 0xe0, 0x2b, 0x80, 0x88, 0xde,
-	0x96, 0xee, 0x33, 0xc7, 0x9c, 0x6f, 0x96, 0xbb, 0xa0, 0x38, 0xa3, 0x86, 0xfd, 0xa3, 0x16, 0x9c,
-	0x53, 0x1f, 0xfc, 0x91, 0xfb, 0x4c, 0xfb, 0xe7, 0x0a, 0x30, 0x71, 0x63, 0x7d, 0xbd, 0x7e, 0x9d,
-	0xc4, 0xe2, 0xda, 0xee, 0xaf, 0x5b, 0xc7, 0x9a, 0x8a, 0xb0, 0x97, 0x14, 0xd8, 0x89, 0x5d, 0x6f,
-	0x9e, 0xbb, 0x5e, 0xcf, 0xd7, 0xfc, 0xf8, 0x76, 0xd8, 0x88, 0x43, 0xd7, 0xdf, 0xca, 0x54, 0x2a,
-	0x4a, 0xe6, 0xa2, 0x98, 0xc7, 0x5c, 0xa0, 0x17, 0x60, 0x98, 0xf9, 0x7e, 0xcb, 0x49, 0x78, 0x4c,
-	0x09, 0x51, 0xac, 0xf4, 0xe8, 0xa0, 0x52, 0xbe, 0x83, 0x6b, 0xfc, 0x0f, 0x16, 0xa8, 0xe8, 0x0e,
-	0x8c, 0x6d, 0xc7, 0x71, 0xfb, 0x06, 0x71, 0x5a, 0x24, 0x94, 0xc7, 0xe1, 0xc5, 0xac, 0xe3, 0x90,
-	0x0e, 0x02, 0x47, 0x4b, 0x4e, 0x90, 0xa4, 0x2c, 0xc2, 0x3a, 0x1d, 0xbb, 0x01, 0x90, 0xc0, 0x4e,
-	0x48, 0xa1, 0x62, 0xff, 0xbe, 0x05, 0x23, 0xdc, 0x0d, 0x2f, 0x44, 0xaf, 0x41, 0x89, 0xdc, 0x27,
-	0x4d, 0xc1, 0x2a, 0x67, 0x76, 0x38, 0xe1, 0xb4, 0xf8, 0xf3, 0x00, 0xfd, 0x8f, 0x59, 0x2d, 0x74,
-	0x03, 0x46, 0x68, 0x6f, 0xaf, 0x2b, 0x9f, 0xc4, 0x27, 0xf2, 0xbe, 0x58, 0x4d, 0x3b, 0x67, 0xce,
-	0x44, 0x11, 0x96, 0xd5, 0x99, 0xaa, 0xbb, 0xd9, 0x6e, 0xd0, 0x13, 0x3b, 0xee, 0xc5, 0x58, 0xac,
-	0x2f, 0xd5, 0x39, 0x92, 0xa0, 0xc6, 0x55, 0xdd, 0xb2, 0x10, 0x27, 0x44, 0xec, 0x75, 0x28, 0xd3,
-	0x49, 0x5d, 0xf0, 0x5c, 0xa7, 0xb7, 0x96, 0xfd, 0x19, 0x28, 0x4b, 0x8d, 0x77, 0x24, 0x3c, 0xb9,
-	0x18, 0x55, 0xa9, 0x10, 0x8f, 0x70, 0x02, 0xb7, 0x37, 0xe1, 0x2c, 0x33, 0x75, 0x70, 0xe2, 0x6d,
-	0x63, 0x8f, 0xf5, 0x5f, 0xcc, 0xcf, 0x0a, 0xc9, 0x93, 0xcf, 0xcc, 0xac, 0xe6, 0x2c, 0x31, 0x2e,
-	0x29, 0x26, 0x52, 0xa8, 0xfd, 0x07, 0x25, 0x78, 0xac, 0xd6, 0xc8, 0xf7, 0xd0, 0x7c, 0x05, 0xc6,
-	0x39, 0x5f, 0x4a, 0x97, 0xb6, 0xe3, 0x89, 0x76, 0xd5, 0x43, 0xe0, 0xba, 0x06, 0xc3, 0x06, 0x26,
-	0xba, 0x00, 0x45, 0xf7, 0x3d, 0x3f, 0x6d, 0x77, 0x5c, 0x7b, 0x73, 0x0d, 0xd3, 0x72, 0x0a, 0xa6,
-	0x2c, 0x2e, 0xbf, 0x3b, 0x14, 0x58, 0xb1, 0xb9, 0xaf, 0xc3, 0xa4, 0x1b, 0x35, 0x23, 0xb7, 0xe6,
-	0xd3, 0x73, 0x46, 0x3b, 0xa9, 0x94, 0x56, 0x84, 0x76, 0x5a, 0x41, 0x71, 0x0a, 0x5b, 0xbb, 0xc8,
-	0x86, 0x06, 0x66, 0x93, 0xfb, 0xba, 0x36, 0x51, 0x09, 0xa0, 0xcd, 0xbe, 0x2e, 0x62, 0x56, 0x7c,
-	0x42, 0x02, 0xe0, 0x1f, 0x1c, 0x61, 0x09, 0xa3, 0x22, 0x67, 0x73, 0xdb, 0x69, 0x2f, 0x74, 0xe2,
-	0xed, 0xaa, 0x1b, 0x35, 0x83, 0x3d, 0x12, 0xee, 0x33, 0x6d, 0xc1, 0x68, 0x22, 0x72, 0x2a, 0xc0,
-	0xd2, 0x8d, 0x85, 0x3a, 0xc5, 0xc4, 0xdd, 0x75, 0x4c, 0x36, 0x18, 0x4e, 0x82, 0x0d, 0x5e, 0x80,
-	0x29, 0xd9, 0x4c, 0x83, 0x44, 0xec, 0x52, 0x1c, 0x63, 0x1d, 0x53, 0xb6, 0xc5, 0xa2, 0x58, 0x75,
-	0x2b, 0x8d, 0x8f, 0x5e, 0x86, 0x09, 0xd7, 0x77, 0x63, 0xd7, 0x89, 0x83, 0x90, 0xb1, 0x14, 0x5c,
-	0x31, 0xc0, 0x4c, 0xf7, 0x6a, 0x3a, 0x00, 0x9b, 0x78, 0xf6, 0x7f, 0x2d, 0xc1, 0x0c, 0x9b, 0xb6,
-	0x6f, 0xad, 0xb0, 0x8f, 0xcc, 0x0a, 0xbb, 0xd3, 0xbd, 0xc2, 0x4e, 0x82, 0xbf, 0xff, 0x30, 0x97,
-	0xd9, 0xbb, 0x50, 0x56, 0xc6, 0xcf, 0xd2, 0xfb, 0xc1, 0xca, 0xf1, 0x7e, 0xe8, 0xcf, 0x7d, 0xc8,
-	0x77, 0xeb, 0x62, 0xe6, 0xbb, 0xf5, 0xdf, 0xb3, 0x20, 0xb1, 0x01, 0x45, 0x37, 0xa0, 0xdc, 0x0e,
-	0x98, 0x9d, 0x45, 0x28, 0x8d, 0x97, 0x1e, 0xcb, 0xbc, 0xa8, 0xf8, 0xa5, 0xc8, 0xc7, 0xaf, 0x2e,
-	0x6b, 0xe0, 0xa4, 0x32, 0x5a, 0x84, 0x91, 0x76, 0x48, 0x1a, 0x31, 0xf3, 0xf9, 0xed, 0x4b, 0x87,
-	0xaf, 0x11, 0x8e, 0x8f, 0x65, 0x45, 0xfb, 0xe7, 0x2d, 0x00, 0xfe, 0x34, 0xec, 0xf8, 0x5b, 0xe4,
-	0x14, 0xd4, 0xdd, 0x55, 0x28, 0x45, 0x6d, 0xd2, 0xec, 0x65, 0x01, 0x93, 0xf4, 0xa7, 0xd1, 0x26,
-	0xcd, 0x64, 0xc0, 0xe9, 0x3f, 0xcc, 0x6a, 0xdb, 0xdf, 0x07, 0x30, 0x99, 0xa0, 0xd5, 0x62, 0xb2,
-	0x8b, 0x9e, 0x33, 0x7c, 0x00, 0xcf, 0xa7, 0x7c, 0x00, 0xcb, 0x0c, 0x5b, 0xd3, 0xac, 0xbe, 0x0b,
-	0xc5, 0x5d, 0xe7, 0xbe, 0x50, 0x9d, 0x3d, 0xd3, 0xbb, 0x1b, 0x94, 0xfe, 0xfc, 0xaa, 0x73, 0x9f,
-	0x0b, 0x89, 0xcf, 0xc8, 0x05, 0xb2, 0xea, 0xdc, 0x3f, 0xe2, 0x76, 0x2e, 0xec, 0x90, 0xba, 0xe5,
-	0x46, 0xf1, 0x97, 0xff, 0x4b, 0xf2, 0x9f, 0x2d, 0x3b, 0xda, 0x08, 0x6b, 0xcb, 0xf5, 0xc5, 0x43,
-	0xe9, 0x40, 0x6d, 0xb9, 0x7e, 0xba, 0x2d, 0xd7, 0x1f, 0xa0, 0x2d, 0xd7, 0x47, 0xef, 0xc3, 0x88,
-	0x30, 0x4a, 0x60, 0xc6, 0xed, 0xa6, 0x5a, 0x2e, 0xaf, 0x3d, 0x61, 0xd3, 0xc0, 0xdb, 0xbc, 0x2a,
-	0x85, 0x60, 0x51, 0xda, 0xb7, 0x5d, 0xd9, 0x20, 0xfa, 0xdb, 0x16, 0x4c, 0x8a, 0xdf, 0x98, 0xbc,
-	0xd7, 0x21, 0x51, 0x2c, 0x78, 0xcf, 0x4f, 0x0f, 0xde, 0x07, 0x51, 0x91, 0x77, 0xe5, 0xd3, 0xf2,
-	0x98, 0x35, 0x81, 0x7d, 0x7b, 0x94, 0xea, 0x05, 0xfa, 0xa7, 0x16, 0x9c, 0xdd, 0x75, 0xee, 0xf3,
-	0x16, 0x79, 0x19, 0x76, 0x62, 0x37, 0x10, 0xc6, 0xfa, 0xaf, 0x0d, 0x36, 0xfd, 0x5d, 0xd5, 0x79,
-	0x27, 0xa5, 0x5d, 0xef, 0xd9, 0x2c, 0x94, 0xbe, 0x5d, 0xcd, 0xec, 0xd7, 0xdc, 0x26, 0x8c, 0xca,
-	0xf5, 0x96, 0xa1, 0x6a, 0xa8, 0xea, 0x8c, 0xf5, 0xb1, 0x6d, 0x42, 0x74, 0x47, 0x3c, 0xda, 0x8e,
-	0x58, 0x6b, 0x0f, 0xb5, 0x9d, 0x77, 0x61, 0x5c, 0x5f, 0x63, 0x0f, 0xb5, 0xad, 0xf7, 0xe0, 0x4c,
-	0xc6, 0x5a, 0x7a, 0xa8, 0x4d, 0xde, 0x83, 0xf3, 0xb9, 0xeb, 0xe3, 0x61, 0x36, 0x6c, 0xff, 0x9c,
-	0xa5, 0x9f, 0x83, 0xa7, 0xf0, 0xe6, 0xb0, 0x64, 0xbe, 0x39, 0x5c, 0xec, 0xbd, 0x73, 0x72, 0x1e,
-	0x1e, 0xde, 0xd1, 0x3b, 0x4d, 0x4f, 0x75, 0xf4, 0x06, 0x0c, 0x7b, 0xb4, 0x44, 0x5a, 0xc3, 0xd8,
-	0xfd, 0x77, 0x64, 0xc2, 0x4b, 0xb1, 0xf2, 0x08, 0x0b, 0x0a, 0xf6, 0x2f, 0x59, 0x50, 0x3a, 0x85,
-	0x91, 0xc0, 0xe6, 0x48, 0x3c, 0x97, 0x4b, 0x5a, 0xc4, 0x70, 0x9b, 0xc7, 0xce, 0xbd, 0xe5, 0xfb,
-	0x31, 0xf1, 0x23, 0x26, 0x2a, 0x66, 0x0e, 0xcc, 0x77, 0xc1, 0x99, 0x5b, 0x81, 0xd3, 0x5a, 0x74,
-	0x3c, 0xc7, 0x6f, 0x92, 0xb0, 0xe6, 0x6f, 0xf5, 0x35, 0xcb, 0xd2, 0x8d, 0xa8, 0x0a, 0xfd, 0x8c,
-	0xa8, 0xec, 0x6d, 0x40, 0x7a, 0x03, 0xc2, 0x70, 0x15, 0xc3, 0x88, 0xcb, 0x9b, 0x12, 0xc3, 0xff,
-	0x54, 0x36, 0x77, 0xd7, 0xd5, 0x33, 0xcd, 0x24, 0x93, 0x17, 0x60, 0x49, 0xc8, 0x7e, 0x05, 0x32,
-	0x9d, 0xd5, 0xfa, 0xab, 0x0d, 0xec, 0xcf, 0xc3, 0x0c, 0xab, 0x79, 0x4c, 0x91, 0xd6, 0x4e, 0x69,
-	0x25, 0x33, 0x62, 0x64, 0xd9, 0x5f, 0xb1, 0x60, 0x6a, 0x2d, 0x15, 0xb0, 0xe3, 0x32, 0x7b, 0x00,
-	0xcd, 0x50, 0x86, 0x37, 0x58, 0x29, 0x16, 0xd0, 0x13, 0xd7, 0x41, 0xfd, 0x99, 0x05, 0x89, 0xff,
-	0xe8, 0x29, 0x30, 0x5e, 0x4b, 0x06, 0xe3, 0x95, 0xa9, 0x1b, 0x51, 0xdd, 0xc9, 0xe3, 0xbb, 0xd0,
-	0x4d, 0x15, 0x2c, 0xa1, 0x87, 0x5a, 0x24, 0x21, 0xc3, 0x5d, 0xeb, 0x27, 0xcd, 0x88, 0x0a, 0x32,
-	0x7c, 0x02, 0xb3, 0x9d, 0x52, 0xb8, 0x1f, 0x11, 0xdb, 0x29, 0xd5, 0x9f, 0x9c, 0x1d, 0x5a, 0xd7,
-	0xba, 0xcc, 0x4e, 0xae, 0x6f, 0x67, 0xb6, 0xf0, 0x8e, 0xe7, 0xbe, 0x4f, 0x54, 0xc4, 0x97, 0x8a,
-	0xb0, 0x6d, 0x17, 0xa5, 0x47, 0x07, 0x95, 0x09, 0xf5, 0x8f, 0x87, 0x05, 0x4b, 0xaa, 0xd8, 0x37,
-	0x60, 0x2a, 0x35, 0x60, 0xe8, 0x25, 0x18, 0x6a, 0x6f, 0x3b, 0x11, 0x49, 0xd9, 0x8b, 0x0e, 0xd5,
-	0x69, 0xe1, 0xd1, 0x41, 0x65, 0x52, 0x55, 0x60, 0x25, 0x98, 0x63, 0xdb, 0xff, 0xd3, 0x82, 0xd2,
-	0x5a, 0xd0, 0x3a, 0x8d, 0xc5, 0xf4, 0xba, 0xb1, 0x98, 0x1e, 0xcf, 0x0b, 0xaa, 0x98, 0xbb, 0x8e,
-	0x56, 0x52, 0xeb, 0xe8, 0x62, 0x2e, 0x85, 0xde, 0x4b, 0x68, 0x17, 0xc6, 0x58, 0xa8, 0x46, 0x61,
-	0xbf, 0xfa, 0x82, 0x21, 0x03, 0x54, 0x52, 0x32, 0xc0, 0x94, 0x86, 0xaa, 0x49, 0x02, 0x4f, 0xc3,
-	0x88, 0xb0, 0xa1, 0x4c, 0x5b, 0xfd, 0x0b, 0x5c, 0x2c, 0xe1, 0xf6, 0x8f, 0x15, 0xc1, 0x08, 0x0d,
-	0x89, 0x7e, 0xc5, 0x82, 0xf9, 0x90, 0xbb, 0x51, 0xb6, 0xaa, 0x9d, 0xd0, 0xf5, 0xb7, 0x1a, 0xcd,
-	0x6d, 0xd2, 0xea, 0x78, 0xae, 0xbf, 0x55, 0xdb, 0xf2, 0x03, 0x55, 0xbc, 0x7c, 0x9f, 0x34, 0x3b,
-	0xec, 0x21, 0xa4, 0x4f, 0x1c, 0x4a, 0x65, 0xa3, 0x74, 0xed, 0xf0, 0xa0, 0x32, 0x8f, 0x8f, 0x45,
-	0x1b, 0x1f, 0xb3, 0x2f, 0xe8, 0x1b, 0x16, 0x5c, 0xe5, 0x11, 0x13, 0x07, 0xef, 0x7f, 0x0f, 0x89,
-	0xa9, 0x2e, 0x49, 0x25, 0x44, 0xd6, 0x49, 0xb8, 0xbb, 0xf8, 0xb2, 0x18, 0xd0, 0xab, 0xf5, 0xe3,
-	0xb5, 0x85, 0x8f, 0xdb, 0x39, 0xfb, 0xdf, 0x14, 0x61, 0x42, 0x78, 0xf0, 0x8b, 0xd0, 0x30, 0x2f,
-	0x19, 0x4b, 0xe2, 0x89, 0xd4, 0x92, 0x98, 0x31, 0x90, 0x4f, 0x26, 0x2a, 0x4c, 0x04, 0x33, 0x9e,
-	0x13, 0xc5, 0x37, 0x88, 0x13, 0xc6, 0x1b, 0xc4, 0xe1, 0xb6, 0x3b, 0xc5, 0x63, 0xdb, 0x19, 0x29,
-	0x15, 0xcd, 0xad, 0x34, 0x31, 0xdc, 0x4d, 0x1f, 0xed, 0x01, 0x62, 0x06, 0x48, 0xa1, 0xe3, 0x47,
-	0xfc, 0x5b, 0x5c, 0xf1, 0x66, 0x70, 0xbc, 0x56, 0xe7, 0x44, 0xab, 0xe8, 0x56, 0x17, 0x35, 0x9c,
-	0xd1, 0x82, 0x66, 0x58, 0x36, 0x34, 0xa8, 0x61, 0xd9, 0x70, 0x1f, 0xd7, 0x1a, 0x1f, 0xa6, 0xbb,
-	0x82, 0x30, 0xbc, 0x0d, 0x65, 0x65, 0x00, 0x28, 0x0e, 0x9d, 0xde, 0xb1, 0x4c, 0xd2, 0x14, 0xb8,
-	0x1a, 0x25, 0x31, 0x3e, 0x4d, 0xc8, 0xd9, 0xff, 0xac, 0x60, 0x34, 0xc8, 0x27, 0x71, 0x0d, 0x46,
-	0x9d, 0x28, 0x72, 0xb7, 0x7c, 0xd2, 0x12, 0x3b, 0xf6, 0xe3, 0x79, 0x3b, 0xd6, 0x68, 0x86, 0x19,
-	0x61, 0x2e, 0x88, 0x9a, 0x58, 0xd1, 0x40, 0x37, 0xb8, 0x85, 0xd4, 0x9e, 0xe4, 0xf9, 0x07, 0xa3,
-	0x06, 0xd2, 0x86, 0x6a, 0x8f, 0x60, 0x51, 0x1f, 0x7d, 0x81, 0x9b, 0xb0, 0xdd, 0xf4, 0x83, 0x7b,
-	0xfe, 0xf5, 0x20, 0x90, 0x6e, 0x77, 0x83, 0x11, 0x9c, 0x91, 0x86, 0x6b, 0xaa, 0x3a, 0x36, 0xa9,
-	0x0d, 0x16, 0xa8, 0xe8, 0xbb, 0xe1, 0x0c, 0x25, 0x6d, 0x3a, 0xcf, 0x44, 0x88, 0xc0, 0x94, 0x08,
-	0x0f, 0x21, 0xcb, 0xc4, 0xd8, 0x65, 0xb2, 0xf3, 0x66, 0xed, 0x44, 0xe9, 0x77, 0xd3, 0x24, 0x81,
-	0xd3, 0x34, 0xed, 0x9f, 0xb4, 0x80, 0x99, 0xfd, 0x9f, 0x02, 0xcb, 0xf0, 0x59, 0x93, 0x65, 0x98,
-	0xcd, 0x1b, 0xe4, 0x1c, 0x6e, 0xe1, 0x45, 0xbe, 0xb2, 0xea, 0x61, 0x70, 0x7f, 0x5f, 0x98, 0x0f,
-	0xf4, 0xe7, 0x64, 0xed, 0xff, 0x6b, 0xf1, 0x43, 0x4c, 0x79, 0xe2, 0xa3, 0xef, 0x81, 0xd1, 0xa6,
-	0xd3, 0x76, 0x9a, 0x3c, 0x8e, 0x71, 0xae, 0x56, 0xc7, 0xa8, 0x34, 0xbf, 0x24, 0x6a, 0x70, 0x2d,
-	0x85, 0x0c, 0x33, 0x32, 0x2a, 0x8b, 0xfb, 0x6a, 0x26, 0x54, 0x93, 0x73, 0x3b, 0x30, 0x61, 0x10,
-	0x7b, 0xa8, 0x22, 0xed, 0xf7, 0xf0, 0x2b, 0x56, 0x85, 0xc5, 0xd9, 0x85, 0x19, 0x5f, 0xfb, 0x4f,
-	0x2f, 0x14, 0x29, 0xa6, 0x7c, 0xbc, 0xdf, 0x25, 0xca, 0x6e, 0x1f, 0xcd, 0xad, 0x21, 0x45, 0x06,
-	0x77, 0x53, 0xb6, 0x7f, 0xdc, 0x82, 0x47, 0x75, 0x44, 0x2d, 0x48, 0x42, 0x3f, 0x3d, 0x71, 0x15,
-	0x46, 0x83, 0x36, 0x09, 0x9d, 0x38, 0x08, 0xc5, 0xad, 0x71, 0x45, 0x0e, 0xfa, 0x6d, 0x51, 0x7e,
-	0x24, 0x02, 0x4a, 0x4a, 0xea, 0xb2, 0x1c, 0xab, 0x9a, 0x54, 0x8e, 0x61, 0x83, 0x11, 0x89, 0x00,
-	0x16, 0xec, 0x0c, 0x60, 0x4f, 0xa6, 0x11, 0x16, 0x10, 0xfb, 0x0f, 0x2c, 0xbe, 0xb0, 0xf4, 0xae,
-	0xa3, 0xf7, 0x60, 0x7a, 0xd7, 0x89, 0x9b, 0xdb, 0xcb, 0xf7, 0xdb, 0x21, 0x57, 0x8f, 0xcb, 0x71,
-	0x7a, 0xa6, 0xdf, 0x38, 0x69, 0x1f, 0x99, 0x58, 0xe5, 0xad, 0xa6, 0x88, 0xe1, 0x2e, 0xf2, 0x68,
-	0x03, 0xc6, 0x58, 0x19, 0x33, 0xff, 0x8e, 0x7a, 0xb1, 0x06, 0x79, 0xad, 0xa9, 0x57, 0xe7, 0xd5,
-	0x84, 0x0e, 0xd6, 0x89, 0xda, 0x5f, 0x2e, 0xf2, 0xdd, 0xce, 0xb8, 0xed, 0xa7, 0x61, 0xa4, 0x1d,
-	0xb4, 0x96, 0x6a, 0x55, 0x2c, 0x66, 0x41, 0x5d, 0x23, 0x75, 0x5e, 0x8c, 0x25, 0x1c, 0xbd, 0x0a,
-	0x40, 0xee, 0xc7, 0x24, 0xf4, 0x1d, 0x4f, 0x59, 0xc9, 0x28, 0xbb, 0xd0, 0x6a, 0xb0, 0x16, 0xc4,
-	0x77, 0x22, 0xf2, 0x5d, 0xcb, 0x0a, 0x05, 0x6b, 0xe8, 0xe8, 0x1a, 0x40, 0x3b, 0x0c, 0xf6, 0xdc,
-	0x16, 0xf3, 0x27, 0x2c, 0x9a, 0x36, 0x24, 0x75, 0x05, 0xc1, 0x1a, 0x16, 0x7a, 0x15, 0x26, 0x3a,
-	0x7e, 0xc4, 0x39, 0x14, 0x67, 0x43, 0x84, 0x63, 0x1c, 0x4d, 0xac, 0x1b, 0xee, 0xe8, 0x40, 0x6c,
-	0xe2, 0xa2, 0x05, 0x18, 0x8e, 0x1d, 0x66, 0x13, 0x31, 0x94, 0x6f, 0xcc, 0xb9, 0x4e, 0x31, 0xf4,
-	0x28, 0xba, 0xb4, 0x02, 0x16, 0x15, 0xd1, 0xdb, 0xd2, 0x39, 0x83, 0x9f, 0xf5, 0xc2, 0x8a, 0x7a,
-	0xb0, 0x7b, 0x41, 0x73, 0xcd, 0x10, 0xd6, 0xd9, 0x06, 0x2d, 0xfb, 0x1b, 0x65, 0x80, 0x84, 0x1d,
-	0x47, 0xef, 0x77, 0x9d, 0x47, 0xcf, 0xf6, 0x66, 0xe0, 0x4f, 0xee, 0x30, 0x42, 0xdf, 0x6f, 0xc1,
-	0x98, 0xe3, 0x79, 0x41, 0xd3, 0x89, 0xd9, 0x28, 0x17, 0x7a, 0x9f, 0x87, 0xa2, 0xfd, 0x85, 0xa4,
-	0x06, 0xef, 0xc2, 0x0b, 0x72, 0xe1, 0x69, 0x90, 0xbe, 0xbd, 0xd0, 0x1b, 0x46, 0x9f, 0x92, 0x52,
-	0x1a, 0x5f, 0x1e, 0x73, 0x69, 0x29, 0xad, 0xcc, 0x8e, 0x7e, 0x4d, 0x40, 0x43, 0x77, 0x8c, 0x48,
-	0x7b, 0xa5, 0xfc, 0xa0, 0x13, 0x06, 0x57, 0xda, 0x2f, 0xc8, 0x1e, 0xaa, 0xeb, 0xde, 0x64, 0x43,
-	0xf9, 0x91, 0x59, 0x34, 0xf1, 0xa7, 0x8f, 0x27, 0xd9, 0xbb, 0x30, 0xd5, 0x32, 0xef, 0x76, 0xb1,
-	0x9a, 0x9e, 0xca, 0xa3, 0x9b, 0x62, 0x05, 0x92, 0xdb, 0x3c, 0x05, 0xc0, 0x69, 0xc2, 0xa8, 0xce,
-	0xfd, 0xfa, 0x6a, 0xfe, 0x66, 0x20, 0xac, 0xf1, 0xed, 0xdc, 0xb9, 0xdc, 0x8f, 0x62, 0xb2, 0x4b,
-	0x31, 0x93, 0x4b, 0x7b, 0x4d, 0xd4, 0xc5, 0x8a, 0x0a, 0x7a, 0x03, 0x86, 0x99, 0x63, 0x70, 0x34,
-	0x3b, 0x9a, 0xaf, 0x4c, 0x34, 0x63, 0x5a, 0x24, 0x9b, 0x8a, 0xfd, 0x8d, 0xb0, 0xa0, 0x80, 0x6e,
-	0xc8, 0xc0, 0x37, 0x51, 0xcd, 0xbf, 0x13, 0x11, 0x16, 0xf8, 0xa6, 0xbc, 0xf8, 0xf1, 0x24, 0xa6,
-	0x0d, 0x2f, 0xcf, 0x8c, 0x97, 0x6f, 0xd4, 0xa4, 0xcc, 0x91, 0xf8, 0x2f, 0xc3, 0xf0, 0xcf, 0x42,
-	0x7e, 0xf7, 0xcc, 0x50, 0xfd, 0xc9, 0x70, 0xde, 0x35, 0x49, 0xe0, 0x34, 0x4d, 0xca, 0x68, 0xf2,
-	0x9d, 0x2b, 0xec, 0xf9, 0xfb, 0xed, 0x7f, 0x2e, 0x5f, 0xb3, 0x4b, 0x86, 0x97, 0x60, 0x51, 0xff,
-	0x54, 0x6f, 0xfd, 0x39, 0x1f, 0xa6, 0xd3, 0x5b, 0xf4, 0xa1, 0x72, 0x19, 0xbf, 0x5f, 0x82, 0x49,
-	0x73, 0x49, 0xa1, 0xab, 0x50, 0x16, 0x44, 0x54, 0x14, 0x56, 0xb5, 0x4b, 0x56, 0x25, 0x00, 0x27,
-	0x38, 0x2c, 0xf8, 0x2e, 0xab, 0xae, 0xd9, 0x61, 0x26, 0xc1, 0x77, 0x15, 0x04, 0x6b, 0x58, 0x54,
-	0x5e, 0xda, 0x08, 0x82, 0x58, 0x5d, 0x2a, 0x6a, 0xdd, 0x2d, 0xb2, 0x52, 0x2c, 0xa0, 0xf4, 0x32,
-	0xd9, 0x21, 0xa1, 0x4f, 0x3c, 0x33, 0xb8, 0x9b, 0xba, 0x4c, 0x6e, 0xea, 0x40, 0x6c, 0xe2, 0xd2,
-	0x5b, 0x32, 0x88, 0xd8, 0x42, 0x16, 0x52, 0x59, 0x62, 0xd7, 0xda, 0xe0, 0x2e, 0xf6, 0x12, 0x8e,
-	0x3e, 0x0f, 0x8f, 0x2a, 0x8f, 0x78, 0xcc, 0x15, 0xd5, 0xb2, 0xc5, 0x61, 0x43, 0x89, 0xf2, 0xe8,
-	0x52, 0x36, 0x1a, 0xce, 0xab, 0x8f, 0x5e, 0x87, 0x49, 0xc1, 0xb9, 0x4b, 0x8a, 0x23, 0xa6, 0xed,
-	0xc4, 0x4d, 0x03, 0x8a, 0x53, 0xd8, 0x32, 0x3c, 0x1d, 0x63, 0x9e, 0x25, 0x85, 0xd1, 0xee, 0xf0,
-	0x74, 0x3a, 0x1c, 0x77, 0xd5, 0x40, 0x0b, 0x30, 0xc5, 0x59, 0x2b, 0xd7, 0xdf, 0xe2, 0x73, 0x22,
-	0xdc, 0x6d, 0xd4, 0x96, 0xba, 0x6d, 0x82, 0x71, 0x1a, 0x1f, 0xbd, 0x02, 0xe3, 0x4e, 0xd8, 0xdc,
-	0x76, 0x63, 0xd2, 0x8c, 0x3b, 0x21, 0xf7, 0xc3, 0xd1, 0x8c, 0x4f, 0x16, 0x34, 0x18, 0x36, 0x30,
-	0xed, 0xf7, 0xe1, 0x4c, 0x86, 0xa7, 0x1e, 0x5d, 0x38, 0x4e, 0xdb, 0x95, 0xdf, 0x94, 0xb2, 0x50,
-	0x5d, 0xa8, 0xd7, 0xe4, 0xd7, 0x68, 0x58, 0x74, 0x75, 0x32, 0x8f, 0x3e, 0x2d, 0xeb, 0x86, 0x5a,
-	0x9d, 0x2b, 0x12, 0x80, 0x13, 0x1c, 0xfb, 0x7f, 0x15, 0x60, 0x2a, 0x43, 0xf9, 0xce, 0x32, 0x3f,
-	0xa4, 0x64, 0x8f, 0x24, 0xd1, 0x83, 0x19, 0xed, 0xb0, 0x70, 0x8c, 0x68, 0x87, 0xc5, 0x7e, 0xd1,
-	0x0e, 0x4b, 0x1f, 0x24, 0xda, 0xa1, 0x39, 0x62, 0x43, 0x03, 0x8d, 0x58, 0x46, 0x84, 0xc4, 0xe1,
-	0x63, 0x46, 0x48, 0x34, 0x06, 0x7d, 0x64, 0x80, 0x41, 0xff, 0x5a, 0x01, 0xa6, 0xd3, 0x46, 0x72,
-	0xa7, 0xa0, 0x8e, 0x7d, 0xc3, 0x50, 0xc7, 0x66, 0xe7, 0x51, 0x49, 0x9b, 0xee, 0xe5, 0xa9, 0x66,
-	0x71, 0x4a, 0x35, 0xfb, 0xc9, 0x81, 0xa8, 0xf5, 0x56, 0xd3, 0xfe, 0x83, 0x02, 0x9c, 0x4b, 0x57,
-	0x59, 0xf2, 0x1c, 0x77, 0xf7, 0x14, 0xc6, 0xe6, 0xb6, 0x31, 0x36, 0xcf, 0x0d, 0xf2, 0x35, 0xac,
-	0x6b, 0xb9, 0x03, 0xf4, 0x56, 0x6a, 0x80, 0xae, 0x0e, 0x4e, 0xb2, 0xf7, 0x28, 0x7d, 0xb3, 0x08,
-	0x17, 0x33, 0xeb, 0x25, 0xda, 0xcc, 0x15, 0x43, 0x9b, 0x79, 0x2d, 0xa5, 0xcd, 0xb4, 0x7b, 0xd7,
-	0x3e, 0x19, 0xf5, 0xa6, 0x70, 0xa1, 0x64, 0x11, 0xf1, 0x1e, 0x50, 0xb5, 0x69, 0xb8, 0x50, 0x2a,
-	0x42, 0xd8, 0xa4, 0xfb, 0x17, 0x49, 0xa5, 0xf9, 0xef, 0x2c, 0x38, 0x9f, 0x39, 0x37, 0xa7, 0xa0,
-	0xc2, 0x5a, 0x33, 0x55, 0x58, 0x4f, 0x0f, 0xbc, 0x5a, 0x73, 0x74, 0x5a, 0xbf, 0x51, 0xca, 0xf9,
-	0x16, 0x26, 0xa0, 0xdf, 0x86, 0x31, 0xa7, 0xd9, 0x24, 0x51, 0xb4, 0x1a, 0xb4, 0x54, 0x84, 0xb8,
-	0xe7, 0x98, 0x9c, 0x95, 0x14, 0x1f, 0x1d, 0x54, 0xe6, 0xd2, 0x24, 0x12, 0x30, 0xd6, 0x29, 0x98,
-	0x41, 0x2d, 0x0b, 0x27, 0x1a, 0xd4, 0xf2, 0x1a, 0xc0, 0x9e, 0xe2, 0xd6, 0xd3, 0x42, 0xbe, 0xc6,
-	0xc7, 0x6b, 0x58, 0xe8, 0x0b, 0x30, 0x1a, 0x89, 0x6b, 0x5c, 0x2c, 0xc5, 0x17, 0x06, 0x9c, 0x2b,
-	0x67, 0x83, 0x78, 0xa6, 0xaf, 0xbe, 0xd2, 0x87, 0x28, 0x92, 0xe8, 0x3b, 0x60, 0x3a, 0xe2, 0xa1,
-	0x60, 0x96, 0x3c, 0x27, 0x62, 0x7e, 0x10, 0x62, 0x15, 0x32, 0x07, 0xfc, 0x46, 0x0a, 0x86, 0xbb,
-	0xb0, 0xd1, 0x8a, 0xfc, 0x28, 0x16, 0xb7, 0x86, 0x2f, 0xcc, 0xcb, 0xc9, 0x07, 0x89, 0xbc, 0x53,
-	0x67, 0xd3, 0xc3, 0xcf, 0x06, 0x5e, 0xab, 0x89, 0xbe, 0x00, 0x40, 0x97, 0x8f, 0xd0, 0x25, 0x8c,
-	0xe4, 0x1f, 0x9e, 0xf4, 0x54, 0x69, 0x65, 0x5a, 0x7e, 0x32, 0xe7, 0xc5, 0xaa, 0x22, 0x82, 0x35,
-	0x82, 0xf6, 0xd7, 0x4a, 0xf0, 0x58, 0x8f, 0x33, 0x12, 0x2d, 0x98, 0x4f, 0xa0, 0xcf, 0xa4, 0x85,
-	0xeb, 0xb9, 0xcc, 0xca, 0x86, 0xb4, 0x9d, 0x5a, 0x8a, 0x85, 0x0f, 0xbc, 0x14, 0x7f, 0xc0, 0xd2,
-	0xd4, 0x1e, 0xdc, 0x98, 0xef, 0xb3, 0xc7, 0x3c, 0xfb, 0x4f, 0x50, 0x0f, 0xb2, 0x99, 0xa1, 0x4c,
-	0xb8, 0x36, 0x70, 0x77, 0x06, 0xd6, 0x2e, 0x9c, 0xae, 0xf2, 0xf7, 0xcb, 0x16, 0x3c, 0x91, 0xd9,
-	0x5f, 0xc3, 0x64, 0xe3, 0x2a, 0x94, 0x9b, 0xb4, 0x50, 0xf3, 0x55, 0x4b, 0x9c, 0x78, 0x25, 0x00,
-	0x27, 0x38, 0x86, 0x65, 0x46, 0xa1, 0xaf, 0x65, 0xc6, 0xbf, 0xb6, 0xa0, 0x6b, 0x7f, 0x9c, 0xc2,
-	0x41, 0x5d, 0x33, 0x0f, 0xea, 0x8f, 0x0f, 0x32, 0x97, 0x39, 0x67, 0xf4, 0x1f, 0x4d, 0xc1, 0x23,
-	0x39, 0xbe, 0x1a, 0x7b, 0x30, 0xb3, 0xd5, 0x24, 0xa6, 0x17, 0xa0, 0xf8, 0x98, 0x4c, 0x87, 0xc9,
-	0x9e, 0x2e, 0x83, 0x2c, 0x1f, 0xd1, 0x4c, 0x17, 0x0a, 0xee, 0x6e, 0x02, 0x7d, 0xd9, 0x82, 0xb3,
-	0xce, 0xbd, 0xa8, 0x2b, 0xeb, 0xa4, 0x58, 0x33, 0x2f, 0x66, 0x2a, 0x41, 0xfa, 0x64, 0xa9, 0xe4,
-	0x09, 0x9a, 0xb2, 0xb0, 0x70, 0x66, 0x5b, 0x08, 0x8b, 0x98, 0xa1, 0x94, 0x9d, 0xef, 0xe1, 0xa7,
-	0x9a, 0xe5, 0x54, 0xc3, 0x8f, 0x6c, 0x09, 0xc1, 0x8a, 0x0e, 0xfa, 0x12, 0x94, 0xb7, 0xa4, 0xa7,
-	0x5b, 0xc6, 0x95, 0x90, 0x0c, 0x64, 0x6f, 0xff, 0x3f, 0xfe, 0x40, 0xa9, 0x90, 0x70, 0x42, 0x14,
-	0xbd, 0x0e, 0x45, 0x7f, 0x33, 0xea, 0x95, 0xe3, 0x28, 0x65, 0xd3, 0xc4, 0xbd, 0xc1, 0xd7, 0x56,
-	0x1a, 0x98, 0x56, 0x44, 0x37, 0xa0, 0x18, 0x6e, 0xb4, 0x84, 0x06, 0x2f, 0xf3, 0x0c, 0xc7, 0x8b,
-	0xd5, 0x9c, 0x5e, 0x31, 0x4a, 0x78, 0xb1, 0x8a, 0x29, 0x09, 0x54, 0x87, 0x21, 0xe6, 0xe0, 0x20,
-	0xee, 0x83, 0x4c, 0xce, 0xb7, 0x87, 0xa3, 0x10, 0x77, 0x19, 0x67, 0x08, 0x98, 0x13, 0x42, 0xeb,
-	0x30, 0xdc, 0x64, 0xf9, 0x70, 0x44, 0xc0, 0xea, 0x4f, 0x65, 0xea, 0xea, 0x7a, 0x24, 0x0a, 0x12,
-	0xaa, 0x2b, 0x86, 0x81, 0x05, 0x2d, 0x46, 0x95, 0xb4, 0xb7, 0x37, 0x23, 0x26, 0xeb, 0xe7, 0x51,
-	0xed, 0x91, 0xff, 0x4a, 0x50, 0x65, 0x18, 0x58, 0xd0, 0x42, 0x9f, 0x81, 0xc2, 0x66, 0x53, 0xf8,
-	0x3f, 0x64, 0x2a, 0xed, 0x4c, 0x87, 0xfe, 0xc5, 0xe1, 0xc3, 0x83, 0x4a, 0x61, 0x65, 0x09, 0x17,
-	0x36, 0x9b, 0x68, 0x0d, 0x46, 0x36, 0xb9, 0x0b, 0xb0, 0xd0, 0xcb, 0x3d, 0x95, 0xed, 0x9d, 0xdc,
-	0xe5, 0x25, 0xcc, 0xed, 0xf6, 0x05, 0x00, 0x4b, 0x22, 0x2c, 0x04, 0xa7, 0x72, 0x65, 0x16, 0xb1,
-	0xa8, 0xe7, 0x8f, 0xe7, 0x7e, 0xce, 0xef, 0xe7, 0xc4, 0x21, 0x1a, 0x6b, 0x14, 0xe9, 0xaa, 0x76,
-	0x64, 0xe6, 0x43, 0x11, 0xab, 0x23, 0x73, 0x55, 0xf7, 0x49, 0x0a, 0xc9, 0x57, 0xb5, 0x42, 0xc2,
-	0x09, 0x51, 0xb4, 0x03, 0x13, 0x7b, 0x51, 0x7b, 0x9b, 0xc8, 0x2d, 0xcd, 0x42, 0x77, 0xe4, 0x5c,
-	0x61, 0x77, 0x05, 0xa2, 0x1b, 0xc6, 0x1d, 0xc7, 0xeb, 0x3a, 0x85, 0xd8, 0xab, 0xf6, 0x5d, 0x9d,
-	0x18, 0x36, 0x69, 0xd3, 0xe1, 0x7f, 0xaf, 0x13, 0x6c, 0xec, 0xc7, 0x44, 0x04, 0xaf, 0xce, 0x1c,
-	0xfe, 0x37, 0x39, 0x4a, 0xf7, 0xf0, 0x0b, 0x00, 0x96, 0x44, 0xd0, 0x5d, 0x31, 0x3c, 0xec, 0xf4,
-	0x9c, 0xce, 0x0f, 0xa6, 0x94, 0x99, 0x7a, 0x54, 0x1b, 0x14, 0x76, 0x5a, 0x26, 0xa4, 0xd8, 0x29,
-	0xd9, 0xde, 0x0e, 0xe2, 0xc0, 0x4f, 0x9d, 0xd0, 0x33, 0xf9, 0xa7, 0x64, 0x3d, 0x03, 0xbf, 0xfb,
-	0x94, 0xcc, 0xc2, 0xc2, 0x99, 0x6d, 0xa1, 0x16, 0x4c, 0xb6, 0x83, 0x30, 0xbe, 0x17, 0x84, 0x72,
-	0x7d, 0xa1, 0x1e, 0x7a, 0x05, 0x03, 0x53, 0xb4, 0xc8, 0x82, 0xa9, 0x9b, 0x10, 0x9c, 0xa2, 0x89,
-	0x3e, 0x07, 0x23, 0x51, 0xd3, 0xf1, 0x48, 0xed, 0xf6, 0xec, 0x99, 0xfc, 0xeb, 0xa7, 0xc1, 0x51,
-	0x72, 0x56, 0x17, 0x9b, 0x1c, 0x81, 0x82, 0x25, 0x39, 0xb4, 0x02, 0x43, 0x2c, 0x23, 0x02, 0x8b,
-	0xbb, 0x9d, 0x13, 0x13, 0xaa, 0xcb, 0xc2, 0x94, 0x9f, 0x4d, 0xac, 0x18, 0xf3, 0xea, 0x74, 0x0f,
-	0x08, 0xf6, 0x3a, 0x88, 0x66, 0xcf, 0xe5, 0xef, 0x01, 0xc1, 0x95, 0xdf, 0x6e, 0xf4, 0xda, 0x03,
-	0x0a, 0x09, 0x27, 0x44, 0xe9, 0xc9, 0x4c, 0x4f, 0xd3, 0x47, 0x7a, 0x18, 0xb4, 0xe4, 0x9e, 0xa5,
-	0xec, 0x64, 0xa6, 0x27, 0x29, 0x25, 0x61, 0xff, 0xee, 0x48, 0x37, 0xcf, 0xc2, 0x04, 0xb2, 0xbf,
-	0x6a, 0x75, 0xbd, 0xd5, 0x7d, 0x7a, 0x50, 0xfd, 0xd0, 0x09, 0x72, 0xab, 0x5f, 0xb6, 0xe0, 0x91,
-	0x76, 0xe6, 0x87, 0x08, 0x06, 0x60, 0x30, 0x35, 0x13, 0xff, 0x74, 0x15, 0x1b, 0x3f, 0x1b, 0x8e,
-	0x73, 0x5a, 0x4a, 0x4b, 0x04, 0xc5, 0x0f, 0x2c, 0x11, 0xac, 0xc2, 0x28, 0x63, 0x32, 0xfb, 0xe4,
-	0x87, 0x4b, 0x0b, 0x46, 0x8c, 0x95, 0x58, 0x12, 0x15, 0xb1, 0x22, 0x81, 0x7e, 0xd0, 0x82, 0x0b,
-	0xe9, 0xae, 0x63, 0xc2, 0xc0, 0x22, 0x92, 0x3c, 0x97, 0x05, 0x57, 0xc4, 0xf7, 0x5f, 0xa8, 0xf7,
-	0x42, 0x3e, 0xea, 0x87, 0x80, 0x7b, 0x37, 0x86, 0xaa, 0x19, 0xc2, 0xe8, 0xb0, 0xa9, 0x80, 0x1f,
-	0x40, 0x20, 0x7d, 0x11, 0xc6, 0x77, 0x83, 0x8e, 0x1f, 0x0b, 0xfb, 0x17, 0xe1, 0xb1, 0xc8, 0x1e,
-	0x9c, 0x57, 0xb5, 0x72, 0x6c, 0x60, 0xa5, 0xc4, 0xd8, 0xd1, 0x07, 0x16, 0x63, 0xdf, 0x49, 0x65,
-	0x01, 0x2f, 0xe7, 0x47, 0x2c, 0x14, 0x12, 0xff, 0x31, 0x72, 0x81, 0x9f, 0xae, 0x6c, 0xf4, 0xd3,
-	0x56, 0x06, 0x53, 0xcf, 0xa5, 0xe5, 0xd7, 0x4c, 0x69, 0xf9, 0x72, 0x5a, 0x5a, 0xee, 0x52, 0xbe,
-	0x1a, 0x82, 0xf2, 0xe0, 0x61, 0xaf, 0x07, 0x8d, 0x23, 0x67, 0x7b, 0x70, 0xa9, 0xdf, 0xb5, 0xc4,
-	0x0c, 0xa1, 0x5a, 0xea, 0xa9, 0x2d, 0x31, 0x84, 0x6a, 0xd5, 0xaa, 0x98, 0x41, 0x06, 0x0d, 0x34,
-	0x62, 0xff, 0x0f, 0x0b, 0x8a, 0xf5, 0xa0, 0x75, 0x0a, 0xca, 0xe4, 0xcf, 0x1a, 0xca, 0xe4, 0xc7,
-	0x72, 0xb2, 0xb3, 0xe7, 0xaa, 0x8e, 0x97, 0x53, 0xaa, 0xe3, 0x0b, 0x79, 0x04, 0x7a, 0x2b, 0x8a,
-	0x7f, 0xa2, 0x08, 0x7a, 0x2e, 0x79, 0xf4, 0x1b, 0x0f, 0x62, 0x85, 0x5c, 0xec, 0x95, 0x5e, 0x5e,
-	0x50, 0x66, 0xf6, 0x53, 0xd2, 0x09, 0xef, 0xcf, 0x99, 0x31, 0xf2, 0x5b, 0xc4, 0xdd, 0xda, 0x8e,
-	0x49, 0x2b, 0xfd, 0x39, 0xa7, 0x67, 0x8c, 0xfc, 0xdf, 0x2c, 0x98, 0x4a, 0xb5, 0x8e, 0x3c, 0x98,
-	0xf0, 0x74, 0x4d, 0xa0, 0x58, 0xa7, 0x0f, 0xa4, 0x44, 0x14, 0xc6, 0x9c, 0x5a, 0x11, 0x36, 0x89,
-	0xa3, 0x79, 0x00, 0xf5, 0x52, 0x27, 0x35, 0x60, 0x8c, 0xeb, 0x57, 0x4f, 0x79, 0x11, 0xd6, 0x30,
-	0xd0, 0x4b, 0x30, 0x16, 0x07, 0xed, 0xc0, 0x0b, 0xb6, 0xf6, 0x6f, 0x12, 0x19, 0xda, 0x46, 0x99,
-	0x68, 0xad, 0x27, 0x20, 0xac, 0xe3, 0xd9, 0x3f, 0x55, 0xe4, 0x1f, 0xea, 0xc7, 0xee, 0xb7, 0xd6,
-	0xe4, 0x47, 0x7b, 0x4d, 0x7e, 0xd3, 0x82, 0x69, 0xda, 0x3a, 0x33, 0x17, 0x91, 0x97, 0xad, 0x4a,
-	0xbf, 0x63, 0xf5, 0x48, 0xbf, 0x73, 0x99, 0x9e, 0x5d, 0xad, 0xa0, 0x13, 0x0b, 0x0d, 0x9a, 0x76,
-	0x38, 0xd1, 0x52, 0x2c, 0xa0, 0x02, 0x8f, 0x84, 0xa1, 0xf0, 0x81, 0xd2, 0xf1, 0x48, 0x18, 0x62,
-	0x01, 0x95, 0xd9, 0x79, 0x4a, 0x39, 0xd9, 0x79, 0x58, 0xa0, 0x3e, 0x61, 0x58, 0x20, 0xd8, 0x1e,
-	0x2d, 0x50, 0x9f, 0xb4, 0x38, 0x48, 0x70, 0xec, 0x9f, 0x2b, 0xc2, 0x78, 0x3d, 0x68, 0x25, 0x6f,
-	0x65, 0x2f, 0x1a, 0x6f, 0x65, 0x97, 0x52, 0x6f, 0x65, 0xd3, 0x3a, 0xee, 0xb7, 0x5e, 0xc6, 0x3e,
-	0xac, 0x97, 0xb1, 0x7f, 0x65, 0xb1, 0x59, 0xab, 0xae, 0x35, 0x44, 0x76, 0xe0, 0xe7, 0x61, 0x8c,
-	0x1d, 0x48, 0xcc, 0xe9, 0x4e, 0x3e, 0x20, 0xb1, 0xc0, 0xfb, 0x6b, 0x49, 0x31, 0xd6, 0x71, 0xd0,
-	0x15, 0x18, 0x8d, 0x88, 0x13, 0x36, 0xb7, 0xd5, 0x19, 0x27, 0x9e, 0x57, 0x78, 0x19, 0x56, 0x50,
-	0xf4, 0x66, 0x12, 0x23, 0xae, 0x98, 0x9f, 0xe7, 0x56, 0xef, 0x0f, 0xdf, 0x22, 0xf9, 0x81, 0xe1,
-	0xec, 0xb7, 0x00, 0x75, 0xe3, 0x0f, 0x10, 0x1c, 0xa9, 0x62, 0x06, 0x47, 0x2a, 0x77, 0x05, 0x46,
-	0xfa, 0x53, 0x0b, 0x26, 0xeb, 0x41, 0x8b, 0x6e, 0xdd, 0xbf, 0x48, 0xfb, 0x54, 0x0f, 0x90, 0x39,
-	0xdc, 0x23, 0x40, 0xe6, 0x3f, 0xb4, 0x60, 0xa4, 0x1e, 0xb4, 0x4e, 0x41, 0xef, 0xfe, 0x9a, 0xa9,
-	0x77, 0x7f, 0x34, 0x67, 0x49, 0xe4, 0xa8, 0xda, 0x7f, 0xa1, 0x08, 0x13, 0xb4, 0x9f, 0xc1, 0x96,
-	0x9c, 0x25, 0x63, 0x44, 0xac, 0x01, 0x46, 0x84, 0xb2, 0xb9, 0x81, 0xe7, 0x05, 0xf7, 0xd2, 0x33,
-	0xb6, 0xc2, 0x4a, 0xb1, 0x80, 0xa2, 0x67, 0x61, 0xb4, 0x1d, 0x92, 0x3d, 0x37, 0x10, 0xfc, 0xa3,
-	0xf6, 0x8a, 0x51, 0x17, 0xe5, 0x58, 0x61, 0x50, 0xb9, 0x2b, 0x72, 0xfd, 0x26, 0x91, 0x49, 0xb6,
-	0x4b, 0x2c, 0x0f, 0x17, 0x8f, 0x7c, 0xad, 0x95, 0x63, 0x03, 0x0b, 0xbd, 0x05, 0x65, 0xf6, 0x9f,
-	0x9d, 0x28, 0xc7, 0xcf, 0x1b, 0x24, 0xd2, 0x4d, 0x08, 0x02, 0x38, 0xa1, 0x85, 0xae, 0x01, 0xc4,
-	0x32, 0x3a, 0x72, 0x24, 0x62, 0xdc, 0x28, 0x5e, 0x5b, 0xc5, 0x4d, 0x8e, 0xb0, 0x86, 0x85, 0x9e,
-	0x81, 0x72, 0xec, 0xb8, 0xde, 0x2d, 0xd7, 0x27, 0x11, 0x53, 0x39, 0x17, 0x65, 0x36, 0x09, 0x51,
-	0x88, 0x13, 0x38, 0xe5, 0x75, 0x98, 0x03, 0x38, 0xcf, 0x3a, 0x36, 0xca, 0xb0, 0x19, 0xaf, 0x73,
-	0x4b, 0x95, 0x62, 0x0d, 0xc3, 0x7e, 0x05, 0xce, 0xd5, 0x83, 0x56, 0x3d, 0x08, 0xe3, 0x95, 0x20,
-	0xbc, 0xe7, 0x84, 0x2d, 0x39, 0x7f, 0x15, 0x99, 0xd8, 0x80, 0x9e, 0x3d, 0x43, 0x7c, 0x67, 0x1a,
-	0x29, 0x0b, 0x5e, 0x60, 0xdc, 0xce, 0x31, 0x9d, 0x3a, 0x9a, 0xec, 0xde, 0x55, 0x09, 0x06, 0xaf,
-	0x3b, 0x31, 0x41, 0xb7, 0x59, 0x52, 0xb2, 0xe4, 0x0a, 0x12, 0xd5, 0x9f, 0xd6, 0x92, 0x92, 0x25,
-	0xc0, 0xcc, 0x3b, 0xcb, 0xac, 0x6f, 0xff, 0x6a, 0x91, 0x9d, 0x46, 0xa9, 0x7c, 0x7b, 0xe8, 0x8b,
-	0x30, 0x19, 0x91, 0x5b, 0xae, 0xdf, 0xb9, 0x2f, 0x85, 0xf0, 0x1e, 0x6e, 0x39, 0x8d, 0x65, 0x1d,
-	0x93, 0xab, 0xf2, 0xcc, 0x32, 0x9c, 0xa2, 0x46, 0xe7, 0x29, 0xec, 0xf8, 0x0b, 0xd1, 0x9d, 0x88,
-	0x84, 0x22, 0xdf, 0x1b, 0x9b, 0x27, 0x2c, 0x0b, 0x71, 0x02, 0xa7, 0xeb, 0x92, 0xfd, 0x59, 0x0b,
-	0x7c, 0x1c, 0x04, 0xb1, 0x5c, 0xc9, 0x2c, 0x63, 0x90, 0x56, 0x8e, 0x0d, 0x2c, 0xb4, 0x02, 0x28,
-	0xea, 0xb4, 0xdb, 0x1e, 0x7b, 0xd8, 0x77, 0xbc, 0xeb, 0x61, 0xd0, 0x69, 0xf3, 0x57, 0xcf, 0x22,
-	0x0f, 0x4c, 0xd8, 0xe8, 0x82, 0xe2, 0x8c, 0x1a, 0xf4, 0xf4, 0xd9, 0x8c, 0xd8, 0x6f, 0xb6, 0xba,
-	0x8b, 0x42, 0xbd, 0xde, 0x60, 0x45, 0x58, 0xc2, 0xe8, 0x62, 0x62, 0xcd, 0x73, 0xcc, 0xe1, 0x64,
-	0x31, 0x61, 0x55, 0x8a, 0x35, 0x0c, 0xb4, 0x0c, 0x23, 0xd1, 0x7e, 0xd4, 0x8c, 0x45, 0x44, 0xa6,
-	0x9c, 0xcc, 0x9d, 0x0d, 0x86, 0xa2, 0x65, 0x93, 0xe0, 0x55, 0xb0, 0xac, 0x6b, 0x7f, 0x0f, 0xbb,
-	0x0c, 0x59, 0x76, 0xb0, 0xb8, 0x13, 0x12, 0xb4, 0x0b, 0x13, 0x6d, 0x36, 0xe5, 0x22, 0x76, 0xb5,
-	0x98, 0xb7, 0x17, 0x07, 0x94, 0x6a, 0xef, 0xd1, 0x83, 0x46, 0x69, 0x9d, 0x98, 0xb8, 0x50, 0xd7,
-	0xc9, 0x61, 0x93, 0xba, 0xfd, 0x35, 0xc4, 0xce, 0xdc, 0x06, 0x17, 0x55, 0x47, 0x84, 0x69, 0xb1,
-	0xe0, 0xcb, 0xe7, 0xf2, 0x75, 0x26, 0xc9, 0x17, 0x09, 0xf3, 0x64, 0x2c, 0xeb, 0xa2, 0x37, 0xd9,
-	0x2b, 0x35, 0x3f, 0xe8, 0xfa, 0x25, 0x69, 0xe6, 0x58, 0xc6, 0x83, 0xb4, 0xa8, 0x88, 0x35, 0x22,
-	0xe8, 0x16, 0x4c, 0x88, 0x64, 0x52, 0x42, 0x29, 0x56, 0x34, 0x94, 0x1e, 0x13, 0x58, 0x07, 0x1e,
-	0xa5, 0x0b, 0xb0, 0x59, 0x19, 0x6d, 0xc1, 0x05, 0x2d, 0xb3, 0xe2, 0xf5, 0xd0, 0x61, 0x2f, 0x97,
-	0x2e, 0xdb, 0x44, 0xda, 0xb9, 0xf9, 0xc4, 0xe1, 0x41, 0xe5, 0xc2, 0x7a, 0x2f, 0x44, 0xdc, 0x9b,
-	0x0e, 0xba, 0x0d, 0xe7, 0xb8, 0x07, 0x5f, 0x95, 0x38, 0x2d, 0xcf, 0xf5, 0xd5, 0xc1, 0xcc, 0xd7,
-	0xe1, 0xf9, 0xc3, 0x83, 0xca, 0xb9, 0x85, 0x2c, 0x04, 0x9c, 0x5d, 0x0f, 0xbd, 0x06, 0xe5, 0x96,
-	0x1f, 0x89, 0x31, 0x18, 0x36, 0x92, 0x86, 0x96, 0xab, 0x6b, 0x0d, 0xf5, 0xfd, 0xc9, 0x1f, 0x9c,
-	0x54, 0x40, 0x5b, 0x5c, 0x31, 0xa6, 0xe4, 0xd0, 0x91, 0xfc, 0x04, 0xf1, 0x62, 0x49, 0x18, 0x3e,
-	0x3c, 0x5c, 0x23, 0xac, 0x6c, 0x60, 0x0d, 0xf7, 0x1e, 0x83, 0x30, 0x7a, 0x03, 0x10, 0x65, 0xd4,
-	0xdc, 0x26, 0x59, 0x68, 0xb2, 0x10, 0xe2, 0x4c, 0x8f, 0x38, 0x6a, 0xf8, 0x4c, 0xa0, 0x46, 0x17,
-	0x06, 0xce, 0xa8, 0x85, 0x6e, 0xd0, 0x83, 0x4c, 0x2f, 0x15, 0xb6, 0xbc, 0x92, 0xb9, 0x9f, 0xad,
-	0x92, 0x76, 0x48, 0x9a, 0x4e, 0x4c, 0x5a, 0x26, 0x45, 0x9c, 0xaa, 0x47, 0xef, 0x52, 0x95, 0x4d,
-	0x08, 0xcc, 0xb0, 0x19, 0xdd, 0x19, 0x85, 0xa8, 0x5c, 0xbc, 0x1d, 0x44, 0xf1, 0x1a, 0x89, 0xef,
-	0x05, 0xe1, 0x8e, 0x88, 0x52, 0x96, 0x04, 0xcc, 0x4c, 0x40, 0x58, 0xc7, 0xa3, 0x7c, 0x30, 0x7b,
-	0x26, 0xae, 0x55, 0xd9, 0x0b, 0xdd, 0x68, 0xb2, 0x4f, 0x6e, 0xf0, 0x62, 0x2c, 0xe1, 0x12, 0xb5,
-	0x56, 0x5f, 0x62, 0xaf, 0x6d, 0x29, 0xd4, 0x5a, 0x7d, 0x09, 0x4b, 0x38, 0x22, 0xdd, 0x09, 0x59,
-	0x27, 0xf3, 0xb5, 0x9a, 0xdd, 0xd7, 0xc1, 0x80, 0x39, 0x59, 0x7d, 0x98, 0x56, 0xa9, 0x60, 0x79,
-	0xf8, 0xb6, 0x68, 0x76, 0x8a, 0x2d, 0x92, 0xc1, 0x63, 0xbf, 0x29, 0x3d, 0x71, 0x2d, 0x45, 0x09,
-	0x77, 0xd1, 0x36, 0x02, 0x99, 0x4c, 0xf7, 0xcd, 0x06, 0x75, 0x15, 0xca, 0x51, 0x67, 0xa3, 0x15,
-	0xec, 0x3a, 0xae, 0xcf, 0x1e, 0xc7, 0x34, 0x26, 0xab, 0x21, 0x01, 0x38, 0xc1, 0x41, 0x2b, 0x30,
-	0xea, 0x48, 0x25, 0x30, 0xca, 0x8f, 0x5a, 0xa0, 0x54, 0xbf, 0xdc, 0x91, 0x57, 0xaa, 0x7d, 0x55,
-	0x5d, 0xf4, 0x2a, 0x4c, 0x08, 0xbf, 0x2d, 0x1e, 0xcb, 0x81, 0x3d, 0x5e, 0x69, 0x86, 0xf9, 0x0d,
-	0x1d, 0x88, 0x4d, 0x5c, 0xf4, 0x05, 0x98, 0xa4, 0x54, 0x92, 0x83, 0x6d, 0xf6, 0xec, 0x20, 0x27,
-	0xa2, 0x96, 0xe5, 0x43, 0xaf, 0x8c, 0x53, 0xc4, 0x50, 0x0b, 0x1e, 0x77, 0x3a, 0x71, 0xc0, 0x14,
-	0xe9, 0xe6, 0xfa, 0x5f, 0x0f, 0x76, 0x88, 0xcf, 0xde, 0xb0, 0x46, 0x17, 0x2f, 0x1d, 0x1e, 0x54,
-	0x1e, 0x5f, 0xe8, 0x81, 0x87, 0x7b, 0x52, 0x41, 0x77, 0x60, 0x2c, 0x0e, 0x3c, 0x66, 0x22, 0x4f,
-	0x59, 0x89, 0x47, 0xf2, 0x03, 0x01, 0xad, 0x2b, 0x34, 0x5d, 0x89, 0xa4, 0xaa, 0x62, 0x9d, 0x0e,
-	0x5a, 0xe7, 0x7b, 0x8c, 0x85, 0x48, 0x25, 0xd1, 0xec, 0xa3, 0xf9, 0x03, 0xa3, 0x22, 0xa9, 0x9a,
-	0x5b, 0x50, 0xd4, 0xc4, 0x3a, 0x19, 0x74, 0x1d, 0x66, 0xda, 0xa1, 0x1b, 0xb0, 0x85, 0xad, 0x1e,
-	0x31, 0x66, 0xcd, 0xc4, 0x0e, 0xf5, 0x34, 0x02, 0xee, 0xae, 0x43, 0x85, 0x4c, 0x59, 0x38, 0x7b,
-	0x9e, 0x67, 0x09, 0xe3, 0x8c, 0x37, 0x2f, 0xc3, 0x0a, 0x8a, 0x56, 0xd9, 0xb9, 0xcc, 0xc5, 0xc1,
-	0xd9, 0xb9, 0xfc, 0x68, 0x0f, 0xba, 0xd8, 0xc8, 0xf9, 0x25, 0xf5, 0x17, 0x27, 0x14, 0xe8, 0xbd,
-	0x11, 0x6d, 0x3b, 0x21, 0xa9, 0x87, 0x41, 0x93, 0x44, 0x5a, 0x54, 0xe6, 0xc7, 0x78, 0x24, 0x47,
-	0x7a, 0x6f, 0x34, 0xb2, 0x10, 0x70, 0x76, 0x3d, 0xd4, 0xd2, 0x92, 0x63, 0x53, 0x36, 0x34, 0x9a,
-	0x7d, 0xbc, 0x87, 0xc1, 0x51, 0x8a, 0x67, 0x4d, 0xd6, 0xa2, 0x51, 0x1c, 0xe1, 0x14, 0x4d, 0xf4,
-	0x1d, 0x30, 0x2d, 0x02, 0x1f, 0x25, 0xe3, 0x7e, 0x21, 0xb1, 0x64, 0xc4, 0x29, 0x18, 0xee, 0xc2,
-	0xe6, 0xb1, 0xa8, 0x9d, 0x0d, 0x8f, 0x88, 0x45, 0x78, 0xcb, 0xf5, 0x77, 0xa2, 0xd9, 0x8b, 0xec,
-	0xab, 0x45, 0x2c, 0xea, 0x34, 0x14, 0x67, 0xd4, 0x98, 0xfb, 0x76, 0x98, 0xe9, 0xba, 0xb9, 0x8e,
-	0x15, 0xbf, 0xfd, 0x4f, 0x86, 0xa0, 0xac, 0x94, 0xf2, 0xe8, 0xaa, 0xf9, 0xd6, 0x72, 0x3e, 0xfd,
-	0xd6, 0x32, 0x4a, 0x65, 0x03, 0xfd, 0x79, 0x65, 0xdd, 0x30, 0xd4, 0x2b, 0xe4, 0x67, 0x4b, 0xd3,
-	0xb9, 0xfb, 0xbe, 0x4e, 0x7f, 0x9a, 0x8e, 0xa5, 0x38, 0xf0, 0xa3, 0x4d, 0xa9, 0xa7, 0xda, 0x66,
-	0xc0, 0x64, 0xc5, 0xe8, 0x49, 0x2a, 0x20, 0xb5, 0x6a, 0xf5, 0x74, 0xf6, 0xce, 0x3a, 0x2d, 0xc4,
-	0x1c, 0xc6, 0x04, 0x49, 0xca, 0x66, 0x31, 0x41, 0x72, 0xe4, 0x01, 0x05, 0x49, 0x49, 0x00, 0x27,
-	0xb4, 0x90, 0x07, 0x33, 0x4d, 0x33, 0xf1, 0xaa, 0x72, 0xf4, 0x7b, 0xb2, 0x6f, 0x0a, 0xd4, 0x8e,
-	0x96, 0xe5, 0x6e, 0x29, 0x4d, 0x05, 0x77, 0x13, 0x46, 0xaf, 0xc2, 0xe8, 0x7b, 0x41, 0xc4, 0x16,
-	0xa5, 0xe0, 0x35, 0xa4, 0x43, 0xd4, 0xe8, 0x9b, 0xb7, 0x1b, 0xac, 0xfc, 0xe8, 0xa0, 0x32, 0x56,
-	0x0f, 0x5a, 0xf2, 0x2f, 0x56, 0x15, 0xd0, 0x7d, 0x38, 0x67, 0x9c, 0xd0, 0xaa, 0xbb, 0x30, 0x78,
-	0x77, 0x2f, 0x88, 0xe6, 0xce, 0xd5, 0xb2, 0x28, 0xe1, 0xec, 0x06, 0xe8, 0xb1, 0xe7, 0x07, 0x22,
-	0x69, 0xb1, 0xe4, 0x67, 0x18, 0xdb, 0x52, 0xd6, 0xdd, 0xe1, 0x53, 0x08, 0xb8, 0xbb, 0x8e, 0xfd,
-	0xcb, 0xfc, 0x0d, 0x43, 0x68, 0x3a, 0x49, 0xd4, 0xf1, 0x4e, 0x23, 0x27, 0xd6, 0xb2, 0xa1, 0x84,
-	0x7d, 0xe0, 0x77, 0xb2, 0x5f, 0xb7, 0xd8, 0x3b, 0xd9, 0x3a, 0xd9, 0x6d, 0x7b, 0x54, 0xde, 0x7e,
-	0xf8, 0x1d, 0x7f, 0x13, 0x46, 0x63, 0xd1, 0x5a, 0xaf, 0x34, 0x5e, 0x5a, 0xa7, 0xd8, 0x5b, 0xa1,
-	0xe2, 0x74, 0x64, 0x29, 0x56, 0x64, 0xec, 0x7f, 0xc1, 0x67, 0x40, 0x42, 0x4e, 0x41, 0x21, 0x56,
-	0x35, 0x15, 0x62, 0x95, 0x3e, 0x5f, 0x90, 0xa3, 0x18, 0xfb, 0xe7, 0x66, 0xbf, 0x99, 0x50, 0xf9,
-	0x51, 0x7f, 0xa0, 0xb5, 0x7f, 0xd8, 0x82, 0xb3, 0x59, 0x16, 0x4d, 0x94, 0x3b, 0xe5, 0x22, 0xad,
-	0x7a, 0xb0, 0x56, 0x23, 0x78, 0x57, 0x94, 0x63, 0x85, 0x31, 0x70, 0x86, 0x8c, 0xe3, 0x45, 0x8c,
-	0xbb, 0x0d, 0x13, 0xf5, 0x90, 0x68, 0x77, 0xc0, 0xeb, 0xdc, 0xb3, 0x8e, 0xf7, 0xe7, 0xd9, 0x63,
-	0x7b, 0xd5, 0xd9, 0x3f, 0x53, 0x80, 0xb3, 0xfc, 0xc5, 0x69, 0x61, 0x2f, 0x70, 0x5b, 0xf5, 0xa0,
-	0x25, 0xb2, 0x9b, 0xbc, 0x0d, 0xe3, 0x6d, 0x4d, 0x0f, 0xd1, 0x2b, 0x66, 0x95, 0xae, 0xaf, 0x48,
-	0xe4, 0x41, 0xbd, 0x14, 0x1b, 0xb4, 0x50, 0x0b, 0xc6, 0xc9, 0x9e, 0xdb, 0x54, 0xcf, 0x16, 0x85,
-	0x63, 0xdf, 0x0d, 0xaa, 0x95, 0x65, 0x8d, 0x0e, 0x36, 0xa8, 0x3e, 0x84, 0x84, 0x77, 0xf6, 0x8f,
-	0x58, 0xf0, 0x68, 0x4e, 0x84, 0x2b, 0xda, 0xdc, 0x3d, 0xf6, 0xb6, 0x27, 0x72, 0x67, 0xa9, 0xe6,
-	0xf8, 0x8b, 0x1f, 0x16, 0x50, 0xf4, 0x39, 0x00, 0xfe, 0x62, 0x47, 0xc5, 0xa3, 0x7e, 0xa1, 0x80,
-	0x8c, 0x28, 0x26, 0x5a, 0xf4, 0x09, 0x59, 0x1f, 0x6b, 0xb4, 0xec, 0x9f, 0x2c, 0xc2, 0x10, 0x7b,
-	0x21, 0x42, 0x2b, 0x30, 0xb2, 0xcd, 0x63, 0x3e, 0x0f, 0x12, 0x5e, 0x3a, 0x91, 0x33, 0x79, 0x01,
-	0x96, 0x95, 0xd1, 0x2a, 0x9c, 0xe1, 0x31, 0xb3, 0xbd, 0x2a, 0xf1, 0x9c, 0x7d, 0xa9, 0xae, 0xe0,
-	0xf9, 0xa6, 0x54, 0x24, 0x8d, 0x5a, 0x37, 0x0a, 0xce, 0xaa, 0x87, 0x5e, 0x87, 0x49, 0xca, 0xdf,
-	0x05, 0x9d, 0x58, 0x52, 0xe2, 0xd1, 0xb2, 0x15, 0x43, 0xb9, 0x6e, 0x40, 0x71, 0x0a, 0x9b, 0x0a,
-	0x5e, 0xed, 0x2e, 0xc5, 0xcc, 0x50, 0x22, 0x78, 0x99, 0xca, 0x18, 0x13, 0x97, 0x99, 0x32, 0x75,
-	0x98, 0xe1, 0xd6, 0xfa, 0x76, 0x48, 0xa2, 0xed, 0xc0, 0x6b, 0x89, 0x74, 0xe5, 0x89, 0x29, 0x53,
-	0x0a, 0x8e, 0xbb, 0x6a, 0x50, 0x2a, 0x9b, 0x8e, 0xeb, 0x75, 0x42, 0x92, 0x50, 0x19, 0x36, 0xa9,
-	0xac, 0xa4, 0xe0, 0xb8, 0xab, 0x06, 0x5d, 0x47, 0xe7, 0x44, 0xfe, 0x70, 0xe9, 0xdf, 0xaf, 0xec,
-	0xd3, 0x46, 0xa4, 0xa7, 0x53, 0x8f, 0x00, 0x37, 0xc2, 0x82, 0x47, 0x65, 0x20, 0xd7, 0xf4, 0x89,
-	0xc2, 0xc7, 0x49, 0x52, 0x79, 0x90, 0x2c, 0xd6, 0xbf, 0x6b, 0xc1, 0x99, 0x0c, 0x3b, 0x58, 0x7e,
-	0x54, 0x6d, 0xb9, 0x51, 0xac, 0x72, 0xea, 0x68, 0x47, 0x15, 0x2f, 0xc7, 0x0a, 0x83, 0xee, 0x07,
-	0x7e, 0x18, 0xa6, 0x0f, 0x40, 0x61, 0x67, 0x26, 0xa0, 0xc7, 0xcc, 0x4e, 0x73, 0x09, 0x4a, 0x9d,
-	0x88, 0xc8, 0xd0, 0x54, 0xea, 0xfc, 0x66, 0x1a, 0x66, 0x06, 0xa1, 0xac, 0xe9, 0x96, 0x52, 0xee,
-	0x6a, 0xac, 0x29, 0xd7, 0xd8, 0x72, 0x98, 0xfd, 0xd5, 0x22, 0x9c, 0xcf, 0xb5, 0x78, 0xa7, 0x5d,
-	0xda, 0x0d, 0x7c, 0x37, 0x0e, 0xd4, 0xeb, 0x23, 0x0f, 0x8e, 0x42, 0xda, 0xdb, 0xab, 0xa2, 0x1c,
-	0x2b, 0x0c, 0x74, 0x59, 0x66, 0xb2, 0x4f, 0x67, 0x0d, 0x5a, 0xac, 0x1a, 0xc9, 0xec, 0x07, 0xcd,
-	0xc8, 0xf6, 0x24, 0x94, 0xda, 0x41, 0xe0, 0xa5, 0x0f, 0x23, 0xda, 0xdd, 0x20, 0xf0, 0x30, 0x03,
-	0xa2, 0x4f, 0x88, 0x71, 0x48, 0x3d, 0xb7, 0x61, 0xa7, 0x15, 0x44, 0xda, 0x60, 0x3c, 0x0d, 0x23,
-	0x3b, 0x64, 0x3f, 0x74, 0xfd, 0xad, 0xf4, 0x33, 0xec, 0x4d, 0x5e, 0x8c, 0x25, 0xdc, 0xcc, 0x21,
-	0x31, 0x72, 0xd2, 0xa9, 0xd4, 0x46, 0xfb, 0x5e, 0x6d, 0x3f, 0x50, 0x84, 0x29, 0xbc, 0x58, 0xfd,
-	0xd6, 0x44, 0xdc, 0xe9, 0x9e, 0x88, 0x93, 0x4e, 0xa5, 0xd6, 0x7f, 0x36, 0x7e, 0xc1, 0x82, 0x29,
-	0x16, 0x67, 0x59, 0x84, 0xe4, 0x70, 0x03, 0xff, 0x14, 0x58, 0xb7, 0x27, 0x61, 0x28, 0xa4, 0x8d,
-	0xa6, 0xd3, 0x05, 0xb1, 0x9e, 0x60, 0x0e, 0x43, 0x8f, 0x43, 0x89, 0x75, 0x81, 0x4e, 0xde, 0x38,
-	0xcf, 0xb4, 0x50, 0x75, 0x62, 0x07, 0xb3, 0x52, 0xe6, 0x67, 0x8e, 0x49, 0xdb, 0x73, 0x79, 0xa7,
-	0x93, 0xa7, 0x8d, 0x8f, 0x86, 0x9f, 0x79, 0x66, 0xd7, 0x3e, 0x98, 0x9f, 0x79, 0x36, 0xc9, 0xde,
-	0x62, 0xd1, 0x1f, 0x16, 0xe0, 0x62, 0x66, 0xbd, 0x81, 0xfd, 0xcc, 0x7b, 0xd7, 0x3e, 0x19, 0x6b,
-	0x9a, 0x6c, 0x23, 0x97, 0xe2, 0x29, 0x1a, 0xb9, 0x94, 0x06, 0xe5, 0x1c, 0x87, 0x06, 0x70, 0xff,
-	0xce, 0x1c, 0xb2, 0x8f, 0x88, 0xfb, 0x77, 0x66, 0xdf, 0x72, 0xc4, 0xba, 0x3f, 0x2b, 0xe4, 0x7c,
-	0x0b, 0x13, 0xf0, 0xae, 0xd0, 0x73, 0x86, 0x01, 0x23, 0xc1, 0x09, 0x8f, 0xf3, 0x33, 0x86, 0x97,
-	0x61, 0x05, 0x45, 0xae, 0xe6, 0x48, 0x5d, 0xc8, 0xcf, 0x9e, 0x99, 0xdb, 0xd4, 0xbc, 0xf9, 0x12,
-	0xa5, 0x86, 0x20, 0xc3, 0xa9, 0x7a, 0x55, 0x13, 0xca, 0x8b, 0x83, 0x0b, 0xe5, 0xe3, 0xd9, 0x02,
-	0x39, 0x5a, 0x80, 0xa9, 0x5d, 0xd7, 0xa7, 0xc7, 0xe6, 0xbe, 0xc9, 0x8a, 0xaa, 0xb8, 0x22, 0xab,
-	0x26, 0x18, 0xa7, 0xf1, 0xe7, 0x5e, 0x85, 0x89, 0x07, 0x57, 0x47, 0x7e, 0xb3, 0x08, 0x8f, 0xf5,
-	0xd8, 0xf6, 0xfc, 0xac, 0x37, 0xe6, 0x40, 0x3b, 0xeb, 0xbb, 0xe6, 0xa1, 0x0e, 0x67, 0x37, 0x3b,
-	0x9e, 0xb7, 0xcf, 0xec, 0x48, 0x49, 0x4b, 0x62, 0x08, 0x5e, 0xf1, 0x71, 0x99, 0xdb, 0x62, 0x25,
-	0x03, 0x07, 0x67, 0xd6, 0x44, 0x6f, 0x00, 0x0a, 0x44, 0xea, 0xde, 0xeb, 0xc4, 0x17, 0xfa, 0x7d,
-	0x36, 0xf0, 0xc5, 0x64, 0x33, 0xde, 0xee, 0xc2, 0xc0, 0x19, 0xb5, 0x28, 0xd3, 0x4f, 0x6f, 0xa5,
-	0x7d, 0xd5, 0xad, 0x14, 0xd3, 0x8f, 0x75, 0x20, 0x36, 0x71, 0xd1, 0x75, 0x98, 0x71, 0xf6, 0x1c,
-	0x97, 0xc7, 0xdb, 0x93, 0x04, 0x38, 0xd7, 0xaf, 0x94, 0x60, 0x0b, 0x69, 0x04, 0xdc, 0x5d, 0x27,
-	0xe5, 0x6a, 0x3d, 0x9c, 0xef, 0x6a, 0xdd, 0xfb, 0x5c, 0xec, 0xa7, 0xd3, 0xb5, 0xff, 0xb3, 0x45,
-	0xaf, 0xaf, 0x8c, 0xf4, 0xfb, 0x74, 0x1c, 0x94, 0x6e, 0x52, 0xf3, 0x7a, 0x3e, 0xa7, 0x59, 0x8a,
-	0x24, 0x40, 0x6c, 0xe2, 0xf2, 0x05, 0x11, 0x25, 0xce, 0x36, 0x06, 0xeb, 0x2e, 0xa2, 0x26, 0x28,
-	0x0c, 0xf4, 0x79, 0x18, 0x69, 0xb9, 0x7b, 0x6e, 0x14, 0x84, 0x62, 0xb3, 0x1c, 0xd3, 0x65, 0x21,
-	0x39, 0x07, 0xab, 0x9c, 0x0c, 0x96, 0xf4, 0xec, 0x1f, 0x28, 0xc0, 0x84, 0x6c, 0xf1, 0xcd, 0x4e,
-	0x10, 0x3b, 0xa7, 0x70, 0x2d, 0x5f, 0x37, 0xae, 0xe5, 0x4f, 0xf4, 0x0a, 0x1d, 0xc1, 0xba, 0x94,
-	0x7b, 0x1d, 0xdf, 0x4e, 0x5d, 0xc7, 0x4f, 0xf5, 0x27, 0xd5, 0xfb, 0x1a, 0xfe, 0x97, 0x16, 0xcc,
-	0x18, 0xf8, 0xa7, 0x70, 0x1b, 0xac, 0x98, 0xb7, 0xc1, 0x13, 0x7d, 0xbf, 0x21, 0xe7, 0x16, 0xf8,
-	0xbe, 0x62, 0xaa, 0xef, 0xec, 0xf4, 0x7f, 0x0f, 0x4a, 0xdb, 0x4e, 0xd8, 0xea, 0x15, 0xa2, 0xb6,
-	0xab, 0xd2, 0xfc, 0x0d, 0x27, 0x6c, 0xf1, 0x33, 0xfc, 0x59, 0x95, 0xff, 0xd2, 0x09, 0x5b, 0x7d,
-	0x7d, 0xcb, 0x58, 0x53, 0xe8, 0x15, 0x18, 0x8e, 0x9a, 0x41, 0x5b, 0x59, 0x7e, 0x5e, 0xe2, 0xb9,
-	0x31, 0x69, 0xc9, 0xd1, 0x41, 0x05, 0x99, 0xcd, 0xd1, 0x62, 0x2c, 0xf0, 0xd1, 0xdb, 0x30, 0xc1,
-	0x7e, 0x29, 0x0b, 0x88, 0x62, 0x7e, 0x62, 0x84, 0x86, 0x8e, 0xc8, 0x0d, 0x69, 0x8c, 0x22, 0x6c,
-	0x92, 0x9a, 0xdb, 0x82, 0xb2, 0xfa, 0xac, 0x87, 0xea, 0x13, 0xf4, 0x1f, 0x8a, 0x70, 0x26, 0x63,
-	0xcd, 0xa1, 0xc8, 0x98, 0x89, 0xe7, 0x07, 0x5c, 0xaa, 0x1f, 0x70, 0x2e, 0x22, 0x26, 0x0d, 0xb5,
-	0xc4, 0xda, 0x1a, 0xb8, 0xd1, 0x3b, 0x11, 0x49, 0x37, 0x4a, 0x8b, 0xfa, 0x37, 0x4a, 0x1b, 0x3b,
-	0xb5, 0xa1, 0xa6, 0x0d, 0xa9, 0x9e, 0x3e, 0xd4, 0x39, 0xfd, 0xe3, 0x22, 0x9c, 0xcd, 0x8a, 0x66,
-	0x83, 0xbe, 0x3b, 0x95, 0x24, 0xe7, 0xc5, 0x41, 0xe3, 0xe0, 0xf0, 0xcc, 0x39, 0x22, 0xc7, 0xf5,
-	0xbc, 0x99, 0x36, 0xa7, 0xef, 0x30, 0x8b, 0x36, 0x99, 0x23, 0x69, 0xc8, 0x93, 0x1b, 0xc9, 0xe3,
-	0xe3, 0xd3, 0x03, 0x77, 0x40, 0x64, 0x45, 0x8a, 0x52, 0x8e, 0xa4, 0xb2, 0xb8, 0xbf, 0x23, 0xa9,
-	0x6c, 0x79, 0xce, 0x85, 0x31, 0xed, 0x6b, 0x1e, 0xea, 0x8c, 0xef, 0xd0, 0xdb, 0x4a, 0xeb, 0xf7,
-	0x43, 0x9d, 0xf5, 0x1f, 0xb1, 0x20, 0x65, 0x66, 0xa9, 0xd4, 0x5d, 0x56, 0xae, 0xba, 0xeb, 0x12,
-	0x94, 0xc2, 0xc0, 0x23, 0xe9, 0x9c, 0x34, 0x38, 0xf0, 0x08, 0x66, 0x10, 0x8a, 0x11, 0x27, 0xca,
-	0x8e, 0x71, 0x5d, 0x90, 0x13, 0x22, 0xda, 0x93, 0x30, 0xe4, 0x91, 0x3d, 0xe2, 0xa5, 0x03, 0xbe,
-	0xdf, 0xa2, 0x85, 0x98, 0xc3, 0xec, 0x5f, 0x28, 0xc1, 0x85, 0x9e, 0xae, 0xd8, 0x54, 0x1c, 0xda,
-	0x72, 0x62, 0x72, 0xcf, 0xd9, 0x4f, 0x47, 0x66, 0xbe, 0xce, 0x8b, 0xb1, 0x84, 0x33, 0xcb, 0x73,
-	0x1e, 0x89, 0x31, 0xa5, 0x1c, 0x14, 0x01, 0x18, 0x05, 0xf4, 0x21, 0xe4, 0xf7, 0xbf, 0x06, 0x10,
-	0x45, 0x1e, 0xb7, 0x1b, 0x68, 0x09, 0x93, 0xf6, 0x24, 0x62, 0x67, 0xe3, 0x96, 0x80, 0x60, 0x0d,
-	0x0b, 0x55, 0x61, 0xba, 0x1d, 0x06, 0x31, 0xd7, 0xb5, 0x56, 0xb9, 0xc1, 0xd1, 0x90, 0xe9, 0x05,
-	0x5b, 0x4f, 0xc1, 0x71, 0x57, 0x0d, 0xf4, 0x12, 0x8c, 0x09, 0xcf, 0xd8, 0x7a, 0x10, 0x78, 0x42,
-	0x0d, 0xa4, 0xcc, 0x57, 0x1a, 0x09, 0x08, 0xeb, 0x78, 0x5a, 0x35, 0xa6, 0xc0, 0x1d, 0xc9, 0xac,
-	0xc6, 0x95, 0xb8, 0x1a, 0x5e, 0x2a, 0xb2, 0xd5, 0xe8, 0x40, 0x91, 0xad, 0x12, 0xc5, 0x58, 0x79,
-	0xe0, 0x37, 0x2b, 0xe8, 0xab, 0x4a, 0xfa, 0xd9, 0x12, 0x9c, 0x11, 0x0b, 0xe7, 0x61, 0x2f, 0x97,
-	0x3b, 0xdd, 0xcb, 0xe5, 0x24, 0x54, 0x67, 0xdf, 0x5a, 0x33, 0xa7, 0xbd, 0x66, 0x7e, 0xd0, 0x02,
-	0x93, 0xbd, 0x42, 0x7f, 0x29, 0x37, 0xb4, 0xfd, 0x4b, 0xb9, 0xec, 0x5a, 0x4b, 0x5e, 0x20, 0x1f,
-	0x30, 0xc8, 0xbd, 0xfd, 0x9f, 0x2c, 0x78, 0xa2, 0x2f, 0x45, 0xb4, 0x0c, 0x65, 0xc6, 0x03, 0x6a,
-	0xd2, 0xd9, 0x53, 0xca, 0x20, 0x51, 0x02, 0x72, 0x58, 0xd2, 0xa4, 0x26, 0x5a, 0xee, 0xca, 0x21,
-	0xf0, 0x74, 0x46, 0x0e, 0x81, 0x73, 0xc6, 0xf0, 0x3c, 0x60, 0x12, 0x81, 0x5f, 0x2e, 0xc2, 0x30,
-	0x5f, 0xf1, 0xa7, 0x20, 0x86, 0xad, 0x08, 0xbd, 0x6d, 0x8f, 0xd8, 0x56, 0xbc, 0x2f, 0xf3, 0x55,
-	0x27, 0x76, 0x38, 0x9b, 0xa0, 0x6e, 0xab, 0x44, 0xc3, 0x8b, 0xe6, 0x8d, 0xfb, 0x6c, 0x2e, 0xa5,
-	0x98, 0x04, 0x4e, 0x43, 0xbb, 0xdd, 0xbe, 0x08, 0x10, 0xb1, 0xfc, 0xfb, 0x94, 0x86, 0x88, 0x92,
-	0xf6, 0xc9, 0x1e, 0xad, 0x37, 0x14, 0x32, 0xef, 0x43, 0xb2, 0xd3, 0x15, 0x00, 0x6b, 0x14, 0xe7,
-	0x5e, 0x86, 0xb2, 0x42, 0xee, 0xa7, 0xc5, 0x19, 0xd7, 0x99, 0x8b, 0xcf, 0xc2, 0x54, 0xaa, 0xad,
-	0x63, 0x29, 0x81, 0x7e, 0xd1, 0x82, 0x29, 0xde, 0xe5, 0x65, 0x7f, 0x4f, 0x9c, 0xa9, 0xef, 0xc3,
-	0x59, 0x2f, 0xe3, 0x6c, 0x13, 0x33, 0x3a, 0xf8, 0x59, 0xa8, 0x94, 0x3e, 0x59, 0x50, 0x9c, 0xd9,
-	0x06, 0xba, 0x42, 0xd7, 0x2d, 0x3d, 0xbb, 0x1c, 0x4f, 0x78, 0x31, 0x8d, 0xf3, 0x35, 0xcb, 0xcb,
-	0xb0, 0x82, 0xda, 0xbf, 0x6d, 0xc1, 0x0c, 0xef, 0xf9, 0x4d, 0xb2, 0xaf, 0x76, 0xf8, 0x87, 0xd9,
-	0x77, 0x91, 0xd6, 0xa3, 0x90, 0x93, 0xd6, 0x43, 0xff, 0xb4, 0x62, 0xcf, 0x4f, 0xfb, 0x19, 0x0b,
-	0xc4, 0x0a, 0x3c, 0x05, 0x51, 0xfe, 0xdb, 0x4d, 0x51, 0x7e, 0x2e, 0x7f, 0x51, 0xe7, 0xc8, 0xf0,
-	0x7f, 0x6a, 0xc1, 0x34, 0x47, 0x48, 0xde, 0x92, 0x3f, 0xd4, 0x79, 0x18, 0x24, 0x3f, 0x9f, 0x4a,
-	0xda, 0x9d, 0xfd, 0x51, 0xc6, 0x64, 0x95, 0x7a, 0x4e, 0x56, 0x4b, 0x6e, 0xa0, 0x63, 0xe4, 0xa6,
-	0x3c, 0x76, 0x78, 0x6c, 0xfb, 0x0f, 0x2c, 0x40, 0xbc, 0x19, 0x83, 0xfd, 0xa1, 0x4c, 0x05, 0x2b,
-	0xd5, 0xae, 0x8b, 0xe4, 0xa8, 0x51, 0x10, 0xac, 0x61, 0x9d, 0xc8, 0xf0, 0xa4, 0x0c, 0x02, 0x8a,
-	0xfd, 0x0d, 0x02, 0x8e, 0x31, 0xa2, 0xff, 0xa7, 0x04, 0x69, 0xb7, 0x02, 0x74, 0x17, 0xc6, 0x9b,
-	0x4e, 0xdb, 0xd9, 0x70, 0x3d, 0x37, 0x76, 0x49, 0xd4, 0xcb, 0x92, 0x68, 0x49, 0xc3, 0x13, 0x4f,
-	0xbd, 0x5a, 0x09, 0x36, 0xe8, 0xa0, 0x79, 0x80, 0x76, 0xe8, 0xee, 0xb9, 0x1e, 0xd9, 0x62, 0x1a,
-	0x07, 0xe6, 0x37, 0xc9, 0xcd, 0x63, 0x64, 0x29, 0xd6, 0x30, 0x32, 0x5c, 0xe0, 0x8a, 0x0f, 0xcf,
-	0x05, 0xae, 0x74, 0x4c, 0x17, 0xb8, 0xa1, 0x81, 0x5c, 0xe0, 0x30, 0x3c, 0x22, 0x59, 0x24, 0xfa,
-	0x7f, 0xc5, 0xf5, 0x88, 0xe0, 0x8b, 0xb9, 0x37, 0xe5, 0xdc, 0xe1, 0x41, 0xe5, 0x11, 0x9c, 0x89,
-	0x81, 0x73, 0x6a, 0xa2, 0xcf, 0xc1, 0xac, 0xe3, 0x79, 0xc1, 0x3d, 0x35, 0x6a, 0xcb, 0x51, 0xd3,
-	0xf1, 0xb8, 0xc6, 0x7e, 0x84, 0x51, 0x7d, 0xfc, 0xf0, 0xa0, 0x32, 0xbb, 0x90, 0x83, 0x83, 0x73,
-	0x6b, 0xa7, 0x3c, 0xe8, 0x46, 0xfb, 0x7a, 0xd0, 0xbd, 0x06, 0xe5, 0x76, 0x18, 0x34, 0x57, 0x35,
-	0xaf, 0x9e, 0x8b, 0x2c, 0xf3, 0xbd, 0x2c, 0x3c, 0x3a, 0xa8, 0x4c, 0xa8, 0x3f, 0xec, 0x86, 0x4f,
-	0x2a, 0xd8, 0x3b, 0x70, 0xa6, 0x41, 0x42, 0x97, 0xe5, 0xd4, 0x6c, 0x25, 0x1b, 0x7a, 0x1d, 0xca,
-	0x61, 0xea, 0x08, 0x1b, 0x28, 0x40, 0x93, 0x16, 0x37, 0x58, 0x1e, 0x59, 0x09, 0x21, 0xfb, 0x4f,
-	0x2c, 0x18, 0x11, 0x16, 0xe6, 0xa7, 0xc0, 0x39, 0x2d, 0x18, 0x0a, 0xec, 0x4a, 0xf6, 0x31, 0xcf,
-	0x3a, 0x93, 0xab, 0xba, 0xae, 0xa5, 0x54, 0xd7, 0x4f, 0xf4, 0x22, 0xd2, 0x5b, 0x69, 0xfd, 0x77,
-	0x8b, 0x30, 0x69, 0x3a, 0x85, 0x9c, 0xc2, 0x10, 0xac, 0xc1, 0x48, 0x24, 0x3c, 0x90, 0x0a, 0xf9,
-	0x96, 0xd3, 0xe9, 0x49, 0x4c, 0xcc, 0xa2, 0x84, 0xcf, 0x91, 0x24, 0x92, 0xe9, 0xda, 0x54, 0x7c,
-	0x88, 0xae, 0x4d, 0xfd, 0xfc, 0x72, 0x4a, 0x27, 0xe1, 0x97, 0x63, 0x7f, 0x9d, 0x5d, 0x35, 0x7a,
-	0xf9, 0x29, 0x70, 0x21, 0xd7, 0xcd, 0x4b, 0xc9, 0xee, 0xb1, 0xb2, 0x44, 0xa7, 0x72, 0xb8, 0x91,
-	0x9f, 0xb7, 0xe0, 0x42, 0xc6, 0x57, 0x69, 0xac, 0xc9, 0xb3, 0x30, 0xea, 0x74, 0x5a, 0xae, 0xda,
-	0xcb, 0xda, 0x33, 0xd6, 0x82, 0x28, 0xc7, 0x0a, 0x03, 0x2d, 0xc1, 0x0c, 0xb9, 0xdf, 0x76, 0xf9,
-	0x3b, 0xa2, 0x6e, 0xbb, 0x58, 0xe4, 0x41, 0x6b, 0x97, 0xd3, 0x40, 0xdc, 0x8d, 0xaf, 0xdc, 0xba,
-	0x8b, 0xb9, 0x6e, 0xdd, 0xff, 0xc4, 0x82, 0x31, 0xe5, 0x6d, 0xf2, 0xd0, 0x47, 0xfb, 0x3b, 0xcc,
-	0xd1, 0x7e, 0xac, 0xc7, 0x68, 0xe7, 0x0c, 0xf3, 0xdf, 0x2f, 0xa8, 0xfe, 0xd6, 0x83, 0x30, 0x1e,
-	0x80, 0xe5, 0x79, 0x05, 0x46, 0xdb, 0x61, 0x10, 0x07, 0xcd, 0xc0, 0x13, 0x1c, 0xcf, 0xe3, 0x49,
-	0xd4, 0x01, 0x5e, 0x7e, 0xa4, 0xfd, 0xc6, 0x0a, 0x9b, 0x8d, 0x5e, 0x10, 0xc6, 0x82, 0xcb, 0x48,
-	0x46, 0x2f, 0x08, 0x63, 0xcc, 0x20, 0xa8, 0x05, 0x10, 0x3b, 0xe1, 0x16, 0x89, 0x69, 0x99, 0x08,
-	0x60, 0x92, 0x7f, 0x78, 0x74, 0x62, 0xd7, 0x9b, 0x77, 0xfd, 0x38, 0x8a, 0xc3, 0xf9, 0x9a, 0x1f,
-	0xdf, 0x0e, 0xb9, 0x00, 0xa5, 0x85, 0x11, 0x50, 0xb4, 0xb0, 0x46, 0x57, 0xfa, 0x7a, 0xb2, 0x36,
-	0x86, 0xcc, 0x07, 0xf1, 0x35, 0x51, 0x8e, 0x15, 0x86, 0xfd, 0x32, 0xbb, 0x4a, 0xd8, 0x00, 0x1d,
-	0xcf, 0xc3, 0xff, 0x1b, 0xa3, 0x6a, 0x68, 0xd9, 0x6b, 0x58, 0x55, 0x8f, 0x23, 0xd0, 0xfb, 0xe4,
-	0xa6, 0x0d, 0xeb, 0x7e, 0x34, 0x49, 0xb0, 0x01, 0xf4, 0x9d, 0x5d, 0x76, 0x12, 0xcf, 0xf5, 0xb9,
-	0x02, 0x8e, 0x61, 0x19, 0xc1, 0x02, 0x69, 0xb3, 0x30, 0xc3, 0xb5, 0xba, 0x58, 0xe4, 0x5a, 0x20,
-	0x6d, 0x01, 0xc0, 0x09, 0x0e, 0xba, 0x2a, 0xc4, 0xef, 0x92, 0x91, 0x4e, 0x4f, 0x8a, 0xdf, 0xf2,
-	0xf3, 0x35, 0xf9, 0xfb, 0x79, 0x18, 0x53, 0x69, 0xf5, 0xea, 0x3c, 0x3b, 0x99, 0x08, 0xe7, 0xb2,
-	0x9c, 0x14, 0x63, 0x1d, 0x07, 0xad, 0xc3, 0x54, 0xc4, 0x75, 0x2f, 0x2a, 0x6a, 0x1f, 0xd7, 0x61,
-	0x7d, 0x52, 0xda, 0x57, 0x34, 0x4c, 0xf0, 0x11, 0x2b, 0xe2, 0x47, 0x87, 0x74, 0xd8, 0x4c, 0x93,
-	0x40, 0xaf, 0xc3, 0xa4, 0xa7, 0x27, 0xb0, 0xaf, 0x0b, 0x15, 0x97, 0x32, 0x3f, 0x36, 0xd2, 0xdb,
-	0xd7, 0x71, 0x0a, 0x9b, 0x72, 0x4a, 0x7a, 0x89, 0x88, 0x34, 0xe9, 0xf8, 0x5b, 0x24, 0x12, 0x49,
-	0xc1, 0x18, 0xa7, 0x74, 0x2b, 0x07, 0x07, 0xe7, 0xd6, 0x46, 0xaf, 0xc0, 0xb8, 0xfc, 0x7c, 0xcd,
-	0x1d, 0x39, 0x31, 0x72, 0xd7, 0x60, 0xd8, 0xc0, 0x44, 0xf7, 0xe0, 0x9c, 0xfc, 0xbf, 0x1e, 0x3a,
-	0x9b, 0x9b, 0x6e, 0x53, 0x78, 0x83, 0x73, 0x4f, 0x9f, 0x05, 0xe9, 0x3a, 0xb4, 0x9c, 0x85, 0x74,
-	0x74, 0x50, 0xb9, 0x24, 0x46, 0x2d, 0x13, 0xce, 0x26, 0x31, 0x9b, 0x3e, 0x5a, 0x85, 0x33, 0xdb,
-	0xc4, 0xf1, 0xe2, 0xed, 0xa5, 0x6d, 0xd2, 0xdc, 0x91, 0x9b, 0x88, 0x39, 0x39, 0x6b, 0xa6, 0xe1,
-	0x37, 0xba, 0x51, 0x70, 0x56, 0x3d, 0xf4, 0x0e, 0xcc, 0xb6, 0x3b, 0x1b, 0x9e, 0x1b, 0x6d, 0xaf,
-	0x05, 0x31, 0x33, 0xe9, 0x50, 0x59, 0xe9, 0x84, 0x37, 0xb4, 0x72, 0xf0, 0xae, 0xe7, 0xe0, 0xe1,
-	0x5c, 0x0a, 0xe8, 0x7d, 0x38, 0x97, 0x5a, 0x0c, 0xc2, 0x37, 0x73, 0x32, 0x3f, 0x6e, 0x6f, 0x23,
-	0xab, 0x82, 0xf0, 0xb5, 0xcc, 0x02, 0xe1, 0xec, 0x26, 0x3e, 0x98, 0xa1, 0xcf, 0x7b, 0xb4, 0xb2,
-	0xc6, 0x94, 0xa1, 0x2f, 0xc1, 0xb8, 0xbe, 0x8a, 0xc4, 0x05, 0x73, 0x39, 0x9b, 0x67, 0xd1, 0x56,
-	0x1b, 0x67, 0xe9, 0xd4, 0x8a, 0xd2, 0x61, 0xd8, 0xa0, 0x68, 0x13, 0xc8, 0xfe, 0x3e, 0x74, 0x0b,
-	0x46, 0x9b, 0x9e, 0x4b, 0xfc, 0xb8, 0x56, 0xef, 0x15, 0x3c, 0x64, 0x49, 0xe0, 0x88, 0x01, 0x13,
-	0x81, 0x4e, 0x79, 0x19, 0x56, 0x14, 0xec, 0x5f, 0x2b, 0x40, 0xa5, 0x4f, 0xd4, 0xdc, 0x94, 0x3e,
-	0xda, 0x1a, 0x48, 0x1f, 0xbd, 0x20, 0x73, 0xec, 0xad, 0xa5, 0x84, 0xf4, 0x54, 0xfe, 0xbc, 0x44,
-	0x54, 0x4f, 0xe3, 0x0f, 0x6c, 0x1f, 0xac, 0xab, 0xb4, 0x4b, 0x7d, 0x2d, 0xd7, 0x8d, 0xa7, 0xac,
-	0xa1, 0xc1, 0x05, 0x91, 0xdc, 0x67, 0x09, 0xfb, 0xeb, 0x05, 0x38, 0xa7, 0x86, 0xf0, 0x2f, 0xee,
-	0xc0, 0xdd, 0xe9, 0x1e, 0xb8, 0x13, 0x78, 0xd4, 0xb1, 0x6f, 0xc3, 0x30, 0x0f, 0xbe, 0x32, 0x00,
-	0x03, 0xf4, 0xa4, 0x19, 0xa9, 0x4b, 0x5d, 0xd3, 0x46, 0xb4, 0xae, 0xbf, 0x66, 0xc1, 0xd4, 0xfa,
-	0x52, 0xbd, 0x11, 0x34, 0x77, 0x48, 0xbc, 0xc0, 0x19, 0x56, 0x2c, 0xf8, 0x1f, 0xeb, 0x01, 0xf9,
-	0x9a, 0x2c, 0x8e, 0xe9, 0x12, 0x94, 0xb6, 0x83, 0x28, 0x4e, 0xbf, 0xf8, 0xde, 0x08, 0xa2, 0x18,
-	0x33, 0x88, 0xfd, 0x3b, 0x16, 0x0c, 0xb1, 0xcc, 0xb0, 0xfd, 0xd2, 0x15, 0x0f, 0xf2, 0x5d, 0xe8,
-	0x25, 0x18, 0x26, 0x9b, 0x9b, 0xa4, 0x19, 0x8b, 0x59, 0x95, 0xee, 0xa8, 0xc3, 0xcb, 0xac, 0x94,
-	0x5e, 0xfa, 0xac, 0x31, 0xfe, 0x17, 0x0b, 0x64, 0xf4, 0x16, 0x94, 0x63, 0x77, 0x97, 0x2c, 0xb4,
-	0x5a, 0xe2, 0xcd, 0xec, 0x01, 0xbc, 0x7f, 0xd7, 0x25, 0x01, 0x9c, 0xd0, 0xb2, 0xbf, 0x5a, 0x00,
-	0x48, 0x42, 0x08, 0xf4, 0xfb, 0xc4, 0xc5, 0xae, 0xd7, 0x94, 0xcb, 0x19, 0xaf, 0x29, 0x28, 0x21,
-	0x98, 0xf1, 0x94, 0xa2, 0x86, 0xa9, 0x38, 0xd0, 0x30, 0x95, 0x8e, 0x33, 0x4c, 0x4b, 0x30, 0x93,
-	0x84, 0x40, 0x30, 0xe3, 0xc1, 0x30, 0x21, 0x65, 0x3d, 0x0d, 0xc4, 0xdd, 0xf8, 0x36, 0x81, 0x4b,
-	0x32, 0x32, 0xa7, 0xbc, 0x6b, 0x98, 0x49, 0xe6, 0x31, 0x32, 0x57, 0x27, 0xcf, 0x45, 0x85, 0xdc,
-	0xe7, 0xa2, 0x1f, 0xb7, 0xe0, 0x6c, 0xba, 0x1d, 0xe6, 0xfb, 0xf6, 0x15, 0x0b, 0xce, 0xb1, 0x47,
-	0x33, 0xd6, 0x6a, 0xf7, 0x13, 0xdd, 0x8b, 0xd9, 0xa1, 0x21, 0x7a, 0xf7, 0x38, 0xf1, 0x7b, 0x5e,
-	0xcd, 0x22, 0x8d, 0xb3, 0x5b, 0xb4, 0xbf, 0x62, 0xc1, 0xf9, 0xdc, 0x84, 0x44, 0xe8, 0x0a, 0x8c,
-	0x3a, 0x6d, 0x97, 0x6b, 0xa4, 0xc4, 0x7e, 0x67, 0xd2, 0x63, 0xbd, 0xc6, 0xf5, 0x51, 0x0a, 0xaa,
-	0x12, 0x25, 0x16, 0x72, 0x13, 0x25, 0xf6, 0xcd, 0x7b, 0x68, 0x7f, 0xbf, 0x05, 0xc2, 0xdd, 0x69,
-	0x80, 0x43, 0xe6, 0x6d, 0x99, 0x67, 0xd6, 0x08, 0x8a, 0x7e, 0x29, 0xdf, 0xff, 0x4b, 0x84, 0x42,
-	0x57, 0x97, 0xba, 0x11, 0x00, 0xdd, 0xa0, 0x65, 0xb7, 0x40, 0x40, 0xab, 0x84, 0xe9, 0xac, 0xfa,
-	0xf7, 0xe6, 0x1a, 0x40, 0x8b, 0xe1, 0x6a, 0xd9, 0x26, 0xd5, 0x15, 0x52, 0x55, 0x10, 0xac, 0x61,
-	0xd9, 0x3f, 0x54, 0x80, 0x31, 0x19, 0x84, 0xbb, 0xe3, 0x0f, 0x22, 0x59, 0x1e, 0x2b, 0x2b, 0x0f,
-	0x4b, 0xcf, 0x4a, 0x09, 0xd7, 0x13, 0x81, 0x3c, 0x49, 0xcf, 0x2a, 0x01, 0x38, 0xc1, 0x41, 0x4f,
-	0xc3, 0x48, 0xd4, 0xd9, 0x60, 0xe8, 0x29, 0x27, 0x9e, 0x06, 0x2f, 0xc6, 0x12, 0x8e, 0x3e, 0x07,
-	0xd3, 0xbc, 0x5e, 0x18, 0xb4, 0x9d, 0x2d, 0xae, 0xfe, 0x1c, 0x52, 0x5e, 0xb5, 0xd3, 0xab, 0x29,
-	0xd8, 0xd1, 0x41, 0xe5, 0x6c, 0xba, 0x8c, 0x29, 0xce, 0xbb, 0xa8, 0xd8, 0x5f, 0x02, 0xd4, 0x1d,
-	0x57, 0x1c, 0xbd, 0xc1, 0x4d, 0xa9, 0xdc, 0x90, 0xb4, 0x7a, 0x69, 0xc4, 0x75, 0x27, 0x50, 0x69,
-	0x48, 0xcf, 0x6b, 0x61, 0x55, 0xdf, 0xfe, 0x9b, 0x45, 0x98, 0x4e, 0xbb, 0x04, 0xa2, 0x1b, 0x30,
-	0xcc, 0x2f, 0x3b, 0x41, 0xbe, 0xc7, 0x83, 0xab, 0xe6, 0x48, 0xc8, 0xb6, 0xbd, 0xb8, 0x2f, 0x45,
-	0x7d, 0xf4, 0x0e, 0x8c, 0xb5, 0x82, 0x7b, 0xfe, 0x3d, 0x27, 0x6c, 0x2d, 0xd4, 0x6b, 0x62, 0x5d,
-	0x66, 0xf2, 0xcc, 0xd5, 0x04, 0x4d, 0x77, 0x4e, 0x64, 0x8f, 0x0b, 0x09, 0x08, 0xeb, 0xe4, 0xd0,
-	0x3a, 0x8b, 0x95, 0xb8, 0xe9, 0x6e, 0xad, 0x3a, 0xed, 0x5e, 0x76, 0xb5, 0x4b, 0x12, 0x49, 0xa3,
-	0x3c, 0x21, 0x02, 0x2a, 0x72, 0x00, 0x4e, 0x08, 0xa1, 0xef, 0x86, 0x33, 0x51, 0x8e, 0x9a, 0x2d,
-	0x2f, 0xcd, 0x44, 0x2f, 0xcd, 0xd3, 0xe2, 0xa3, 0x54, 0x9a, 0xc9, 0x52, 0xc8, 0x65, 0x35, 0x63,
-	0x7f, 0xf9, 0x0c, 0x18, 0xbb, 0xd1, 0xc8, 0x3a, 0x64, 0x9d, 0x50, 0xd6, 0x21, 0x0c, 0xa3, 0x64,
-	0xb7, 0x1d, 0xef, 0x57, 0xdd, 0xb0, 0x57, 0x56, 0xbc, 0x65, 0x81, 0xd3, 0x4d, 0x53, 0x42, 0xb0,
-	0xa2, 0x93, 0x9d, 0x1a, 0xaa, 0xf8, 0x21, 0xa6, 0x86, 0x2a, 0x9d, 0x62, 0x6a, 0xa8, 0x35, 0x18,
-	0xd9, 0x72, 0x63, 0x4c, 0xda, 0x81, 0x60, 0x33, 0x33, 0xd7, 0xe1, 0x75, 0x8e, 0xd2, 0x9d, 0x84,
-	0x44, 0x00, 0xb0, 0x24, 0x82, 0xde, 0x50, 0x3b, 0x70, 0x38, 0x5f, 0x4a, 0xeb, 0x7e, 0x19, 0xcc,
-	0xdc, 0x83, 0x22, 0x01, 0xd4, 0xc8, 0x83, 0x26, 0x80, 0x5a, 0x91, 0x69, 0x9b, 0x46, 0xf3, 0x8d,
-	0xe0, 0x59, 0x56, 0xa6, 0x3e, 0xc9, 0x9a, 0xee, 0xea, 0xa9, 0xae, 0xca, 0xf9, 0x27, 0x81, 0xca,
-	0x62, 0x35, 0x60, 0x82, 0xab, 0xef, 0xb7, 0xe0, 0x5c, 0x3b, 0x2b, 0xeb, 0x9b, 0x48, 0xb6, 0xf4,
-	0xd2, 0xc0, 0x69, 0xed, 0x8c, 0x06, 0x99, 0xb8, 0x9e, 0x89, 0x86, 0xb3, 0x9b, 0xa3, 0x03, 0x1d,
-	0x6e, 0xb4, 0x44, 0x86, 0xa6, 0x27, 0x73, 0x32, 0x65, 0xf5, 0xc8, 0x8f, 0xb5, 0x9e, 0x91, 0x95,
-	0xe9, 0xe3, 0x79, 0x59, 0x99, 0x06, 0xce, 0xc5, 0xf4, 0x86, 0xca, 0x91, 0x35, 0x91, 0xbf, 0x94,
-	0x78, 0x06, 0xac, 0xbe, 0x99, 0xb1, 0xde, 0x50, 0x99, 0xb1, 0x7a, 0xc4, 0x8c, 0xe3, 0x79, 0xaf,
-	0xfa, 0xe6, 0xc3, 0xd2, 0x72, 0x5a, 0x4d, 0x9d, 0x4c, 0x4e, 0x2b, 0xe3, 0xaa, 0xe1, 0x69, 0x95,
-	0x9e, 0xe9, 0x73, 0xd5, 0x18, 0x74, 0x7b, 0x5f, 0x36, 0x3c, 0x7f, 0xd7, 0xcc, 0x03, 0xe5, 0xef,
-	0xba, 0xab, 0xe7, 0xc3, 0x42, 0x7d, 0x12, 0x3e, 0x51, 0xa4, 0x01, 0xb3, 0x60, 0xdd, 0xd5, 0x2f,
-	0xc0, 0x33, 0xf9, 0x74, 0xd5, 0x3d, 0xd7, 0x4d, 0x37, 0xf3, 0x0a, 0xec, 0xca, 0xae, 0x75, 0xf6,
-	0x74, 0xb2, 0x6b, 0x9d, 0x3b, 0xf1, 0xec, 0x5a, 0x8f, 0x9c, 0x42, 0x76, 0xad, 0x47, 0x3f, 0xd4,
-	0xec, 0x5a, 0xb3, 0x0f, 0x21, 0xbb, 0xd6, 0x5a, 0x92, 0x5d, 0xeb, 0x7c, 0xfe, 0x94, 0x64, 0x58,
-	0xe6, 0xe6, 0xe4, 0xd4, 0xba, 0xcb, 0x9e, 0xe7, 0x79, 0xcc, 0x0a, 0x11, 0xd4, 0x2e, 0x3b, 0x93,
-	0x70, 0x56, 0x60, 0x0b, 0x3e, 0x25, 0x0a, 0x84, 0x13, 0x52, 0x94, 0x6e, 0x92, 0x63, 0xeb, 0xb1,
-	0x1e, 0x0a, 0xd9, 0x2c, 0x55, 0x57, 0x7e, 0x66, 0x2d, 0xfb, 0xaf, 0x17, 0xe0, 0x62, 0xef, 0x75,
-	0x9d, 0xe8, 0xc9, 0xea, 0xc9, 0xbb, 0x4e, 0x4a, 0x4f, 0xc6, 0x85, 0x9c, 0x04, 0x6b, 0xe0, 0xc0,
-	0x3e, 0xd7, 0x61, 0x46, 0x99, 0xe4, 0x7a, 0x6e, 0x73, 0x5f, 0xcb, 0x30, 0xac, 0x5c, 0x0f, 0x1b,
-	0x69, 0x04, 0xdc, 0x5d, 0x07, 0x2d, 0xc0, 0x94, 0x51, 0x58, 0xab, 0x0a, 0x61, 0x46, 0x29, 0xe6,
-	0x1a, 0x26, 0x18, 0xa7, 0xf1, 0xed, 0x9f, 0xb6, 0xe0, 0xd1, 0x9c, 0xc4, 0x13, 0x03, 0xc7, 0xad,
-	0xd9, 0x84, 0xa9, 0xb6, 0x59, 0xb5, 0x4f, 0x78, 0x2b, 0x23, 0xbd, 0x85, 0xea, 0x6b, 0x0a, 0x80,
-	0xd3, 0x44, 0x17, 0xaf, 0xfc, 0xe6, 0xef, 0x5d, 0xfc, 0xd8, 0x6f, 0xfd, 0xde, 0xc5, 0x8f, 0xfd,
-	0xf6, 0xef, 0x5d, 0xfc, 0xd8, 0x5f, 0x3e, 0xbc, 0x68, 0xfd, 0xe6, 0xe1, 0x45, 0xeb, 0xb7, 0x0e,
-	0x2f, 0x5a, 0xbf, 0x7d, 0x78, 0xd1, 0xfa, 0xdd, 0xc3, 0x8b, 0xd6, 0x57, 0x7f, 0xff, 0xe2, 0xc7,
-	0xde, 0x2e, 0xec, 0x3d, 0xff, 0xff, 0x03, 0x00, 0x00, 0xff, 0xff, 0x84, 0x97, 0x9c, 0xb4, 0x50,
-	0xe8, 0x00, 0x00,
+	// 12751 bytes of a gzipped FileDescriptorProto
+	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xec, 0xbd, 0x6b, 0x6c, 0x24, 0x57,
+	0x76, 0x18, 0xbc, 0xd5, 0xdd, 0x7c, 0xf4, 0xe1, 0xfb, 0xce, 0x8b, 0x43, 0xcd, 0x4c, 0x8f, 0x4a,
+	0xbb, 0xa3, 0xd1, 0x4a, 0x22, 0x57, 0x23, 0x69, 0x25, 0xaf, 0x76, 0x65, 0x93, 0x6c, 0x72, 0x86,
+	0x9a, 0x21, 0xa7, 0x75, 0x9b, 0x33, 0xda, 0x95, 0xb5, 0xeb, 0x2d, 0x76, 0x5f, 0x92, 0x25, 0x16,
+	0xab, 0x5a, 0x55, 0xd5, 0x9c, 0xa1, 0x3e, 0x1b, 0xf8, 0xb2, 0x8e, 0x9d, 0xf8, 0x81, 0x60, 0x11,
+	0x1b, 0x79, 0xd8, 0x86, 0x03, 0x38, 0x0e, 0x6c, 0xc7, 0x49, 0x10, 0xc7, 0x8e, 0xed, 0xec, 0xda,
+	0x89, 0xe3, 0x24, 0x80, 0xf3, 0x67, 0xe3, 0x04, 0x08, 0xd6, 0x80, 0x11, 0xc6, 0xa6, 0x8d, 0x04,
+	0xfe, 0x91, 0x07, 0xe2, 0xfc, 0x31, 0x63, 0xc4, 0xc1, 0x7d, 0xd6, 0xbd, 0xd5, 0x55, 0xdd, 0xcd,
+	0x11, 0x87, 0x92, 0x8d, 0xfd, 0xd7, 0x7d, 0xcf, 0xb9, 0xe7, 0xde, 0xba, 0xcf, 0x73, 0xce, 0x3d,
+	0x0f, 0x78, 0x6d, 0xe7, 0xd5, 0x68, 0xd6, 0x0d, 0xe6, 0x76, 0xda, 0x1b, 0x24, 0xf4, 0x49, 0x4c,
+	0xa2, 0xb9, 0x3d, 0xe2, 0x37, 0x83, 0x70, 0x4e, 0x00, 0x9c, 0x96, 0x3b, 0xd7, 0x08, 0x42, 0x32,
+	0xb7, 0xf7, 0xc2, 0xdc, 0x16, 0xf1, 0x49, 0xe8, 0xc4, 0xa4, 0x39, 0xdb, 0x0a, 0x83, 0x38, 0x40,
+	0x88, 0xe3, 0xcc, 0x3a, 0x2d, 0x77, 0x96, 0xe2, 0xcc, 0xee, 0xbd, 0x30, 0xf3, 0xfc, 0x96, 0x1b,
+	0x6f, 0xb7, 0x37, 0x66, 0x1b, 0xc1, 0xee, 0xdc, 0x56, 0xb0, 0x15, 0xcc, 0x31, 0xd4, 0x8d, 0xf6,
+	0x26, 0xfb, 0xc7, 0xfe, 0xb0, 0x5f, 0x9c, 0xc4, 0xcc, 0x6a, 0xd2, 0x0c, 0x79, 0x18, 0x13, 0x3f,
+	0x72, 0x03, 0x3f, 0x7a, 0xde, 0x69, 0xb9, 0x11, 0x09, 0xf7, 0x48, 0x38, 0xd7, 0xda, 0xd9, 0xa2,
+	0xb0, 0xc8, 0x44, 0x98, 0xdb, 0x7b, 0x61, 0x83, 0xc4, 0x4e, 0x47, 0x8f, 0x66, 0x5e, 0x4a, 0xc8,
+	0xed, 0x3a, 0x8d, 0x6d, 0xd7, 0x27, 0xe1, 0xbe, 0xa4, 0x31, 0x17, 0x92, 0x28, 0x68, 0x87, 0x0d,
+	0x72, 0xac, 0x5a, 0xd1, 0xdc, 0x2e, 0x89, 0x9d, 0x8c, 0xaf, 0x9f, 0x99, 0xcb, 0xab, 0x15, 0xb6,
+	0xfd, 0xd8, 0xdd, 0xed, 0x6c, 0xe6, 0xd3, 0xbd, 0x2a, 0x44, 0x8d, 0x6d, 0xb2, 0xeb, 0x74, 0xd4,
+	0x7b, 0x31, 0xaf, 0x5e, 0x3b, 0x76, 0xbd, 0x39, 0xd7, 0x8f, 0xa3, 0x38, 0x4c, 0x57, 0xb2, 0xbf,
+	0x69, 0xc1, 0xd5, 0xf9, 0xb7, 0xea, 0x4b, 0x9e, 0x13, 0xc5, 0x6e, 0x63, 0xc1, 0x0b, 0x1a, 0x3b,
+	0xf5, 0x38, 0x08, 0xc9, 0xfd, 0xc0, 0x6b, 0xef, 0x92, 0x3a, 0x1b, 0x08, 0xf4, 0x1c, 0x0c, 0xef,
+	0xb1, 0xff, 0x2b, 0xd5, 0x69, 0xeb, 0xaa, 0x75, 0xbd, 0xbc, 0x30, 0xf9, 0x5b, 0x07, 0x95, 0x8f,
+	0x1d, 0x1e, 0x54, 0x86, 0xef, 0x8b, 0x72, 0xac, 0x30, 0xd0, 0x35, 0x18, 0xdc, 0x8c, 0xd6, 0xf7,
+	0x5b, 0x64, 0xba, 0xc0, 0x70, 0xc7, 0x05, 0xee, 0xe0, 0x72, 0x9d, 0x96, 0x62, 0x01, 0x45, 0x73,
+	0x50, 0x6e, 0x39, 0x61, 0xec, 0xc6, 0x6e, 0xe0, 0x4f, 0x17, 0xaf, 0x5a, 0xd7, 0x07, 0x16, 0xa6,
+	0x04, 0x6a, 0xb9, 0x26, 0x01, 0x38, 0xc1, 0xa1, 0xdd, 0x08, 0x89, 0xd3, 0xbc, 0xeb, 0x7b, 0xfb,
+	0xd3, 0xa5, 0xab, 0xd6, 0xf5, 0xe1, 0xa4, 0x1b, 0x58, 0x94, 0x63, 0x85, 0x61, 0xff, 0x58, 0x01,
+	0x86, 0xe7, 0x37, 0x37, 0x5d, 0xdf, 0x8d, 0xf7, 0xd1, 0x7d, 0x18, 0xf5, 0x83, 0x26, 0x91, 0xff,
+	0xd9, 0x57, 0x8c, 0xdc, 0xb8, 0x3a, 0xdb, 0xb9, 0x32, 0x67, 0xd7, 0x34, 0xbc, 0x85, 0xc9, 0xc3,
+	0x83, 0xca, 0xa8, 0x5e, 0x82, 0x0d, 0x3a, 0x08, 0xc3, 0x48, 0x2b, 0x68, 0x2a, 0xb2, 0x05, 0x46,
+	0xb6, 0x92, 0x45, 0xb6, 0x96, 0xa0, 0x2d, 0x4c, 0x1c, 0x1e, 0x54, 0x46, 0xb4, 0x02, 0xac, 0x13,
+	0x41, 0x1b, 0x30, 0x41, 0xff, 0xfa, 0xb1, 0xab, 0xe8, 0x16, 0x19, 0xdd, 0xa7, 0xf2, 0xe8, 0x6a,
+	0xa8, 0x0b, 0x67, 0x0e, 0x0f, 0x2a, 0x13, 0xa9, 0x42, 0x9c, 0x26, 0x68, 0xbf, 0x0f, 0xe3, 0xf3,
+	0x71, 0xec, 0x34, 0xb6, 0x49, 0x93, 0xcf, 0x20, 0x7a, 0x09, 0x4a, 0xbe, 0xb3, 0x4b, 0xc4, 0xfc,
+	0x5e, 0x15, 0x03, 0x5b, 0x5a, 0x73, 0x76, 0xc9, 0xd1, 0x41, 0x65, 0xf2, 0x9e, 0xef, 0xbe, 0xd7,
+	0x16, 0xab, 0x82, 0x96, 0x61, 0x86, 0x8d, 0x6e, 0x00, 0x34, 0xc9, 0x9e, 0xdb, 0x20, 0x35, 0x27,
+	0xde, 0x16, 0xf3, 0x8d, 0x44, 0x5d, 0xa8, 0x2a, 0x08, 0xd6, 0xb0, 0xec, 0x87, 0x50, 0x9e, 0xdf,
+	0x0b, 0xdc, 0x66, 0x2d, 0x68, 0x46, 0x68, 0x07, 0x26, 0x5a, 0x21, 0xd9, 0x24, 0xa1, 0x2a, 0x9a,
+	0xb6, 0xae, 0x16, 0xaf, 0x8f, 0xdc, 0xb8, 0x9e, 0xf9, 0xb1, 0x26, 0xea, 0x92, 0x1f, 0x87, 0xfb,
+	0x0b, 0x17, 0x44, 0x7b, 0x13, 0x29, 0x28, 0x4e, 0x53, 0xb6, 0xff, 0x75, 0x01, 0xce, 0xcd, 0xbf,
+	0xdf, 0x0e, 0x49, 0xd5, 0x8d, 0x76, 0xd2, 0x2b, 0xbc, 0xe9, 0x46, 0x3b, 0x6b, 0xc9, 0x08, 0xa8,
+	0xa5, 0x55, 0x15, 0xe5, 0x58, 0x61, 0xa0, 0xe7, 0x61, 0x88, 0xfe, 0xbe, 0x87, 0x57, 0xc4, 0x27,
+	0x9f, 0x11, 0xc8, 0x23, 0x55, 0x27, 0x76, 0xaa, 0x1c, 0x84, 0x25, 0x0e, 0x5a, 0x85, 0x91, 0x06,
+	0xdb, 0x90, 0x5b, 0xab, 0x41, 0x93, 0xb0, 0xc9, 0x2c, 0x2f, 0x3c, 0x4b, 0xd1, 0x17, 0x93, 0xe2,
+	0xa3, 0x83, 0xca, 0x34, 0xef, 0x9b, 0x20, 0xa1, 0xc1, 0xb0, 0x5e, 0x1f, 0xd9, 0x6a, 0x7f, 0x95,
+	0x18, 0x25, 0xc8, 0xd8, 0x5b, 0xd7, 0xb5, 0xad, 0x32, 0xc0, 0xb6, 0xca, 0x68, 0xf6, 0x36, 0x41,
+	0x2f, 0x40, 0x69, 0xc7, 0xf5, 0x9b, 0xd3, 0x83, 0x8c, 0xd6, 0x65, 0x3a, 0xe7, 0xb7, 0x5d, 0xbf,
+	0x79, 0x74, 0x50, 0x99, 0x32, 0xba, 0x43, 0x0b, 0x31, 0x43, 0xb5, 0xff, 0xd8, 0x82, 0x0a, 0x83,
+	0x2d, 0xbb, 0x1e, 0xa9, 0x91, 0x30, 0x72, 0xa3, 0x98, 0xf8, 0xb1, 0x31, 0xa0, 0x37, 0x00, 0x22,
+	0xd2, 0x08, 0x49, 0xac, 0x0d, 0xa9, 0x5a, 0x18, 0x75, 0x05, 0xc1, 0x1a, 0x16, 0x3d, 0x10, 0xa2,
+	0x6d, 0x27, 0x64, 0xeb, 0x4b, 0x0c, 0xac, 0x3a, 0x10, 0xea, 0x12, 0x80, 0x13, 0x1c, 0xe3, 0x40,
+	0x28, 0xf6, 0x3a, 0x10, 0xd0, 0xe7, 0x60, 0x22, 0x69, 0x2c, 0x6a, 0x39, 0x0d, 0x39, 0x80, 0x6c,
+	0xcb, 0xd4, 0x4d, 0x10, 0x4e, 0xe3, 0xda, 0x7f, 0xdf, 0x12, 0x8b, 0x87, 0x7e, 0xf5, 0x47, 0xfc,
+	0x5b, 0xed, 0x5f, 0xb5, 0x60, 0x68, 0xc1, 0xf5, 0x9b, 0xae, 0xbf, 0x85, 0xbe, 0x0c, 0xc3, 0xf4,
+	0x6e, 0x6a, 0x3a, 0xb1, 0x23, 0xce, 0xbd, 0x4f, 0x69, 0x7b, 0x4b, 0x5d, 0x15, 0xb3, 0xad, 0x9d,
+	0x2d, 0x5a, 0x10, 0xcd, 0x52, 0x6c, 0xba, 0xdb, 0xee, 0x6e, 0xbc, 0x4b, 0x1a, 0xf1, 0x2a, 0x89,
+	0x9d, 0xe4, 0x73, 0x92, 0x32, 0xac, 0xa8, 0xa2, 0xdb, 0x30, 0x18, 0x3b, 0xe1, 0x16, 0x89, 0xc5,
+	0x01, 0x98, 0x79, 0x50, 0xf1, 0x9a, 0x98, 0xee, 0x48, 0xe2, 0x37, 0x48, 0x72, 0x2d, 0xac, 0xb3,
+	0xaa, 0x58, 0x90, 0xb0, 0x7f, 0x70, 0x10, 0x2e, 0x2e, 0xd6, 0x57, 0x72, 0xd6, 0xd5, 0x35, 0x18,
+	0x6c, 0x86, 0xee, 0x1e, 0x09, 0xc5, 0x38, 0x2b, 0x2a, 0x55, 0x56, 0x8a, 0x05, 0x14, 0xbd, 0x0a,
+	0xa3, 0xfc, 0x42, 0xba, 0xe5, 0xf8, 0x4d, 0x4f, 0x0e, 0xf1, 0x59, 0x81, 0x3d, 0x7a, 0x5f, 0x83,
+	0x61, 0x03, 0xf3, 0x98, 0x8b, 0xea, 0x5a, 0x6a, 0x33, 0xe6, 0x5d, 0x76, 0x3f, 0x60, 0xc1, 0x24,
+	0x6f, 0x66, 0x3e, 0x8e, 0x43, 0x77, 0xa3, 0x1d, 0x93, 0x68, 0x7a, 0x80, 0x9d, 0x74, 0x8b, 0x59,
+	0xa3, 0x95, 0x3b, 0x02, 0xb3, 0xf7, 0x53, 0x54, 0xf8, 0x21, 0x38, 0x2d, 0xda, 0x9d, 0x4c, 0x83,
+	0x71, 0x47, 0xb3, 0xe8, 0x7b, 0x2d, 0x98, 0x69, 0x04, 0x7e, 0x1c, 0x06, 0x9e, 0x47, 0xc2, 0x5a,
+	0x7b, 0xc3, 0x73, 0xa3, 0x6d, 0xbe, 0x4e, 0x31, 0xd9, 0x64, 0x27, 0x41, 0xce, 0x1c, 0x2a, 0x24,
+	0x31, 0x87, 0x57, 0x0e, 0x0f, 0x2a, 0x33, 0x8b, 0xb9, 0xa4, 0x70, 0x97, 0x66, 0xd0, 0x0e, 0x20,
+	0x7a, 0x95, 0xd6, 0x63, 0x67, 0x8b, 0x24, 0x8d, 0x0f, 0xf5, 0xdf, 0xf8, 0xf9, 0xc3, 0x83, 0x0a,
+	0x5a, 0xeb, 0x20, 0x81, 0x33, 0xc8, 0xa2, 0xf7, 0xe0, 0x2c, 0x2d, 0xed, 0xf8, 0xd6, 0xe1, 0xfe,
+	0x9b, 0x9b, 0x3e, 0x3c, 0xa8, 0x9c, 0x5d, 0xcb, 0x20, 0x82, 0x33, 0x49, 0xcf, 0x2c, 0xc2, 0xb9,
+	0xcc, 0xa9, 0x42, 0x93, 0x50, 0xdc, 0x21, 0x9c, 0x05, 0x29, 0x63, 0xfa, 0x13, 0x9d, 0x85, 0x81,
+	0x3d, 0xc7, 0x6b, 0x8b, 0x55, 0x8a, 0xf9, 0x9f, 0xcf, 0x14, 0x5e, 0xb5, 0xec, 0x06, 0x8c, 0x2e,
+	0x3a, 0x2d, 0x67, 0xc3, 0xf5, 0xdc, 0xd8, 0x25, 0x11, 0x7a, 0x1a, 0x8a, 0x4e, 0xb3, 0xc9, 0xae,
+	0xc8, 0xf2, 0xc2, 0xb9, 0xc3, 0x83, 0x4a, 0x71, 0xbe, 0x49, 0xcf, 0x6a, 0x50, 0x58, 0xfb, 0x98,
+	0x62, 0xa0, 0x4f, 0x42, 0xa9, 0x19, 0x06, 0xad, 0xe9, 0x02, 0xc3, 0xa4, 0x43, 0x55, 0xaa, 0x86,
+	0x41, 0x2b, 0x85, 0xca, 0x70, 0x6c, 0x17, 0x2e, 0x2c, 0x3a, 0x51, 0xc3, 0x69, 0x76, 0xde, 0x8b,
+	0x74, 0xbb, 0xb9, 0xd1, 0x8e, 0xe2, 0xfb, 0x92, 0xed, 0xc6, 0x4a, 0xb1, 0x80, 0xf6, 0xcb, 0xf3,
+	0xd9, 0xbf, 0x51, 0x80, 0x4b, 0x8b, 0xa4, 0xb5, 0xbd, 0x5c, 0xcf, 0xd9, 0xdf, 0xd7, 0x61, 0x78,
+	0x37, 0xf0, 0xdd, 0x38, 0x08, 0x23, 0xf1, 0x95, 0xec, 0xe2, 0x5a, 0x15, 0x65, 0x58, 0x41, 0xd1,
+	0x55, 0x28, 0xb5, 0x12, 0xa6, 0x63, 0x54, 0x32, 0x2c, 0x8c, 0xdd, 0x60, 0x10, 0x8a, 0xd1, 0x8e,
+	0x48, 0x28, 0x2e, 0x5c, 0x85, 0x71, 0x2f, 0x22, 0x21, 0x66, 0x90, 0xe4, 0xe4, 0xa6, 0x67, 0xba,
+	0xd8, 0xc1, 0xa9, 0x93, 0x9b, 0x42, 0xb0, 0x86, 0x85, 0x6a, 0x50, 0x8e, 0xd4, 0xfa, 0x19, 0xe8,
+	0x7f, 0xfd, 0x8c, 0xb1, 0xa3, 0x5d, 0x2d, 0x9a, 0x84, 0x88, 0x71, 0xe2, 0x0c, 0xf6, 0x3c, 0xda,
+	0xbf, 0x5e, 0x00, 0xc4, 0x87, 0xf0, 0xcf, 0xd9, 0xc0, 0xdd, 0xeb, 0x1c, 0xb8, 0x4c, 0x26, 0xef,
+	0x4e, 0xd0, 0x70, 0xbc, 0xf4, 0x6d, 0x71, 0x52, 0xa3, 0xf7, 0xbf, 0x2d, 0xb8, 0xb4, 0xe8, 0xfa,
+	0x4d, 0x12, 0xe6, 0x2c, 0xc0, 0xc7, 0x23, 0xeb, 0x1c, 0xef, 0x52, 0x31, 0x96, 0x58, 0xe9, 0x04,
+	0x96, 0x98, 0xfd, 0x3f, 0x2c, 0x40, 0xfc, 0xb3, 0x3f, 0x72, 0x1f, 0x7b, 0xaf, 0xf3, 0x63, 0x4f,
+	0x60, 0x59, 0xd8, 0x77, 0x60, 0x7c, 0xd1, 0x73, 0x89, 0x1f, 0xaf, 0xd4, 0x16, 0x03, 0x7f, 0xd3,
+	0xdd, 0x42, 0x9f, 0x81, 0x71, 0x2a, 0x3e, 0x07, 0xed, 0xb8, 0x4e, 0x1a, 0x81, 0xcf, 0x24, 0x0d,
+	0x2a, 0x74, 0xa2, 0xc3, 0x83, 0xca, 0xf8, 0xba, 0x01, 0xc1, 0x29, 0x4c, 0xfb, 0x77, 0xe9, 0xf8,
+	0x05, 0xbb, 0xad, 0xc0, 0x27, 0x7e, 0xbc, 0x18, 0xf8, 0x4d, 0x2e, 0x91, 0x7e, 0x06, 0x4a, 0x31,
+	0x1d, 0x0f, 0x3e, 0x76, 0xd7, 0xe4, 0x46, 0xa1, 0xa3, 0x70, 0x74, 0x50, 0x39, 0xdf, 0x59, 0x83,
+	0x8d, 0x13, 0xab, 0x83, 0xbe, 0x0d, 0x06, 0xa3, 0xd8, 0x89, 0xdb, 0x91, 0x18, 0xcd, 0x27, 0xe5,
+	0x68, 0xd6, 0x59, 0xe9, 0xd1, 0x41, 0x65, 0x42, 0x55, 0xe3, 0x45, 0x58, 0x54, 0x40, 0xcf, 0xc0,
+	0xd0, 0x2e, 0x89, 0x22, 0x67, 0x4b, 0x0a, 0x13, 0x13, 0xa2, 0xee, 0xd0, 0x2a, 0x2f, 0xc6, 0x12,
+	0x8e, 0x9e, 0x82, 0x01, 0x12, 0x86, 0x41, 0x28, 0xf6, 0xe8, 0x98, 0x40, 0x1c, 0x58, 0xa2, 0x85,
+	0x98, 0xc3, 0xec, 0x7f, 0x67, 0xc1, 0x84, 0xea, 0x2b, 0x6f, 0xeb, 0x14, 0xb8, 0xc6, 0xb7, 0x01,
+	0x1a, 0xf2, 0x03, 0x23, 0x76, 0x51, 0x8d, 0xdc, 0xb8, 0x96, 0xc9, 0x0b, 0x75, 0x0c, 0x63, 0x42,
+	0x59, 0x15, 0x45, 0x58, 0xa3, 0x66, 0xff, 0xba, 0x05, 0x67, 0x52, 0x5f, 0x74, 0xc7, 0x8d, 0x62,
+	0xf4, 0x4e, 0xc7, 0x57, 0xcd, 0xf6, 0xf7, 0x55, 0xb4, 0x36, 0xfb, 0x26, 0xb5, 0x94, 0x65, 0x89,
+	0xf6, 0x45, 0xb7, 0x60, 0xc0, 0x8d, 0xc9, 0xae, 0xfc, 0x98, 0xa7, 0xba, 0x7e, 0x0c, 0xef, 0x55,
+	0x32, 0x23, 0x2b, 0xb4, 0x26, 0xe6, 0x04, 0xec, 0x1f, 0x29, 0x42, 0x99, 0x2f, 0xdb, 0x55, 0xa7,
+	0x75, 0x0a, 0x73, 0xb1, 0x02, 0x25, 0x46, 0x9d, 0x77, 0xfc, 0xe9, 0xec, 0x8e, 0x8b, 0xee, 0xcc,
+	0x52, 0x91, 0x90, 0x73, 0x9d, 0xea, 0x6a, 0xa0, 0x45, 0x98, 0x91, 0x40, 0x0e, 0xc0, 0x86, 0xeb,
+	0x3b, 0xe1, 0x3e, 0x2d, 0x9b, 0x2e, 0x32, 0x82, 0xcf, 0x77, 0x27, 0xb8, 0xa0, 0xf0, 0x39, 0x59,
+	0xd5, 0xd7, 0x04, 0x80, 0x35, 0xa2, 0x33, 0xaf, 0x40, 0x59, 0x21, 0x1f, 0x87, 0x9d, 0x9a, 0xf9,
+	0x1c, 0x4c, 0xa4, 0xda, 0xea, 0x55, 0x7d, 0x54, 0xe7, 0xc6, 0xbe, 0xc6, 0x4e, 0x01, 0xd1, 0xeb,
+	0x25, 0x7f, 0x4f, 0x9c, 0xa2, 0xef, 0xc3, 0x59, 0x2f, 0xe3, 0x70, 0x12, 0x53, 0xd5, 0xff, 0x61,
+	0x76, 0x49, 0x7c, 0xf6, 0xd9, 0x2c, 0x28, 0xce, 0x6c, 0x83, 0x5e, 0xfb, 0x41, 0x8b, 0xae, 0x79,
+	0xc7, 0x63, 0xfd, 0x15, 0x82, 0xfe, 0x5d, 0x51, 0x86, 0x15, 0x94, 0x1e, 0x61, 0x67, 0x55, 0xe7,
+	0x6f, 0x93, 0xfd, 0x3a, 0xf1, 0x48, 0x23, 0x0e, 0xc2, 0x0f, 0xb5, 0xfb, 0x97, 0xf9, 0xe8, 0xf3,
+	0x13, 0x70, 0x44, 0x10, 0x28, 0xde, 0x26, 0xfb, 0x7c, 0x2a, 0xf4, 0xaf, 0x2b, 0x76, 0xfd, 0xba,
+	0x5f, 0xb0, 0x60, 0x4c, 0x7d, 0xdd, 0x29, 0x6c, 0xf5, 0x05, 0x73, 0xab, 0x5f, 0xee, 0xba, 0xc0,
+	0x73, 0x36, 0xf9, 0xd7, 0x0b, 0x70, 0x51, 0xe1, 0x50, 0xc9, 0x82, 0xff, 0x11, 0xab, 0x6a, 0x0e,
+	0xca, 0xbe, 0x52, 0x54, 0x58, 0xa6, 0x86, 0x20, 0x51, 0x53, 0x24, 0x38, 0x94, 0x6b, 0xf3, 0x13,
+	0x6d, 0xc2, 0xa8, 0xae, 0xc1, 0x13, 0xda, 0xba, 0x05, 0x28, 0xb6, 0xdd, 0xa6, 0xb8, 0x33, 0x3e,
+	0x25, 0x47, 0xfb, 0xde, 0x4a, 0xf5, 0xe8, 0xa0, 0xf2, 0x64, 0x9e, 0xf6, 0x98, 0x5e, 0x56, 0xd1,
+	0xec, 0xbd, 0x95, 0x2a, 0xa6, 0x95, 0xd1, 0x3c, 0x4c, 0x48, 0x05, 0xf9, 0x7d, 0xca, 0x41, 0x05,
+	0xbe, 0xb8, 0x5a, 0x94, 0x1a, 0x0e, 0x9b, 0x60, 0x9c, 0xc6, 0x47, 0x55, 0x98, 0xdc, 0x69, 0x6f,
+	0x10, 0x8f, 0xc4, 0xfc, 0x83, 0x6f, 0x13, 0xae, 0xa4, 0x2a, 0x27, 0x52, 0xec, 0xed, 0x14, 0x1c,
+	0x77, 0xd4, 0xb0, 0xff, 0x8c, 0x1d, 0xf1, 0x62, 0xf4, 0x6a, 0x61, 0x40, 0x17, 0x16, 0xa5, 0xfe,
+	0x61, 0x2e, 0xe7, 0x7e, 0x56, 0xc5, 0x6d, 0xb2, 0xbf, 0x1e, 0x50, 0x66, 0x3b, 0x7b, 0x55, 0x18,
+	0x6b, 0xbe, 0xd4, 0x75, 0xcd, 0xff, 0x52, 0x01, 0xce, 0xa9, 0x11, 0x30, 0xf8, 0xba, 0x3f, 0xef,
+	0x63, 0xf0, 0x02, 0x8c, 0x34, 0xc9, 0xa6, 0xd3, 0xf6, 0x62, 0xa5, 0x31, 0x1d, 0xe0, 0x5a, 0xf3,
+	0x6a, 0x52, 0x8c, 0x75, 0x9c, 0x63, 0x0c, 0xdb, 0x4f, 0x8f, 0xb0, 0xbb, 0x35, 0x76, 0xe8, 0x1a,
+	0x57, 0xbb, 0xc6, 0xca, 0xdd, 0x35, 0x4f, 0xc1, 0x80, 0xbb, 0x4b, 0x79, 0xad, 0x82, 0xc9, 0x42,
+	0xad, 0xd0, 0x42, 0xcc, 0x61, 0xe8, 0x13, 0x30, 0xd4, 0x08, 0x76, 0x77, 0x1d, 0xbf, 0xc9, 0xae,
+	0xbc, 0xf2, 0xc2, 0x08, 0x65, 0xc7, 0x16, 0x79, 0x11, 0x96, 0x30, 0x74, 0x09, 0x4a, 0x4e, 0xb8,
+	0x15, 0x4d, 0x97, 0x18, 0xce, 0x30, 0x6d, 0x69, 0x3e, 0xdc, 0x8a, 0x30, 0x2b, 0xa5, 0x52, 0xd5,
+	0x83, 0x20, 0xdc, 0x71, 0xfd, 0xad, 0xaa, 0x1b, 0x8a, 0x2d, 0xa1, 0xee, 0xc2, 0xb7, 0x14, 0x04,
+	0x6b, 0x58, 0x68, 0x19, 0x06, 0x5a, 0x41, 0x18, 0x47, 0xd3, 0x83, 0x6c, 0xb8, 0x9f, 0xcc, 0x39,
+	0x88, 0xf8, 0xd7, 0xd6, 0x82, 0x30, 0x4e, 0x3e, 0x80, 0xfe, 0x8b, 0x30, 0xaf, 0x8e, 0xbe, 0x0d,
+	0x8a, 0xc4, 0xdf, 0x9b, 0x1e, 0x62, 0x54, 0x66, 0xb2, 0xa8, 0x2c, 0xf9, 0x7b, 0xf7, 0x9d, 0x30,
+	0x39, 0xa5, 0x97, 0xfc, 0x3d, 0x4c, 0xeb, 0xa0, 0x2f, 0x40, 0x59, 0x6e, 0xf1, 0x48, 0x68, 0x54,
+	0x32, 0x97, 0x98, 0x3c, 0x18, 0x30, 0x79, 0xaf, 0xed, 0x86, 0x64, 0x97, 0xf8, 0x71, 0x94, 0x9c,
+	0x69, 0x12, 0x1a, 0xe1, 0x84, 0x1a, 0xfa, 0x82, 0x54, 0xe3, 0xad, 0x06, 0x6d, 0x3f, 0x8e, 0xa6,
+	0xcb, 0xac, 0x7b, 0x99, 0x0f, 0x2c, 0xf7, 0x13, 0xbc, 0xb4, 0x9e, 0x8f, 0x57, 0xc6, 0x06, 0x29,
+	0x84, 0x61, 0xcc, 0x73, 0xf7, 0x88, 0x4f, 0xa2, 0xa8, 0x16, 0x06, 0x1b, 0x64, 0x1a, 0x58, 0xcf,
+	0x2f, 0x66, 0xbf, 0x3b, 0x04, 0x1b, 0x64, 0x61, 0xea, 0xf0, 0xa0, 0x32, 0x76, 0x47, 0xaf, 0x83,
+	0x4d, 0x12, 0xe8, 0x1e, 0x8c, 0x53, 0xb9, 0xc6, 0x4d, 0x88, 0x8e, 0xf4, 0x22, 0xca, 0xa4, 0x0f,
+	0x6c, 0x54, 0xc2, 0x29, 0x22, 0xe8, 0x0d, 0x28, 0x7b, 0xee, 0x26, 0x69, 0xec, 0x37, 0x3c, 0x32,
+	0x3d, 0xca, 0x28, 0x66, 0x6e, 0xab, 0x3b, 0x12, 0x89, 0xcb, 0x45, 0xea, 0x2f, 0x4e, 0xaa, 0xa3,
+	0xfb, 0x70, 0x3e, 0x26, 0xe1, 0xae, 0xeb, 0x3b, 0x74, 0x3b, 0x08, 0x79, 0x81, 0xbd, 0xde, 0x8c,
+	0xb1, 0xf5, 0x76, 0x45, 0x0c, 0xdd, 0xf9, 0xf5, 0x4c, 0x2c, 0x9c, 0x53, 0x1b, 0xdd, 0x85, 0x09,
+	0xb6, 0x13, 0x6a, 0x6d, 0xcf, 0xab, 0x05, 0x9e, 0xdb, 0xd8, 0x9f, 0x1e, 0x67, 0x04, 0x3f, 0x21,
+	0xef, 0x85, 0x15, 0x13, 0x7c, 0x74, 0x50, 0x81, 0xe4, 0x1f, 0x4e, 0xd7, 0x46, 0x1b, 0x4c, 0x5d,
+	0xdf, 0x0e, 0xdd, 0x78, 0x9f, 0xae, 0x5f, 0xf2, 0x30, 0x9e, 0x9e, 0xe8, 0x2a, 0x0a, 0xeb, 0xa8,
+	0x4a, 0xa7, 0xaf, 0x17, 0xe2, 0x34, 0x41, 0xba, 0xb5, 0xa3, 0xb8, 0xe9, 0xfa, 0xd3, 0x93, 0xec,
+	0xc4, 0x50, 0x3b, 0xa3, 0x4e, 0x0b, 0x31, 0x87, 0x31, 0x55, 0x3d, 0xfd, 0x71, 0x97, 0x9e, 0xa0,
+	0x53, 0x0c, 0x31, 0x51, 0xd5, 0x4b, 0x00, 0x4e, 0x70, 0x28, 0x53, 0x13, 0xc7, 0xfb, 0xd3, 0x88,
+	0xa1, 0xaa, 0xed, 0xb2, 0xbe, 0xfe, 0x05, 0x4c, 0xcb, 0xd1, 0x1d, 0x18, 0x22, 0xfe, 0xde, 0x72,
+	0x18, 0xec, 0x4e, 0x9f, 0xc9, 0xdf, 0xb3, 0x4b, 0x1c, 0x85, 0x1f, 0xe8, 0x89, 0x80, 0x27, 0x8a,
+	0xb1, 0x24, 0x81, 0x1e, 0xc2, 0x74, 0xc6, 0x8c, 0xf0, 0x09, 0x38, 0xcb, 0x26, 0xe0, 0xb3, 0xa2,
+	0xee, 0xf4, 0x7a, 0x0e, 0xde, 0x51, 0x17, 0x18, 0xce, 0xa5, 0x8e, 0xbe, 0x08, 0x63, 0x7c, 0x43,
+	0xf1, 0x77, 0xbe, 0x68, 0xfa, 0x1c, 0xfb, 0x9a, 0xab, 0xf9, 0x9b, 0x93, 0x23, 0x2e, 0x9c, 0x13,
+	0x1d, 0x1a, 0xd3, 0x4b, 0x23, 0x6c, 0x52, 0xb3, 0x37, 0x60, 0x5c, 0x9d, 0x5b, 0x6c, 0xe9, 0xa0,
+	0x0a, 0x0c, 0x30, 0x6e, 0x47, 0xe8, 0xb7, 0xca, 0x74, 0xa6, 0x18, 0x27, 0x84, 0x79, 0x39, 0x9b,
+	0x29, 0xf7, 0x7d, 0xb2, 0xb0, 0x1f, 0x13, 0x2e, 0x55, 0x17, 0xb5, 0x99, 0x92, 0x00, 0x9c, 0xe0,
+	0xd8, 0xff, 0x97, 0x73, 0x8d, 0xc9, 0xe1, 0xd8, 0xc7, 0x75, 0xf0, 0x1c, 0x0c, 0x6f, 0x07, 0x51,
+	0x4c, 0xb1, 0x59, 0x1b, 0x03, 0x09, 0x9f, 0x78, 0x4b, 0x94, 0x63, 0x85, 0x81, 0x5e, 0x83, 0xb1,
+	0x86, 0xde, 0x80, 0xb8, 0xcb, 0xd4, 0x10, 0x18, 0xad, 0x63, 0x13, 0x17, 0xbd, 0x0a, 0xc3, 0xec,
+	0x95, 0xbe, 0x11, 0x78, 0x82, 0xc9, 0x92, 0x17, 0xf2, 0x70, 0x4d, 0x94, 0x1f, 0x69, 0xbf, 0xb1,
+	0xc2, 0x46, 0xd7, 0x60, 0x90, 0x76, 0x61, 0xa5, 0x26, 0x6e, 0x11, 0xa5, 0xaa, 0xb9, 0xc5, 0x4a,
+	0xb1, 0x80, 0xda, 0x7f, 0xbd, 0xa0, 0x8d, 0x32, 0x95, 0x48, 0x09, 0xaa, 0xc1, 0xd0, 0x03, 0xc7,
+	0x8d, 0x5d, 0x7f, 0x4b, 0xb0, 0x0b, 0xcf, 0x74, 0xbd, 0x52, 0x58, 0xa5, 0xb7, 0x78, 0x05, 0x7e,
+	0xe9, 0x89, 0x3f, 0x58, 0x92, 0xa1, 0x14, 0xc3, 0xb6, 0xef, 0x53, 0x8a, 0x85, 0x7e, 0x29, 0x62,
+	0x5e, 0x81, 0x53, 0x14, 0x7f, 0xb0, 0x24, 0x83, 0xde, 0x01, 0x90, 0xcb, 0x92, 0x34, 0xc5, 0xeb,
+	0xf8, 0x73, 0xbd, 0x89, 0xae, 0xab, 0x3a, 0x0b, 0xe3, 0xf4, 0x4a, 0x4d, 0xfe, 0x63, 0x8d, 0x9e,
+	0x1d, 0x33, 0xb6, 0xaa, 0xb3, 0x33, 0xe8, 0x3b, 0xe9, 0x49, 0xe0, 0x84, 0x31, 0x69, 0xce, 0xc7,
+	0x62, 0x70, 0x3e, 0xd9, 0x9f, 0x4c, 0xb1, 0xee, 0xee, 0x12, 0xfd, 0xd4, 0x10, 0x44, 0x70, 0x42,
+	0xcf, 0xfe, 0x95, 0x22, 0x4c, 0xe7, 0x75, 0x97, 0x2e, 0x3a, 0xf2, 0xd0, 0x8d, 0x17, 0x29, 0x37,
+	0x64, 0x99, 0x8b, 0x6e, 0x49, 0x94, 0x63, 0x85, 0x41, 0x67, 0x3f, 0x72, 0xb7, 0xa4, 0x48, 0x38,
+	0x90, 0xcc, 0x7e, 0x9d, 0x95, 0x62, 0x01, 0xa5, 0x78, 0x21, 0x71, 0x22, 0x61, 0x7e, 0xa1, 0xad,
+	0x12, 0xcc, 0x4a, 0xb1, 0x80, 0xea, 0xfa, 0xa6, 0x52, 0x0f, 0x7d, 0x93, 0x31, 0x44, 0x03, 0x27,
+	0x3b, 0x44, 0xe8, 0x4b, 0x00, 0x9b, 0xae, 0xef, 0x46, 0xdb, 0x8c, 0xfa, 0xe0, 0xb1, 0xa9, 0x2b,
+	0x5e, 0x6a, 0x59, 0x51, 0xc1, 0x1a, 0x45, 0xf4, 0x32, 0x8c, 0xa8, 0x0d, 0xb8, 0x52, 0x65, 0x6f,
+	0x51, 0xda, 0xdb, 0x7e, 0x72, 0x1a, 0x55, 0xb1, 0x8e, 0x67, 0xbf, 0x9b, 0x5e, 0x2f, 0x62, 0x07,
+	0x68, 0xe3, 0x6b, 0xf5, 0x3b, 0xbe, 0x85, 0xee, 0xe3, 0x6b, 0xff, 0x66, 0x11, 0x26, 0x8c, 0xc6,
+	0xda, 0x51, 0x1f, 0x67, 0xd6, 0x4d, 0x7a, 0xcf, 0x39, 0x31, 0x11, 0xfb, 0xcf, 0xee, 0xbd, 0x55,
+	0xf4, 0xbb, 0x90, 0xee, 0x00, 0x5e, 0x1f, 0x7d, 0x09, 0xca, 0x9e, 0x13, 0x31, 0xdd, 0x15, 0x11,
+	0xfb, 0xae, 0x1f, 0x62, 0x89, 0x1c, 0xe1, 0x44, 0xb1, 0x76, 0xd5, 0x70, 0xda, 0x09, 0x49, 0x7a,
+	0x21, 0x53, 0xde, 0x47, 0xda, 0xf7, 0xa8, 0x4e, 0x50, 0x06, 0x69, 0x1f, 0x73, 0x18, 0x7a, 0x15,
+	0x46, 0x43, 0xc2, 0x56, 0xc5, 0x22, 0x65, 0xe5, 0xd8, 0x32, 0x1b, 0x48, 0x78, 0x3e, 0xac, 0xc1,
+	0xb0, 0x81, 0x99, 0xb0, 0xf2, 0x83, 0x5d, 0x58, 0xf9, 0x67, 0x60, 0x88, 0xfd, 0x50, 0x2b, 0x40,
+	0xcd, 0xc6, 0x0a, 0x2f, 0xc6, 0x12, 0x9e, 0x5e, 0x30, 0xc3, 0x7d, 0x2e, 0x98, 0x4f, 0xc2, 0x78,
+	0xd5, 0x21, 0xbb, 0x81, 0xbf, 0xe4, 0x37, 0x5b, 0x81, 0xeb, 0xc7, 0x68, 0x1a, 0x4a, 0xec, 0x76,
+	0xe0, 0x7b, 0xbb, 0x44, 0x29, 0xe0, 0x12, 0x65, 0xcc, 0xed, 0x2d, 0x38, 0x57, 0x0d, 0x1e, 0xf8,
+	0x0f, 0x9c, 0xb0, 0x39, 0x5f, 0x5b, 0xd1, 0xe4, 0xdc, 0x35, 0x29, 0x67, 0x71, 0x7b, 0x99, 0xcc,
+	0x33, 0x55, 0xab, 0xc9, 0xef, 0xda, 0x65, 0xd7, 0x23, 0x39, 0xda, 0x88, 0xbf, 0x59, 0x30, 0x5a,
+	0x4a, 0xf0, 0xd5, 0x83, 0x91, 0x95, 0xfb, 0x60, 0xf4, 0x26, 0x0c, 0x6f, 0xba, 0xc4, 0x6b, 0x62,
+	0xb2, 0x29, 0x96, 0xd8, 0xd3, 0xf9, 0x26, 0x00, 0xcb, 0x14, 0x53, 0x6a, 0x9f, 0xb8, 0x94, 0xb6,
+	0x2c, 0x2a, 0x63, 0x45, 0x06, 0xed, 0xc0, 0xa4, 0x14, 0x03, 0x24, 0x54, 0x2c, 0xb8, 0x67, 0xba,
+	0xc9, 0x16, 0x26, 0xf1, 0xb3, 0x87, 0x07, 0x95, 0x49, 0x9c, 0x22, 0x83, 0x3b, 0x08, 0x53, 0xb1,
+	0x6c, 0x97, 0x1e, 0xad, 0x25, 0x36, 0xfc, 0x4c, 0x2c, 0x63, 0x12, 0x26, 0x2b, 0xb5, 0x7f, 0xc2,
+	0x82, 0x0b, 0x1d, 0x23, 0x23, 0x24, 0xed, 0x13, 0x9e, 0x85, 0xb4, 0xe4, 0x5b, 0xe8, 0x2d, 0xf9,
+	0xda, 0xff, 0xc0, 0x82, 0xb3, 0x4b, 0xbb, 0xad, 0x78, 0xbf, 0xea, 0x9a, 0xaf, 0x3b, 0xaf, 0xc0,
+	0xe0, 0x2e, 0x69, 0xba, 0xed, 0x5d, 0x31, 0x73, 0x15, 0x79, 0xfc, 0xac, 0xb2, 0xd2, 0xa3, 0x83,
+	0xca, 0x58, 0x3d, 0x0e, 0x42, 0x67, 0x8b, 0xf0, 0x02, 0x2c, 0xd0, 0xd9, 0x21, 0xee, 0xbe, 0x4f,
+	0xee, 0xb8, 0xbb, 0xae, 0x34, 0xe9, 0xe8, 0xaa, 0x3b, 0x9b, 0x95, 0x03, 0x3a, 0xfb, 0x66, 0xdb,
+	0xf1, 0x63, 0x37, 0xde, 0x17, 0x0f, 0x33, 0x92, 0x08, 0x4e, 0xe8, 0xd9, 0xdf, 0xb4, 0x60, 0x42,
+	0xae, 0xfb, 0xf9, 0x66, 0x33, 0x24, 0x51, 0x84, 0x66, 0xa0, 0xe0, 0xb6, 0x44, 0x2f, 0x41, 0xf4,
+	0xb2, 0xb0, 0x52, 0xc3, 0x05, 0xb7, 0x85, 0x6a, 0x50, 0xe6, 0x96, 0x21, 0xc9, 0xe2, 0xea, 0xcb,
+	0xbe, 0x84, 0xf5, 0x60, 0x5d, 0xd6, 0xc4, 0x09, 0x11, 0xc9, 0xc1, 0xb1, 0x33, 0xb3, 0x68, 0xbe,
+	0x7a, 0xdd, 0x12, 0xe5, 0x58, 0x61, 0xa0, 0xeb, 0x30, 0xec, 0x07, 0x4d, 0x6e, 0xa8, 0xc3, 0x6f,
+	0x3f, 0xb6, 0x64, 0xd7, 0x44, 0x19, 0x56, 0x50, 0xfb, 0x87, 0x2d, 0x18, 0x95, 0x5f, 0xd6, 0x27,
+	0x33, 0x49, 0xb7, 0x56, 0xc2, 0x48, 0x26, 0x5b, 0x8b, 0x32, 0x83, 0x0c, 0x62, 0xf0, 0x80, 0xc5,
+	0xe3, 0xf0, 0x80, 0xf6, 0x8f, 0x17, 0x60, 0x5c, 0x76, 0xa7, 0xde, 0xde, 0x88, 0x48, 0x8c, 0xd6,
+	0xa1, 0xec, 0xf0, 0x21, 0x27, 0x72, 0xc5, 0x3e, 0x95, 0x2d, 0x7c, 0x18, 0xf3, 0x93, 0x5c, 0xcb,
+	0xf3, 0xb2, 0x36, 0x4e, 0x08, 0x21, 0x0f, 0xa6, 0xfc, 0x20, 0x66, 0x47, 0xb4, 0x82, 0x77, 0x7b,
+	0x02, 0x49, 0x53, 0xbf, 0x28, 0xa8, 0x4f, 0xad, 0xa5, 0xa9, 0xe0, 0x4e, 0xc2, 0x68, 0x49, 0x2a,
+	0x3c, 0x8a, 0xf9, 0xe2, 0x86, 0x3e, 0x0b, 0xd9, 0xfa, 0x0e, 0xfb, 0xd7, 0x2c, 0x28, 0x4b, 0xb4,
+	0xd3, 0x78, 0xed, 0x5a, 0x85, 0xa1, 0x88, 0x4d, 0x82, 0x1c, 0x1a, 0xbb, 0x5b, 0xc7, 0xf9, 0x7c,
+	0x25, 0x37, 0x0f, 0xff, 0x1f, 0x61, 0x49, 0x83, 0xe9, 0xbb, 0x55, 0xf7, 0x3f, 0x22, 0xfa, 0x6e,
+	0xd5, 0x9f, 0x9c, 0x1b, 0xe6, 0xbf, 0xb2, 0x3e, 0x6b, 0x62, 0x2d, 0x65, 0x90, 0x5a, 0x21, 0xd9,
+	0x74, 0x1f, 0xa6, 0x19, 0xa4, 0x1a, 0x2b, 0xc5, 0x02, 0x8a, 0xde, 0x81, 0xd1, 0x86, 0x54, 0x74,
+	0x26, 0xc7, 0xc0, 0xb5, 0xae, 0x4a, 0x77, 0xf5, 0x3e, 0xc3, 0x8d, 0x78, 0x17, 0xb5, 0xfa, 0xd8,
+	0xa0, 0x66, 0x3e, 0xb7, 0x17, 0x7b, 0x3d, 0xb7, 0x27, 0x74, 0xf3, 0x1f, 0x9f, 0x7f, 0xd2, 0x82,
+	0x41, 0xae, 0x2e, 0xeb, 0x4f, 0xbf, 0xa8, 0x3d, 0x57, 0x25, 0x63, 0x77, 0x9f, 0x16, 0x8a, 0xe7,
+	0x27, 0xb4, 0x0a, 0x65, 0xf6, 0x83, 0xa9, 0x0d, 0x8a, 0xf9, 0xd6, 0xcb, 0xbc, 0x55, 0xbd, 0x83,
+	0xf7, 0x65, 0x35, 0x9c, 0x50, 0xb0, 0x7f, 0xb4, 0x48, 0x8f, 0xaa, 0x04, 0xd5, 0xb8, 0xc1, 0xad,
+	0xc7, 0x77, 0x83, 0x17, 0x1e, 0xd7, 0x0d, 0xbe, 0x05, 0x13, 0x0d, 0xed, 0x71, 0x2b, 0x99, 0xc9,
+	0xeb, 0x5d, 0x17, 0x89, 0xf6, 0x0e, 0xc6, 0x55, 0x46, 0x8b, 0x26, 0x11, 0x9c, 0xa6, 0x8a, 0xbe,
+	0x13, 0x46, 0xf9, 0x3c, 0x8b, 0x56, 0xb8, 0xc5, 0xc2, 0x27, 0xf2, 0xd7, 0x8b, 0xde, 0x04, 0x5b,
+	0x89, 0x75, 0xad, 0x3a, 0x36, 0x88, 0xd9, 0xbf, 0x32, 0x0c, 0x03, 0x4b, 0x7b, 0xc4, 0x8f, 0x4f,
+	0xe1, 0x40, 0x6a, 0xc0, 0xb8, 0xeb, 0xef, 0x05, 0xde, 0x1e, 0x69, 0x72, 0xf8, 0x71, 0x2e, 0xd7,
+	0xf3, 0x82, 0xf4, 0xf8, 0x8a, 0x41, 0x02, 0xa7, 0x48, 0x3e, 0x0e, 0x09, 0xf3, 0x26, 0x0c, 0xf2,
+	0xb9, 0x17, 0xe2, 0x65, 0xa6, 0x32, 0x98, 0x0d, 0xa2, 0xd8, 0x05, 0x89, 0xf4, 0xcb, 0xb5, 0xcf,
+	0xa2, 0x3a, 0x7a, 0x17, 0xc6, 0x37, 0xdd, 0x30, 0x8a, 0xa9, 0x68, 0x18, 0xc5, 0xce, 0x6e, 0xeb,
+	0x11, 0x24, 0x4a, 0x35, 0x0e, 0xcb, 0x06, 0x25, 0x9c, 0xa2, 0x8c, 0xb6, 0x60, 0x8c, 0x0a, 0x39,
+	0x49, 0x53, 0x43, 0xc7, 0x6e, 0x4a, 0xa9, 0x8c, 0xee, 0xe8, 0x84, 0xb0, 0x49, 0x97, 0x1e, 0x26,
+	0x0d, 0x26, 0x14, 0x0d, 0x33, 0x8e, 0x42, 0x1d, 0x26, 0x5c, 0x1a, 0xe2, 0x30, 0x7a, 0x26, 0x31,
+	0xb3, 0x95, 0xb2, 0x79, 0x26, 0x69, 0xc6, 0x29, 0x5f, 0x86, 0x32, 0xa1, 0x43, 0x48, 0x09, 0x0b,
+	0xc5, 0xf8, 0x5c, 0x7f, 0x7d, 0x5d, 0x75, 0x1b, 0x61, 0x60, 0xca, 0xf2, 0x4b, 0x92, 0x12, 0x4e,
+	0x88, 0xa2, 0x45, 0x18, 0x8c, 0x48, 0xe8, 0x92, 0x48, 0xa8, 0xc8, 0xbb, 0x4c, 0x23, 0x43, 0xe3,
+	0x66, 0xee, 0xfc, 0x37, 0x16, 0x55, 0xe9, 0xf2, 0x72, 0x98, 0x34, 0xc4, 0xb4, 0xe2, 0xda, 0xf2,
+	0x9a, 0x67, 0xa5, 0x58, 0x40, 0xd1, 0x1b, 0x30, 0x14, 0x12, 0x8f, 0x29, 0x8b, 0xc6, 0xfa, 0x5f,
+	0xe4, 0x5c, 0xf7, 0xc4, 0xeb, 0x61, 0x49, 0x00, 0xdd, 0x06, 0x14, 0x12, 0xca, 0x43, 0xb8, 0xfe,
+	0x96, 0x32, 0xe6, 0x10, 0xba, 0xee, 0x27, 0x44, 0xfb, 0x67, 0x70, 0x82, 0x21, 0x0d, 0x60, 0x71,
+	0x46, 0x35, 0x74, 0x13, 0xa6, 0x54, 0xe9, 0x8a, 0x1f, 0xc5, 0x8e, 0xdf, 0x20, 0x4c, 0xcd, 0x5d,
+	0x4e, 0xb8, 0x22, 0x9c, 0x46, 0xc0, 0x9d, 0x75, 0xec, 0x9f, 0xa3, 0xec, 0x0c, 0x1d, 0xad, 0x53,
+	0xe0, 0x05, 0x5e, 0x37, 0x79, 0x81, 0x8b, 0xb9, 0x33, 0x97, 0xc3, 0x07, 0x1c, 0x5a, 0x30, 0xa2,
+	0xcd, 0x6c, 0xb2, 0x66, 0xad, 0x2e, 0x6b, 0xb6, 0x0d, 0x93, 0x74, 0xa5, 0xdf, 0xdd, 0x60, 0x1e,
+	0x5f, 0x4d, 0xb6, 0x30, 0x0b, 0x8f, 0xb6, 0x30, 0xd5, 0x2b, 0xf3, 0x9d, 0x14, 0x41, 0xdc, 0xd1,
+	0x04, 0x7a, 0x45, 0x6a, 0x4e, 0x8a, 0x86, 0x91, 0x16, 0xd7, 0x8a, 0x1c, 0x1d, 0x54, 0x26, 0xb5,
+	0x0f, 0xd1, 0x35, 0x25, 0xf6, 0x97, 0xe5, 0x37, 0xaa, 0xd7, 0xfc, 0x86, 0x5a, 0x2c, 0xa9, 0xd7,
+	0x7c, 0xb5, 0x1c, 0x70, 0x82, 0x43, 0xf7, 0x28, 0x15, 0x41, 0xd2, 0xaf, 0xf9, 0x54, 0x40, 0xc1,
+	0x0c, 0x62, 0xbf, 0x08, 0xb0, 0xf4, 0x90, 0x34, 0xf8, 0x52, 0xd7, 0x1f, 0x20, 0xad, 0xfc, 0x07,
+	0x48, 0xfb, 0x3f, 0x58, 0x30, 0xbe, 0xbc, 0x68, 0x88, 0x89, 0xb3, 0x00, 0x5c, 0x36, 0x7a, 0xeb,
+	0xad, 0x35, 0xa9, 0x5b, 0xe7, 0xea, 0x51, 0x55, 0x8a, 0x35, 0x0c, 0x74, 0x11, 0x8a, 0x5e, 0xdb,
+	0x17, 0x22, 0xcb, 0xd0, 0xe1, 0x41, 0xa5, 0x78, 0xa7, 0xed, 0x63, 0x5a, 0xa6, 0x59, 0x08, 0x16,
+	0xfb, 0xb6, 0x10, 0xec, 0xe9, 0xc9, 0x85, 0x2a, 0x30, 0xf0, 0xe0, 0x81, 0xdb, 0xe4, 0xf6, 0xf2,
+	0x42, 0xef, 0xff, 0xd6, 0x5b, 0x2b, 0xd5, 0x08, 0xf3, 0x72, 0xfb, 0xab, 0x45, 0x98, 0x59, 0xf6,
+	0xc8, 0xc3, 0x0f, 0xe8, 0x33, 0xd0, 0xaf, 0x7d, 0xe3, 0xf1, 0xf8, 0xc5, 0xe3, 0xda, 0xb0, 0xf6,
+	0x1e, 0x8f, 0x4d, 0x18, 0xe2, 0x8f, 0xd9, 0xd2, 0x83, 0xe0, 0xb5, 0xac, 0xd6, 0xf3, 0x07, 0x64,
+	0x96, 0x3f, 0x8a, 0x0b, 0xcf, 0x01, 0x75, 0xd3, 0x8a, 0x52, 0x2c, 0x89, 0xcf, 0x7c, 0x06, 0x46,
+	0x75, 0xcc, 0x63, 0x19, 0xae, 0xff, 0xa5, 0x22, 0x4c, 0xd2, 0x1e, 0x3c, 0xd6, 0x89, 0xb8, 0xd7,
+	0x39, 0x11, 0x27, 0x6d, 0x51, 0xdc, 0x7b, 0x36, 0xde, 0x49, 0xcf, 0xc6, 0x0b, 0x79, 0xb3, 0x71,
+	0xda, 0x73, 0xf0, 0xbd, 0x16, 0x9c, 0x59, 0xf6, 0x82, 0xc6, 0x4e, 0xca, 0xea, 0xf7, 0x65, 0x18,
+	0xa1, 0xe7, 0x78, 0x64, 0x38, 0x2c, 0x19, 0x2e, 0x6c, 0x02, 0x84, 0x75, 0x3c, 0xad, 0xda, 0xbd,
+	0x7b, 0x2b, 0xd5, 0x2c, 0xcf, 0x37, 0x01, 0xc2, 0x3a, 0x9e, 0xfd, 0x0d, 0x0b, 0x2e, 0xdf, 0x5c,
+	0x5c, 0x4a, 0x96, 0x62, 0x96, 0x93, 0x41, 0xab, 0xa9, 0x75, 0x25, 0x91, 0x02, 0xab, 0xac, 0x17,
+	0x02, 0xfa, 0x51, 0x71, 0x2c, 0xfd, 0x59, 0x0b, 0xce, 0xdc, 0x74, 0x63, 0x7a, 0x2d, 0xa7, 0xdd,
+	0xc0, 0xe8, 0xbd, 0x1c, 0xb9, 0x71, 0x10, 0xee, 0xa7, 0xdd, 0xc0, 0xb0, 0x82, 0x60, 0x0d, 0x8b,
+	0xb7, 0xbc, 0xe7, 0x32, 0x33, 0xaa, 0x82, 0xa9, 0x8a, 0xc2, 0xa2, 0x1c, 0x2b, 0x0c, 0xfa, 0x61,
+	0x4d, 0x37, 0x64, 0xa2, 0xc4, 0xbe, 0x38, 0x61, 0xd5, 0x87, 0x55, 0x25, 0x00, 0x27, 0x38, 0xf6,
+	0x4f, 0x58, 0x70, 0xee, 0xa6, 0xd7, 0x8e, 0x62, 0x12, 0x6e, 0x46, 0x46, 0x67, 0x5f, 0x84, 0x32,
+	0x91, 0xe2, 0xba, 0xe8, 0xab, 0x62, 0x30, 0x95, 0x1c, 0xcf, 0x7d, 0xd0, 0x14, 0x5e, 0x1f, 0x9e,
+	0x03, 0xc7, 0xf3, 0x52, 0xfb, 0xc5, 0x02, 0x8c, 0xdd, 0x5a, 0x5f, 0xaf, 0xdd, 0x24, 0xb1, 0xb8,
+	0xc5, 0x7a, 0xab, 0x9a, 0xb1, 0xa6, 0x31, 0xeb, 0x26, 0x14, 0xb5, 0x63, 0xd7, 0x9b, 0xe5, 0x4e,
+	0xcf, 0xb3, 0x2b, 0x7e, 0x7c, 0x37, 0xac, 0xc7, 0xa1, 0xeb, 0x6f, 0x65, 0xea, 0xd8, 0xe4, 0x5d,
+	0x5b, 0xcc, 0xbb, 0x6b, 0xd1, 0x8b, 0x30, 0xc8, 0xbc, 0xae, 0xa5, 0x78, 0xf2, 0x84, 0x92, 0x29,
+	0x58, 0xe9, 0xd1, 0x41, 0xa5, 0x7c, 0x0f, 0xaf, 0xf0, 0x3f, 0x58, 0xa0, 0xa2, 0x7b, 0x30, 0xb2,
+	0x1d, 0xc7, 0xad, 0x5b, 0xc4, 0x69, 0x92, 0x50, 0x9e, 0x0e, 0x57, 0xb2, 0x4e, 0x07, 0x3a, 0x08,
+	0x1c, 0x2d, 0xd9, 0x50, 0x49, 0x59, 0x84, 0x75, 0x3a, 0x76, 0x1d, 0x20, 0x81, 0x9d, 0x90, 0x7e,
+	0xc1, 0xfe, 0x03, 0x0b, 0x86, 0xb8, 0x03, 0x5c, 0x88, 0x3e, 0x0b, 0x25, 0xf2, 0x90, 0x34, 0x04,
+	0xe7, 0x98, 0xd9, 0xe1, 0x84, 0xf1, 0xe0, 0xda, 0x72, 0xfa, 0x1f, 0xb3, 0x5a, 0xe8, 0x16, 0x0c,
+	0xd1, 0xde, 0xde, 0x54, 0xde, 0x80, 0x4f, 0xe6, 0x7d, 0xb1, 0x9a, 0x76, 0xce, 0xab, 0x88, 0x22,
+	0x2c, 0xab, 0x33, 0xcd, 0x6f, 0xa3, 0x55, 0xa7, 0x07, 0x58, 0xdc, 0xed, 0x9e, 0x5d, 0x5f, 0xac,
+	0x71, 0x24, 0x41, 0x8d, 0x6b, 0x7e, 0x65, 0x21, 0x4e, 0x88, 0xd8, 0xeb, 0x50, 0xa6, 0x93, 0x3a,
+	0xef, 0xb9, 0x4e, 0x77, 0xa5, 0xf3, 0xb3, 0x50, 0x96, 0x0a, 0xe0, 0x48, 0xf8, 0x50, 0x31, 0xaa,
+	0x52, 0x3f, 0x1c, 0xe1, 0x04, 0x6e, 0x6f, 0xc2, 0x59, 0xf6, 0xf2, 0xef, 0xc4, 0xdb, 0xc6, 0x1e,
+	0xeb, 0xbd, 0x98, 0x9f, 0x13, 0x82, 0x18, 0x9f, 0x99, 0x69, 0xcd, 0x77, 0x60, 0x54, 0x52, 0x4c,
+	0x84, 0x32, 0xfb, 0x8f, 0x4a, 0xf0, 0xc4, 0x4a, 0x3d, 0xdf, 0x37, 0xf2, 0x55, 0x18, 0xe5, 0x6c,
+	0x1a, 0x5d, 0xda, 0x8e, 0x27, 0xda, 0x55, 0xef, 0x62, 0xeb, 0x1a, 0x0c, 0x1b, 0x98, 0xe8, 0x32,
+	0x14, 0xdd, 0xf7, 0xfc, 0xb4, 0x19, 0xee, 0xca, 0x9b, 0x6b, 0x98, 0x96, 0x53, 0x30, 0xe5, 0xf8,
+	0xf8, 0x51, 0xaa, 0xc0, 0x8a, 0xeb, 0x7b, 0x1d, 0xc6, 0xdd, 0xa8, 0x11, 0xb9, 0x2b, 0x3e, 0x3d,
+	0x67, 0x12, 0xbf, 0xda, 0x44, 0x49, 0x40, 0x3b, 0xad, 0xa0, 0x38, 0x85, 0xad, 0x9d, 0xeb, 0x03,
+	0x7d, 0x73, 0x8d, 0x3d, 0x3d, 0x7d, 0x28, 0x43, 0xdc, 0x62, 0x5f, 0x17, 0x31, 0xa3, 0x36, 0xc1,
+	0x10, 0xf3, 0x0f, 0x8e, 0xb0, 0x84, 0x51, 0x09, 0xac, 0xb1, 0xed, 0xb4, 0xe6, 0xdb, 0xf1, 0x76,
+	0xd5, 0x8d, 0x1a, 0xc1, 0x1e, 0x09, 0xf7, 0x99, 0xf0, 0x3c, 0x9c, 0x48, 0x60, 0x0a, 0xb0, 0x78,
+	0x6b, 0xbe, 0x46, 0x31, 0x71, 0x67, 0x1d, 0x93, 0x2b, 0x84, 0x93, 0xe0, 0x0a, 0xe7, 0x61, 0x42,
+	0x36, 0x53, 0x27, 0x11, 0xbb, 0x23, 0x46, 0x58, 0xc7, 0x94, 0xa9, 0xad, 0x28, 0x56, 0xdd, 0x4a,
+	0xe3, 0xa3, 0x57, 0x60, 0xcc, 0xf5, 0xdd, 0xd8, 0x75, 0xe2, 0x20, 0x64, 0x37, 0x2c, 0x97, 0x93,
+	0x99, 0x25, 0xdb, 0x8a, 0x0e, 0xc0, 0x26, 0x9e, 0xfd, 0x87, 0x25, 0x98, 0x62, 0xd3, 0xf6, 0xad,
+	0x15, 0xf6, 0x91, 0x59, 0x61, 0xf7, 0x3a, 0x57, 0xd8, 0x49, 0xb0, 0xbb, 0x1f, 0xe6, 0x32, 0x7b,
+	0x17, 0xca, 0xca, 0x16, 0x58, 0x3a, 0x03, 0x58, 0x39, 0xce, 0x00, 0xbd, 0xb9, 0x0f, 0xf9, 0x8c,
+	0x5b, 0xcc, 0x7c, 0xc6, 0xfd, 0xdb, 0x16, 0x24, 0x26, 0x91, 0xe8, 0x16, 0x94, 0x5b, 0x01, 0x33,
+	0x3b, 0x08, 0xa5, 0x2d, 0xcf, 0x13, 0x99, 0x17, 0x15, 0xbf, 0x14, 0xf9, 0xf8, 0xd5, 0x64, 0x0d,
+	0x9c, 0x54, 0x46, 0x0b, 0x30, 0xd4, 0x0a, 0x49, 0x3d, 0x66, 0xde, 0xb6, 0x3d, 0xe9, 0xf0, 0x35,
+	0xc2, 0xf1, 0xb1, 0xac, 0x68, 0xff, 0x92, 0x05, 0xc0, 0x5f, 0x4a, 0x1d, 0x7f, 0x8b, 0x9c, 0x82,
+	0xf6, 0xb7, 0x0a, 0xa5, 0xa8, 0x45, 0x1a, 0xdd, 0x0c, 0x42, 0x92, 0xfe, 0xd4, 0x5b, 0xa4, 0x91,
+	0x0c, 0x38, 0xfd, 0x87, 0x59, 0x6d, 0xfb, 0xfb, 0x00, 0xc6, 0x13, 0xb4, 0x95, 0x98, 0xec, 0xa2,
+	0xe7, 0x0d, 0x97, 0xb8, 0x8b, 0x29, 0x97, 0xb8, 0x32, 0xc3, 0xd6, 0x14, 0x8d, 0xef, 0x42, 0x71,
+	0xd7, 0x79, 0x28, 0x34, 0x49, 0xcf, 0x76, 0xef, 0x06, 0xa5, 0x3f, 0xbb, 0xea, 0x3c, 0xe4, 0x32,
+	0xd3, 0xb3, 0x72, 0x81, 0xac, 0x3a, 0x0f, 0x8f, 0xb8, 0xd9, 0x07, 0x3b, 0xa4, 0xee, 0xb8, 0x51,
+	0xfc, 0x95, 0xff, 0x9c, 0xfc, 0x67, 0xcb, 0x8e, 0x36, 0xc2, 0xda, 0x72, 0x7d, 0xf1, 0x6e, 0xd8,
+	0x57, 0x5b, 0xae, 0x9f, 0x6e, 0xcb, 0xf5, 0xfb, 0x68, 0xcb, 0xf5, 0xd1, 0xfb, 0x30, 0x24, 0xde,
+	0xe8, 0x99, 0xad, 0xb7, 0xa9, 0xa5, 0xca, 0x6b, 0x4f, 0x3c, 0xf1, 0xf3, 0x36, 0xe7, 0xa4, 0x4c,
+	0x28, 0x4a, 0x7b, 0xb6, 0x2b, 0x1b, 0x44, 0x7f, 0xc3, 0x82, 0x71, 0xf1, 0x1b, 0x93, 0xf7, 0xda,
+	0x24, 0x8a, 0x05, 0xef, 0xf9, 0xe9, 0xfe, 0xfb, 0x20, 0x2a, 0xf2, 0xae, 0x7c, 0x5a, 0x1e, 0xb3,
+	0x26, 0xb0, 0x67, 0x8f, 0x52, 0xbd, 0x40, 0xff, 0xc8, 0x82, 0xb3, 0xbb, 0xce, 0x43, 0xde, 0x22,
+	0x2f, 0xc3, 0x4e, 0xec, 0x06, 0xc2, 0x76, 0xfd, 0xb3, 0xfd, 0x4d, 0x7f, 0x47, 0x75, 0xde, 0x49,
+	0x69, 0xe6, 0x7a, 0x36, 0x0b, 0xa5, 0x67, 0x57, 0x33, 0xfb, 0x35, 0xb3, 0x09, 0xc3, 0x72, 0xbd,
+	0x65, 0x48, 0xde, 0x55, 0x9d, 0xb1, 0x3e, 0xb6, 0x89, 0x84, 0xee, 0x97, 0x46, 0xdb, 0x11, 0x6b,
+	0xed, 0xb1, 0xb6, 0xf3, 0x2e, 0x8c, 0xea, 0x6b, 0xec, 0xb1, 0xb6, 0xf5, 0x1e, 0x9c, 0xc9, 0x58,
+	0x4b, 0x8f, 0xb5, 0xc9, 0x07, 0x70, 0x31, 0x77, 0x7d, 0x3c, 0xce, 0x86, 0xed, 0x5f, 0xb4, 0xf4,
+	0x73, 0xf0, 0x14, 0x54, 0xf0, 0x8b, 0xa6, 0x0a, 0xfe, 0x4a, 0xf7, 0x9d, 0x93, 0xa3, 0x87, 0x7f,
+	0x47, 0xef, 0x34, 0x3d, 0xd5, 0xd1, 0x1b, 0x30, 0xe8, 0xd1, 0x12, 0x69, 0x1c, 0x62, 0xf7, 0xde,
+	0x91, 0x09, 0x2f, 0xc5, 0xca, 0x23, 0x2c, 0x28, 0xd8, 0xbf, 0x6a, 0x41, 0xe9, 0x14, 0x46, 0x02,
+	0x9b, 0x23, 0xf1, 0x7c, 0x2e, 0x69, 0x11, 0x3d, 0x6d, 0x16, 0x3b, 0x0f, 0x96, 0x64, 0x84, 0xb8,
+	0x9c, 0x81, 0xf9, 0x2e, 0x38, 0x73, 0x27, 0x70, 0x9a, 0x0b, 0x8e, 0xe7, 0xf8, 0x0d, 0x12, 0xae,
+	0xf8, 0x5b, 0x3d, 0xad, 0x94, 0x74, 0x9b, 0xa2, 0x42, 0x2f, 0x9b, 0x22, 0x7b, 0x1b, 0x90, 0xde,
+	0x80, 0xb0, 0xe3, 0xc4, 0x30, 0xe4, 0xf2, 0xa6, 0xc4, 0xf0, 0x3f, 0x9d, 0xcd, 0xdd, 0x75, 0xf4,
+	0x4c, 0xb3, 0x50, 0xe4, 0x05, 0x58, 0x12, 0xb2, 0x5f, 0x85, 0x4c, 0xdf, 0xad, 0xde, 0x6a, 0x03,
+	0xfb, 0x65, 0x98, 0x62, 0x35, 0x8f, 0x27, 0xd2, 0xda, 0x3f, 0x60, 0xc1, 0xc4, 0x5a, 0x2a, 0x36,
+	0xc5, 0x35, 0xf6, 0xd6, 0x97, 0xa1, 0xf7, 0xad, 0xb3, 0x52, 0x2c, 0xa0, 0x27, 0xae, 0x5f, 0xfa,
+	0x33, 0x0b, 0x12, 0x57, 0xc9, 0x53, 0x60, 0xaa, 0x16, 0x0d, 0xa6, 0x2a, 0x53, 0xef, 0xa1, 0xba,
+	0x93, 0xc7, 0x53, 0xa1, 0xdb, 0x2a, 0x2e, 0x40, 0x17, 0x95, 0x47, 0x42, 0x86, 0x7b, 0x91, 0x8f,
+	0x9b, 0xc1, 0x03, 0x64, 0xa4, 0x00, 0x66, 0x26, 0xa4, 0x70, 0x3f, 0x22, 0x66, 0x42, 0xaa, 0x3f,
+	0x39, 0xbb, 0xaf, 0xa6, 0x75, 0x99, 0x9d, 0x4a, 0xdf, 0xce, 0xcc, 0xbe, 0x1d, 0xcf, 0x7d, 0x9f,
+	0xa8, 0xe0, 0x26, 0x15, 0x61, 0xc6, 0x2d, 0x4a, 0x8f, 0x0e, 0x2a, 0x63, 0xea, 0x1f, 0x0f, 0xb6,
+	0x95, 0x54, 0xb1, 0x6f, 0xc1, 0x44, 0x6a, 0xc0, 0xd0, 0xcb, 0x30, 0xd0, 0xda, 0x76, 0x22, 0x92,
+	0x32, 0x8d, 0x1c, 0xa8, 0xd1, 0xc2, 0xa3, 0x83, 0xca, 0xb8, 0xaa, 0xc0, 0x4a, 0x30, 0xc7, 0xb6,
+	0xff, 0xa7, 0x05, 0xa5, 0xb5, 0xa0, 0x79, 0x1a, 0x8b, 0xe9, 0x75, 0x63, 0x31, 0x5d, 0xca, 0x0b,
+	0x55, 0x98, 0xbb, 0x8e, 0x96, 0x53, 0xeb, 0xe8, 0x4a, 0x2e, 0x85, 0xee, 0x4b, 0x68, 0x17, 0x46,
+	0x58, 0x00, 0x44, 0x61, 0xaa, 0xf9, 0xa2, 0xc1, 0xdf, 0x57, 0x52, 0xfc, 0xfd, 0x84, 0x86, 0xaa,
+	0x71, 0xf9, 0xcf, 0xc0, 0x90, 0x30, 0x17, 0x4c, 0x1b, 0xb8, 0x0b, 0x5c, 0x2c, 0xe1, 0xf6, 0x4f,
+	0x16, 0xc1, 0x08, 0xb8, 0x88, 0x7e, 0xcd, 0x82, 0xd9, 0x90, 0x7b, 0x0c, 0x36, 0xab, 0xed, 0xd0,
+	0xf5, 0xb7, 0xea, 0x8d, 0x6d, 0xd2, 0x6c, 0x7b, 0xae, 0xbf, 0xb5, 0xb2, 0xe5, 0x07, 0xaa, 0x78,
+	0xe9, 0x21, 0x69, 0xb4, 0x99, 0xce, 0xbf, 0x47, 0x74, 0x47, 0x65, 0x8e, 0x73, 0xe3, 0xf0, 0xa0,
+	0x32, 0x8b, 0x8f, 0x45, 0x1b, 0x1f, 0xb3, 0x2f, 0xe8, 0x1b, 0x16, 0xcc, 0xf1, 0x38, 0x84, 0xfd,
+	0xf7, 0xbf, 0x8b, 0x34, 0x54, 0x93, 0xa4, 0x12, 0x22, 0xeb, 0x24, 0xdc, 0x5d, 0x78, 0x45, 0x0c,
+	0xe8, 0x5c, 0xed, 0x78, 0x6d, 0xe1, 0xe3, 0x76, 0xce, 0xfe, 0x97, 0x45, 0x18, 0x13, 0xce, 0xea,
+	0x22, 0x0a, 0xca, 0xcb, 0xc6, 0x92, 0x78, 0x32, 0xb5, 0x24, 0xa6, 0x0c, 0xe4, 0x93, 0x09, 0x80,
+	0x12, 0xc1, 0x94, 0xe7, 0x44, 0xf1, 0x2d, 0xe2, 0x84, 0xf1, 0x06, 0x71, 0xb8, 0x99, 0x4a, 0xf1,
+	0xd8, 0x26, 0x35, 0x4a, 0xfd, 0x72, 0x27, 0x4d, 0x0c, 0x77, 0xd2, 0x47, 0x7b, 0x80, 0x98, 0xad,
+	0x4d, 0xe8, 0xf8, 0x11, 0xff, 0x16, 0x57, 0xbc, 0x07, 0x1c, 0xaf, 0xd5, 0x19, 0xd1, 0x2a, 0xba,
+	0xd3, 0x41, 0x0d, 0x67, 0xb4, 0xa0, 0xd9, 0x50, 0x0d, 0xf4, 0x6b, 0x43, 0x35, 0xd8, 0xc3, 0x8b,
+	0xc4, 0x87, 0xc9, 0x8e, 0x78, 0x03, 0x6f, 0x43, 0x59, 0xd9, 0xba, 0x89, 0x43, 0xa7, 0x7b, 0xd8,
+	0x8e, 0x34, 0x05, 0xae, 0x22, 0x49, 0xec, 0x2c, 0x13, 0x72, 0xf6, 0x3f, 0x2e, 0x18, 0x0d, 0xf2,
+	0x49, 0x5c, 0x83, 0x61, 0x27, 0x8a, 0xdc, 0x2d, 0x9f, 0x34, 0xc5, 0x8e, 0xfd, 0x78, 0xde, 0x8e,
+	0x35, 0x9a, 0x61, 0xf6, 0x86, 0xf3, 0xa2, 0x26, 0x56, 0x34, 0xd0, 0x2d, 0x6e, 0x0c, 0xb4, 0x27,
+	0xf9, 0xf9, 0xfe, 0xa8, 0x81, 0x34, 0x17, 0xda, 0x23, 0x58, 0xd4, 0x47, 0x5f, 0xe4, 0xd6, 0x5a,
+	0xb7, 0xfd, 0xe0, 0x81, 0x7f, 0x33, 0x08, 0xa4, 0x87, 0x59, 0x7f, 0x04, 0xa7, 0xa4, 0x8d, 0x96,
+	0xaa, 0x8e, 0x4d, 0x6a, 0xfd, 0xc5, 0xe4, 0xf9, 0x6e, 0x38, 0x43, 0x49, 0x9b, 0x7e, 0x22, 0x11,
+	0x22, 0x30, 0x21, 0x22, 0x21, 0xc8, 0x32, 0x31, 0x76, 0x99, 0xac, 0xba, 0x59, 0x3b, 0x51, 0xe8,
+	0xdd, 0x36, 0x49, 0xe0, 0x34, 0x4d, 0xfb, 0x67, 0x2c, 0x60, 0x16, 0xee, 0xa7, 0xc0, 0x32, 0x7c,
+	0xce, 0x64, 0x19, 0xa6, 0xf3, 0x06, 0x39, 0x87, 0x5b, 0x78, 0x89, 0xaf, 0xac, 0x5a, 0x18, 0x3c,
+	0xdc, 0x17, 0x2f, 0xe5, 0x7d, 0x70, 0xa9, 0xff, 0xc7, 0xe2, 0x87, 0x98, 0x72, 0x3a, 0x47, 0xdf,
+	0x03, 0xc3, 0x0d, 0xa7, 0xe5, 0x34, 0x78, 0x74, 0xe0, 0x5c, 0x8d, 0x8d, 0x51, 0x69, 0x76, 0x51,
+	0xd4, 0xe0, 0x1a, 0x08, 0x19, 0x51, 0x63, 0x58, 0x16, 0xf7, 0xd4, 0x3a, 0xa8, 0x26, 0x67, 0x76,
+	0x60, 0xcc, 0x20, 0xf6, 0x58, 0xc5, 0xd5, 0xef, 0xe1, 0x57, 0xac, 0x8a, 0x00, 0xb3, 0x0b, 0x53,
+	0xbe, 0xf6, 0x9f, 0x5e, 0x28, 0x52, 0x04, 0xf9, 0x78, 0xaf, 0x4b, 0x94, 0xdd, 0x3e, 0x9a, 0x05,
+	0x7f, 0x8a, 0x0c, 0xee, 0xa4, 0x6c, 0xff, 0x94, 0x05, 0x17, 0x74, 0x44, 0x2d, 0x1e, 0x40, 0x2f,
+	0x1d, 0x70, 0x15, 0x86, 0x83, 0x16, 0x09, 0x9d, 0x38, 0x08, 0xc5, 0xad, 0x71, 0x5d, 0x0e, 0xfa,
+	0x5d, 0x51, 0x7e, 0x24, 0xc2, 0x34, 0x4a, 0xea, 0xb2, 0x1c, 0xab, 0x9a, 0xc8, 0x86, 0x41, 0x36,
+	0x18, 0x91, 0x88, 0xd5, 0xc0, 0xce, 0x00, 0xf6, 0x1c, 0x1a, 0x61, 0x01, 0xb1, 0xff, 0xc8, 0xe2,
+	0x0b, 0x4b, 0xef, 0x3a, 0x7a, 0x0f, 0x26, 0x77, 0x9d, 0xb8, 0xb1, 0xbd, 0xf4, 0xb0, 0x15, 0x72,
+	0xd5, 0xb7, 0x1c, 0xa7, 0x67, 0x7b, 0x8d, 0x93, 0xf6, 0x91, 0x89, 0x01, 0xda, 0x6a, 0x8a, 0x18,
+	0xee, 0x20, 0x8f, 0x36, 0x60, 0x84, 0x95, 0x31, 0x4b, 0xe7, 0xa8, 0x1b, 0x6b, 0x90, 0xd7, 0x9a,
+	0x7a, 0x51, 0x5e, 0x4d, 0xe8, 0x60, 0x9d, 0xa8, 0xfd, 0x95, 0x22, 0xdf, 0xed, 0x8c, 0xdb, 0x7e,
+	0x06, 0x86, 0x5a, 0x41, 0x73, 0x71, 0xa5, 0x8a, 0xc5, 0x2c, 0xa8, 0x6b, 0xa4, 0xc6, 0x8b, 0xb1,
+	0x84, 0xa3, 0xd7, 0x00, 0xc8, 0xc3, 0x98, 0x84, 0xbe, 0xe3, 0x29, 0x83, 0x10, 0x65, 0x02, 0x59,
+	0x0d, 0xd6, 0x82, 0xf8, 0x5e, 0x44, 0xbe, 0x6b, 0x49, 0xa1, 0x60, 0x0d, 0x1d, 0xdd, 0x00, 0x68,
+	0x85, 0xc1, 0x9e, 0xdb, 0x64, 0xae, 0x73, 0x45, 0xd3, 0x5c, 0xa2, 0xa6, 0x20, 0x58, 0xc3, 0x42,
+	0xaf, 0xc1, 0x58, 0xdb, 0x8f, 0x38, 0x87, 0xe2, 0x6c, 0x88, 0xc8, 0x83, 0xc3, 0x89, 0xe5, 0xc2,
+	0x3d, 0x1d, 0x88, 0x4d, 0x5c, 0x34, 0x0f, 0x83, 0xb1, 0xc3, 0xec, 0x1d, 0x06, 0xf2, 0xed, 0x16,
+	0xd7, 0x29, 0x86, 0x1e, 0x9b, 0x96, 0x56, 0xc0, 0xa2, 0x22, 0x7a, 0x5b, 0xfa, 0x21, 0xf0, 0xb3,
+	0x5e, 0x18, 0x0c, 0xf7, 0x77, 0x2f, 0x68, 0x5e, 0x08, 0xc2, 0x10, 0xd9, 0xa0, 0x65, 0x7f, 0xa3,
+	0x0c, 0x90, 0xb0, 0xe3, 0xe8, 0xfd, 0x8e, 0xf3, 0xe8, 0xb9, 0xee, 0x0c, 0xfc, 0xc9, 0x1d, 0x46,
+	0xe8, 0xfb, 0x2d, 0x18, 0x71, 0x3c, 0x2f, 0x68, 0x38, 0x31, 0x1b, 0xe5, 0x42, 0xf7, 0xf3, 0x50,
+	0xb4, 0x3f, 0x9f, 0xd4, 0xe0, 0x5d, 0x78, 0x51, 0x2e, 0x3c, 0x0d, 0xd2, 0xb3, 0x17, 0x7a, 0xc3,
+	0xe8, 0x53, 0x52, 0x4a, 0xe3, 0xcb, 0x63, 0x26, 0x2d, 0xa5, 0x95, 0xd9, 0xd1, 0xaf, 0x09, 0x68,
+	0xe8, 0x9e, 0x11, 0x54, 0xae, 0x94, 0x1f, 0x5f, 0xc1, 0xe0, 0x4a, 0x7b, 0xc5, 0x93, 0x43, 0x35,
+	0xdd, 0x71, 0x6a, 0x20, 0x3f, 0x08, 0x89, 0x26, 0xfe, 0xf4, 0x70, 0x9a, 0x7a, 0x17, 0x26, 0x9a,
+	0xe6, 0xdd, 0x2e, 0x56, 0xd3, 0xd3, 0x79, 0x74, 0x53, 0xac, 0x40, 0x72, 0x9b, 0xa7, 0x00, 0x38,
+	0x4d, 0x18, 0xd5, 0xb8, 0x0b, 0xdb, 0x8a, 0xbf, 0x19, 0x08, 0xc3, 0x73, 0x3b, 0x77, 0x2e, 0xf7,
+	0xa3, 0x98, 0xec, 0x52, 0xcc, 0xe4, 0xd2, 0x5e, 0x13, 0x75, 0xb1, 0xa2, 0x82, 0xde, 0x80, 0x41,
+	0xe6, 0x03, 0x1b, 0x4d, 0x0f, 0xe7, 0x2b, 0x0a, 0xcd, 0xf0, 0x0d, 0xc9, 0xa6, 0x62, 0x7f, 0x23,
+	0x2c, 0x28, 0xa0, 0x5b, 0x32, 0xc6, 0x4b, 0xb4, 0xe2, 0xdf, 0x8b, 0x08, 0x8b, 0xf1, 0x52, 0x5e,
+	0xf8, 0x78, 0x12, 0xbe, 0x85, 0x97, 0x67, 0x46, 0xa1, 0x37, 0x6a, 0x52, 0xe6, 0x48, 0xfc, 0x97,
+	0xc1, 0xed, 0xa7, 0x21, 0xbf, 0x7b, 0x66, 0x00, 0xfc, 0x64, 0x38, 0xef, 0x9b, 0x24, 0x70, 0x9a,
+	0x26, 0x65, 0x34, 0xf9, 0xce, 0x15, 0xa6, 0xeb, 0xbd, 0xf6, 0x3f, 0x97, 0xaf, 0xd9, 0x25, 0xc3,
+	0x4b, 0xb0, 0xa8, 0x7f, 0xaa, 0xb7, 0xfe, 0x8c, 0x0f, 0x93, 0xe9, 0x2d, 0xfa, 0x58, 0xb9, 0x8c,
+	0x3f, 0x28, 0xc1, 0xb8, 0xb9, 0xa4, 0xd0, 0x1c, 0x94, 0x05, 0x11, 0x15, 0x70, 0x54, 0xed, 0x92,
+	0x55, 0x09, 0xc0, 0x09, 0x0e, 0x8b, 0x33, 0xcb, 0xaa, 0x6b, 0x26, 0x87, 0x49, 0x9c, 0x59, 0x05,
+	0xc1, 0x1a, 0x16, 0x95, 0x97, 0x36, 0x82, 0x20, 0x56, 0x97, 0x8a, 0x5a, 0x77, 0x0b, 0xac, 0x14,
+	0x0b, 0x28, 0xbd, 0x4c, 0x76, 0x48, 0xe8, 0x13, 0xcf, 0x8c, 0x63, 0xa6, 0x2e, 0x93, 0xdb, 0x3a,
+	0x10, 0x9b, 0xb8, 0xf4, 0x96, 0x0c, 0x22, 0xb6, 0x90, 0x85, 0x54, 0x96, 0x98, 0x70, 0xd6, 0xb9,
+	0x37, 0xb9, 0x84, 0xa3, 0x2f, 0xc0, 0x05, 0xe5, 0xfc, 0x8d, 0xb9, 0x12, 0x5a, 0xb6, 0x38, 0x68,
+	0x28, 0x51, 0x2e, 0x2c, 0x66, 0xa3, 0xe1, 0xbc, 0xfa, 0xe8, 0x75, 0x18, 0x17, 0x9c, 0xbb, 0xa4,
+	0x38, 0x64, 0xda, 0x45, 0xdc, 0x36, 0xa0, 0x38, 0x85, 0x2d, 0x23, 0xb1, 0x31, 0xe6, 0x59, 0x52,
+	0x18, 0xee, 0x8c, 0xc4, 0xa6, 0xc3, 0x71, 0x47, 0x0d, 0x34, 0x0f, 0x13, 0x9c, 0xb5, 0x72, 0xfd,
+	0x2d, 0x3e, 0x27, 0xc2, 0xb3, 0x44, 0x6d, 0xa9, 0xbb, 0x26, 0x18, 0xa7, 0xf1, 0xd1, 0xab, 0x30,
+	0xea, 0x84, 0x8d, 0x6d, 0x37, 0x26, 0x8d, 0xb8, 0x1d, 0x72, 0x97, 0x13, 0xcd, 0xb0, 0x64, 0x5e,
+	0x83, 0x61, 0x03, 0xd3, 0x7e, 0x1f, 0xce, 0x64, 0x38, 0xa5, 0xd1, 0x85, 0xe3, 0xb4, 0x5c, 0xf9,
+	0x4d, 0x29, 0x63, 0xcc, 0xf9, 0xda, 0x8a, 0xfc, 0x1a, 0x0d, 0x8b, 0xae, 0x4e, 0xe6, 0xbc, 0xa6,
+	0xe5, 0xb2, 0x50, 0xab, 0x73, 0x59, 0x02, 0x70, 0x82, 0x63, 0xff, 0xaf, 0x02, 0x4c, 0x64, 0x28,
+	0xd6, 0x59, 0x3e, 0x85, 0x94, 0xec, 0x91, 0xa4, 0x4f, 0x30, 0x03, 0xfb, 0x15, 0x8e, 0x11, 0xd8,
+	0xaf, 0xd8, 0x2b, 0xb0, 0x5f, 0xe9, 0x83, 0x04, 0xf6, 0x33, 0x47, 0x6c, 0xa0, 0xaf, 0x11, 0xcb,
+	0x08, 0x06, 0x38, 0x78, 0xcc, 0x60, 0x80, 0xc6, 0xa0, 0x0f, 0xf5, 0x31, 0xe8, 0x3f, 0x5a, 0x80,
+	0xc9, 0xb4, 0x01, 0xdc, 0x29, 0xa8, 0x63, 0xdf, 0x30, 0xd4, 0xb1, 0xd9, 0xd9, 0x49, 0xd2, 0x66,
+	0x79, 0x79, 0xaa, 0x59, 0x9c, 0x52, 0xcd, 0x7e, 0xb2, 0x2f, 0x6a, 0xdd, 0xd5, 0xb4, 0x7f, 0xb7,
+	0x00, 0xe7, 0xd2, 0x55, 0x16, 0x3d, 0xc7, 0xdd, 0x3d, 0x85, 0xb1, 0xb9, 0x6b, 0x8c, 0xcd, 0xf3,
+	0xfd, 0x7c, 0x0d, 0xeb, 0x5a, 0xee, 0x00, 0xbd, 0x95, 0x1a, 0xa0, 0xb9, 0xfe, 0x49, 0x76, 0x1f,
+	0xa5, 0x6f, 0x16, 0xe1, 0x4a, 0x66, 0xbd, 0x44, 0x9b, 0xb9, 0x6c, 0x68, 0x33, 0x6f, 0xa4, 0xb4,
+	0x99, 0x76, 0xf7, 0xda, 0x27, 0xa3, 0xde, 0x14, 0xde, 0x82, 0x2c, 0xf8, 0xdb, 0x23, 0xaa, 0x36,
+	0x0d, 0x6f, 0x41, 0x45, 0x08, 0x9b, 0x74, 0xff, 0x22, 0xa9, 0x34, 0xff, 0xad, 0x05, 0x17, 0x33,
+	0xe7, 0xe6, 0x14, 0x54, 0x58, 0x6b, 0xa6, 0x0a, 0xeb, 0x99, 0xbe, 0x57, 0x6b, 0x8e, 0x4e, 0xeb,
+	0x0f, 0x8b, 0x39, 0xdf, 0xc2, 0x04, 0xf4, 0xbb, 0x30, 0xe2, 0x34, 0x1a, 0x24, 0x8a, 0x56, 0x83,
+	0xa6, 0x0a, 0x86, 0xf6, 0x3c, 0x93, 0xb3, 0x92, 0xe2, 0xa3, 0x83, 0xca, 0x4c, 0x9a, 0x44, 0x02,
+	0xc6, 0x3a, 0x05, 0x33, 0x7e, 0x63, 0xe1, 0x44, 0xe3, 0x37, 0xde, 0x00, 0xd8, 0x53, 0xdc, 0x7a,
+	0x5a, 0xc8, 0xd7, 0xf8, 0x78, 0x0d, 0x0b, 0x7d, 0x11, 0x86, 0x23, 0x71, 0x8d, 0x8b, 0xa5, 0xf8,
+	0x62, 0x9f, 0x73, 0xe5, 0x6c, 0x10, 0xcf, 0x74, 0x4b, 0x57, 0xfa, 0x10, 0x45, 0x12, 0x7d, 0x07,
+	0x4c, 0x46, 0x3c, 0xea, 0xc9, 0xa2, 0xe7, 0x44, 0xcc, 0xc7, 0x41, 0xac, 0x42, 0xe6, 0x6b, 0x5e,
+	0x4f, 0xc1, 0x70, 0x07, 0x36, 0x5a, 0x96, 0x1f, 0xc5, 0x42, 0xb4, 0xf0, 0x85, 0x79, 0x2d, 0xf9,
+	0x20, 0x91, 0xcd, 0xe9, 0x6c, 0x7a, 0xf8, 0xd9, 0xc0, 0x6b, 0x35, 0xed, 0x1f, 0x2d, 0xc1, 0x13,
+	0x5d, 0x0e, 0x31, 0x34, 0x6f, 0xbe, 0x51, 0x3e, 0x9b, 0x96, 0x7e, 0x67, 0x32, 0x2b, 0x1b, 0xe2,
+	0x70, 0x6a, 0xad, 0x14, 0x3e, 0xf0, 0x5a, 0xf9, 0x21, 0x4b, 0xd3, 0x4b, 0x70, 0x4b, 0xba, 0xcf,
+	0x1d, 0xf3, 0x70, 0x3e, 0x41, 0x45, 0xc5, 0x66, 0x86, 0xb4, 0x7f, 0xa3, 0xef, 0xee, 0xf4, 0x2d,
+	0xfe, 0x9f, 0xae, 0x76, 0xf6, 0x2b, 0x16, 0x3c, 0x99, 0xd9, 0x5f, 0xc3, 0xa6, 0x62, 0x0e, 0xca,
+	0x0d, 0x5a, 0xa8, 0xf9, 0x4d, 0x25, 0x0e, 0xa5, 0x12, 0x80, 0x13, 0x1c, 0xc3, 0x74, 0xa2, 0xd0,
+	0xd3, 0x74, 0xe2, 0x5f, 0x58, 0xd0, 0xb1, 0x80, 0x4f, 0xe1, 0x24, 0x5d, 0x31, 0x4f, 0xd2, 0x8f,
+	0xf7, 0x33, 0x97, 0x39, 0x87, 0xe8, 0xbf, 0x99, 0x84, 0xf3, 0x39, 0x8e, 0x12, 0x7b, 0x30, 0xb5,
+	0xd5, 0x20, 0xa6, 0x47, 0x9a, 0xf8, 0x98, 0x4c, 0xe7, 0xbd, 0xae, 0xee, 0x6b, 0x2c, 0x0d, 0xcf,
+	0x54, 0x07, 0x0a, 0xee, 0x6c, 0x02, 0x7d, 0xc5, 0x82, 0xb3, 0xce, 0x83, 0xa8, 0x23, 0xd9, 0xa2,
+	0x58, 0x33, 0x2f, 0x65, 0x6a, 0x29, 0x7a, 0x24, 0x67, 0xe4, 0x79, 0x89, 0xb2, 0xb0, 0x70, 0x66,
+	0x5b, 0x08, 0x8b, 0xf8, 0x95, 0x94, 0xdf, 0xee, 0xe2, 0x33, 0x99, 0xe5, 0xd1, 0xc2, 0xcf, 0x54,
+	0x09, 0xc1, 0x8a, 0x0e, 0xba, 0x0f, 0xe5, 0x2d, 0xe9, 0x66, 0x26, 0xce, 0xec, 0xcc, 0x4b, 0x30,
+	0xd3, 0x17, 0x8d, 0xbf, 0x1b, 0x2a, 0x10, 0x4e, 0x48, 0xa1, 0xd7, 0xa1, 0xe8, 0x6f, 0x46, 0xdd,
+	0xb2, 0xec, 0xa4, 0x4c, 0x8d, 0xb8, 0x3f, 0xf2, 0xda, 0x72, 0x1d, 0xd3, 0x8a, 0xe8, 0x16, 0x14,
+	0xc3, 0x8d, 0xa6, 0x50, 0xac, 0x65, 0xf2, 0xa5, 0x78, 0xa1, 0x9a, 0xbd, 0x48, 0x38, 0x25, 0xbc,
+	0x50, 0xc5, 0x94, 0x04, 0xaa, 0xc1, 0x00, 0xf3, 0x29, 0x10, 0xfa, 0xb3, 0x4c, 0x86, 0xb4, 0x8b,
+	0x6f, 0x0e, 0x77, 0x5a, 0x66, 0x08, 0x98, 0x13, 0x42, 0xeb, 0x30, 0xd8, 0x60, 0x19, 0x59, 0x44,
+	0xc8, 0xe4, 0x4f, 0x65, 0xaa, 0xd0, 0xba, 0xa4, 0xaa, 0x11, 0x1a, 0x25, 0x86, 0x81, 0x05, 0x2d,
+	0x46, 0x95, 0xb4, 0xb6, 0x37, 0x23, 0x26, 0x82, 0xe7, 0x51, 0xed, 0x92, 0x81, 0x49, 0x50, 0x65,
+	0x18, 0x58, 0xd0, 0x42, 0x9f, 0x81, 0xc2, 0x66, 0x43, 0xb8, 0x1c, 0x64, 0xea, 0xd2, 0x4c, 0x97,
+	0xf2, 0x85, 0xc1, 0xc3, 0x83, 0x4a, 0x61, 0x79, 0x11, 0x17, 0x36, 0x1b, 0x68, 0x0d, 0x86, 0x36,
+	0xb9, 0x13, 0xaa, 0x50, 0x97, 0x3d, 0x9d, 0xed, 0x1f, 0xdb, 0xe1, 0xa7, 0xca, 0x4d, 0xe5, 0x05,
+	0x00, 0x4b, 0x22, 0x2c, 0x08, 0xa4, 0x72, 0xa6, 0x15, 0xd1, 0x90, 0x67, 0x8f, 0xe7, 0x00, 0xcd,
+	0xdd, 0xdb, 0x13, 0x97, 0x5c, 0xac, 0x51, 0x44, 0x5f, 0x86, 0xb2, 0x23, 0xd3, 0xfc, 0x89, 0x68,
+	0x11, 0x2f, 0x66, 0x6e, 0xcc, 0xee, 0x19, 0x10, 0xf9, 0xaa, 0x56, 0x48, 0x38, 0x21, 0x8a, 0x76,
+	0x60, 0x6c, 0x2f, 0x6a, 0x6d, 0x13, 0xb9, 0x91, 0x59, 0xf0, 0x88, 0x9c, 0x8b, 0xeb, 0xbe, 0x40,
+	0x74, 0xc3, 0xb8, 0xed, 0x78, 0x1d, 0x67, 0x0f, 0x7b, 0x6c, 0xbe, 0xaf, 0x13, 0xc3, 0x26, 0x6d,
+	0x3a, 0xfc, 0xef, 0xb5, 0x83, 0x8d, 0xfd, 0x98, 0x88, 0xf0, 0xc9, 0x99, 0xc3, 0xff, 0x26, 0x47,
+	0xe9, 0x1c, 0x7e, 0x01, 0xc0, 0x92, 0x08, 0xfa, 0x12, 0x8c, 0x34, 0x92, 0x64, 0x61, 0x2c, 0x70,
+	0x72, 0xce, 0x7b, 0x54, 0x4e, 0x4e, 0x31, 0x1e, 0xcd, 0x4e, 0x03, 0x62, 0x9d, 0x20, 0x3b, 0x23,
+	0x5b, 0xdb, 0x41, 0x1c, 0xf8, 0xa9, 0xf3, 0x79, 0x2a, 0xff, 0x8c, 0xac, 0x65, 0xe0, 0x77, 0x9e,
+	0x91, 0x59, 0x58, 0x38, 0xb3, 0x2d, 0xd4, 0x84, 0xf1, 0x56, 0x10, 0xc6, 0x0f, 0x82, 0x50, 0xae,
+	0x33, 0xd4, 0x45, 0xec, 0x37, 0x30, 0x45, 0x8b, 0x2c, 0xac, 0xb7, 0x09, 0xc1, 0x29, 0x9a, 0xe8,
+	0xf3, 0x30, 0x14, 0x35, 0x1c, 0x8f, 0xac, 0xdc, 0x9d, 0x3e, 0x93, 0x7f, 0xf9, 0xd4, 0x39, 0x4a,
+	0xce, 0x2a, 0x63, 0x93, 0x24, 0x50, 0xb0, 0x24, 0x87, 0x96, 0x61, 0x80, 0xc5, 0xe6, 0x67, 0x11,
+	0xa0, 0x73, 0xa2, 0x13, 0x75, 0x18, 0x77, 0xf2, 0x33, 0x8a, 0x15, 0x63, 0x5e, 0x9d, 0xee, 0x05,
+	0xc1, 0xfd, 0x06, 0xd1, 0xf4, 0xb9, 0xfc, 0xbd, 0x20, 0x98, 0xe6, 0xbb, 0xf5, 0x6e, 0x7b, 0x41,
+	0x21, 0xe1, 0x84, 0x28, 0x3d, 0xa1, 0xe9, 0xa9, 0x7a, 0xbe, 0x8b, 0xbd, 0x49, 0xee, 0x99, 0xca,
+	0x4e, 0x68, 0x7a, 0xa2, 0x52, 0x12, 0xf4, 0x0e, 0x72, 0x64, 0x6e, 0xd7, 0xe9, 0x0b, 0xf9, 0x77,
+	0x50, 0x66, 0x02, 0x58, 0x6d, 0xb7, 0xb2, 0x65, 0x91, 0x90, 0xb2, 0x7f, 0x6f, 0xa8, 0x93, 0x13,
+	0x62, 0x72, 0xd8, 0x5f, 0xb6, 0x3a, 0x9e, 0xe8, 0x3e, 0xdd, 0xaf, 0x5a, 0xe8, 0x04, 0x79, 0xe0,
+	0xaf, 0x58, 0x70, 0xbe, 0x95, 0x39, 0x40, 0x82, 0xad, 0xe8, 0x4f, 0xbb, 0xc4, 0x87, 0x41, 0x45,
+	0x7f, 0xcf, 0x86, 0xe3, 0x9c, 0x96, 0xd2, 0x72, 0x46, 0xf1, 0x03, 0xcb, 0x19, 0xab, 0x30, 0xcc,
+	0x58, 0xd7, 0x1e, 0x19, 0xd0, 0xd2, 0x5e, 0x6e, 0x8c, 0x41, 0x59, 0x14, 0x15, 0xb1, 0x22, 0x81,
+	0x7e, 0xd8, 0x82, 0xcb, 0xe9, 0xae, 0x63, 0xc2, 0xc0, 0x22, 0x56, 0x3a, 0x17, 0x01, 0x97, 0xc5,
+	0xf7, 0x5f, 0xae, 0x75, 0x43, 0x3e, 0xea, 0x85, 0x80, 0xbb, 0x37, 0x86, 0xaa, 0x19, 0x32, 0xe8,
+	0xa0, 0xa9, 0x77, 0xef, 0x43, 0x0e, 0x7d, 0x09, 0x46, 0x77, 0x83, 0xb6, 0x1f, 0x0b, 0xb3, 0x17,
+	0xe1, 0x84, 0xc8, 0xde, 0x99, 0x57, 0xb5, 0x72, 0x6c, 0x60, 0xa5, 0xa4, 0xd7, 0xe1, 0x47, 0x95,
+	0x5e, 0xd1, 0x3b, 0xa9, 0x94, 0xda, 0xe5, 0xfc, 0x98, 0x7c, 0x42, 0xd0, 0x3f, 0x46, 0x62, 0xed,
+	0xd3, 0x95, 0xb8, 0x7e, 0xce, 0xca, 0x10, 0x15, 0xb8, 0x0c, 0xfe, 0x59, 0x53, 0x06, 0xbf, 0x96,
+	0x96, 0xc1, 0x3b, 0x74, 0xae, 0x86, 0xf8, 0xdd, 0x7f, 0x60, 0xe7, 0x7e, 0x23, 0xa5, 0xd9, 0x1e,
+	0x5c, 0xed, 0x75, 0xdd, 0x31, 0xfb, 0xa7, 0xa6, 0x7a, 0x61, 0x4b, 0xec, 0x9f, 0x9a, 0x2b, 0x55,
+	0xcc, 0x20, 0x7d, 0xe7, 0xeb, 0xfc, 0x6f, 0x16, 0x14, 0x6b, 0x41, 0xf3, 0x14, 0x74, 0xc8, 0x9f,
+	0x33, 0x74, 0xc8, 0x4f, 0xe4, 0xa4, 0x3a, 0xcf, 0xd5, 0x18, 0x2f, 0xa5, 0x34, 0xc6, 0x97, 0xf3,
+	0x08, 0x74, 0xd7, 0x0f, 0xff, 0x74, 0x11, 0xf4, 0xc4, 0xec, 0xe8, 0x5f, 0x3d, 0x8a, 0xf1, 0x71,
+	0xb1, 0x5b, 0xae, 0x76, 0x41, 0x99, 0x99, 0x4d, 0x49, 0xbf, 0xba, 0x3f, 0x67, 0x36, 0xc8, 0x6f,
+	0x11, 0x77, 0x6b, 0x3b, 0x26, 0xcd, 0xf4, 0xe7, 0x9c, 0x9e, 0x0d, 0xf2, 0x7f, 0xb1, 0x60, 0x22,
+	0xd5, 0x3a, 0xf2, 0x60, 0xcc, 0xd3, 0x15, 0x80, 0x62, 0x9d, 0x3e, 0x92, 0xee, 0x50, 0xd8, 0x70,
+	0x6a, 0x45, 0xd8, 0x24, 0x8e, 0x66, 0x01, 0xd4, 0x03, 0x9d, 0xd4, 0xab, 0x31, 0xa9, 0x42, 0xbd,
+	0xe0, 0x45, 0x58, 0xc3, 0x40, 0x2f, 0xc3, 0x48, 0x1c, 0xb4, 0x02, 0x2f, 0xd8, 0xda, 0xbf, 0x4d,
+	0x64, 0xf0, 0x16, 0x65, 0x99, 0xb5, 0x9e, 0x80, 0xb0, 0x8e, 0x67, 0xff, 0x6c, 0x11, 0xd2, 0xc9,
+	0xfc, 0xbf, 0xb5, 0x26, 0x3f, 0x9a, 0x6b, 0xf2, 0x9b, 0x16, 0x4c, 0xd2, 0xd6, 0x99, 0x95, 0x88,
+	0xbc, 0x6c, 0x55, 0x82, 0x19, 0xab, 0x4b, 0x82, 0x99, 0x6b, 0xf4, 0xec, 0x6a, 0x06, 0xed, 0x58,
+	0xe8, 0xe5, 0xb4, 0xc3, 0x89, 0x96, 0x62, 0x01, 0x15, 0x78, 0x24, 0x0c, 0x85, 0xeb, 0x93, 0x8e,
+	0x47, 0xc2, 0x10, 0x0b, 0xa8, 0xcc, 0x3f, 0x53, 0xca, 0xc9, 0x3f, 0xc3, 0x42, 0xd1, 0x09, 0x7b,
+	0x02, 0xc1, 0xf6, 0x68, 0xa1, 0xe8, 0xa4, 0xa1, 0x41, 0x82, 0x63, 0xff, 0x62, 0x11, 0x46, 0x6b,
+	0x41, 0x33, 0x79, 0x22, 0x7b, 0xc9, 0x78, 0x22, 0xbb, 0x9a, 0x7a, 0x22, 0x9b, 0xd4, 0x71, 0xbf,
+	0xf5, 0x20, 0xf6, 0x61, 0x3d, 0x88, 0xfd, 0x73, 0x8b, 0xcd, 0x5a, 0x75, 0xad, 0x2e, 0xf2, 0xdf,
+	0xbe, 0x00, 0x23, 0xec, 0x40, 0x62, 0xbe, 0x76, 0xf2, 0xdd, 0x88, 0x09, 0xe3, 0x6b, 0x49, 0x31,
+	0xd6, 0x71, 0xd0, 0x75, 0x18, 0x8e, 0x88, 0x13, 0x36, 0xb6, 0xd5, 0x19, 0x27, 0x5e, 0x55, 0x78,
+	0x19, 0x56, 0x50, 0xf4, 0x66, 0x12, 0x05, 0xad, 0x98, 0x9f, 0xc9, 0x55, 0xef, 0x0f, 0xdf, 0x22,
+	0xf9, 0xa1, 0xcf, 0xec, 0xb7, 0x00, 0x75, 0xe2, 0xf7, 0x11, 0xef, 0xa8, 0x62, 0xc6, 0x3b, 0x2a,
+	0x77, 0xc4, 0x3a, 0xfa, 0x53, 0x0b, 0xc6, 0x6b, 0x41, 0x93, 0x6e, 0xdd, 0xbf, 0x48, 0xfb, 0x54,
+	0x0f, 0x01, 0x39, 0xd8, 0x25, 0x04, 0xe4, 0xdf, 0xb3, 0x60, 0xa8, 0x16, 0x34, 0x4f, 0x41, 0x9b,
+	0xff, 0x59, 0x53, 0x9b, 0x7f, 0x21, 0x67, 0x49, 0xe4, 0x28, 0xf0, 0x7f, 0xb9, 0x08, 0x63, 0xb4,
+	0x9f, 0xc1, 0x96, 0x9c, 0x25, 0x63, 0x44, 0xac, 0x3e, 0x46, 0x84, 0xb2, 0xb9, 0x81, 0xe7, 0x05,
+	0x0f, 0xd2, 0x33, 0xb6, 0xcc, 0x4a, 0xb1, 0x80, 0xa2, 0xe7, 0x60, 0xb8, 0x15, 0x92, 0x3d, 0x37,
+	0x10, 0xfc, 0xa3, 0xf6, 0x36, 0x52, 0x13, 0xe5, 0x58, 0x61, 0x50, 0xb9, 0x2b, 0x72, 0xfd, 0x06,
+	0x91, 0x69, 0xa4, 0x4b, 0x2c, 0xd3, 0x14, 0x8f, 0xed, 0xac, 0x95, 0x63, 0x03, 0x0b, 0xbd, 0x05,
+	0x65, 0xf6, 0x9f, 0x9d, 0x28, 0xc7, 0xcf, 0x8c, 0x23, 0x12, 0x2a, 0x08, 0x02, 0x38, 0xa1, 0x85,
+	0x6e, 0x00, 0xc4, 0x32, 0xfe, 0x6f, 0x24, 0xc2, 0xd6, 0x28, 0x5e, 0x5b, 0x45, 0x06, 0x8e, 0xb0,
+	0x86, 0x85, 0x9e, 0x85, 0x72, 0xec, 0xb8, 0xde, 0x1d, 0xd7, 0x27, 0x11, 0x53, 0x69, 0x17, 0x65,
+	0xbe, 0x04, 0x51, 0x88, 0x13, 0x38, 0xe5, 0x75, 0x98, 0x4f, 0x37, 0xcf, 0xab, 0x35, 0xcc, 0xb0,
+	0x19, 0xaf, 0x73, 0x47, 0x95, 0x62, 0x0d, 0xc3, 0x7e, 0x15, 0xce, 0xd5, 0x82, 0x66, 0x2d, 0x08,
+	0xe3, 0xe5, 0x20, 0x7c, 0xe0, 0x84, 0x4d, 0x39, 0x7f, 0x15, 0x19, 0xba, 0x9f, 0x9e, 0x3d, 0x03,
+	0x7c, 0x67, 0x1a, 0x41, 0xf9, 0x5f, 0x64, 0xdc, 0xce, 0x31, 0x7d, 0x39, 0x1a, 0xec, 0xde, 0x55,
+	0x29, 0xf4, 0x6e, 0x3a, 0x31, 0x41, 0x77, 0x59, 0xda, 0xad, 0xe4, 0x0a, 0x12, 0xd5, 0x9f, 0xd1,
+	0xd2, 0x6e, 0x25, 0xc0, 0xcc, 0x3b, 0xcb, 0xac, 0x6f, 0xff, 0x7a, 0x91, 0x9d, 0x46, 0xa9, 0x8c,
+	0x72, 0xe8, 0x4b, 0x30, 0x1e, 0x91, 0x3b, 0xae, 0xdf, 0x7e, 0x28, 0x85, 0xf0, 0x2e, 0xde, 0x38,
+	0xf5, 0x25, 0x1d, 0x93, 0xab, 0x08, 0xcd, 0x32, 0x9c, 0xa2, 0x46, 0xe7, 0x29, 0x6c, 0xfb, 0xf3,
+	0xd1, 0xbd, 0x88, 0x84, 0x22, 0xa3, 0x19, 0x9b, 0x27, 0x2c, 0x0b, 0x71, 0x02, 0xa7, 0xeb, 0x92,
+	0xfd, 0x59, 0x0b, 0x7c, 0x1c, 0x04, 0xb1, 0x5c, 0xc9, 0x2c, 0x27, 0x8e, 0x56, 0x8e, 0x0d, 0x2c,
+	0xb4, 0x0c, 0x28, 0x6a, 0xb7, 0x5a, 0x1e, 0x7b, 0xcf, 0x77, 0xbc, 0x9b, 0x61, 0xd0, 0x6e, 0xf1,
+	0xb7, 0xd4, 0xe2, 0xc2, 0x79, 0x7a, 0x85, 0xd5, 0x3b, 0xa0, 0x38, 0xa3, 0x06, 0x3d, 0x7d, 0x36,
+	0x23, 0xf6, 0x9b, 0xad, 0xee, 0xa2, 0x50, 0xdf, 0xd7, 0x59, 0x11, 0x96, 0x30, 0xba, 0x98, 0x58,
+	0xf3, 0x1c, 0x73, 0x30, 0x59, 0x4c, 0x58, 0x95, 0x62, 0x0d, 0x03, 0x2d, 0xc1, 0x50, 0xb4, 0x1f,
+	0x35, 0x62, 0x11, 0x64, 0x29, 0x27, 0x37, 0x65, 0x9d, 0xa1, 0x68, 0xf9, 0x12, 0x78, 0x15, 0x2c,
+	0xeb, 0xda, 0xdf, 0xc3, 0x2e, 0x43, 0x96, 0xff, 0x2a, 0x6e, 0x87, 0x04, 0xed, 0xc2, 0x58, 0x8b,
+	0x4d, 0xb9, 0x88, 0xce, 0x2c, 0xe6, 0xed, 0xa5, 0x3e, 0xa5, 0xda, 0x07, 0xf4, 0xa0, 0x51, 0x5a,
+	0x27, 0x26, 0x2e, 0xd4, 0x74, 0x72, 0xd8, 0xa4, 0x6e, 0xff, 0xe0, 0x14, 0x3b, 0x73, 0xeb, 0x5c,
+	0x54, 0x1d, 0x12, 0x16, 0xc5, 0x82, 0x2f, 0x9f, 0xc9, 0xd7, 0x99, 0x24, 0x5f, 0x24, 0xac, 0x92,
+	0xb1, 0xac, 0x8b, 0xde, 0x64, 0x6f, 0xdf, 0xfc, 0xa0, 0xeb, 0x95, 0x86, 0x98, 0x63, 0x19, 0xcf,
+	0xdc, 0xa2, 0x22, 0xd6, 0x88, 0xa0, 0x3b, 0x30, 0x26, 0xd2, 0x25, 0x09, 0xa5, 0x58, 0xd1, 0x50,
+	0x7a, 0x8c, 0x61, 0x1d, 0x78, 0x94, 0x2e, 0xc0, 0x66, 0x65, 0xb4, 0x05, 0x97, 0xb5, 0xdc, 0x81,
+	0x37, 0x43, 0x87, 0xbd, 0x87, 0xba, 0x6c, 0x13, 0x69, 0xe7, 0xe6, 0x93, 0x87, 0x07, 0x95, 0xcb,
+	0xeb, 0xdd, 0x10, 0x71, 0x77, 0x3a, 0xe8, 0x2e, 0x9c, 0xe3, 0x8e, 0x7b, 0x55, 0xe2, 0x34, 0x3d,
+	0xd7, 0x57, 0x07, 0x33, 0x5f, 0x87, 0x17, 0x0f, 0x0f, 0x2a, 0xe7, 0xe6, 0xb3, 0x10, 0x70, 0x76,
+	0x3d, 0xf4, 0x59, 0x28, 0x37, 0xfd, 0x48, 0x8c, 0xc1, 0xa0, 0x91, 0x16, 0xb3, 0x5c, 0x5d, 0xab,
+	0xab, 0xef, 0x4f, 0xfe, 0xe0, 0xa4, 0x02, 0xda, 0xe2, 0x8a, 0x31, 0x25, 0x87, 0x0e, 0xe5, 0xa7,
+	0x40, 0x17, 0x4b, 0xc2, 0x70, 0xdd, 0xe1, 0x1a, 0x61, 0x65, 0xfa, 0x6a, 0x78, 0xf5, 0x18, 0x84,
+	0xd1, 0x1b, 0x80, 0x28, 0xa3, 0xe6, 0x36, 0xc8, 0x7c, 0x83, 0x05, 0xc9, 0x66, 0x7a, 0xc4, 0x61,
+	0xc3, 0x55, 0x02, 0xd5, 0x3b, 0x30, 0x70, 0x46, 0x2d, 0x74, 0x8b, 0x1e, 0x64, 0x7a, 0xa9, 0x30,
+	0xe1, 0x95, 0xcc, 0xfd, 0x74, 0x95, 0xb4, 0x42, 0xd2, 0x70, 0x62, 0xd2, 0x34, 0x29, 0xe2, 0x54,
+	0x3d, 0x7a, 0x97, 0xaa, 0x7c, 0x39, 0x60, 0x46, 0xc2, 0xe8, 0xcc, 0x99, 0x43, 0xe5, 0xe2, 0xed,
+	0x20, 0x8a, 0xd7, 0x48, 0xfc, 0x20, 0x08, 0x77, 0x44, 0xe0, 0xb1, 0x24, 0x06, 0x66, 0x02, 0xc2,
+	0x3a, 0x1e, 0xe5, 0x83, 0xd9, 0xe3, 0xf3, 0x4a, 0x95, 0xbd, 0x00, 0x0e, 0x27, 0xfb, 0xe4, 0x16,
+	0x2f, 0xc6, 0x12, 0x2e, 0x51, 0x57, 0x6a, 0x8b, 0xec, 0x35, 0x2f, 0x85, 0xba, 0x52, 0x5b, 0xc4,
+	0x12, 0x8e, 0x48, 0x67, 0xca, 0xd1, 0xf1, 0x7c, 0xad, 0x66, 0xe7, 0x75, 0xd0, 0x67, 0xd6, 0x51,
+	0x1f, 0x26, 0x55, 0xb2, 0x53, 0x1e, 0x91, 0x2d, 0x9a, 0x9e, 0x60, 0x8b, 0xa4, 0xff, 0x70, 0x6e,
+	0x4a, 0x4f, 0xbc, 0x92, 0xa2, 0x84, 0x3b, 0x68, 0x1b, 0xb1, 0x49, 0x26, 0x7b, 0xe6, 0x3b, 0x9a,
+	0x83, 0x72, 0xd4, 0xde, 0x68, 0x06, 0xbb, 0x8e, 0xeb, 0xb3, 0x47, 0x37, 0x8d, 0xc9, 0xaa, 0x4b,
+	0x00, 0x4e, 0x70, 0xd0, 0x32, 0x0c, 0x3b, 0x52, 0x09, 0x8c, 0xf2, 0x83, 0x15, 0x28, 0xd5, 0x2f,
+	0xf7, 0xdf, 0x95, 0x6a, 0x5f, 0x55, 0x17, 0xbd, 0x06, 0x63, 0xc2, 0x5d, 0x8b, 0x87, 0x70, 0x60,
+	0x8f, 0x62, 0x9a, 0x3d, 0x7e, 0x5d, 0x07, 0x62, 0x13, 0x17, 0x7d, 0x11, 0xc6, 0x29, 0x95, 0xe4,
+	0x60, 0x9b, 0x3e, 0xdb, 0xcf, 0x89, 0xa8, 0xe5, 0xb1, 0xd0, 0x2b, 0xe3, 0x14, 0x31, 0xd4, 0x84,
+	0x4b, 0x4e, 0x3b, 0x0e, 0x98, 0x22, 0xdd, 0x5c, 0xff, 0xeb, 0xc1, 0x0e, 0xf1, 0xd9, 0xdb, 0xd8,
+	0xf0, 0xc2, 0xd5, 0xc3, 0x83, 0xca, 0xa5, 0xf9, 0x2e, 0x78, 0xb8, 0x2b, 0x15, 0x74, 0x0f, 0x46,
+	0xe2, 0xc0, 0x63, 0x96, 0xf1, 0x94, 0x95, 0x38, 0x9f, 0x1f, 0xdb, 0x67, 0x5d, 0xa1, 0xe9, 0x4a,
+	0x24, 0x55, 0x15, 0xeb, 0x74, 0xd0, 0x3a, 0xdf, 0x63, 0x2c, 0xea, 0x29, 0x89, 0xa6, 0x2f, 0xe4,
+	0x0f, 0x8c, 0x0a, 0x8e, 0x6a, 0x6e, 0x41, 0x51, 0x13, 0xeb, 0x64, 0xd0, 0x4d, 0x98, 0x6a, 0x85,
+	0x6e, 0xc0, 0x16, 0xb6, 0x7a, 0xc4, 0x98, 0x36, 0x53, 0x17, 0xd4, 0xd2, 0x08, 0xb8, 0xb3, 0x0e,
+	0x15, 0x32, 0x65, 0xe1, 0xf4, 0x45, 0x9e, 0x07, 0x8b, 0x33, 0xde, 0xbc, 0x0c, 0x2b, 0x28, 0x5a,
+	0x65, 0xe7, 0x32, 0x17, 0x07, 0xa7, 0x67, 0xf2, 0x83, 0x3c, 0xe8, 0x62, 0x23, 0xe7, 0x97, 0xd4,
+	0x5f, 0x9c, 0x50, 0xa0, 0xf7, 0x46, 0xb4, 0xed, 0x84, 0xa4, 0x16, 0x06, 0x0d, 0xc2, 0x3b, 0xc3,
+	0x8d, 0xf2, 0x9f, 0xe0, 0xc1, 0x19, 0xe9, 0xbd, 0x51, 0xcf, 0x42, 0xc0, 0xd9, 0xf5, 0x50, 0x53,
+	0x4b, 0xff, 0x4c, 0xd9, 0xd0, 0x68, 0xfa, 0x52, 0x17, 0x33, 0xa6, 0x14, 0xcf, 0x9a, 0xac, 0x45,
+	0xa3, 0x38, 0xc2, 0x29, 0x9a, 0x33, 0xdf, 0x0e, 0x53, 0x1d, 0xf7, 0xc5, 0xb1, 0xe2, 0x82, 0xff,
+	0xc9, 0x00, 0x94, 0x95, 0x2a, 0x1c, 0xcd, 0x99, 0x2f, 0x1c, 0x17, 0xd3, 0x2f, 0x1c, 0xc3, 0x94,
+	0x23, 0xd7, 0x1f, 0x35, 0xd6, 0x0d, 0xa3, 0xbb, 0x42, 0x7e, 0x16, 0x2e, 0x9d, 0xa7, 0xee, 0xe9,
+	0x61, 0xa7, 0x69, 0x36, 0x8a, 0x7d, 0x3f, 0x95, 0x94, 0xba, 0x2a, 0x4b, 0xfa, 0x4c, 0x82, 0x4b,
+	0x85, 0xff, 0x56, 0xd0, 0x5c, 0xa9, 0xa5, 0xb3, 0x42, 0xd6, 0x68, 0x21, 0xe6, 0x30, 0x26, 0xbe,
+	0x51, 0xe6, 0x86, 0x89, 0x6f, 0x43, 0x8f, 0x28, 0xbe, 0x49, 0x02, 0x38, 0xa1, 0x85, 0x3c, 0x98,
+	0x6a, 0x98, 0x09, 0x3d, 0x95, 0x57, 0xdd, 0x53, 0x3d, 0x53, 0x6b, 0xb6, 0xb5, 0xec, 0x69, 0x8b,
+	0x69, 0x2a, 0xb8, 0x93, 0x30, 0x7a, 0x0d, 0x86, 0xdf, 0x0b, 0x22, 0xb6, 0xf9, 0xc4, 0x0d, 0x2f,
+	0xbd, 0x8f, 0x86, 0xdf, 0xbc, 0x5b, 0x67, 0xe5, 0x47, 0x07, 0x95, 0x91, 0x5a, 0xd0, 0x94, 0x7f,
+	0xb1, 0xaa, 0x80, 0x1e, 0xc2, 0x39, 0xe3, 0x5c, 0x54, 0xdd, 0x85, 0xfe, 0xbb, 0x7b, 0x59, 0x34,
+	0x77, 0x6e, 0x25, 0x8b, 0x12, 0xce, 0x6e, 0x80, 0x1e, 0x36, 0x7e, 0x20, 0x92, 0xe1, 0x4a, 0x2e,
+	0x82, 0x31, 0x0b, 0x65, 0xdd, 0xf7, 0x3c, 0x85, 0x80, 0x3b, 0xeb, 0xd8, 0x5f, 0xe3, 0x2f, 0x07,
+	0x42, 0xbf, 0x48, 0xa2, 0xb6, 0x77, 0x1a, 0xb9, 0x96, 0x96, 0x0c, 0xd5, 0xe7, 0x23, 0xbf, 0x4e,
+	0xfd, 0xa6, 0xc5, 0x5e, 0xa7, 0xd6, 0xc9, 0x6e, 0xcb, 0xa3, 0x52, 0xee, 0xe3, 0xef, 0xf8, 0x9b,
+	0x30, 0x1c, 0x8b, 0xd6, 0xba, 0xa5, 0x87, 0xd2, 0x3a, 0xc5, 0x5e, 0xe8, 0x14, 0x7f, 0x21, 0x4b,
+	0xb1, 0x22, 0x63, 0xff, 0x53, 0x3e, 0x03, 0x12, 0x72, 0x0a, 0x6a, 0xa8, 0xaa, 0xa9, 0x86, 0xaa,
+	0xf4, 0xf8, 0x82, 0x1c, 0x75, 0xd4, 0x3f, 0x31, 0xfb, 0xcd, 0x44, 0xb9, 0x8f, 0xfa, 0xb3, 0xa8,
+	0xfd, 0x63, 0x16, 0x9c, 0xcd, 0xb2, 0x4f, 0xa2, 0x3c, 0x21, 0x17, 0x24, 0xd5, 0x33, 0xb1, 0x1a,
+	0xc1, 0xfb, 0xa2, 0x1c, 0x2b, 0x8c, 0xbe, 0x33, 0x2f, 0x1c, 0x2f, 0x3c, 0xdb, 0x5d, 0x18, 0xab,
+	0x85, 0x44, 0xbb, 0x03, 0x5e, 0xe7, 0x6e, 0x6c, 0xbc, 0x3f, 0xcf, 0x1d, 0xdb, 0x85, 0xcd, 0xfe,
+	0xf9, 0x02, 0x9c, 0xe5, 0xef, 0x3c, 0xf3, 0x7b, 0x81, 0xdb, 0xac, 0x05, 0x4d, 0x91, 0x35, 0xe3,
+	0x6d, 0x18, 0x6d, 0x69, 0xd2, 0x7f, 0xb7, 0x00, 0x51, 0xba, 0x96, 0x20, 0x91, 0xc2, 0xf4, 0x52,
+	0x6c, 0xd0, 0x42, 0x4d, 0x18, 0x25, 0x7b, 0x6e, 0x43, 0x3d, 0x16, 0x14, 0x8e, 0x7d, 0x37, 0xa8,
+	0x56, 0x96, 0x34, 0x3a, 0xd8, 0xa0, 0xfa, 0x18, 0x12, 0xa9, 0xd9, 0x3f, 0x6e, 0xc1, 0x85, 0x9c,
+	0x70, 0x52, 0xb4, 0xb9, 0x07, 0xec, 0x45, 0x4d, 0xe4, 0x64, 0x52, 0xcd, 0xf1, 0x77, 0x36, 0x2c,
+	0xa0, 0xe8, 0xf3, 0x00, 0xfc, 0x9d, 0x8c, 0x0a, 0x25, 0xbd, 0xe2, 0xee, 0x18, 0x21, 0x43, 0xb4,
+	0x50, 0x0f, 0xb2, 0x3e, 0xd6, 0x68, 0xd9, 0x3f, 0x53, 0x84, 0x01, 0xf6, 0x2e, 0x83, 0x96, 0x61,
+	0x68, 0x9b, 0x07, 0x4f, 0xee, 0x27, 0x4e, 0x73, 0x22, 0xdd, 0xf1, 0x02, 0x2c, 0x2b, 0xa3, 0x55,
+	0x38, 0xc3, 0x83, 0x4f, 0x7b, 0x55, 0xe2, 0x39, 0xfb, 0x52, 0x49, 0xc0, 0xf3, 0x18, 0xa9, 0xb0,
+	0x15, 0x2b, 0x9d, 0x28, 0x38, 0xab, 0x1e, 0x7a, 0x1d, 0xc6, 0x63, 0x77, 0x97, 0x04, 0xed, 0x58,
+	0x52, 0xe2, 0x61, 0xa7, 0x15, 0x1b, 0xb7, 0x6e, 0x40, 0x71, 0x0a, 0x9b, 0x8a, 0x3b, 0xad, 0x0e,
+	0x75, 0xc8, 0x40, 0x22, 0xee, 0x98, 0x2a, 0x10, 0x13, 0x97, 0x19, 0x10, 0xb5, 0x99, 0xb9, 0xd4,
+	0xfa, 0x76, 0x48, 0xa2, 0xed, 0xc0, 0x6b, 0x8a, 0x34, 0xd8, 0x89, 0x01, 0x51, 0x0a, 0x8e, 0x3b,
+	0x6a, 0x50, 0x2a, 0x9b, 0x8e, 0xeb, 0xb5, 0x43, 0x92, 0x50, 0x19, 0x34, 0xa9, 0x2c, 0xa7, 0xe0,
+	0xb8, 0xa3, 0x06, 0x5d, 0x47, 0xe7, 0x44, 0x5e, 0x6a, 0xe9, 0x4c, 0xaf, 0xac, 0xc2, 0x86, 0xa4,
+	0x5b, 0x51, 0x97, 0x68, 0x32, 0xc2, 0x6e, 0x46, 0x65, 0xb6, 0xd6, 0xb4, 0x78, 0xc2, 0xa1, 0x48,
+	0x52, 0x79, 0x94, 0xec, 0xc8, 0xbf, 0x67, 0xc1, 0x99, 0x0c, 0xeb, 0x56, 0x7e, 0x54, 0x6d, 0xb9,
+	0x51, 0xac, 0x72, 0xb5, 0x68, 0x47, 0x15, 0x2f, 0xc7, 0x0a, 0x83, 0xee, 0x07, 0x7e, 0x18, 0xa6,
+	0x0f, 0x40, 0x61, 0xdd, 0x25, 0xa0, 0xc7, 0x3b, 0x00, 0xd1, 0x55, 0x28, 0xb5, 0x23, 0x22, 0xe3,
+	0x40, 0xa9, 0xf3, 0x9b, 0xe9, 0x75, 0x19, 0x84, 0xb2, 0xa6, 0x5b, 0x4a, 0xa5, 0xaa, 0xb1, 0xa6,
+	0x5c, 0x4f, 0xca, 0x61, 0xf6, 0x57, 0x8b, 0x70, 0x31, 0xd7, 0x8e, 0x9d, 0x76, 0x69, 0x37, 0xf0,
+	0xdd, 0x38, 0x50, 0x6f, 0x7e, 0x3c, 0x12, 0x09, 0x69, 0x6d, 0xaf, 0x8a, 0x72, 0xac, 0x30, 0xd0,
+	0x35, 0x99, 0x21, 0x3d, 0x9d, 0x8d, 0x66, 0xa1, 0x6a, 0x24, 0x49, 0xef, 0x37, 0xd3, 0xd7, 0x53,
+	0x50, 0x6a, 0x05, 0x81, 0x97, 0x3e, 0x8c, 0x68, 0x77, 0x83, 0xc0, 0xc3, 0x0c, 0x88, 0x3e, 0x21,
+	0xc6, 0x21, 0xf5, 0xc8, 0x85, 0x9d, 0x66, 0x10, 0x69, 0x83, 0xf1, 0x0c, 0x0c, 0xed, 0x90, 0xfd,
+	0xd0, 0xf5, 0xb7, 0xd2, 0x8f, 0x9f, 0xb7, 0x79, 0x31, 0x96, 0x70, 0x33, 0x19, 0xc3, 0xd0, 0x49,
+	0xa7, 0xe8, 0x1a, 0xee, 0x79, 0xb5, 0xfd, 0x50, 0x11, 0x26, 0xf0, 0x42, 0xf5, 0x5b, 0x13, 0x71,
+	0xaf, 0x73, 0x22, 0x4e, 0x3a, 0x45, 0x57, 0xef, 0xd9, 0xf8, 0x65, 0x0b, 0x26, 0x58, 0xc0, 0x62,
+	0x11, 0xff, 0xc2, 0x0d, 0xfc, 0x53, 0x60, 0xdd, 0x9e, 0x82, 0x81, 0x90, 0x36, 0x9a, 0xce, 0xbb,
+	0xc3, 0x7a, 0x82, 0x39, 0x0c, 0x5d, 0x82, 0x12, 0xeb, 0x02, 0x9d, 0xbc, 0x51, 0x9e, 0xb2, 0xa0,
+	0xea, 0xc4, 0x0e, 0x66, 0xa5, 0xcc, 0xa9, 0x1b, 0x93, 0x96, 0xe7, 0xf2, 0x4e, 0x27, 0x0f, 0x0a,
+	0x1f, 0x0d, 0xa7, 0xee, 0xcc, 0xae, 0x7d, 0x30, 0xa7, 0xee, 0x6c, 0x92, 0xdd, 0xc5, 0xa2, 0xff,
+	0x5e, 0x80, 0x2b, 0x99, 0xf5, 0xfa, 0x76, 0xea, 0xee, 0x5e, 0xfb, 0x64, 0x6c, 0x58, 0xb2, 0x4d,
+	0x4b, 0x8a, 0xa7, 0x68, 0x5a, 0x52, 0xea, 0x97, 0x73, 0x1c, 0xe8, 0xc3, 0xd7, 0x3a, 0x73, 0xc8,
+	0x3e, 0x22, 0xbe, 0xd6, 0x99, 0x7d, 0xcb, 0x11, 0xeb, 0xfe, 0xac, 0x90, 0xf3, 0x2d, 0x4c, 0xc0,
+	0xbb, 0x4e, 0xcf, 0x19, 0x06, 0x8c, 0x04, 0x27, 0x3c, 0xca, 0xcf, 0x18, 0x5e, 0x86, 0x15, 0x14,
+	0xb9, 0x9a, 0xd7, 0x72, 0x21, 0x3f, 0x2b, 0x63, 0x6e, 0x53, 0xb3, 0xe6, 0xfb, 0x8f, 0x1a, 0x82,
+	0x0c, 0x0f, 0xe6, 0x55, 0x4d, 0x28, 0x2f, 0xf6, 0x2f, 0x94, 0x8f, 0x66, 0x0b, 0xe4, 0x68, 0x1e,
+	0x26, 0x76, 0x5d, 0x9f, 0x65, 0xd9, 0x37, 0x59, 0x51, 0x15, 0xc4, 0x63, 0xd5, 0x04, 0xe3, 0x34,
+	0xfe, 0xcc, 0x6b, 0x30, 0xf6, 0xe8, 0xea, 0xc8, 0x6f, 0x16, 0xe1, 0x89, 0x2e, 0xdb, 0x9e, 0x9f,
+	0xf5, 0xc6, 0x1c, 0x68, 0x67, 0x7d, 0xc7, 0x3c, 0xd4, 0xe0, 0xec, 0x66, 0xdb, 0xf3, 0xf6, 0x99,
+	0xf5, 0x26, 0x69, 0x4a, 0x0c, 0xc1, 0x2b, 0x5e, 0x92, 0x49, 0x22, 0x96, 0x33, 0x70, 0x70, 0x66,
+	0x4d, 0xf4, 0x06, 0xa0, 0x40, 0xa4, 0x84, 0xbd, 0x49, 0x7c, 0xa1, 0x55, 0x67, 0x03, 0x5f, 0x4c,
+	0x36, 0xe3, 0xdd, 0x0e, 0x0c, 0x9c, 0x51, 0x8b, 0x32, 0xfd, 0xf4, 0x56, 0xda, 0x57, 0xdd, 0x4a,
+	0x31, 0xfd, 0x58, 0x07, 0x62, 0x13, 0x17, 0xdd, 0x84, 0x29, 0x67, 0xcf, 0x71, 0x79, 0x70, 0x3b,
+	0x49, 0x80, 0x73, 0xfd, 0x4a, 0x09, 0x36, 0x9f, 0x46, 0xc0, 0x9d, 0x75, 0x52, 0x6e, 0xd3, 0x83,
+	0xf9, 0x6e, 0xd3, 0xdd, 0xcf, 0xc5, 0x5e, 0x3a, 0x5d, 0xfb, 0x3f, 0x59, 0xf4, 0xfa, 0xca, 0x48,
+	0xeb, 0x4e, 0xc7, 0x41, 0xe9, 0x26, 0x35, 0x0f, 0xe6, 0x73, 0x9a, 0x7d, 0x46, 0x02, 0xc4, 0x26,
+	0x2e, 0x5f, 0x10, 0x51, 0xe2, 0xe2, 0x62, 0xb0, 0xee, 0x22, 0x44, 0x81, 0xc2, 0x40, 0x5f, 0x80,
+	0xa1, 0xa6, 0xbb, 0xe7, 0x46, 0x41, 0x28, 0x36, 0xcb, 0x31, 0x1d, 0x05, 0x92, 0x73, 0xb0, 0xca,
+	0xc9, 0x60, 0x49, 0xcf, 0xfe, 0xa1, 0x02, 0x8c, 0xc9, 0x16, 0xdf, 0x6c, 0x07, 0xb1, 0x73, 0x0a,
+	0xd7, 0xf2, 0x4d, 0xe3, 0x5a, 0xfe, 0x44, 0xb7, 0x38, 0x0d, 0xac, 0x4b, 0xb9, 0xd7, 0xf1, 0xdd,
+	0xd4, 0x75, 0xfc, 0x74, 0x6f, 0x52, 0xdd, 0xaf, 0xe1, 0x7f, 0x66, 0xc1, 0x94, 0x81, 0x7f, 0x0a,
+	0xb7, 0xc1, 0xb2, 0x79, 0x1b, 0x3c, 0xd9, 0xf3, 0x1b, 0x72, 0x6e, 0x81, 0xef, 0x2b, 0xa6, 0xfa,
+	0xce, 0x4e, 0xff, 0xf7, 0xa0, 0xb4, 0xed, 0x84, 0xcd, 0x6e, 0xf1, 0x60, 0x3b, 0x2a, 0xcd, 0xde,
+	0x72, 0xc2, 0x26, 0x3f, 0xc3, 0x9f, 0x53, 0x89, 0x24, 0x9d, 0xb0, 0xd9, 0xd3, 0xa3, 0x8b, 0x35,
+	0x85, 0x5e, 0x85, 0xc1, 0xa8, 0x11, 0xb4, 0x94, 0xbd, 0xe5, 0x55, 0x9e, 0x64, 0x92, 0x96, 0x1c,
+	0x1d, 0x54, 0x90, 0xd9, 0x1c, 0x2d, 0xc6, 0x02, 0x1f, 0xbd, 0x0d, 0x63, 0xec, 0x97, 0xb2, 0x3b,
+	0x28, 0xe6, 0x67, 0x21, 0xa8, 0xeb, 0x88, 0xdc, 0x7c, 0xc5, 0x28, 0xc2, 0x26, 0xa9, 0x99, 0x2d,
+	0x28, 0xab, 0xcf, 0x7a, 0xac, 0x9e, 0x38, 0xff, 0xbe, 0x08, 0x67, 0x32, 0xd6, 0x1c, 0x8a, 0x8c,
+	0x99, 0x78, 0xa1, 0xcf, 0xa5, 0xfa, 0x01, 0xe7, 0x22, 0x62, 0xd2, 0x50, 0x53, 0xac, 0xad, 0xbe,
+	0x1b, 0xbd, 0x17, 0x91, 0x74, 0xa3, 0xb4, 0xa8, 0x77, 0xa3, 0xb4, 0xb1, 0x53, 0x1b, 0x6a, 0xda,
+	0x90, 0xea, 0xe9, 0x63, 0x9d, 0xd3, 0x3f, 0x2e, 0xc2, 0xd9, 0xac, 0xd0, 0x31, 0xe8, 0xbb, 0x53,
+	0xd9, 0x66, 0x5e, 0xea, 0x37, 0xe8, 0x0c, 0x4f, 0x41, 0x23, 0x72, 0x27, 0xcf, 0x9a, 0xf9, 0x67,
+	0x7a, 0x0e, 0xb3, 0x68, 0x93, 0xb9, 0x6f, 0x86, 0x3c, 0x4b, 0x90, 0x3c, 0x3e, 0x3e, 0xdd, 0x77,
+	0x07, 0x44, 0x7a, 0xa1, 0x28, 0xe5, 0xbe, 0x29, 0x8b, 0x7b, 0xbb, 0x6f, 0xca, 0x96, 0x67, 0x5c,
+	0x18, 0xd1, 0xbe, 0xe6, 0xb1, 0xce, 0xf8, 0x0e, 0xbd, 0xad, 0xb4, 0x7e, 0x3f, 0xd6, 0x59, 0xff,
+	0x71, 0x0b, 0x52, 0xc6, 0x8d, 0x4a, 0xdd, 0x65, 0xe5, 0xaa, 0xbb, 0xae, 0x42, 0x29, 0x0c, 0x3c,
+	0x92, 0x4e, 0x00, 0x83, 0x03, 0x8f, 0x60, 0x06, 0xa1, 0x18, 0x71, 0xa2, 0xec, 0x18, 0xd5, 0x05,
+	0x39, 0x21, 0xa2, 0x3d, 0x05, 0x03, 0x1e, 0xd9, 0x23, 0x5e, 0x3a, 0xba, 0xfa, 0x1d, 0x5a, 0x88,
+	0x39, 0xcc, 0xfe, 0xe5, 0x12, 0x5c, 0xee, 0xea, 0x58, 0x4d, 0xc5, 0xa1, 0x2d, 0x27, 0x26, 0x0f,
+	0x9c, 0xfd, 0x74, 0x18, 0xe4, 0x9b, 0xbc, 0x18, 0x4b, 0x38, 0xb3, 0xf7, 0xe6, 0x61, 0x0f, 0x53,
+	0xca, 0x41, 0x11, 0xed, 0x50, 0x40, 0x1f, 0x43, 0xde, 0xf8, 0x1b, 0x00, 0x51, 0xe4, 0x2d, 0xf9,
+	0x94, 0xbb, 0x6b, 0x0a, 0x43, 0xf2, 0x24, 0x3c, 0x66, 0xfd, 0x8e, 0x80, 0x60, 0x0d, 0x0b, 0x55,
+	0x61, 0xb2, 0x15, 0x06, 0x31, 0xd7, 0xb5, 0x56, 0xb9, 0x99, 0xcf, 0x80, 0xe9, 0x7b, 0x5a, 0x4b,
+	0xc1, 0x71, 0x47, 0x0d, 0xf4, 0x32, 0x8c, 0x08, 0x7f, 0xd4, 0x5a, 0x10, 0x78, 0x42, 0x0d, 0xa4,
+	0x8c, 0x46, 0xea, 0x09, 0x08, 0xeb, 0x78, 0x5a, 0x35, 0xa6, 0xc0, 0x1d, 0xca, 0xac, 0xc6, 0x95,
+	0xb8, 0x1a, 0x5e, 0x2a, 0x8c, 0xd4, 0x70, 0x5f, 0x61, 0xa4, 0x12, 0xc5, 0x58, 0xb9, 0xef, 0x37,
+	0x2b, 0xe8, 0xa9, 0x4a, 0xfa, 0x85, 0x12, 0x9c, 0x11, 0x0b, 0xe7, 0x71, 0x2f, 0x97, 0xc7, 0x94,
+	0xdd, 0xfe, 0x5b, 0x6b, 0xe6, 0xb4, 0xd7, 0xcc, 0x0f, 0x5b, 0x60, 0xb2, 0x57, 0xe8, 0xff, 0xcb,
+	0x8d, 0x23, 0xff, 0x72, 0x2e, 0xbb, 0xd6, 0x94, 0x17, 0xc8, 0x07, 0x8c, 0x28, 0x6f, 0xff, 0x47,
+	0x0b, 0x9e, 0xec, 0x49, 0x11, 0x2d, 0x41, 0x99, 0xf1, 0x80, 0x9a, 0x74, 0xf6, 0xb4, 0x32, 0x03,
+	0x94, 0x80, 0x1c, 0x96, 0x34, 0xa9, 0x89, 0x96, 0x3a, 0x02, 0xf6, 0x3f, 0x93, 0x11, 0xb0, 0xff,
+	0x9c, 0x31, 0x3c, 0x8f, 0x18, 0xb1, 0xff, 0x6b, 0x45, 0x18, 0xe4, 0x2b, 0xfe, 0x14, 0xc4, 0xb0,
+	0x65, 0xa1, 0xb7, 0xed, 0x12, 0xa7, 0x8a, 0xf7, 0x65, 0xb6, 0xea, 0xc4, 0x0e, 0x67, 0x13, 0xd4,
+	0x6d, 0x95, 0x68, 0x78, 0xd1, 0xac, 0x71, 0x9f, 0xcd, 0xa4, 0x14, 0x93, 0xc0, 0x69, 0x68, 0xb7,
+	0xdb, 0x97, 0x00, 0x22, 0x96, 0xc8, 0x9e, 0xd2, 0x10, 0x11, 0xcf, 0x3e, 0xd9, 0xa5, 0xf5, 0xba,
+	0x42, 0xe6, 0x7d, 0x48, 0x76, 0xba, 0x02, 0x60, 0x8d, 0xe2, 0xcc, 0x2b, 0x50, 0x56, 0xc8, 0xbd,
+	0xb4, 0x38, 0xa3, 0x3a, 0x73, 0xf1, 0x39, 0x98, 0x48, 0xb5, 0x75, 0x2c, 0x25, 0xd0, 0xaf, 0x58,
+	0x30, 0xc1, 0xbb, 0xbc, 0xe4, 0xef, 0x89, 0x33, 0xf5, 0x7d, 0x38, 0xeb, 0x65, 0x9c, 0x6d, 0x62,
+	0x46, 0xfb, 0x3f, 0x0b, 0x95, 0xd2, 0x27, 0x0b, 0x8a, 0x33, 0xdb, 0x40, 0xd7, 0xe9, 0xba, 0xa5,
+	0x67, 0x97, 0xe3, 0x09, 0xdf, 0xa1, 0x51, 0xbe, 0x66, 0x79, 0x19, 0x56, 0x50, 0xfb, 0x77, 0x2c,
+	0x98, 0xe2, 0x3d, 0xbf, 0x4d, 0xf6, 0xd5, 0x0e, 0xff, 0x30, 0xfb, 0x2e, 0x72, 0x68, 0x14, 0x72,
+	0x72, 0x68, 0xe8, 0x9f, 0x56, 0xec, 0xfa, 0x69, 0x3f, 0x6f, 0x81, 0x58, 0x81, 0xa7, 0x20, 0xca,
+	0x7f, 0xbb, 0x29, 0xca, 0xcf, 0xe4, 0x2f, 0xea, 0x1c, 0x19, 0xfe, 0x4f, 0x2d, 0x98, 0xe4, 0x08,
+	0xc9, 0x5b, 0xf2, 0x87, 0x3a, 0x0f, 0xfd, 0x24, 0xc3, 0x53, 0xd9, 0xaf, 0xb3, 0x3f, 0xca, 0x98,
+	0xac, 0x52, 0xd7, 0xc9, 0x6a, 0xca, 0x0d, 0x74, 0x8c, 0x24, 0x8f, 0xc7, 0x8e, 0x45, 0x6d, 0xff,
+	0x91, 0x05, 0x88, 0x37, 0x63, 0xb0, 0x3f, 0x94, 0xa9, 0x60, 0xa5, 0xda, 0x75, 0x91, 0x1c, 0x35,
+	0x0a, 0x82, 0x35, 0xac, 0x13, 0x19, 0x9e, 0x94, 0x41, 0x40, 0xb1, 0xb7, 0x41, 0xc0, 0x31, 0x46,
+	0xf4, 0x6b, 0x25, 0x48, 0x1b, 0xf3, 0xa3, 0xfb, 0x30, 0xda, 0x70, 0x5a, 0xce, 0x86, 0xeb, 0xb9,
+	0xb1, 0x4b, 0xa2, 0x6e, 0x96, 0x44, 0x8b, 0x1a, 0x9e, 0x78, 0xea, 0xd5, 0x4a, 0xb0, 0x41, 0x07,
+	0xcd, 0x02, 0xb4, 0x42, 0x77, 0xcf, 0xf5, 0xc8, 0x16, 0xd3, 0x38, 0x30, 0x6f, 0x45, 0x6e, 0x1e,
+	0x23, 0x4b, 0xb1, 0x86, 0x91, 0xe1, 0x78, 0x56, 0x7c, 0x7c, 0x8e, 0x67, 0xa5, 0x63, 0x3a, 0x9e,
+	0x0d, 0xf4, 0xe5, 0x78, 0x86, 0xe1, 0xbc, 0x64, 0x91, 0xe8, 0xff, 0x65, 0xd7, 0x23, 0x82, 0x2f,
+	0xe6, 0x3e, 0x8c, 0x33, 0x87, 0x07, 0x95, 0xf3, 0x38, 0x13, 0x03, 0xe7, 0xd4, 0x44, 0x9f, 0x87,
+	0x69, 0xc7, 0xf3, 0x82, 0x07, 0x6a, 0xd4, 0x96, 0xa2, 0x86, 0xe3, 0x71, 0x8d, 0xfd, 0x10, 0xa3,
+	0x7a, 0xe9, 0xf0, 0xa0, 0x32, 0x3d, 0x9f, 0x83, 0x83, 0x73, 0x6b, 0xa7, 0xfc, 0xd6, 0x86, 0x7b,
+	0xf9, 0xad, 0xd9, 0x3b, 0x70, 0xa6, 0x4e, 0x42, 0x97, 0xa5, 0xa0, 0x6c, 0x26, 0x5b, 0x72, 0x1d,
+	0xca, 0x61, 0xea, 0x10, 0xea, 0x2b, 0xb0, 0x91, 0x16, 0x66, 0x57, 0x1e, 0x3a, 0x09, 0x21, 0xfb,
+	0x4f, 0x2c, 0x18, 0x12, 0x0e, 0x05, 0xa7, 0xc0, 0xfb, 0xcc, 0x1b, 0x2a, 0xe8, 0x4a, 0xf6, 0x41,
+	0xcd, 0x3a, 0x93, 0xab, 0x7c, 0x5e, 0x49, 0x29, 0x9f, 0x9f, 0xec, 0x46, 0xa4, 0xbb, 0xda, 0xf9,
+	0x6f, 0x15, 0x61, 0xdc, 0x74, 0xa6, 0x38, 0x85, 0x21, 0x58, 0x83, 0xa1, 0x48, 0x78, 0xee, 0x14,
+	0xf2, 0x6d, 0x9f, 0xd3, 0x93, 0x98, 0x18, 0x36, 0x09, 0x5f, 0x1d, 0x49, 0x24, 0xd3, 0x25, 0xa8,
+	0xf8, 0x18, 0x5d, 0x82, 0x7a, 0xf9, 0xb3, 0x94, 0x4e, 0xc2, 0x9f, 0xc5, 0xfe, 0x3a, 0xbb, 0x2c,
+	0xf4, 0xf2, 0x53, 0xe0, 0x23, 0x6e, 0x9a, 0xd7, 0x8a, 0xdd, 0x65, 0x65, 0x89, 0x4e, 0xe5, 0xf0,
+	0x13, 0xbf, 0x64, 0xc1, 0xe5, 0x8c, 0xaf, 0xd2, 0x98, 0x8b, 0xe7, 0x60, 0xd8, 0x69, 0x37, 0x5d,
+	0xb5, 0x97, 0xb5, 0x87, 0xa8, 0x79, 0x51, 0x8e, 0x15, 0x06, 0x5a, 0x84, 0x29, 0xf2, 0xb0, 0xe5,
+	0xf2, 0x97, 0x40, 0xdd, 0xfa, 0xb0, 0xc8, 0x43, 0xc8, 0x2e, 0xa5, 0x81, 0xb8, 0x13, 0x5f, 0xb9,
+	0x43, 0x17, 0x73, 0xdd, 0xa1, 0xff, 0xa1, 0x05, 0x23, 0xa2, 0xdb, 0xa7, 0x30, 0xda, 0xdf, 0x61,
+	0x8e, 0xf6, 0x13, 0x5d, 0x46, 0x3b, 0x67, 0x98, 0xff, 0x4e, 0x41, 0xf5, 0xb7, 0x16, 0x84, 0x71,
+	0x1f, 0x4c, 0xcb, 0xab, 0x30, 0xdc, 0x0a, 0x83, 0x38, 0x68, 0x04, 0x9e, 0xe0, 0x59, 0x2e, 0x25,
+	0xde, 0xfa, 0xbc, 0xfc, 0x48, 0xfb, 0x8d, 0x15, 0x36, 0x1b, 0xbd, 0x20, 0x8c, 0x05, 0x9f, 0x90,
+	0x8c, 0x5e, 0x10, 0xc6, 0x98, 0x41, 0x50, 0x13, 0x20, 0x76, 0xc2, 0x2d, 0x12, 0xd3, 0x32, 0x11,
+	0xf8, 0x23, 0xff, 0xf0, 0x68, 0xc7, 0xae, 0x37, 0xeb, 0xfa, 0x71, 0x14, 0x87, 0xb3, 0x2b, 0x7e,
+	0x7c, 0x37, 0xe4, 0x22, 0x90, 0xe6, 0x7e, 0xaf, 0x68, 0x61, 0x8d, 0xae, 0xf4, 0x91, 0x64, 0x6d,
+	0x0c, 0x98, 0x4f, 0xda, 0x6b, 0xa2, 0x1c, 0x2b, 0x0c, 0xfb, 0x15, 0x76, 0x95, 0xb0, 0x01, 0x3a,
+	0x9e, 0x67, 0xfc, 0x37, 0x86, 0xd5, 0xd0, 0xb2, 0xf7, 0xac, 0xaa, 0xee, 0x7f, 0xdf, 0xfd, 0xe4,
+	0xa6, 0x0d, 0xeb, 0x9e, 0x30, 0x89, 0x93, 0x3e, 0xfa, 0xce, 0x0e, 0x4b, 0x87, 0xe7, 0x7b, 0x5c,
+	0x01, 0xc7, 0xb0, 0x6d, 0x60, 0x61, 0xad, 0x59, 0xf8, 0xdf, 0x95, 0x9a, 0x58, 0xe4, 0x5a, 0x58,
+	0x6b, 0x01, 0xc0, 0x09, 0x0e, 0x9a, 0x13, 0x02, 0x74, 0xc9, 0xc8, 0x3e, 0x27, 0x05, 0x68, 0xf9,
+	0xf9, 0x9a, 0x04, 0xfd, 0x02, 0x8c, 0xa8, 0x2c, 0x74, 0x35, 0x9e, 0xcc, 0x4b, 0x84, 0x41, 0x59,
+	0x4a, 0x8a, 0xb1, 0x8e, 0x83, 0xd6, 0x61, 0x22, 0xe2, 0xda, 0x13, 0x15, 0xed, 0x8e, 0x6b, 0xa1,
+	0x3e, 0x29, 0x2d, 0x24, 0xea, 0x26, 0xf8, 0x88, 0x15, 0xf1, 0xa3, 0x43, 0x3a, 0x3a, 0xa6, 0x49,
+	0xa0, 0xd7, 0x61, 0xdc, 0xd3, 0x73, 0xb9, 0xd7, 0x84, 0x92, 0x4a, 0x19, 0x10, 0x1b, 0x99, 0xde,
+	0x6b, 0x38, 0x85, 0x4d, 0x79, 0x1d, 0xbd, 0x44, 0x44, 0x68, 0x74, 0xfc, 0x2d, 0x12, 0x89, 0x1c,
+	0x5a, 0x8c, 0xd7, 0xb9, 0x93, 0x83, 0x83, 0x73, 0x6b, 0xa3, 0x57, 0x61, 0x54, 0x7e, 0xbe, 0xe6,
+	0xc6, 0x9b, 0x98, 0xa9, 0x6b, 0x30, 0x6c, 0x60, 0xa2, 0x07, 0x70, 0x4e, 0xfe, 0x5f, 0x0f, 0x9d,
+	0xcd, 0x4d, 0xb7, 0x21, 0xbc, 0xa8, 0xb9, 0xaf, 0xce, 0xbc, 0x74, 0xfe, 0x59, 0xca, 0x42, 0x3a,
+	0x3a, 0xa8, 0x5c, 0x15, 0xa3, 0x96, 0x09, 0x67, 0x93, 0x98, 0x4d, 0x1f, 0xad, 0xc2, 0x99, 0x6d,
+	0xe2, 0x78, 0xf1, 0xf6, 0xe2, 0x36, 0x69, 0xec, 0xc8, 0x4d, 0xc4, 0x9c, 0x83, 0x35, 0xe3, 0xee,
+	0x5b, 0x9d, 0x28, 0x38, 0xab, 0x1e, 0x7a, 0x07, 0xa6, 0x5b, 0xed, 0x0d, 0xcf, 0x8d, 0xb6, 0xd7,
+	0x82, 0x98, 0x19, 0x65, 0xa8, 0x24, 0x6e, 0xc2, 0x8b, 0x58, 0x39, 0x46, 0xd7, 0x72, 0xf0, 0x70,
+	0x2e, 0x05, 0xf4, 0x3e, 0x9c, 0x4b, 0x2d, 0x06, 0xe1, 0xd3, 0x38, 0x9e, 0x1f, 0xb6, 0xb4, 0x9e,
+	0x55, 0x41, 0xf8, 0x28, 0x66, 0x81, 0x70, 0x76, 0x13, 0x1f, 0xcc, 0x54, 0xe7, 0x3d, 0x5a, 0x59,
+	0x63, 0xca, 0xd0, 0x97, 0x61, 0x54, 0x5f, 0x45, 0xe2, 0x82, 0xb9, 0x96, 0xcd, 0xb3, 0x68, 0xab,
+	0x8d, 0xb3, 0x74, 0x6a, 0x45, 0xe9, 0x30, 0x6c, 0x50, 0xb4, 0x09, 0x64, 0x7f, 0x1f, 0xba, 0x03,
+	0xc3, 0x0d, 0xcf, 0x25, 0x7e, 0xbc, 0x52, 0xeb, 0x16, 0x74, 0x63, 0x51, 0xe0, 0x88, 0x01, 0x13,
+	0x01, 0x42, 0x79, 0x19, 0x56, 0x14, 0xec, 0xdf, 0x28, 0x40, 0xa5, 0x47, 0x14, 0xdb, 0x94, 0x46,
+	0xd9, 0xea, 0x4b, 0xa3, 0x3c, 0x2f, 0x53, 0xd2, 0xad, 0xa5, 0xc4, 0xec, 0x54, 0xba, 0xb9, 0x44,
+	0xd8, 0x4e, 0xe3, 0xf7, 0x6d, 0xe1, 0xab, 0x2b, 0xa5, 0x4b, 0x3d, 0x6d, 0xcf, 0x8d, 0xc7, 0xa8,
+	0x81, 0xfe, 0x05, 0x91, 0xdc, 0x87, 0x05, 0xfb, 0xeb, 0x05, 0x38, 0xa7, 0x86, 0xf0, 0x2f, 0xee,
+	0xc0, 0xdd, 0xeb, 0x1c, 0xb8, 0x13, 0x78, 0x96, 0xb1, 0xef, 0xc2, 0x20, 0x0f, 0x5a, 0xd2, 0x07,
+	0x03, 0xf4, 0x94, 0x19, 0xe1, 0x4a, 0x5d, 0xd3, 0x46, 0x94, 0xab, 0xbf, 0x62, 0xc1, 0xc4, 0xfa,
+	0x62, 0xad, 0x1e, 0x34, 0x76, 0x48, 0x3c, 0xcf, 0x19, 0x56, 0x2c, 0xf8, 0x1f, 0xeb, 0x11, 0xf9,
+	0x9a, 0x2c, 0x8e, 0xe9, 0x2a, 0x94, 0xb6, 0x83, 0x28, 0x4e, 0xbf, 0xd9, 0xde, 0x0a, 0xa2, 0x18,
+	0x33, 0x88, 0xfd, 0xbb, 0x16, 0x0c, 0xb0, 0x44, 0xaa, 0xbd, 0xb2, 0xfb, 0xf6, 0xf3, 0x5d, 0xe8,
+	0x65, 0x18, 0x24, 0x9b, 0x9b, 0xa4, 0x11, 0x8b, 0x59, 0x95, 0x0e, 0xa5, 0x83, 0x4b, 0xac, 0x94,
+	0x5e, 0xfa, 0xac, 0x31, 0xfe, 0x17, 0x0b, 0x64, 0xf4, 0x16, 0x94, 0x63, 0x77, 0x97, 0xcc, 0x37,
+	0x9b, 0xe2, 0xd5, 0xeb, 0x11, 0xfc, 0x77, 0xd7, 0x25, 0x01, 0x9c, 0xd0, 0xb2, 0xbf, 0x5a, 0x00,
+	0x48, 0x5c, 0xef, 0x7b, 0x7d, 0xe2, 0x42, 0xc7, 0x7b, 0xc8, 0xb5, 0x8c, 0xf7, 0x10, 0x94, 0x10,
+	0xcc, 0x78, 0x0c, 0x51, 0xc3, 0x54, 0xec, 0x6b, 0x98, 0x4a, 0xc7, 0x19, 0xa6, 0x45, 0x98, 0x4a,
+	0x42, 0x07, 0x98, 0x71, 0x54, 0x98, 0x90, 0xb2, 0x9e, 0x06, 0xe2, 0x4e, 0x7c, 0x9b, 0xc0, 0x55,
+	0x19, 0xd1, 0x52, 0xde, 0x35, 0xcc, 0xa8, 0xf2, 0x18, 0x89, 0x9e, 0x93, 0x07, 0x9f, 0x42, 0xee,
+	0x83, 0xcf, 0x4f, 0x59, 0x70, 0x36, 0xdd, 0x0e, 0xf3, 0x5e, 0xfb, 0x01, 0x0b, 0xce, 0xb1, 0x67,
+	0x2f, 0xd6, 0x6a, 0xe7, 0x23, 0xdb, 0x4b, 0xd9, 0x21, 0x15, 0xba, 0xf7, 0x38, 0xf1, 0x5c, 0x5e,
+	0xcd, 0x22, 0x8d, 0xb3, 0x5b, 0xb4, 0xbf, 0xdf, 0x02, 0xe1, 0x24, 0xd4, 0xc7, 0xc6, 0x7e, 0x5b,
+	0xa6, 0x42, 0x35, 0x02, 0x78, 0x5f, 0xcd, 0xf7, 0x9a, 0x12, 0x61, 0xbb, 0xd5, 0x45, 0x6a, 0x04,
+	0xeb, 0x36, 0x68, 0xd9, 0x4d, 0x10, 0xd0, 0x2a, 0x61, 0x7a, 0xa2, 0xde, 0xbd, 0xb9, 0x01, 0xd0,
+	0x64, 0xb8, 0x5a, 0x42, 0x44, 0x75, 0x6c, 0x57, 0x15, 0x04, 0x6b, 0x58, 0xf6, 0x8f, 0x14, 0x60,
+	0x44, 0x06, 0x8c, 0x6e, 0xfb, 0xfd, 0x48, 0x73, 0xc7, 0xca, 0x4b, 0xc3, 0x32, 0x88, 0x52, 0xc2,
+	0xb5, 0x44, 0x08, 0x4e, 0x32, 0x88, 0x4a, 0x00, 0x4e, 0x70, 0xd0, 0x33, 0x30, 0x14, 0xb5, 0x37,
+	0x18, 0x7a, 0xca, 0xf5, 0xa5, 0xce, 0x8b, 0xb1, 0x84, 0xa3, 0xcf, 0xc3, 0x24, 0xaf, 0x17, 0x06,
+	0x2d, 0x67, 0x8b, 0x2b, 0x0d, 0x07, 0x94, 0x2f, 0xea, 0xe4, 0x6a, 0x0a, 0x76, 0x74, 0x50, 0x39,
+	0x9b, 0x2e, 0x63, 0xea, 0xe6, 0x0e, 0x2a, 0xf6, 0x97, 0x01, 0x75, 0xc6, 0xc0, 0x46, 0x6f, 0x70,
+	0x03, 0x24, 0x37, 0x24, 0xcd, 0x6e, 0x7a, 0x64, 0xdd, 0x75, 0x52, 0x9a, 0x9f, 0xf3, 0x5a, 0x58,
+	0xd5, 0xb7, 0xff, 0x5a, 0x11, 0x26, 0xd3, 0x8e, 0x74, 0xe8, 0x16, 0x0c, 0xf2, 0x0b, 0x46, 0x90,
+	0xef, 0xf2, 0x4c, 0xa9, 0xb9, 0xdf, 0xb1, 0xad, 0x26, 0xee, 0x28, 0x51, 0x1f, 0xbd, 0x03, 0x23,
+	0xcd, 0xe0, 0x81, 0xff, 0xc0, 0x09, 0x9b, 0xf3, 0xb5, 0x15, 0xb1, 0x2e, 0x33, 0xf9, 0xd4, 0x6a,
+	0x82, 0xa6, 0xbb, 0xf4, 0x31, 0x95, 0x7c, 0x02, 0xc2, 0x3a, 0x39, 0xb4, 0xce, 0xe2, 0xfa, 0x6d,
+	0xba, 0x5b, 0xab, 0x4e, 0xab, 0x9b, 0x35, 0xea, 0xa2, 0x44, 0xd2, 0x28, 0x8f, 0x89, 0xe0, 0x7f,
+	0x1c, 0x80, 0x13, 0x42, 0xe8, 0xbb, 0xe1, 0x4c, 0x94, 0xa3, 0xda, 0xca, 0x4b, 0xb5, 0xd0, 0x4d,
+	0xdb, 0xb3, 0x70, 0x81, 0x4a, 0x10, 0x59, 0x4a, 0xb0, 0xac, 0x66, 0xec, 0xc3, 0x33, 0x60, 0xec,
+	0x46, 0x23, 0xef, 0x8e, 0x75, 0x42, 0x79, 0x77, 0x30, 0x0c, 0x93, 0xdd, 0x56, 0xbc, 0x5f, 0x75,
+	0xc3, 0x6e, 0x89, 0xdb, 0x96, 0x04, 0x4e, 0x27, 0x4d, 0x09, 0xc1, 0x8a, 0x4e, 0x76, 0x72, 0xa4,
+	0xe2, 0x87, 0x98, 0x1c, 0xa9, 0x74, 0x8a, 0xc9, 0x91, 0xd6, 0x60, 0x68, 0xcb, 0x8d, 0x31, 0x69,
+	0x05, 0x82, 0xb5, 0xcb, 0x5c, 0x87, 0x37, 0x39, 0x4a, 0x67, 0x22, 0x0e, 0x01, 0xc0, 0x92, 0x08,
+	0x7a, 0x43, 0xed, 0xc0, 0xc1, 0x7c, 0xc9, 0xa8, 0xf3, 0x3d, 0x2d, 0x73, 0x0f, 0x8a, 0x64, 0x48,
+	0x43, 0x8f, 0x9a, 0x0c, 0x69, 0x59, 0xa6, 0x30, 0x1a, 0xce, 0x37, 0x1d, 0x67, 0x19, 0x8a, 0x7a,
+	0x24, 0x2e, 0x32, 0x92, 0x3d, 0x95, 0x4f, 0x2e, 0xd9, 0xd3, 0xf7, 0x5b, 0x70, 0xae, 0x95, 0x95,
+	0xf7, 0x4c, 0x24, 0x1e, 0x7a, 0xb9, 0xef, 0xc4, 0x6e, 0x46, 0x83, 0x4c, 0x44, 0xce, 0x44, 0xc3,
+	0xd9, 0xcd, 0xd1, 0x81, 0x0e, 0x37, 0x9a, 0x22, 0x5b, 0xd1, 0x53, 0x39, 0x59, 0xa3, 0xba, 0xe4,
+	0x8a, 0x5a, 0xcf, 0xc8, 0x50, 0xf4, 0xf1, 0xbc, 0x0c, 0x45, 0x7d, 0xe7, 0x25, 0x7a, 0x43, 0xe5,
+	0x8b, 0x1a, 0xcb, 0x5f, 0x4a, 0x3c, 0x1b, 0x54, 0xcf, 0x2c, 0x51, 0x6f, 0xa8, 0x2c, 0x51, 0x5d,
+	0xe2, 0x9b, 0xf1, 0x1c, 0x50, 0x3d, 0x73, 0x43, 0x69, 0xf9, 0x9d, 0x26, 0x4e, 0x26, 0xbf, 0x93,
+	0x71, 0xd5, 0x74, 0x49, 0x30, 0xa4, 0xdd, 0x27, 0x9d, 0x09, 0x86, 0x72, 0x2f, 0x1b, 0x9e, 0xcb,
+	0x6a, 0xea, 0x91, 0x72, 0x59, 0xdd, 0xd7, 0x73, 0x43, 0xa1, 0x1e, 0x39, 0x66, 0x28, 0x52, 0x9f,
+	0x19, 0xa1, 0xee, 0xeb, 0x17, 0xe0, 0x99, 0x7c, 0xba, 0xea, 0x9e, 0xeb, 0xa4, 0x9b, 0x79, 0x05,
+	0x76, 0x64, 0x9a, 0x3a, 0x7b, 0x3a, 0x99, 0xa6, 0xce, 0x3d, 0x86, 0x4c, 0x53, 0xe7, 0x4f, 0x2d,
+	0xd3, 0xd4, 0x85, 0x0f, 0x35, 0xd3, 0xd4, 0xf4, 0x63, 0xc8, 0x34, 0xb5, 0x96, 0x64, 0x9a, 0xba,
+	0x98, 0x3f, 0x35, 0x19, 0x76, 0xad, 0x39, 0xf9, 0xa5, 0xee, 0x43, 0xb9, 0x25, 0x23, 0x3e, 0x88,
+	0x40, 0x6c, 0xd9, 0x49, 0x6f, 0xb3, 0xc2, 0x42, 0xf0, 0xf5, 0xaa, 0x40, 0x38, 0x21, 0x45, 0xe9,
+	0x26, 0xf9, 0xa6, 0x9e, 0xe8, 0xa2, 0x0c, 0xcd, 0x52, 0x33, 0x75, 0xc9, 0x32, 0x65, 0xe4, 0x86,
+	0xba, 0x74, 0x72, 0xb9, 0xa1, 0xfe, 0x6a, 0x01, 0xae, 0x74, 0xdf, 0x37, 0x89, 0xee, 0xab, 0x96,
+	0xbc, 0xd5, 0xa4, 0x74, 0x5f, 0x5c, 0x88, 0x4a, 0xb0, 0xfa, 0x0e, 0xb7, 0x73, 0x13, 0xa6, 0x94,
+	0xa1, 0xac, 0xe7, 0x36, 0xf6, 0xb5, 0x24, 0xbb, 0xca, 0x21, 0xb0, 0x9e, 0x46, 0xc0, 0x9d, 0x75,
+	0xd0, 0x3c, 0x4c, 0x18, 0x85, 0x2b, 0x55, 0x21, 0x2c, 0x29, 0x65, 0x5b, 0xdd, 0x04, 0xe3, 0x34,
+	0xbe, 0xfd, 0x73, 0x16, 0x5c, 0xc8, 0x49, 0xc2, 0xd0, 0x77, 0x34, 0x99, 0x4d, 0x98, 0x68, 0x99,
+	0x55, 0x7b, 0x04, 0x9d, 0x32, 0x52, 0x3d, 0xa8, 0xbe, 0xa6, 0x00, 0x38, 0x4d, 0x74, 0xe1, 0xfa,
+	0x6f, 0xfd, 0xfe, 0x95, 0x8f, 0xfd, 0xf6, 0xef, 0x5f, 0xf9, 0xd8, 0xef, 0xfc, 0xfe, 0x95, 0x8f,
+	0xfd, 0xff, 0x87, 0x57, 0xac, 0xdf, 0x3a, 0xbc, 0x62, 0xfd, 0xf6, 0xe1, 0x15, 0xeb, 0x77, 0x0e,
+	0xaf, 0x58, 0xbf, 0x77, 0x78, 0xc5, 0xfa, 0xea, 0x1f, 0x5c, 0xf9, 0xd8, 0xdb, 0x85, 0xbd, 0x17,
+	0xfe, 0x5f, 0x00, 0x00, 0x00, 0xff, 0xff, 0x60, 0x08, 0xf7, 0x9c, 0xf8, 0xe6, 0x00, 0x00,
 }
diff --git a/staging/src/k8s.io/api/core/v1/types.go b/staging/src/k8s.io/api/core/v1/types.go
index 43e70b9bad..5417d75199 100644
--- a/staging/src/k8s.io/api/core/v1/types.go
+++ b/staging/src/k8s.io/api/core/v1/types.go
@@ -28,8 +28,6 @@ const (
 	NamespaceDefault string = "default"
 	// NamespaceAll is the default argument to specify on a context when you want to list or filter resources across all namespaces
 	NamespaceAll string = ""
-	// NamespaceNodeLease is the namespace where we place node lease objects (used for node heartbeats)
-	NamespaceNodeLease string = "kube-node-lease"
 )
 
 // Volume represents a named volume in a pod that may be accessed by any container in the pod.
@@ -135,9 +133,9 @@ type VolumeSource struct {
 	// Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
 	// +optional
 	Quobyte *QuobyteVolumeSource `json:"quobyte,omitempty" protobuf:"bytes,21,opt,name=quobyte"`
-	// AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
+	// CascadeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine
 	// +optional
-	AzureDisk *AzureDiskVolumeSource `json:"azureDisk,omitempty" protobuf:"bytes,22,opt,name=azureDisk"`
+	CascadeDisk *CascadeDiskVolumeSource `json:"vkeDisk,omitempty" protobuf:"bytes,22,opt,name=cascadeDisk"`
 	// PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
 	PhotonPersistentDisk *PhotonPersistentDiskVolumeSource `json:"photonPersistentDisk,omitempty" protobuf:"bytes,23,opt,name=photonPersistentDisk"`
 	// Items for all in one resources secrets, configmaps, and downward API
@@ -151,6 +149,9 @@ type VolumeSource struct {
 	// StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
 	// +optional
 	StorageOS *StorageOSVolumeSource `json:"storageos,omitempty" protobuf:"bytes,27,opt,name=storageos"`
+	// AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
+	// +optional
+	AzureDisk *AzureDiskVolumeSource `json:"azureDisk,omitempty" protobuf:"bytes,28,opt,name=azureDisk"`
 }
 
 // PersistentVolumeClaimVolumeSource references the user's PVC in the same namespace.
@@ -191,7 +192,7 @@ type PersistentVolumeSource struct {
 	// exposed to the pod. Provisioned by an admin.
 	// More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md
 	// +optional
-	Glusterfs *GlusterfsPersistentVolumeSource `json:"glusterfs,omitempty" protobuf:"bytes,4,opt,name=glusterfs"`
+	Glusterfs *GlusterfsVolumeSource `json:"glusterfs,omitempty" protobuf:"bytes,4,opt,name=glusterfs"`
 	// NFS represents an NFS mount on the host. Provisioned by an admin.
 	// More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
 	// +optional
@@ -230,9 +231,9 @@ type PersistentVolumeSource struct {
 	// Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
 	// +optional
 	Quobyte *QuobyteVolumeSource `json:"quobyte,omitempty" protobuf:"bytes,15,opt,name=quobyte"`
-	// AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
+	// CascadeDisk represents a Cascade persistent disk attached and mounted on kubelets host machine
 	// +optional
-	AzureDisk *AzureDiskVolumeSource `json:"azureDisk,omitempty" protobuf:"bytes,16,opt,name=azureDisk"`
+	CascadeDisk *CascadeDiskVolumeSource `json:"vkeDisk,omitempty" protobuf:"bytes,16,opt,name=cascadeDisk"`
 	// PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
 	PhotonPersistentDisk *PhotonPersistentDiskVolumeSource `json:"photonPersistentDisk,omitempty" protobuf:"bytes,17,opt,name=photonPersistentDisk"`
 	// PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
@@ -251,6 +252,9 @@ type PersistentVolumeSource struct {
 	// CSI represents storage that handled by an external CSI driver (Beta feature).
 	// +optional
 	CSI *CSIPersistentVolumeSource `json:"csi,omitempty" protobuf:"bytes,22,opt,name=csi"`
+	// AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
+	// +optional
+	AzureDisk *AzureDiskVolumeSource `json:"azureDisk,omitempty" protobuf:"bytes,23,opt,name=azureDisk"`
 }
 
 const (
@@ -326,7 +330,7 @@ type PersistentVolumeSpec struct {
 	MountOptions []string `json:"mountOptions,omitempty" protobuf:"bytes,7,opt,name=mountOptions"`
 	// volumeMode defines if a volume is intended to be used with a formatted filesystem
 	// or to remain in raw block state. Value of Filesystem is implied when not included in spec.
-	// This is a beta feature.
+	// This is an alpha feature and may change in the future.
 	// +optional
 	VolumeMode *PersistentVolumeMode `json:"volumeMode,omitempty" protobuf:"bytes,8,opt,name=volumeMode,casttype=PersistentVolumeMode"`
 	// NodeAffinity defines constraints that limit what nodes this volume can be accessed from.
@@ -455,19 +459,9 @@ type PersistentVolumeClaimSpec struct {
 	StorageClassName *string `json:"storageClassName,omitempty" protobuf:"bytes,5,opt,name=storageClassName"`
 	// volumeMode defines what type of volume is required by the claim.
 	// Value of Filesystem is implied when not included in claim spec.
-	// This is a beta feature.
+	// This is an alpha feature and may change in the future.
 	// +optional
 	VolumeMode *PersistentVolumeMode `json:"volumeMode,omitempty" protobuf:"bytes,6,opt,name=volumeMode,casttype=PersistentVolumeMode"`
-	// This field requires the VolumeSnapshotDataSource alpha feature gate to be
-	// enabled and currently VolumeSnapshot is the only supported data source.
-	// If the provisioner can support VolumeSnapshot data source, it will create
-	// a new volume and data will be restored to the volume at the same time.
-	// If the provisioner does not support VolumeSnapshot data source, volume will
-	// not be created and the failure will be reported as an event.
-	// In the future, we plan to support more data source types and the behavior
-	// of the provisioner may change.
-	// +optional
-	DataSource *TypedLocalObjectReference `json:"dataSource" protobuf:"bytes,7,opt,name=dataSource"`
 }
 
 // PersistentVolumeClaimConditionType is a valid value of PersistentVolumeClaimCondition.Type
@@ -636,30 +630,6 @@ type GlusterfsVolumeSource struct {
 	ReadOnly bool `json:"readOnly,omitempty" protobuf:"varint,3,opt,name=readOnly"`
 }
 
-// Represents a Glusterfs mount that lasts the lifetime of a pod.
-// Glusterfs volumes do not support ownership management or SELinux relabeling.
-type GlusterfsPersistentVolumeSource struct {
-	// EndpointsName is the endpoint name that details Glusterfs topology.
-	// More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod
-	EndpointsName string `json:"endpoints" protobuf:"bytes,1,opt,name=endpoints"`
-
-	// Path is the Glusterfs volume path.
-	// More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod
-	Path string `json:"path" protobuf:"bytes,2,opt,name=path"`
-
-	// ReadOnly here will force the Glusterfs volume to be mounted with read-only permissions.
-	// Defaults to false.
-	// More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod
-	// +optional
-	ReadOnly bool `json:"readOnly,omitempty" protobuf:"varint,3,opt,name=readOnly"`
-
-	// EndpointsNamespace is the namespace that contains Glusterfs endpoint.
-	// If this field is empty, the EndpointNamespace defaults to the same namespace as the bound PVC.
-	// More info: https://releases.k8s.io/HEAD/examples/volumes/glusterfs/README.md#create-a-pod
-	// +optional
-	EndpointsNamespace *string `json:"endpointsNamespace,omitempty" protobuf:"bytes,4,opt,name=endpointsNamespace"`
-}
-
 // Represents a Rados Block Device mount that lasts the lifetime of a pod.
 // RBD volumes support ownership management and SELinux relabeling.
 type RBDVolumeSource struct {
@@ -895,8 +865,6 @@ const (
 	ProtocolTCP Protocol = "TCP"
 	// ProtocolUDP is the UDP protocol.
 	ProtocolUDP Protocol = "UDP"
-	// ProtocolSCTP is the SCTP protocol.
-	ProtocolSCTP Protocol = "SCTP"
 )
 
 // Represents a Persistent Disk resource in Google Compute Engine.
@@ -1377,7 +1345,6 @@ type ScaleIOVolumeSource struct {
 	// +optional
 	StoragePool string `json:"storagePool,omitempty" protobuf:"bytes,6,opt,name=storagePool"`
 	// Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned.
-	// Default is ThinProvisioned.
 	// +optional
 	StorageMode string `json:"storageMode,omitempty" protobuf:"bytes,7,opt,name=storageMode"`
 	// The name of a volume already created in the ScaleIO system
@@ -1385,8 +1352,7 @@ type ScaleIOVolumeSource struct {
 	VolumeName string `json:"volumeName,omitempty" protobuf:"bytes,8,opt,name=volumeName"`
 	// Filesystem type to mount.
 	// Must be a filesystem type supported by the host operating system.
-	// Ex. "ext4", "xfs", "ntfs".
-	// Default is "xfs".
+	// Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
 	// +optional
 	FSType string `json:"fsType,omitempty" protobuf:"bytes,9,opt,name=fsType"`
 	// Defaults to false (read/write). ReadOnly here will force
@@ -1414,7 +1380,6 @@ type ScaleIOPersistentVolumeSource struct {
 	// +optional
 	StoragePool string `json:"storagePool,omitempty" protobuf:"bytes,6,opt,name=storagePool"`
 	// Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned.
-	// Default is ThinProvisioned.
 	// +optional
 	StorageMode string `json:"storageMode,omitempty" protobuf:"bytes,7,opt,name=storageMode"`
 	// The name of a volume already created in the ScaleIO system
@@ -1422,8 +1387,7 @@ type ScaleIOPersistentVolumeSource struct {
 	VolumeName string `json:"volumeName,omitempty" protobuf:"bytes,8,opt,name=volumeName"`
 	// Filesystem type to mount.
 	// Must be a filesystem type supported by the host operating system.
-	// Ex. "ext4", "xfs", "ntfs".
-	// Default is "xfs"
+	// Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
 	// +optional
 	FSType string `json:"fsType,omitempty" protobuf:"bytes,9,opt,name=fsType"`
 	// Defaults to false (read/write). ReadOnly here will force
@@ -1488,6 +1452,16 @@ type StorageOSPersistentVolumeSource struct {
 	SecretRef *ObjectReference `json:"secretRef,omitempty" protobuf:"bytes,5,opt,name=secretRef"`
 }
 
+// Represents a Photon Controller persistent disk resource.
+type CascadeDiskVolumeSource struct {
+	// ID that identifies Cascade persistent disk
+	DiskID string `json:"diskID" protobuf:"bytes,1,opt,name=diskID"`
+	// Filesystem type to mount.
+	// Must be a filesystem type supported by the host operating system.
+	// Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
+	FSType string `json:"fsType,omitempty" protobuf:"bytes,2,opt,name=fsType"`
+}
+
 // Adapts a ConfigMap into a volume.
 //
 // The contents of the target ConfigMap's Data field will be presented in a
@@ -1625,14 +1599,10 @@ type KeyToPath struct {
 type LocalVolumeSource struct {
 	// The full path to the volume on the node.
 	// It can be either a directory or block device (disk, partition, ...).
+	// Directories can be represented only by PersistentVolume with VolumeMode=Filesystem.
+	// Block devices can be represented only by VolumeMode=Block, which also requires the
+	// BlockVolume alpha feature gate to be enabled.
 	Path string `json:"path" protobuf:"bytes,1,opt,name=path"`
-
-	// Filesystem type to mount.
-	// It applies only when the Path is a block device.
-	// Must be a filesystem type supported by the host operating system.
-	// Ex. "ext4", "xfs", "ntfs". The default value is to auto-select a fileystem if unspecified.
-	// +optional
-	FSType *string `json:"fsType,omitempty" protobuf:"bytes,2,opt,name=fsType"`
 }
 
 // Represents storage that is managed by an external CSI volume driver (Beta feature)
@@ -1664,7 +1634,7 @@ type CSIPersistentVolumeSource struct {
 	// ControllerPublishSecretRef is a reference to the secret object containing
 	// sensitive information to pass to the CSI driver to complete the CSI
 	// ControllerPublishVolume and ControllerUnpublishVolume calls.
-	// This field is optional, and may be empty if no secret is required. If the
+	// This field is optional, and  may be empty if no secret is required. If the
 	// secret object contains more than one secret, all secrets are passed.
 	// +optional
 	ControllerPublishSecretRef *SecretReference `json:"controllerPublishSecretRef,omitempty" protobuf:"bytes,6,opt,name=controllerPublishSecretRef"`
@@ -1672,7 +1642,7 @@ type CSIPersistentVolumeSource struct {
 	// NodeStageSecretRef is a reference to the secret object containing sensitive
 	// information to pass to the CSI driver to complete the CSI NodeStageVolume
 	// and NodeStageVolume and NodeUnstageVolume calls.
-	// This field is optional, and may be empty if no secret is required. If the
+	// This field is optional, and  may be empty if no secret is required. If the
 	// secret object contains more than one secret, all secrets are passed.
 	// +optional
 	NodeStageSecretRef *SecretReference `json:"nodeStageSecretRef,omitempty" protobuf:"bytes,7,opt,name=nodeStageSecretRef"`
@@ -1680,7 +1650,7 @@ type CSIPersistentVolumeSource struct {
 	// NodePublishSecretRef is a reference to the secret object containing
 	// sensitive information to pass to the CSI driver to complete the CSI
 	// NodePublishVolume and NodeUnpublishVolume calls.
-	// This field is optional, and may be empty if no secret is required. If the
+	// This field is optional, and  may be empty if no secret is required. If the
 	// secret object contains more than one secret, all secrets are passed.
 	// +optional
 	NodePublishSecretRef *SecretReference `json:"nodePublishSecretRef,omitempty" protobuf:"bytes,8,opt,name=nodePublishSecretRef"`
@@ -1702,7 +1672,7 @@ type ContainerPort struct {
 	// Number of port to expose on the pod's IP address.
 	// This must be a valid port number, 0 < x < 65536.
 	ContainerPort int32 `json:"containerPort" protobuf:"varint,3,opt,name=containerPort"`
-	// Protocol for port. Must be UDP, TCP, or SCTP.
+	// Protocol for port. Must be UDP or TCP.
 	// Defaults to "TCP".
 	// +optional
 	Protocol Protocol `json:"protocol,omitempty" protobuf:"bytes,4,opt,name=protocol,casttype=Protocol"`
@@ -2084,9 +2054,6 @@ type Container struct {
 	// +optional
 	// +patchMergeKey=containerPort
 	// +patchStrategy=merge
-	// +listType=map
-	// +listMapKey=containerPort
-	// +listMapKey=protocol
 	Ports []ContainerPort `json:"ports,omitempty" patchStrategy:"merge" patchMergeKey:"containerPort" protobuf:"bytes,6,rep,name=ports"`
 	// List of sources to populate environment variables in the container.
 	// The keys defined within a source must be a C_IDENTIFIER. All invalid keys
@@ -2104,7 +2071,7 @@ type Container struct {
 	Env []EnvVar `json:"env,omitempty" patchStrategy:"merge" patchMergeKey:"name" protobuf:"bytes,7,rep,name=env"`
 	// Compute Resources required by this container.
 	// Cannot be updated.
-	// More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
+	// More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
 	// +optional
 	Resources ResourceRequirements `json:"resources,omitempty" protobuf:"bytes,8,opt,name=resources"`
 	// Pod volumes to mount into the container's filesystem.
@@ -2114,7 +2081,7 @@ type Container struct {
 	// +patchStrategy=merge
 	VolumeMounts []VolumeMount `json:"volumeMounts,omitempty" patchStrategy:"merge" patchMergeKey:"mountPath" protobuf:"bytes,9,rep,name=volumeMounts"`
 	// volumeDevices is the list of block devices to be used by the container.
-	// This is a beta feature.
+	// This is an alpha feature and may change in the future.
 	// +patchMergeKey=devicePath
 	// +patchStrategy=merge
 	// +optional
@@ -2843,7 +2810,7 @@ type PodSpec struct {
 	// in the same pod, and the first process in each container will not be assigned PID 1.
 	// HostPID and ShareProcessNamespace cannot both be set.
 	// Optional: Default to false.
-	// This field is beta-level and may be disabled with the PodShareProcessNamespace feature.
+	// This field is alpha-level and is honored only by servers that enable the PodShareProcessNamespace feature.
 	// +k8s:conversion-gen=false
 	// +optional
 	ShareProcessNamespace *bool `json:"shareProcessNamespace,omitempty" protobuf:"varint,27,opt,name=shareProcessNamespace"`
@@ -2910,25 +2877,8 @@ type PodSpec struct {
 	// More info: https://github.com/kubernetes/community/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md
 	// +optional
 	ReadinessGates []PodReadinessGate `json:"readinessGates,omitempty" protobuf:"bytes,28,opt,name=readinessGates"`
-	// RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used
-	// to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run.
-	// If unset or empty, the "legacy" RuntimeClass will be used, which is an implicit class with an
-	// empty definition that uses the default runtime handler.
-	// More info: https://github.com/kubernetes/community/blob/master/keps/sig-node/0014-runtime-class.md
-	// This is an alpha feature and may change in the future.
-	// +optional
-	RuntimeClassName *string `json:"runtimeClassName,omitempty" protobuf:"bytes,29,opt,name=runtimeClassName"`
-	// EnableServiceLinks indicates whether information about services should be injected into pod's
-	// environment variables, matching the syntax of Docker links.
-	// +optional
-	EnableServiceLinks *bool `json:"enableServiceLinks,omitempty" protobuf:"varint,30,opt,name=enableServiceLinks"`
 }
 
-const (
-	// The default value for enableServiceLinks attribute.
-	DefaultEnableServiceLinks = true
-)
-
 // HostAlias holds the mapping between IP and hostnames that will be injected as an entry in the
 // pod's hosts file.
 type HostAlias struct {
@@ -3309,8 +3259,8 @@ type ReplicationControllerCondition struct {
 }
 
 // +genclient
-// +genclient:method=GetScale,verb=get,subresource=scale,result=k8s.io/api/autoscaling/v1.Scale
-// +genclient:method=UpdateScale,verb=update,subresource=scale,input=k8s.io/api/autoscaling/v1.Scale,result=k8s.io/api/autoscaling/v1.Scale
+// +genclient:method=GetScale,verb=get,subresource=scale,result=k8s.io/api/extensions/v1beta1.Scale
+// +genclient:method=UpdateScale,verb=update,subresource=scale,input=k8s.io/api/extensions/v1beta1.Scale,result=k8s.io/api/extensions/v1beta1.Scale
 // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
 
 // ReplicationController represents the configuration of a replication controller.
@@ -3567,7 +3517,7 @@ type ServicePort struct {
 	// +optional
 	Name string `json:"name,omitempty" protobuf:"bytes,1,opt,name=name"`
 
-	// The IP protocol for this port. Supports "TCP", "UDP", and "SCTP".
+	// The IP protocol for this port. Supports "TCP" and "UDP".
 	// Default is TCP.
 	// +optional
 	Protocol Protocol `json:"protocol,omitempty" protobuf:"bytes,2,opt,name=protocol,casttype=Protocol"`
@@ -3781,7 +3731,7 @@ type EndpointPort struct {
 	Port int32 `json:"port" protobuf:"varint,2,opt,name=port"`
 
 	// The IP protocol for this port.
-	// Must be UDP, TCP, or SCTP.
+	// Must be UDP or TCP.
 	// Default is TCP.
 	// +optional
 	Protocol Protocol `json:"protocol,omitempty" protobuf:"bytes,3,opt,name=protocol,casttype=Protocol"`
@@ -4528,20 +4478,6 @@ type LocalObjectReference struct {
 	Name string `json:"name,omitempty" protobuf:"bytes,1,opt,name=name"`
 }
 
-// TypedLocalObjectReference contains enough information to let you locate the
-// typed referenced object inside the same namespace.
-type TypedLocalObjectReference struct {
-	// APIGroup is the group for the resource being referenced.
-	// If APIGroup is not specified, the specified Kind must be in the core API group.
-	// For any other third-party types, APIGroup is required.
-	// +optional
-	APIGroup *string `json:"apiGroup" protobuf:"bytes,1,opt,name=apiGroup"`
-	// Kind is the type of resource being referenced
-	Kind string `json:"kind" protobuf:"bytes,2,opt,name=kind"`
-	// Name is the name of resource being referenced
-	Name string `json:"name" protobuf:"bytes,3,opt,name=name"`
-}
-
 // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
 
 // SerializedReference is a reference to serialized object.
@@ -5023,10 +4959,6 @@ const (
 	TLSCertKey = "tls.crt"
 	// TLSPrivateKeyKey is the key for the private key field in a TLS secret.
 	TLSPrivateKeyKey = "tls.key"
-	// SecretTypeBootstrapToken is used during the automated bootstrap process (first
-	// implemented by kubeadm). It stores tokens that are used to sign well known
-	// ConfigMaps. They are used for authn.
-	SecretTypeBootstrapToken SecretType = "bootstrap.kubernetes.io/token"
 )
 
 // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
@@ -5245,28 +5177,8 @@ type SecurityContext struct {
 	// 2) has CAP_SYS_ADMIN
 	// +optional
 	AllowPrivilegeEscalation *bool `json:"allowPrivilegeEscalation,omitempty" protobuf:"varint,7,opt,name=allowPrivilegeEscalation"`
-	// procMount denotes the type of proc mount to use for the containers.
-	// The default is DefaultProcMount which uses the container runtime defaults for
-	// readonly paths and masked paths.
-	// This requires the ProcMountType feature flag to be enabled.
-	// +optional
-	ProcMount *ProcMountType `json:"procMount,omitempty" protobuf:"bytes,9,opt,name=procMount"`
 }
 
-type ProcMountType string
-
-const (
-	// DefaultProcMount uses the container runtime defaults for readonly and masked
-	// paths for /proc.  Most container runtimes mask certain paths in /proc to avoid
-	// accidental security exposure of special devices or information.
-	DefaultProcMount ProcMountType = "Default"
-
-	// UnmaskedProcMount bypasses the default masking behavior of the container
-	// runtime and ensures the newly created /proc the container stays in tact with
-	// no modifications.
-	UnmaskedProcMount ProcMountType = "Unmasked"
-)
-
 // SELinuxOptions are the labels to be applied to the container
 type SELinuxOptions struct {
 	// User is a SELinux user label that applies to the container.
-- 
2.19.1

